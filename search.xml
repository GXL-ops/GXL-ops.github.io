<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>LeetCode442</title>
      <link href="/2022/05/08/leetcode/mei-ri-yi-ti/leetcode442/"/>
      <url>/2022/05/08/leetcode/mei-ri-yi-ti/leetcode442/</url>
      
        <content type="html"><![CDATA[<h1><span id="442-数组中重复的数据">442. 数组中重复的数据</span></h1><blockquote><ol><li>数组中重复的数据：<a href="https://leetcode-cn.com/problems/find-all-duplicates-in-an-array/">https://leetcode-cn.com/problems/find-all-duplicates-in-an-array/</a></li></ol></blockquote><h2><span id="题目">题目</span></h2><p>给你一个长度为 <code>n</code> 的整数数组 <code>nums</code> ，其中 <code>nums</code> 的所有整数都在范围 <code>[1, n]</code> 内，且每个整数出现一次或两次 。请你找出所有出现两次的整数，并以数组形式返回。</p><p><strong>注意：</strong>你必须设计并实现一个时间复杂度为 O(n) 且仅使用常量额外空间的算法解决此问题。</p><h2><span id="示例">示例</span></h2><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">示例 1：</span><br><span class="line">输入：nums = [4,3,2,7,8,2,3,1]</span><br><span class="line">输出：[2,3]</span><br><span class="line"></span><br><span class="line">示例 2：</span><br><span class="line">输入：nums = [1,1,2]</span><br><span class="line">输出：[1]</span><br><span class="line"></span><br><span class="line">示例 3：</span><br><span class="line">输入：nums = [1]</span><br><span class="line">输出：[]</span><br></pre></td></tr></tbody></table></figure><h2><span id="解题思路">解题思路</span></h2><p>因为题目要求必须使用常量额外空间的算法来解决问题，所以只能在原数组上进行修改，才能达到额外空间为常量。使用替换的方式对原数组进行位置调整，每个元素放在自己的位置（index+1=num）上</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">findDuplicates</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        res, n = [], <span class="built_in">len</span>(nums)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            <span class="keyword">while</span> <span class="number">1</span> &lt;= nums[i] &lt;= n <span class="keyword">and</span> nums[i] != nums[nums[i] - <span class="number">1</span>]:</span><br><span class="line">                nums[nums[i] - <span class="number">1</span>], nums[i] = nums[i], nums[nums[i] - <span class="number">1</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            <span class="keyword">if</span> nums[i] != i + <span class="number">1</span>:</span><br><span class="line">                res.append(nums[i])</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> 难度-中等 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeetCode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习面经</title>
      <link href="/2022/05/07/ji-qi-xue-xi-mian-jing/"/>
      <url>/2022/05/07/ji-qi-xue-xi-mian-jing/</url>
      
        <content type="html"><![CDATA[<h1><span id="机器学习面经">机器学习面经</span></h1><h2><span id="1-分类问题">1. 分类问题</span></h2><h3><span id="11-交叉熵公式">1.1 交叉熵公式</span></h3><p>交叉熵：设p(x)、q(x)是X中取值的两个概率分布，则p对q的相对熵是：</p><script type="math/tex; mode=display">D(p||q)=\sum_xp(x)\log\frac{p(x)}{q(x)}=E_{p(x)}\log\frac{p(x)}{q(x)}</script><h3><span id="12-lr公式">1.2 LR公式</span></h3><h4><span id="121-公式推到">1.2.1 公式推到</span></h4><h4><span id="122-损失函数">1.2.2 损失函数</span></h4><h3><span id="13-逻辑回归怎么实现多分类">1.3 逻辑回归怎么实现多分类</span></h3><ol><li>方式一：修改逻辑回归的损失函数，使用softmax函数构造模型解决多分类问题，softmax分类模型会有相同于类别数的输出，输出的值为对于样本属于各个类别的概率，最后对于样本进行预测的类型为概率值最高的那个类别。</li><li>方式一：根据每个类别都建立一个二分类器，本类别的样本标签定义为0,其它分类样本标签定义为1,则有多少个类别就构造多少个逻辑回归分类器</li></ol><p>若所有类别之间有明显的互斥则使用softmax分类器，若所有类别不互斥有交叉的情况则构造相应类别个数的逻辑回归分类器。 </p><h3><span id="14-svm中什么时候用线性核什么时候用高斯核">1.4 SVM中什么时候用线性核什么时候用高斯核?</span></h3><ol><li>当数据的特征提取的较好，所包含的信息量足够大，很多问题是线性可分的那么可以采用线性核。</li><li>若特征数较少,样本数适中，对于时间不敏感，遇到的问题是线性不可分的时候可以使用高斯核来达到更好的效果。</li></ol><h3><span id="15-什么是支持向量机svm与lr的区别">1.5 什么是支持向量机,SVM与LR的区别?</span></h3><p>支持向量机为一个二分类模型，它的基本模型定义为特征空间上的间隔最大的线性分类器。而它的学习策略为最大化分类间隔，最终可转化为凸二次规划问题求解。</p><ol><li>LR是参数模型，SVM为非参数模型。</li><li>LR采用的损失函数为logistical loss，而SVM采用的是hinge loss。</li><li>在学习分类器的时候，SVM只考虑与分类最相关的少数支持向量点。LR的模型相对简单,在进行大规模线性分类时比较方便。</li></ol><h3><span id="16-监督学习和无监督学习的区别">1.6 监督学习和无监督学习的区别</span></h3><p>输入的数据有标签则为监督学习，输入数据无标签为非监督学习。</p><h3><span id="17-机器学习中的距离计算方法">1.7 机器学习中的距离计算方法?</span></h3><p>两点 $(x_1,y_1),(x_2,y_2)$</p><ol><li><p>欧式距离</p><script type="math/tex; mode=display">\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}</script></li><li><p>哈曼顿距离</p><script type="math/tex; mode=display">|X1-X2|+|Y1-Y2|</script></li><li><p>余弦距离</p><script type="math/tex; mode=display">cos=\frac{x_1*x_2+y_1*y_2}{\sqrt{x_1^2+y_1^2}\sqrt{x_2^2+y_2^2}}</script></li><li><p>切比雪夫距离</p><script type="math/tex; mode=display">max(|x_i−y_i|)</script></li></ol><h3><span id="18-朴素贝叶斯naive-bayes法的要求是">1.8 朴素贝叶斯（naive Bayes）法的要求是？</span></h3><p>贝叶斯定理、特征条件独立假设</p><p>解析：朴素贝叶斯属于生成式模型，学习输入和输出的联合概率分布。给定输入x，利用贝叶斯概率定理求出最大的后验概率作为输出y。</p><p>？？？需要弄明白</p><h3><span id="19-训练集中类别不均衡哪个参数最不准确">1.9 训练集中类别不均衡，哪个参数最不准确？</span></h3><p>准确度（Accuracy）</p><p>解析：举例，对于二分类问题来说，正负样例比相差较大为99:1，模型更容易被训练成预测较大占比的类别。因为模型只需要对每个样例按照0.99的概率预测正类，该模型就能达到99%的准确率。</p><h3><span id="110-bi-lstm的优点以及与rnn和lstm的对比">1.10 Bi-LSTM的优点以及与rnn和lstm的对比</span></h3><p>所谓的Bi-LSTM以及Bi-RNN，可以看成是两层神经网络：</p><ol><li>第一层从左边作为系列的起始输入，在文本处理上可以理解成从句子的开头开始输入；</li><li>而第二层则是从右边作为系列的起始输入，在文本处理上可以理解成从句子的最后一个词语作为输入，反向做与第一层一样的处理处理。</li><li>最后对得到的两个结果进行处理。</li></ol><h3><span id="111-svm的作用基本实现原理">1.11 SVM的作用，基本实现原理</span></h3><p>SVM可以用于解决二分类或者多分类问题，此处以二分类为例。SVM的目标是寻找一个最优化超平面在空间中分割两类数据，这个最优化超平面需要满足的条件是：离其最近的点到其的距离最大化，这些点被称为支持向量。</p><p>解析：建议练习推导SVM，从基本式的推导，到拉格朗日对偶问题。</p><p>？？？</p><h3><span id="112-如果数据有问题怎么处理">1.12 如果数据有问题，怎么处理；</span></h3><ol><li>上下采样平衡正负样例比；</li><li>考虑缺失值；</li><li>数据归一化</li></ol><h3><span id="113-如果给你一些数据集你会如何分类">1.13 如果给你一些数据集，你会如何分类</span></h3><ol><li>数据的大小；</li><li>特征；</li><li>是否缺失；</li></ol><p>根据数据类型选择不同的模型，如Lr或者SVM，决策树。假如特征维数较多，可以选择SVM模型，如果样本数量较大可以选择LR模型，但是LR模型需要进行数据预处理；假如缺失值较多可以选择决策树。</p><h3><span id="114-svm的物理意义是什么">1.14 SVM的物理意义是什么</span></h3><p>构造一个最优化的超平面在空间中分割数据</p><h3><span id="115-svm使用对偶计算的目的是什么如何推出来的手写推导损失函数">1.15 SVM使用对偶计算的目的是什么，如何推出来的，手写推导，损失函数</span></h3><p>目的有两个：</p><ol><li>一是方便核函数的引入；</li><li>二是原问题的求解复杂度与特征的维数相关，而转成对偶问题后只与问题的变量个数有关。</li></ol><p>由于SVM的变量个数为支持向量的个数，相较于特征位数较少，因此转对偶问题。通过拉格朗日算子发使带约束的优化目标转为不带约束的优化函数，使得W和b的偏导数等于零，带入原来的式子，再通过转成对偶问题。</p><h3><span id="116-分层抽样的适用范围">1.16 分层抽样的适用范围</span></h3><p>分层抽样利用事先掌握的信息，充分考虑了保持样本结构和总体结构的一致性，当总体由差异明显的几部分组成的时候，适合用分层抽样。</p><h3><span id="117-lr和线性回归的区别">1.17 LR和线性回归的区别</span></h3><ol><li>线性回归用来做预测，LR用来做分类。</li><li>线性回归是来拟合函数，LR是来预测函数。</li><li>线性回归用最小二乘法来计算参数，LR用最大似然估计来计算参数。</li><li>线性回归更容易受到异常值的影响，而LR对异常值有较好的稳定性。</li></ol><h3><span id="118-生成模型和判别模型基本形式有哪些">1.18 生成模型和判别模型基本形式，有哪些？</span></h3><p>生成式：朴素贝叶斯、HMM、Gaussians、马尔科夫随机场</p><p>判别式：LR，SVM，神经网络，CRF，Boosting</p><p>详情：支持向量机</p><h3><span id="119-核函数的种类和应用场景">1.19 核函数的种类和应用场景</span></h3><p>线性核、多项式核、高斯核。</p><ol><li>特征维数高选择线性核</li><li>样本数量可观、特征少选择高斯核（非线性核）</li><li>样本数量非常多选择线性核（避免造成庞大的计算量）</li></ol><p>详情：支持向量机</p><h3><span id="120-分类算法列一下有多少种应用场景">1.20 分类算法列一下有多少种？应用场景</span></h3><p>单一的分类方法主要包括：</p><ul><li>LR逻辑回归</li><li>SVM支持向量机</li><li>DT决策树</li><li>NB朴素贝叶斯</li><li>NN人工神经网络</li><li>K-近邻</li></ul><p>集成学习算法：</p><ul><li>基于Bagging和Boosting算法思想，</li><li>RF随机森林,</li><li>GBDT，</li><li>Adaboost,</li><li>XGboost。</li></ul><h3><span id="121-核函数的作用">1.21 核函数的作用</span></h3><p>核函数隐含着一个从低维空间到高维空间的映射,这个映射可以把低维空间中线性不可分的两类点变成线性可分的。</p><h3><span id="122-id3c45和cart三种决策树的区别">1.22 ID3,C4.5和CART三种决策树的区别</span></h3><ol><li>ID3决策树优先选择<strong>信息增益</strong>大的属性来对样本进行划分，但是这样的分裂节点方法有一个很大的缺点，当一个属性可取值数目较多时，可能在这个属性对应值下的样本只有一个或者很少个，此时它的信息增益将很高，ID3会认为这个属性很适合划分，但实际情况下叫多属性的取值会使模型的泛化能力较差；</li><li>所以C4.5不采用信息增益作为划分依据，而是采用<strong>信息增益率</strong>作为划分依据。但是仍不能完全解决以上问题，而是有所改善；</li><li>这个时候引入了CART树，它使用<strong>gini系数</strong>作为节点的分裂依据。</li></ol><h3><span id="123-svm和全部数据有关还是和局部数据有关">1.23 SVM和全部数据有关还是和局部数据有关?</span></h3><p>SVM只和分类界限上的支持向量点有关,换而言之只和局部数据有关。</p><h3><span id="124-为什么高斯核能够拟合无穷维度">1.24 为什么高斯核能够拟合无穷维度</span></h3><p>因为将泰勒展开式代入高斯核,将会得到一个无穷维度的映射。</p><h3><span id="125-朴素贝叶斯基本原理和预测过程">1.25 朴素贝叶斯基本原理和预测过程</span></h3><p>朴素贝叶斯分类和预测算法的原理</p><p>决策树和朴素贝叶斯是最常用的两种分类算法，本篇文章介绍朴素贝叶斯算法。贝叶斯定理是以英国数学家贝叶斯命名，用来解决两个条件概率之间的关系问题。简单的说就是在已知 P(A|B) 时如何获得 P(B|A) 的概率。朴素贝叶斯（Naive Bayes）假设特征 P(A) 在特定结果 P(B) 下是独立的。</p><p>1.概率基础：</p><p>在开始介绍贝叶斯之前，先简单介绍下概率的基础知识。概率是某一结果出现的可能性。例如，抛一枚匀质硬币，正面向上的可能性多大？概率值是一个0-1之间的数字，用来衡量一个事件发生可能性的大小。概率值越接近1，事件发生的可能性越大，概率值越接近0，事件越不可能发生。我们日常生活中听到最多的是天气预报中的降水概率。概率的表示方法叫维恩图。下面我们通过维恩图来说明贝叶斯公式中常见的几个概率。</p><h2><span id="2-时间序列">2. 时间序列</span></h2><h3><span id="21-对应时间序列的数据集如何进行交叉验证">2.1 对应时间序列的数据集如何进行交叉验证？</span></h3><ol><li>传统的交叉验证由于假定样本独立同分布，因此随机打乱分为训练集和验证集。</li><li>但是对于时间序列来讲，需要考虑序列间的时间依赖。</li><li>分为K份，每次取前 $1,2,…,K-1$ 份作为训练集，第 $2,3,…,K$ 份作为测试集即可。</li></ol><h2><span id="3-数据预处理">3. 数据预处理</span></h2><h3><span id="31-正负样本不平衡的解决办法评价指标的参考价值">3.1 正负样本不平衡的解决办法？评价指标的参考价值？</span></h3><ol><li>上采样：</li><li>下采样</li></ol><p>好的指标：ROC 和 AUC、F值、G-Mean；不好的指标：Precision、Recall</p><h2><span id="4-迁移学习">4. 迁移学习</span></h2><p>迁移学习就是把之前训练好的模型直接拿来用，可以充分利用之前数据信息，而且能够避免自己实验数据量较小等问题。简单来讲就是给模型做初始化，初始化的数据来自于训练好的模型。</p><h2><span id="5-生成模型和判别模型的区别">5. 生成模型和判别模型的区别</span></h2><p>监督学习的任务：学习一个模型，应用这一模型，对给定的输入预测相应的输出。这一模型的一般形式为一个决策函数或者条件概率分布：</p><ol><li>决策函数<script type="math/tex; mode=display">y=f(x)</script></li></ol><ol><li><p>条件概率分布</p><script type="math/tex; mode=display">P(y|x)</script><p>预测时用 最大后验概率 $(MAP)y = argmax_{yi}P(y_i|x)$ 的方法决定输出类别 y 。（例如贝叶斯分类器）</p></li><li><p>生成模型：</p><p><em>源头导向</em>。尝试去找到底这个数据是怎么产生的，然后再对一个信号进行分类。基于你学习到的生成假设，判断哪个类别最有可能产生这个信号，这个样本就属于那个类别。</p><ol><li>先由数据学习联合概率分布 $P(x,y)$ 和先验概率分布 $P(x)$，然后求出条件概率分布 $P(y|x)=P(x,y)/P(x)$ 作为预测的模型，即得到生成模型:<script type="math/tex; mode=display">P(y|x)=\frac{P(x,y)}{P(x)}</script></li></ol></li></ol><ol><li><p>特点</p><ol><li>反映同类数据本身的相似度</li><li>生成方法能还原出联合概率分布，而判别方法不能</li><li>生成方法的学习收敛速度更快、即当样本容量增加的时候，学到的模型可以更快地收敛于真实模型</li><li>当存在隐变量时，仍可以用生成方法学习，此时判别方法不能用</li></ol></li><li><p>典型的生成模型</p><ol><li>朴素贝叶斯分类器</li><li>马尔科夫模型</li><li>高斯混合模型</li></ol></li></ol><ol><li><p>判别模型</p><p><em>结果导向</em>。并不关心样本数据是怎么生成的，它只关心样本之间的差别，然后用差别来简单对给定的一个样本进行分类。</p><ol><li>判别方法由数据直接学习决策函数 $f(x)$ 或者条件概率分布 $P(y|x)$ 作为预测的。判别模型利用正负例和分类标签，关注在判别模型的边缘分布。判别方法强调的是：对给定的输入 x，应该预测什么样的输出 y 。</li><li>特点：<ol><li>判别方法寻找不同类别之间的最优分类面，反映的是异类数据之间的差异</li><li>直接学习的是条件概率P(Y|X)或者决策函数f(X)，直接面对预测，往往学习的准确率更高；</li><li>由于直接学习条件概率P(Y|X)或者决策函数f(X)，可以对数据进行各种程度上的抽象、定义特征并使用特征，因此可以简化学习问题。</li><li>缺点是不能反映训练数据本身的特性</li></ol></li><li>典型的判别模型<ul><li>k近邻法</li><li>感知机</li><li>决策树</li><li>logistic回归</li><li>最大熵模型</li><li>SVM</li><li>boosting方法</li><li>条件随机场</li></ul></li></ol></li></ol><h2><span id="6-监督学习和非监督学习的区别">6. 监督学习和非监督学习的区别</span></h2><ol><li>数据上区分：训练数据中是否有标签，监督学习的数据既有特征又有标签，而非监督学习的数据中只有特征而没有标签。</li><li>监督学习是通过训练让机器自己找到特征和标签之间的联系，监督学习可以分为两大类：回归分析和分类，二者之间的区别在于回归分析针对的是连续数据，而分类针对的是离散数据。<ol><li><strong>监督学习方法又可以分为</strong>生成方法(generative approach)<strong>和</strong>判别方法(discriminative approach)<strong>。所学到的模型分别为</strong>生成模型(generative model)<strong>和</strong>判别模型(discriminative model)**。</li></ol></li><li>非监督学习由于训练数据中只有特征没有标签，所以就需要自己对数据进行聚类分析，然后就可以通过聚类的方式从数据中提取一个特殊的结构。<ol><li>由于没有标准的分类方法，有可能从数据中挖出启发与亮点。</li></ol></li><li>半监督学习的训练数据中有一部分是有标签的，另一部分是没有标签的，而没标签的数据量远远大于有标签的数据量。</li></ol><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>深度学习面经</title>
      <link href="/2022/05/07/shen-du-xue-xi-mian-jing/"/>
      <url>/2022/05/07/shen-du-xue-xi-mian-jing/</url>
      
        <content type="html"><![CDATA[<h1><span id="深度学习面经">深度学习面经</span></h1><h2><span id="1-batchnormalization的作用">1. BatchNormalization的作用</span></h2><p>为何：</p><ol><li>神经网络在训练的时候随着网络层数的加深，激活函数的输入值的整体分布逐渐往激活函数的取值区间上下限靠近，从而导致在反向传播时低层的神经网络的梯度消失。</li><li>而BatchNormalization的作用是通过规范化的手段，将越来越偏的分布拉回到标准化的分布，使得激活函数的输入值落在激活函数对输入比较敏感的区域，从而使梯度变大，加快学习收敛速度，避免梯度消失的问题。</li></ol><p>优势：</p><ul><li>批量归一化会固定小批量中的均值和方差，然后学习出适合的偏移和缩放</li><li>能够加速收敛速度，但是一般不改变模型的精度。</li></ul><h3><span id="11-bn层的作用为什么要在后面加伽马和贝塔不加可以吗">1.1 BN层的作用，为什么要在后面加伽马和贝塔，不加可以吗</span></h3><p>BN层的作用是把一个batch内的所有数据，从不规范的分布拉到正态分布。这样做的好处是使得数据能够分布在激活函数的敏感区域，敏感区域即为梯度较大的区域，因此在反向传播的时候能够较快反馈误差传播。</p><p>批量归一化没有起到优化作用，可以通过这两个参数进行抵消。</p><h2><span id="2-梯度消失">2. 梯度消失</span></h2><p><strong>说法一：</strong>本质是由于链式法则的乘法特性导致的，对于Sigmoid，导数的最大值在输入为0处，值为0.25.考虑一个激活函数都是Sigmoid的多层神经网络，则梯度向后传导时，没经过一个Sigmoid就需要乘以一个小于0.25的梯度。而每乘以一个小于0.25的梯度，则梯度的值又变得更小一些。况且在优化的过程中，每个激活层输入都在0附近的概率非常的低。也就是说随着层数的加深，梯度的衰减会非常的大，迅速接近0，这就是梯度消失的现象。</p><p><strong>说法二：</strong>在神经网络中，当前面隐藏层的学习速率低于后面隐藏层的学习速率，即随着隐藏层数目的增加，分类准确率反而下降了。这种现象叫做消失的梯度问题。</p><p><strong>说法三：</strong>激活函数在计算 $\prod_{i = t}^{d-1}\frac{\delta h^{i+1}}{\delta h^{i}}=\prod_{i=t}^{d-1}diag(\sigma’(W^ih^{i-1}))(W^i)^T$ 的一些元素会来自于 $\prod_{i = t}^{d-1}(W^i)^T$。如果 d-t 很大（即网络层数很深），假设激活函数使用sigmoid时，每次乘以一个很小的值，结果趋近于0，呈现梯度消失。</p><p>解决思路：</p><ul><li><p>用ReLU代替Sigmoid；</p><ul><li>可以发现，relu函数的导数在正数部分，是等于1的，因此就可以避免梯度消失的问题。</li><li>但是负数部分的导数等于0，这样意味着，只要在链式法则中某一个 zj小于0，那么这个神经元的梯度就是0，不会更新。</li><li>解决办法：<ul><li><strong>【leakyReLU】</strong>：在ReLU的负数部分，增加了一定的斜率，解决了ReLU中会有死神经元的问题。</li><li>跟 LeakyReLU 一样是为了解决死神经元问题，但是增加的斜率不是固定的：</li></ul></li></ul></li><li><p>用BN层；</p><ul><li>BN层提出来的本质就是为了<strong>解决反向传播中的梯度问题</strong>。</li></ul></li><li><p>用残差结构解决梯度消失问题。</p><ul><li>残差结构，就是让深层网络通过走捷径，让网络不那么深层。这样梯度消失的问题就缓解了。</li></ul></li></ul><h2><span id="3-梯度爆炸">3. 梯度爆炸</span></h2><p>梯度爆炸的表现：</p><ol><li>在深度多层感知机网络中，梯度爆炸会导致网络不稳定，最好的结果是无法从训练数据中学习，</li><li>由于权重值为NaN而无法更新权重。</li><li>模型无法在训练数据上收敛（比如，损失函数值非常差，波动大）；</li></ol><p>去和确定梯度爆炸：</p><ol><li>模型在训练过程中，权重变化非常大；</li><li>模型在训练过程中，权重变成NaN值；</li><li>每层的每个节点在训练时，其误差梯度值一直是大于1.0；</li></ol><p>解决思路：</p><ol><li><strong>重新设计网络模型</strong>：<ol><li>将网络模型的层数变少来解决；</li><li>使用较小批量也有一些好处；</li><li>在循环神经网络中，训练时使用较小时间步长更新；</li></ol></li><li><strong>使用修正线性激活函数</strong>：<ol><li>使用修正线性激活函数（ReLU）能够减少梯度爆炸发生的概率；</li></ol></li><li><strong>使用长短周期记忆网络</strong>：<ol><li>通过使用长短期记忆单元（LSTM）或相关的门控神经结构能够减少梯度爆炸发生的概率。</li></ol></li><li><strong>使用梯度裁剪</strong>：<ol><li>在深度多层感知网络中，当有大批量数据以及LSTM是用于很长时间序列时，梯度爆炸仍然会发生。当梯度爆炸发生时，可以在网络训练时检查并限制梯度的大小，这被称作梯度裁剪。</li><li>梯度剪裁，若误差梯度值超过设定的阈值，则截断或设置为阈值。</li></ol></li><li><strong>使用权重正则化</strong>：<ol><li>如果梯度爆炸问题仍然发生，另外一个方法是对网络权重的大小进行校验，并对大权重的损失函数增添一项惩罚项，这也被称作权重正则化，常用的有L1（权重的绝对值和）正则化与L2（权重的绝对值平方和再开方）正则化。</li></ol></li></ol><h2><span id="4-循环神经网络为什么好">4. 循环神经网络，为什么好?</span></h2><p>循环神经网络模型（RNN）是一种节点定向连接成环的人工神经网络，是一种反馈神经网络，RNN利用内部的记忆来处理任意时序的输入序列。使得RNN可以更加容易处理不分段的文本等</p><h2><span id="5-什么是group-convolution">5. 什么是Group Convolution</span></h2><p>若卷积神将网络的上一层有N个卷积核，则对应的通道数也为N。设群数目为M，在进行卷积操作的时候，将通道分成M份，每个group对应N/M个通道，然后每个group卷积完成后输出叠在一起，作为当前层的输出通道。</p><h2><span id="6-什么是rnn">6. 什么是RNN</span></h2><p>一个序列当前的输出与前面的输出也有关，在RNN网络结构中，隐藏层的输入不仅包括输入层的输出还包含上一时刻隐藏层的输出，网络会对之前的信息进行记忆并应用于当前的输入计算中。</p><h2><span id="7-训练过程中若一个模型不收敛那么是否说明这个模型无效导致模型不收敛的原因有哪些">7. 训练过程中，若一个模型不收敛，那么是否说明这个模型无效？导致模型不收敛的原因有哪些？</span></h2><ol><li>并不能说明这个模型无效，有可能是因为数据的问题。导致模型不收敛的原因可能有数据分类的标注不准确，数据样本量太少，样本的信息量太大导致模型不足以fit整个样本空间。</li><li>学习率设置的太大容易产生震荡，太小会导致不收敛。</li><li>可能复杂的分类任务用了简单的模型。</li><li>数据没有进行归一化的操作。<ol><li>提高模型精度；</li><li>加快收敛速度</li></ol></li></ol><h2><span id="8-vgg使用33卷积核的优势是什么">8. VGG使用3*3卷积核的优势是什么?</span></h2><ol><li>2个<code>3*3</code>的卷积核串联和<code>5*5</code>的卷积核有相同的感知野，前者拥有更少的参数。</li><li>多个<code>3*3</code>的卷积核比一个较大尺寸的卷积核有更多层的非线性函数，增加了非线性表达，提取的特征更加具有优势。</li></ol><h2><span id="9-图像处理中锐化和平滑的操作">9. 图像处理中锐化和平滑的操作</span></h2><ol><li>锐化就是通过增强高频分量来减少图像中的模糊，在增强图像边缘的同时也增加了图像的噪声。</li><li>平滑与锐化相反，过滤掉高频分量，减少图像的噪声是图片变得模糊。</li></ol><h2><span id="10-激活函数">10. 激活函数</span></h2><p>激活函数是用来加入非线性因素的，提高神经网络对模型的表达能力，解决线性模型所不能解决的问题。</p><h3><span id="101-relu比sigmoid的效果好在哪里">10.1 Relu比Sigmoid的效果好在哪里?</span></h3><ol><li>Sigmoid的导数只有在0的附近时有较好的激活性，而在正负饱和区域的梯度趋向于0，易产生提取消失。</li><li>而relu在大于0的部分梯度为常数，所以不会有梯度弥散现象。</li><li>Relu的导数计算的更快。</li><li>Relu在负半区的导数为0,所以神经元激活值为负时,梯度为0,此神经元不参与训练,具有稀疏性。</li></ol><h2><span id="11-神经网络中权重共享的是">11. 神经网络中权重共享的是？</span></h2><p>卷积神经网络、循环神经网络。解析：通过网络结构直接解释</p><h2><span id="12-神经网络激活函数">12. 神经网络激活函数？</span></h2><p>sigmod、tanh、relu</p><p>解析：需要掌握函数图像，特点，互相比较，优缺点以及改进方法</p><h2><span id="13-在深度学习中通常会finetuning已有的成熟模型再基于新数据修改最后几层神经网络权值为什么">13. 在深度学习中，通常会finetuning已有的成熟模型，再基于新数据，修改最后几层神经网络权值，为什么？</span></h2><p>实践中的数据集质量参差不齐，可以使用训练好的网络来进行提取特征。把训练好的网络当做特征提取器。</p><h2><span id="14-画gru-lstm-rnn结构图">14. 画GRU、LSTM、RNN结构图</span></h2><p>先画图，写公式，再说区别</p><p>区别：</p><ol><li>RNN在处理long term memory的时候存在缺陷，因此LSTM应运而生。</li><li>LSTM是一种变种的RNN，它的精髓在于引入了细胞状态这样一个概念，不同于RNN只考虑最近的状态，LSTM的细胞状态会决定哪些状态应该被留下来，哪些状态应该被遗忘。</li></ol><p>RNN</p><p><img src="http://xiaomanzhan.com.cn/content/311436_1552882148264_F085D21D1BB5554A2B17E0B4905A207A" alt="img"></p><p>LSTM</p><p><img src="http://xiaomanzhan.com.cn/content/311436_1552882134531_88F162FE8ECCDD9CB2F430E751687AF3" alt="img"></p><h3><span id="141-lstm-与-gru-结构的区别">14.1 LSTM 与 GRU 结构的区别</span></h3><ol><li>GRU和LSTM的性能在很多任务上不分伯仲。</li><li>GRU 参数更少因此更容易收敛，但是数据集很大的情况下，LSTM表达性能更好。</li><li>从结构上来说，GRU只有两个门（update和reset），LSTM有三个门（forget，input，output），GRU直接将hidden state 传给下一个单元，而LSTM则用memory cell 把hidden state 包装起来。</li></ol><h3><span id="142-rnn容易梯度消失怎么解决">14.2 RNN容易梯度消失，怎么解决？</span></h3><p>1）、梯度裁剪（Clipping Gradient）</p><p>既然在BP过程中会产生梯度消失（就是偏导无限接近0，导致长时记忆无法更新），那么最简单粗暴的方法，设定阈值，当梯度小于阈值时，更新的梯度为阈值。</p><p>优点：简单粗暴</p><p>缺点：很难找到满意的阈值</p><p>2）、LSTM（Long Short-Term Memory）</p><p>增加三个门和记忆单元进行处理，能够很大程度上保存梯度信息，防止梯度消失，同时模型能够自动学习更新参数。</p><h2><span id="15-attention机制的作用">15. Attention机制的作用</span></h2><p>注意力机制的本质就是定位到感兴趣的信息，抑制无用信息，结果通常都是以概率图或者概率特征向量的形式展示。让系统更加容易的找到输入的数据中与当前输出信息相关的有用信息，从而提高输出的质量。</p><h2><span id="16-lstm和gru的原理">16. Lstm和Gru的原理</span></h2><p>Lstm由输入门、遗忘门、输出门和一个cell组成。</p><ol><li>第一步是决定从cell状态中丢弃什么信息；</li><li>然后在决定有多少新的信息进入到cell状态中；</li><li>最终基于目前的cell状态决定输出什么样的信息。</li></ol><p>GRU由重置门和更新门组成，其输入为前一时刻隐藏层的输出和当前的输入，输出为下一时刻隐藏层的信息。</p><ol><li>重置门用来计算候选隐藏层的输出，其作用是控制保留多少前一时刻的隐藏层。</li><li>更新门的作用是控制加入多少候选隐藏层的输出信息，从而得到当前隐藏层的输出。</li></ol><h2><span id="17-什么是dropoutdropconnect">17. 什么是dropout，DropConnect</span></h2><p>dropout：在神经网络的训练过程中，对于神经单元按一定的概率将其随机从网络中丢弃，迫使网络在每个训练步骤中适应不同的连接，从而达到对于每个mini-batch都是在训练不同网络的效果，防止过拟合。</p><p>DropConnect：</p><ol><li>是为了提高 Deep Network 的泛化能力的，两者都号称是对 Dropout (Dropout简单理解)的改进。</li><li>DropConnect 的思想也很简单，与Dropout不同的是，它不是随机将隐含层节点的输出清0，而是将节点中的每个与其相连的输入权值以1-p的概率清0。（一个是输出，一个是输入）（这里需要注意的是，dropconnect对输入权重进行置0不是真的把权重w变成0，只是在计算上让它等于0而已。。。后续权重还是保持和上一轮一样的。。）</li></ol><p><img src="http://xiaomanzhan.com.cn/content/v2-514b53d46fcf34cafd55b27f207884ec_720w.jpg" alt="img"></p><h2><span id="18-防止过拟合">18. 防止过拟合</span></h2><ul><li>提前终止（当验证集上的效果变差的时候）</li><li>L1和L2正则化加权</li><li>soft weight sharing，权重共享有利于防止过拟合</li><li>dropout</li><li>BatchNormalization ；</li><li>网络bagging</li></ul><h2><span id="19-深度学习了解多少有看过底层代码吗">19. 深度学习了解多少，有看过底层代码吗</span></h2><h2><span id="20-adam">20. Adam</span></h2><p>Adam 算法和传统的随机梯度下降不同。随机梯度下降保持单一的学习率（即 alpha）更新所有的权重，学习率在训练过程中并不会改变。而 Adam 通过计算梯度的 <strong>一阶矩估计</strong> 和 <strong>二阶矩估计</strong> 而为不同的参数设计独立的自适应性学习率。</p><h2><span id="21-attention机制">21. attention机制</span></h2><p>Attention简单理解就是权重分配，以seq2seq中的attention公式作为讲解。就是对输入的每个词分配一个权重，权重的计算方式为与解码端的隐含层时刻作比较，得到的权重的意义就是权重越大，该词越重要。最终加权求和。</p><p><img src="http://xiaomanzhan.com.cn/content/311436_1552881536175_D404B240266A897C983A190746BE361D" alt="img"></p><h2><span id="22-rnn梯度消失问题为什么lstm和gru可以解决此问题">22. RNN梯度消失问题，为什么LSTM和GRU可以解决此问题</span></h2><ol><li>RNN由于网络较深，后面层的输出误差很难影响到前面层的计算，RNN的某一单元主要受它附近单元的影响。</li><li>而LSTM因为可以通过阀门记忆一些长期的信息，相应的也就保留了更多的梯度。</li><li>而GRU也可通过重置和更新两个阀门保留长期的记忆，也相对解决了梯度消失的问题。</li></ol><h2><span id="23-gan网络的思想">23. GAN网络的思想</span></h2><ol><li>GAN用一个生成模型和一个判别模型，判别模型用于判断给定的图片是不是真实的图片，生成模型自己生成一张图片和想要的图片很像；</li><li>开始时两个模型都没有训练；</li><li>然后两个模型一起进行对抗训练；</li><li>生成模型产生图片去欺骗判别模型，判别模型去判别真假，最终两个模型在训练过程中，能力越来越强最终达到稳态。</li></ol><h2><span id="24-11的卷积作用">24. 1*1的卷积作用</span></h2><p>实现跨通道的交互和信息整合，实现卷积核通道数的降维和升维，可以实现多个feature map的线性组合，而且可是实现与全连接层的等价效果。</p><h2><span id="25-怎么提升网络的泛化能力">25. 怎么提升网络的泛化能力</span></h2><ol><li>数据上：<ol><li>收集更多的数据；</li><li>对数据做缩放和变换；</li><li>特征组合和重新定义问题。</li></ol></li><li>算法调优上：<ol><li>权重的初始化，用小的随机数初始化权重。</li><li>对学习率进行调节；</li><li>尝试选择合适的激活函数；</li><li>调整网络的拓扑结构；</li><li>调节batch和epoch的大小；</li><li>添加正则化的方法；</li><li>尝试使用其它的优化方法,使用early stopping。</li></ol></li></ol><h2><span id="26-卷积层和池化层有什么区别">26. 卷积层和池化层有什么区别</span></h2><div class="table-container"><table><thead><tr><th></th><th>卷积层</th><th>池化层</th></tr></thead><tbody><tr><td>功能</td><td>提取特征</td><td>压缩特征图，提取主要特征</td></tr><tr><td>操作</td><td>可惜是二维的，对于三维数据比如RGB图像（3通道），卷积核的深度必须同输入的通道数，输出的通道数等于卷积核的个数。</td><td>池化只是在二维数据上操作的，因此不改变输入的通道数。对于多通道的输入，这一点和卷积区别很大。</td></tr><tr><td>特性</td><td>权值共享：减少了参数的数量，并利用了图像目标的位置无关性。</td></tr></tbody></table></div><h2><span id="27-图像检测算法了解">27. 图像检测算法了解</span></h2><h2><span id="28什么是seq2seq-model">28.什么是seq2seq model</span></h2><p>Seq2seq属于encoder-decoder结构的一种，利用两个RNN，一个作为encoder一个作为decoder。Encoder负责将输入序列压缩成指定长度的向量，这个向量可以看作这段序列的语义，而decoder负责根据语义向量生成指定的序列。</p><h2><span id="29-神经网络为啥用交叉熵">29. 神经网络为啥用交叉熵</span></h2><p>通过神经网络解决多分类问题时使用，最常用的一种方式就是在最后一层设置n个输出节点，即分类任务的目标数为n。假设最后的节点数为N，那么对于每一个样例，神经网络可以得到一个N维的数组作为输出结果，数组中每一个维度会对应一个类别。在最理想的情况下，如果一个样本属于k，那么这个类别所对应的的输出节点的输出值应该为1，而其他节点的输出都为0，即[0,0,1,0,….0,0]，这个数组也就是样本的Label，是神经网络最期望的输出结果，交叉熵就是用来判定实际的输出与期望的输出的接近程度。</p><h3><span id="291-计算公式">29.1 计算公式</span></h3><p>？？？</p><h2><span id="30-注意力公式">30. 注意力公式</span></h2><p>Soft attention、global attention、动态attention、Hard attention、静态attention、“半软半硬”的attention （local attention）、强制前向attention</p><script type="math/tex; mode=display">Attention(Query, Source)=\sum^{L_x}_{i=1}\alpha_i\cdot Value_i</script><h2><span id="31-lenet-alexnet-vgg-resnet架构区别">31. LeNet、AlexNet、VGG、ResNet架构区别</span></h2><h2><span id="32-dnn的梯度更新方式">32. DNN的梯度更新方式</span></h2><ol><li>批量梯度下降法BGD：<ol><li>批量梯度下降法（Batch Gradient Descent，简称BGD）是梯度下降法最原始的形式，它的具体思路是在更新每一参数时都使用所有的样本来进行更新</li></ol></li><li>随机梯度下降法SGD<ol><li>由于批量梯度下降法在更新每一个参数时，都需要所有的训练样本，所以训练过程会随着样本数量的加大而变得异常的缓慢。随机梯度下降法（Stochastic Gradient Descent，简称SGD）正是为了解决批量梯度下降法这一弊端而提出的。</li></ol></li><li>小批量梯度下降法MBGD<ol><li>有上述的两种梯度下降法可以看出，其各自均有优缺点，那么能不能在两种方法的性能之间取得一个折衷呢？即，算法的训练过程比较快，而且也要保证最终参数训练的准确率，而这正是小批量梯度下降法（Mini-batch Gradient Descent，简称MBGD）的初衷。</li></ol></li></ol><h2><span id="33-cnn为什么比dnn在图像识别上更好">33. CNN为什么比DNN在图像识别上更好</span></h2><ol><li>DNN的输入是向量形式，并未考虑到平面的结构信息，在图像和NLP领域这一结构信息尤为重要，例如识别图像中的数字，同一数字与所在位置无关（换句话说任一位置的权重都应相同）；</li><li>CNN的输入可以是tensor，例如二维矩阵，通过filter获得局部特征，较好的保留了平面结构信息。</li></ol><h2><span id="34-使用的-cnn-模型权重之间有关联吗">34. 使用的 CNN 模型权重之间有关联吗？</span></h2><p>权重之间有关联。CNN是权重共享，减少了参数的数量。每个卷积核对图像进行特征提取，就会得到一个Feature Map。</p><h2><span id="35-用过哪些-optimizer效果如何">35. 用过哪些 Optimizer，效果如何</span></h2><p>1）SGD；2）Momentum；3）Nesterov；4）Adagrad；5）Adadelta；6）RMSprop；7）Adam；8）Adamax；9）Nadam。</p><p>（1）对于稀疏数据，尽量使用学习率可自适应的算法，不用手动调节，而且最好采用默认参数。（2）SGD通常训练时间最长，但是在好的初始化和学习率调度方案下，结果往往更可靠。但SGD容易困在鞍点，这个缺点也不能忽略。（3）如果在意收敛的速度，并且需要训练比较深比较复杂的网络时，推荐使用学习率自适应的优化方法。（4）Adagrad，Adadelta和RMSprop是比较相近的算法，表现都差不多。（5）在能使用带动量的RMSprop或者Adam的地方，使用Nadam往往能取得更好的效果。</p><h2><span id="36-图像基础传统图像处理方法知道哪些图像对比度增强说一下">36. 图像基础：传统图像处理方法知道哪些，图像对比度增强说一下</span></h2><p>数字图像处理常用方法：</p><ol><li>图像变换；</li><li>图像编码压缩；</li><li>图像增强和复原；</li><li>图像分割；</li><li>图像描述；</li><li>图像分类（识别）</li></ol><p>全局对比度增强</p><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Attention Is All You Need</title>
      <link href="/2022/05/07/paper/attention-is-all-you-need/"/>
      <url>/2022/05/07/paper/attention-is-all-you-need/</url>
      
        <content type="html"><![CDATA[<h1><span id="attention-is-all-you-need">Attention Is All You Need</span></h1><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> paper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Transformer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode433</title>
      <link href="/2022/05/07/leetcode/mei-ri-yi-ti/leetcode433/"/>
      <url>/2022/05/07/leetcode/mei-ri-yi-ti/leetcode433/</url>
      
        <content type="html"><![CDATA[<h1><span id="433-最小基因变化">433. 最小基因变化</span></h1><blockquote><ol><li>最小基因变化：<a href="https://leetcode-cn.com/problems/minimum-genetic-mutation/">https://leetcode-cn.com/problems/minimum-genetic-mutation/</a></li></ol></blockquote><h2><span id="题目">题目</span></h2><p>基因序列可以表示为一条由 8 个字符组成的字符串，其中每个字符都是 ‘A’、’C’、’G’ 和 ‘T’ 之一。假设我们需要调查从基因序列 start 变为 end 所发生的基因变化。一次基因变化就意味着这个基因序列中的一个字符发生了变化。</p><ul><li>例如，”AACCGGTT” —&gt; “AACCGGTA” 就是一次基因变化。</li></ul><p>另有一个基因库 bank 记录了所有有效的基因变化，只有基因库中的基因才是有效的基因序列。</p><p>给你两个基因序列 start 和 end ，以及一个基因库 bank ，请你找出并返回能够使 start 变化为 end 所需的最少变化次数。如果无法完成此基因变化，返回 -1 。</p><p>注意：起始基因序列 start 默认是有效的，但是它并不一定会出现在基因库中。</p><h2><span id="示例">示例</span></h2><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">示例 1：</span><br><span class="line">输入：start = "AACCGGTT", end = "AACCGGTA", bank = ["AACCGGTA"]</span><br><span class="line">输出：1</span><br><span class="line"></span><br><span class="line">示例 2：</span><br><span class="line">输入：start = "AACCGGTT", end = "AAACGGTA", bank = ["AACCGGTA","AACCGCTA","AAACGGTA"]</span><br><span class="line">输出：2</span><br><span class="line"></span><br><span class="line">示例 3：</span><br><span class="line">输入：start = "AAAAACCC", end = "AACCCCCC", bank = ["AAAACCCC","AAACCCCC","AACCCCCC"]</span><br><span class="line">输出：3</span><br></pre></td></tr></tbody></table></figure><h2><span id="解题思路">解题思路</span></h2><p>深度优先搜索的想法，每次针对当前字符串进行遍历修改，在基因库中查找符合条件的修改结果，找到之后进入下一层，注意隐藏条件：基因库中的基因最多在修改结果中出现一次</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">minMutation</span>(<span class="params">self, start: <span class="built_in">str</span>, end: <span class="built_in">str</span>, bank: <span class="type">List</span>[<span class="built_in">str</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="keyword">if</span> end <span class="keyword">not</span> <span class="keyword">in</span> bank:</span><br><span class="line">            <span class="keyword">return</span> -<span class="number">1</span></span><br><span class="line">        steps, bank_list = [], [<span class="literal">True</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(bank))]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">dfs</span>(<span class="params">curr_str: <span class="built_in">str</span>, step: <span class="built_in">int</span></span>):</span><br><span class="line">            <span class="keyword">nonlocal</span> steps</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(curr_str)):</span><br><span class="line">                curr_ch = curr_str[i]</span><br><span class="line">                <span class="keyword">for</span> ch <span class="keyword">in</span> [<span class="string">'A'</span>, <span class="string">'C'</span>, <span class="string">'G'</span>, <span class="string">'T'</span>]:</span><br><span class="line">                    <span class="keyword">if</span> ch != curr_ch:</span><br><span class="line">                        curr_str = curr_str[:i] + ch + curr_str[i + <span class="number">1</span>:]</span><br><span class="line">                        <span class="keyword">if</span> curr_str <span class="keyword">in</span> bank <span class="keyword">and</span> bank_list[bank.index(curr_str)]:</span><br><span class="line">                            <span class="keyword">if</span> curr_str == end:</span><br><span class="line">                                steps.append(step + <span class="number">1</span>)</span><br><span class="line">                            bank_list[bank.index(curr_str)] = <span class="literal">False</span></span><br><span class="line">                            dfs(curr_str, step + <span class="number">1</span>)</span><br><span class="line">                            bank_list[bank.index(curr_str)] = <span class="literal">True</span></span><br><span class="line">                curr_str = curr_str[:i] + curr_ch + curr_str[i + <span class="number">1</span>:]</span><br><span class="line"></span><br><span class="line">        dfs(start, <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">min</span>(steps) <span class="keyword">if</span> <span class="built_in">len</span>(steps) &gt; <span class="number">0</span> <span class="keyword">else</span> -<span class="number">1</span></span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> 难度-中等 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeetCode </tag>
            
            <tag> 深度优先搜索 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode933</title>
      <link href="/2022/05/06/leetcode/mei-ri-yi-ti/leetcode933/"/>
      <url>/2022/05/06/leetcode/mei-ri-yi-ti/leetcode933/</url>
      
        <content type="html"><![CDATA[<h1><span id="933-最近的请求次数">933. 最近的请求次数</span></h1><blockquote><ol><li>最近的请求次数：<a href="https://leetcode-cn.com/problems/number-of-recent-calls/">https://leetcode-cn.com/problems/number-of-recent-calls/</a></li></ol></blockquote><h2><span id="题目">题目</span></h2><p>写一个 <code>RecentCounter</code> 类来计算特定时间范围内最近的请求。</p><p>请你实现 <code>RecentCounter</code> 类：</p><ul><li><code>RecentCounter()</code> 初始化计数器，请求数为 0 。</li><li><code>int ping(int t)</code> 在时间 <code>t</code> 添加一个新请求，其中 <code>t</code> 表示以毫秒为单位的某个时间，并返回过去 <code>3000</code> 毫秒内发生的所有请求数（包括新请求）。确切地说，返回在 <code>[t-3000, t]</code> 内发生的请求数。保证每次对 <code>ping</code> 的调用都使用比之前更大的 t 值。</li></ul><h2><span id="示例">示例</span></h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">输入：</span><br><span class="line">[<span class="string">"RecentCounter"</span>, <span class="string">"ping"</span>, <span class="string">"ping"</span>, <span class="string">"ping"</span>, <span class="string">"ping"</span>]</span><br><span class="line">[[], [<span class="number">1</span>], [<span class="number">100</span>], [<span class="number">3001</span>], [<span class="number">3002</span>]]</span><br><span class="line">输出：</span><br><span class="line">[null, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">解释：</span><br><span class="line">RecentCounter recentCounter = new RecentCounter();</span><br><span class="line">recentCounter.ping(<span class="number">1</span>);     // requests = [<span class="number">1</span>]，范围是 [-<span class="number">2999</span>,<span class="number">1</span>]，返回 <span class="number">1</span></span><br><span class="line">recentCounter.ping(<span class="number">100</span>);   // requests = [<span class="number">1</span>, <span class="number">100</span>]，范围是 [-<span class="number">2900</span>,<span class="number">100</span>]，返回 <span class="number">2</span></span><br><span class="line">recentCounter.ping(<span class="number">3001</span>);  // requests = [<span class="number">1</span>, <span class="number">100</span>, <span class="number">3001</span>]，范围是 [<span class="number">1</span>,<span class="number">3001</span>]，返回 <span class="number">3</span></span><br><span class="line">recentCounter.ping(<span class="number">3002</span>);  // requests = [<span class="number">1</span>, <span class="number">100</span>, <span class="number">3001</span>, <span class="number">3002</span>]，范围是 [<span class="number">2</span>,<span class="number">3002</span>]，返回 <span class="number">3</span></span><br></pre></td></tr></tbody></table></figure><h2><span id="解题思路">解题思路</span></h2><p>使用一个队列来维护 <code>3000</code> 毫秒范围内发生的请求，每次来新的请求的时候进行更新</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RecentCounter</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.ping_list = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">ping</span>(<span class="params">self, t: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="keyword">while</span> self.ping_list <span class="keyword">and</span> (t - <span class="number">3000</span>) &gt; self.ping_list[<span class="number">0</span>]:</span><br><span class="line">            self.ping_list.pop(<span class="number">0</span>)</span><br><span class="line">        self.ping_list.append(t)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.ping_list)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Your RecentCounter object will be instantiated and called as such:</span></span><br><span class="line"><span class="comment"># obj = RecentCounter()</span></span><br><span class="line"><span class="comment"># param_1 = obj.ping(t)</span></span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> 难度-简单 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeetCode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode713</title>
      <link href="/2022/05/05/leetcode/mei-ri-yi-ti/leetcode713/"/>
      <url>/2022/05/05/leetcode/mei-ri-yi-ti/leetcode713/</url>
      
        <content type="html"><![CDATA[<h1><span id="713-乘积小于-k-的子数组">713. 乘积小于 K 的子数组</span></h1><blockquote><ol><li>乘积小于 K 的子数组：<a href="https://leetcode-cn.com/problems/subarray-product-less-than-k/">https://leetcode-cn.com/problems/subarray-product-less-than-k/</a></li></ol></blockquote><h2><span id="题目">题目</span></h2><p>给你一个整数数组 <code>nums</code> 和一个整数 <code>k</code> ，请你返回子数组内所有元素的乘积严格小于 <code>k</code> 的连续子数组的数目。</p><h2><span id="示例">示例</span></h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">示例 <span class="number">1</span>：</span><br><span class="line">输入：nums = [<span class="number">10</span>,<span class="number">5</span>,<span class="number">2</span>,<span class="number">6</span>], k = <span class="number">100</span></span><br><span class="line">输出：<span class="number">8</span></span><br><span class="line">解释：<span class="number">8</span> 个乘积小于 <span class="number">100</span> 的子数组分别为：[<span class="number">10</span>]、[<span class="number">5</span>]、[<span class="number">2</span>],、[<span class="number">6</span>]、[<span class="number">10</span>,<span class="number">5</span>]、[<span class="number">5</span>,<span class="number">2</span>]、[<span class="number">2</span>,<span class="number">6</span>]、[<span class="number">5</span>,<span class="number">2</span>,<span class="number">6</span>]。</span><br><span class="line">需要注意的是 [<span class="number">10</span>,<span class="number">5</span>,<span class="number">2</span>] 并不是乘积小于 <span class="number">100</span> 的子数组。</span><br><span class="line"></span><br><span class="line">示例 <span class="number">2</span>：</span><br><span class="line">输入：nums = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>], k = <span class="number">0</span></span><br><span class="line">输出：<span class="number">0</span></span><br></pre></td></tr></tbody></table></figure><h2><span id="解题思路">解题思路</span></h2><p>使用双指针的思路，前追后赶。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">numSubarrayProductLessThanK</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], k: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        ans, prod, i = <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> j, num <span class="keyword">in</span> <span class="built_in">enumerate</span>(nums):</span><br><span class="line">            prod *= num</span><br><span class="line">            <span class="keyword">while</span> i &lt;= j <span class="keyword">and</span> prod &gt;= k:</span><br><span class="line">                prod //= nums[i]</span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">            ans += j - i + <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> 难度-中等 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeetCode </tag>
            
            <tag> 双指针 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode1823</title>
      <link href="/2022/05/04/leetcode/mei-ri-yi-ti/leetcode1823/"/>
      <url>/2022/05/04/leetcode/mei-ri-yi-ti/leetcode1823/</url>
      
        <content type="html"><![CDATA[<h1><span id="1823-找出游戏的获胜者">1823. 找出游戏的获胜者</span></h1><blockquote><ol><li>找出游戏的获胜者：<a href="https://leetcode-cn.com/problems/find-the-winner-of-the-circular-game/">https://leetcode-cn.com/problems/find-the-winner-of-the-circular-game/</a></li></ol></blockquote><h2><span id="题目">题目</span></h2><p>共有 <code>n</code> 名小伙伴一起做游戏。小伙伴们围成一圈，按顺时针顺序从 <code>1</code> 到 <code>n</code> 编号。确切地说，从第 <code>i</code> 名小伙伴顺时针移动一位会到达第 (<code>i+1</code>) 名小伙伴的位置，其中 <code>1 &lt;= i &lt; n</code> ，从第 <code>n</code> 名小伙伴顺时针移动一位会回到第 <code>1</code> 名小伙伴的位置。</p><p>游戏遵循如下规则：</p><ol><li><p>从第 <code>1</code> 名小伙伴所在位置 开始 。</p></li><li><p>沿着顺时针方向数 <code>k</code> 名小伙伴，计数时需要 包含 起始时的那位小伙伴。逐个绕圈进行计数，一些小伙伴可能会被数过不止一次。</p></li><li><p>你数到的最后一名小伙伴需要离开圈子，并视作输掉游戏。</p></li><li><p>如果圈子中仍然有不止一名小伙伴，从刚刚输掉的小伙伴的顺时针下一位小伙伴开始，回到步骤 <code>2</code> 继续执行。</p></li><li><p>否则，圈子中最后一名小伙伴赢得游戏。</p></li></ol><p>给你参与游戏的小伙伴总数 <code>n</code> ，和一个整数 <code>k</code> ，返回游戏的获胜者。</p><p><img src="http://xiaomanzhan.com.cn/content/ic234-q2-ex11.png" alt="img"></p><h2><span id="示例">示例</span></h2><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">示例 1：</span><br><span class="line">输入：n = 5, k = 2</span><br><span class="line">输出：3</span><br><span class="line">解释：游戏运行步骤如下：</span><br><span class="line">1) 从小伙伴 1 开始。</span><br><span class="line">2) 顺时针数 2 名小伙伴，也就是小伙伴 1 和 2 。</span><br><span class="line">3) 小伙伴 2 离开圈子。下一次从小伙伴 3 开始。</span><br><span class="line">4) 顺时针数 2 名小伙伴，也就是小伙伴 3 和 4 。</span><br><span class="line">5) 小伙伴 4 离开圈子。下一次从小伙伴 5 开始。</span><br><span class="line">6) 顺时针数 2 名小伙伴，也就是小伙伴 5 和 1 。</span><br><span class="line">7) 小伙伴 1 离开圈子。下一次从小伙伴 3 开始。</span><br><span class="line">8) 顺时针数 2 名小伙伴，也就是小伙伴 3 和 5 。</span><br><span class="line">9) 小伙伴 5 离开圈子。只剩下小伙伴 3 。所以小伙伴 3 是游戏的获胜者。</span><br><span class="line"></span><br><span class="line">示例 2：</span><br><span class="line">输入：n = 6, k = 5</span><br><span class="line">输出：1</span><br><span class="line">解释：小伙伴离开圈子的顺序：5、4、6、2、3 。小伙伴 1 是游戏的获胜者。</span><br></pre></td></tr></tbody></table></figure><h2><span id="解题思路">解题思路</span></h2><p>约瑟夫环问题是这样的：</p><p>$0,1,…,n−1$ 这 n 个数字排成一个圆圈，从数字 0 开始，每次从这个圆圈里删除第 m 个数字。求出这个圆圈里剩下的最后一个数字。</p><p>如图所示：</p><p><img src="http://xiaomanzhan.com.cn/content/1.png" alt="1"></p><p>根据上图中的箭头，我们可以看到每一轮中移走的是第 m 个数字（因为数组下标是从 0 开始，所以被移走的数字下标为 m - 1）。<br>所以每一轮的第 m + 1 个数字（下标为 m），将成为下一轮的开头元素（下标变成 0）。</p><p>解决约瑟夫环问题，我们采用倒推，我们倒推出：最后剩下的这个数字，在最开始的数组中的位置。</p><ol><li>剩下最后一个数字（简称“它”）的时候，总个数为 1，它的下标 $pos = 0$。</li><li>那么它在上一轮也是安全的，总个数为 2，它的下标 $pos = (0 + m) \% 2$； （解释：在上一轮中，它前面的数字（即红色的数字，下标为 $m - 1$）被移走了；因此它的下标是 m；由于是环，因此需要 $\% 2$）</li><li>那么它在上上轮也是安全的，总个数为 3，它的下标 $pos = ((0 + m) \% 2 + m) \% 3$；</li><li>那么它在上上上轮也是安全的，总个数为 4，它的下标 $pos = (((0 + m) \% 2 + m) \% 3 + m) \% 4$；</li><li>…</li><li>那么它在游戏开始的第一轮也是安全的，总个数为 n，它的下标 pos 就是所求。</li></ol><p>即如果从下向上反推的时候：假如它下一轮的下标为 pos，那么当前轮次的下标就是： $(pos + m) \%$ 当前轮次的人数。    </p><h3><span id="题解">题解</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">findTheWinner</span>(<span class="params">self, n: <span class="built_in">int</span>, k: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        pos = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, n + <span class="number">1</span>):</span><br><span class="line">            pos = (pos + k) % i</span><br><span class="line">        <span class="keyword">return</span> pos + <span class="number">1</span></span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> 难度-中等 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeetCode </tag>
            
            <tag> 约瑟夫环 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode937</title>
      <link href="/2022/05/03/leetcode/mei-ri-yi-ti/leetcode937/"/>
      <url>/2022/05/03/leetcode/mei-ri-yi-ti/leetcode937/</url>
      
        <content type="html"><![CDATA[<h1><span id="937-重新排列日志文件">937. 重新排列日志文件</span></h1><blockquote><ol><li>重新排列日志文件：<a href="https://leetcode-cn.com/problems/reorder-data-in-log-files/">https://leetcode-cn.com/problems/reorder-data-in-log-files/</a></li></ol></blockquote><h2><span id="题目">题目</span></h2><p>给你一个日志数组 <code>logs</code>。每条日志都是以空格分隔的字串，其第一个字为字母与数字混合的 <strong>标识符</strong> 。</p><p>有两种不同类型的日志：</p><ul><li><strong>字母日志</strong>：除标识符之外，所有字均由小写字母组成</li><li><strong>数字日志</strong>：除标识符之外，所有字均由数字组成</li></ul><p>请按下述规则将日志重新排序：</p><ul><li>所有 <strong>字母日志</strong> 都排在 数字日志 之前。</li><li><strong>字母日志</strong> 在内容不同时，忽略标识符后，按内容字母顺序排序；在内容相同时，按标识符排序。</li><li><strong>数字日志</strong> 应该保留原来的相对顺序。</li></ul><p>返回日志的最终顺序。</p><h2><span id="示例">示例</span></h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">示例 <span class="number">1</span>：</span><br><span class="line">输入：logs = [<span class="string">"dig1 8 1 5 1"</span>,<span class="string">"let1 art can"</span>,<span class="string">"dig2 3 6"</span>,<span class="string">"let2 own kit dig"</span>,<span class="string">"let3 art zero"</span>]</span><br><span class="line">输出：[<span class="string">"let1 art can"</span>,<span class="string">"let3 art zero"</span>,<span class="string">"let2 own kit dig"</span>,<span class="string">"dig1 8 1 5 1"</span>,<span class="string">"dig2 3 6"</span>]</span><br><span class="line">解释：</span><br><span class="line">字母日志的内容都不同，所以顺序为 <span class="string">"art can"</span>, <span class="string">"art zero"</span>, <span class="string">"own kit dig"</span> 。</span><br><span class="line">数字日志保留原来的相对顺序 <span class="string">"dig1 8 1 5 1"</span>, <span class="string">"dig2 3 6"</span> 。</span><br><span class="line"></span><br><span class="line">示例 <span class="number">2</span>：</span><br><span class="line">输入：logs = [<span class="string">"a1 9 2 3 1"</span>,<span class="string">"g1 act car"</span>,<span class="string">"zo4 4 7"</span>,<span class="string">"ab1 off key dog"</span>,<span class="string">"a8 act zoo"</span>]</span><br><span class="line">输出：[<span class="string">"g1 act car"</span>,<span class="string">"a8 act zoo"</span>,<span class="string">"ab1 off key dog"</span>,<span class="string">"a1 9 2 3 1"</span>,<span class="string">"zo4 4 7"</span>]</span><br></pre></td></tr></tbody></table></figure><h2><span id="解题思路">解题思路</span></h2><p>使用list排序的方法，key通过自己构建的方法得到，实现最终的排序——自定义排序</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reorderLogFiles</span>(<span class="params">self, logs: <span class="type">List</span>[<span class="built_in">str</span>]</span>) -&gt; <span class="type">List</span>[<span class="built_in">str</span>]:</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">trans</span>(<span class="params">log: <span class="built_in">str</span></span>) -&gt; <span class="built_in">tuple</span>:</span><br><span class="line">            a, b = log.split(<span class="string">' '</span>, <span class="number">1</span>)</span><br><span class="line">            <span class="keyword">return</span> (<span class="number">0</span>, b, a) <span class="keyword">if</span> b[<span class="number">0</span>].isalpha <span class="keyword">else</span> (<span class="number">1</span>,)</span><br><span class="line">        logs.sort(key=trans)</span><br><span class="line">        <span class="keyword">return</span> logs</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> 难度-简单 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeetCode </tag>
            
            <tag> 自定义排序 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>文本预处理</title>
      <link href="/2022/05/02/machine-learning/xun-huan-shen-jing-wang-luo/2.wen-ben-yu-chu-li/"/>
      <url>/2022/05/02/machine-learning/xun-huan-shen-jing-wang-luo/2.wen-ben-yu-chu-li/</url>
      
        <content type="html"><![CDATA[<h1><span id="文本预处理">文本预处理</span></h1><h2><span id="1-加载数据">1. 加载数据</span></h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 文本预处理</span></span><br><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将数据集读取到由多条文本行组成的列表中，一种简单的预处理</span></span><br><span class="line">d2l.DATA_HUB[<span class="string">'time_machine'</span>] = (</span><br><span class="line">    d2l.DATA_URL + <span class="string">'timemachine.txt'</span>,</span><br><span class="line">    <span class="string">'090b5e7e70c295757f55df93cb0a180b9691891a'</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">read_time_machine</span>():  </span><br><span class="line">    <span class="string">"""Load the time machine dataset into a list of text lines."""</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(d2l.download(<span class="string">'time_machine'</span>), <span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        lines = f.readlines()</span><br><span class="line">    <span class="comment"># 将非大小写字母全部变成空格，变小写</span></span><br><span class="line">    <span class="keyword">return</span> [re.sub(<span class="string">'[^A-Za-z]+'</span>, <span class="string">' '</span>, line).strip().lower() <span class="keyword">for</span> line <span class="keyword">in</span> lines]</span><br><span class="line"></span><br><span class="line">lines = read_time_machine()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f'# text lines: <span class="subst">{<span class="built_in">len</span>(lines)}</span>'</span>)</span><br><span class="line"><span class="built_in">print</span>(lines[<span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(lines[<span class="number">10</span>])</span><br></pre></td></tr></tbody></table></figure><p>输出如下：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># text lines: 3221</span><br><span class="line">the time machine by h g wells</span><br><span class="line">twinkled and his usually pale face was flushed and animated the</span><br></pre></td></tr></tbody></table></figure><h2><span id="2-文本拆成序列标记">2.  文本拆成序列标记</span></h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将每个文本序列拆分为一个标记列表</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">tokenize</span>(<span class="params">lines, token=<span class="string">'word'</span></span>):</span><br><span class="line">    <span class="string">"""将文本行拆分为单词或字符标记"""</span></span><br><span class="line">    <span class="keyword">if</span> token == <span class="string">"word"</span>:</span><br><span class="line">        <span class="keyword">return</span> [line.split() <span class="keyword">for</span> line <span class="keyword">in</span> lines]</span><br><span class="line">    <span class="keyword">elif</span> token ==<span class="string">'char'</span>:</span><br><span class="line">        <span class="keyword">return</span> [<span class="built_in">list</span>(line) <span class="keyword">for</span> line <span class="keyword">in</span> lines]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">"错误：未知令牌类型： "</span> + token)</span><br><span class="line"></span><br><span class="line">tokens = tokenize(lines)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">11</span>):</span><br><span class="line">    <span class="built_in">print</span>(tokens[i])</span><br></pre></td></tr></tbody></table></figure><p>输出如下：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">['the', 'time', 'machine', 'by', 'h', 'g', 'wells']</span><br><span class="line">[]</span><br><span class="line">[]</span><br><span class="line">[]</span><br><span class="line">[]</span><br><span class="line">['i']</span><br><span class="line">[]</span><br><span class="line">[]</span><br><span class="line">['the', 'time', 'traveller', 'for', 'so', 'it', 'will', 'be', 'convenient', 'to', 'speak', 'of', 'him']</span><br><span class="line">['was', 'expounding', 'a', 'recondite', 'matter', 'to', 'us', 'his', 'grey', 'eyes', 'shone', 'and']</span><br><span class="line">['twinkled', 'and', 'his', 'usually', 'pale', 'face', 'was', 'flushed', 'and', 'animated', 'the']</span><br></pre></td></tr></tbody></table></figure><h2><span id="3-构建词汇表">3. 构建词汇表</span></h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构建一个字典，通常也叫做词汇表（vocabulary），</span></span><br><span class="line"><span class="comment"># 用来将字符串类型的标记映射到从0开始的数字索引中</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Vocab</span>:</span><br><span class="line">    <span class="string">"""文本词汇表"""</span></span><br><span class="line">    <span class="comment"># min_freq：文本中出现次数小于min_freq的词丢掉，当做不认识</span></span><br><span class="line">    <span class="comment"># reserved_tokens：句子开始结束的token</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, tokens=<span class="literal">None</span>, min_freq=<span class="number">0</span>, reserved_tokens=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="keyword">if</span> tokens <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            tokens = []</span><br><span class="line">        <span class="keyword">if</span> reserved_tokens <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            reserved_tokens = []</span><br><span class="line">        counter = count_corpus(tokens)</span><br><span class="line">        self.token_freqs = <span class="built_in">sorted</span>(counter.items(), key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>],</span><br><span class="line">                                  reverse=<span class="literal">True</span>)</span><br><span class="line">        self.unk, uniq_tokens = <span class="number">0</span>, [<span class="string">'&lt;unk&gt;'</span>] + reserved_tokens</span><br><span class="line">        uniq_tokens += [</span><br><span class="line">            token <span class="keyword">for</span> token, freq <span class="keyword">in</span> self.token_freqs</span><br><span class="line">            <span class="keyword">if</span> freq &gt;= min_freq <span class="keyword">and</span> token <span class="keyword">not</span> <span class="keyword">in</span> uniq_tokens]</span><br><span class="line">        self.idx_to_token, self.token_to_idx = [], <span class="built_in">dict</span>()</span><br><span class="line">        <span class="keyword">for</span> token <span class="keyword">in</span> uniq_tokens:</span><br><span class="line">            self.idx_to_token.append(token)</span><br><span class="line">            self.token_to_idx[token] = <span class="built_in">len</span>(self.idx_to_token) - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.idx_to_token)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, tokens</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(tokens, (<span class="built_in">list</span>, <span class="built_in">tuple</span>)):</span><br><span class="line">            <span class="keyword">return</span> self.token_to_idx.get(tokens, self.unk)</span><br><span class="line">        <span class="keyword">return</span> [self.__getitem__(token) <span class="keyword">for</span> token <span class="keyword">in</span> tokens]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">to_tokens</span>(<span class="params">self, indices</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(indices, (<span class="built_in">list</span>, <span class="built_in">tuple</span>)):</span><br><span class="line">            <span class="keyword">return</span> self.idx_to_token[indices]</span><br><span class="line">        <span class="keyword">return</span> [self.idx_to_token[index] <span class="keyword">for</span> index <span class="keyword">in</span> indices]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">count_corpus</span>(<span class="params">tokens</span>):  </span><br><span class="line">    <span class="string">"""统计标记的频率。"""</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(tokens) == <span class="number">0</span> <span class="keyword">or</span> <span class="built_in">isinstance</span>(tokens[<span class="number">0</span>], <span class="built_in">list</span>):</span><br><span class="line">        tokens = [token <span class="keyword">for</span> line <span class="keyword">in</span> tokens <span class="keyword">for</span> token <span class="keyword">in</span> line]</span><br><span class="line">    <span class="keyword">return</span> collections.Counter(tokens)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建词汇表</span></span><br><span class="line">vocab = Vocab(tokens)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">list</span>(vocab.token_to_idx.items())[:<span class="number">10</span>])</span><br></pre></td></tr></tbody></table></figure><p>输出如下：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[('&lt;unk&gt;', 0), ('the', 1), ('i', 2), ('and', 3), ('of', 4), ('a', 5), ('to', 6), ('was', 7), ('in', 8), ('that', 9)]</span><br></pre></td></tr></tbody></table></figure><p>查看每行文本的转换效果</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">words: [<span class="string">'the'</span>, <span class="string">'time'</span>, <span class="string">'machine'</span>, <span class="string">'by'</span>, <span class="string">'h'</span>, <span class="string">'g'</span>, <span class="string">'wells'</span>]</span><br><span class="line">indices: [<span class="number">1</span>, <span class="number">19</span>, <span class="number">50</span>, <span class="number">40</span>, <span class="number">2183</span>, <span class="number">2184</span>, <span class="number">400</span>]</span><br><span class="line">words: [<span class="string">'twinkled'</span>, <span class="string">'and'</span>, <span class="string">'his'</span>, <span class="string">'usually'</span>, <span class="string">'pale'</span>, <span class="string">'face'</span>, <span class="string">'was'</span>, <span class="string">'flushed'</span>, <span class="string">'and'</span>, <span class="string">'animated'</span>, <span class="string">'the'</span>]</span><br><span class="line">indices: [<span class="number">2186</span>, <span class="number">3</span>, <span class="number">25</span>, <span class="number">1044</span>, <span class="number">362</span>, <span class="number">113</span>, <span class="number">7</span>, <span class="number">1421</span>, <span class="number">3</span>, <span class="number">1045</span>, <span class="number">1</span>]</span><br></pre></td></tr></tbody></table></figure><p>输出如下：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">words: ['the', 'time', 'machine', 'by', 'h', 'g', 'wells']</span><br><span class="line">indices: [1, 19, 50, 40, 2183, 2184, 400]</span><br><span class="line">words: ['twinkled', 'and', 'his', 'usually', 'pale', 'face', 'was', 'flushed', 'and', 'animated', 'the']</span><br><span class="line">indices: [2186, 3, 25, 1044, 362, 113, 7, 1421, 3, 1045, 1]</span><br></pre></td></tr></tbody></table></figure><h2><span id="4-所有内容打包返回">4. 所有内容打包返回</span></h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将所有内容打包到load_corpus_time_machine函数中</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_corpus_time_machine</span>(<span class="params">max_tokens=-<span class="number">1</span></span>):  </span><br><span class="line">    <span class="string">"""返回时光机器数据集的标记索引列表和词汇表。"""</span></span><br><span class="line">    lines = read_time_machine()</span><br><span class="line">    tokens = tokenize(lines, <span class="string">'char'</span>)</span><br><span class="line">    vocab = Vocab(tokens)</span><br><span class="line">    corpus = [vocab[token] <span class="keyword">for</span> line <span class="keyword">in</span> tokens <span class="keyword">for</span> token <span class="keyword">in</span> line]</span><br><span class="line">    <span class="keyword">if</span> max_tokens &gt; <span class="number">0</span>:</span><br><span class="line">        corpus = corpus[:max_tokens]</span><br><span class="line">    <span class="keyword">return</span> corpus, vocab</span><br><span class="line"></span><br><span class="line">corpus, vocab = load_corpus_time_machine()</span><br><span class="line"><span class="comment"># corpus词编码信息，vocab词汇表</span></span><br><span class="line"><span class="built_in">len</span>(corpus), <span class="built_in">len</span>(vocab)</span><br></pre></td></tr></tbody></table></figure><p>输出如下：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(170580, 28)</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 循环神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 循环神经网络 </tag>
            
            <tag> 文本预处理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode591</title>
      <link href="/2022/05/02/leetcode/mei-ri-yi-ti/leetcode591/"/>
      <url>/2022/05/02/leetcode/mei-ri-yi-ti/leetcode591/</url>
      
        <content type="html"><![CDATA[<h1><span id="591-标签验证器">591. 标签验证器</span></h1><blockquote><ol><li>标签验证器：<a href="https://leetcode-cn.com/problems/tag-validator/">https://leetcode-cn.com/problems/tag-validator/</a></li></ol></blockquote><h2><span id="题目">题目</span></h2><p>给定一个表示代码片段的字符串，你需要实现一个验证器来解析这段代码，并返回它是否合法。合法的代码片段需要遵守以下的所有规则：</p><ol><li>代码必须被<strong>合法的闭合标签包围</strong>。否则，代码是无效的。</li><li><strong>闭合标签</strong>（不一定合法）要严格符合格式：<code>&lt;TAG_NAME&gt;TAG_CONTENT&lt;/TAG_NAME&gt;</code>。其中，<code>&lt;TAG_NAME&gt;</code>是起始标签，<code>&lt;/TAG_NAME&gt;</code>是结束标签。起始和结束标签中的 TAG_NAME 应当相同。当且仅当 TAG_NAME 和 TAG_CONTENT 都是合法的，闭合标签才是<strong>合法的</strong>。</li><li><strong>合法的</strong> <code>TAG_NAME</code> 仅含有<strong>大写字母</strong>，长度在范围 <code>[1,9]</code> 之间。否则，该 <code>TAG_NAME</code> 是不合法的。</li><li><strong>合法的</strong><code>TAG_CONTENT</code> 可以包含其他<strong>合法的闭合标签</strong>，<strong>cdata</strong> （请参考规则7）和任意字符（注意参考规则1）<strong>除了</strong>不匹配的 <code>&lt;</code>、不匹配的起始和结束标签、不匹配的或带有不合法 TAG_NAME 的闭合标签。否则，<code>TAG_CONTENT</code> 是不合法的。</li><li>一个起始标签，如果没有具有相同 TAG_NAME 的结束标签与之匹配，是不合法的。反之亦然。不过，你也需要考虑标签嵌套的问题。</li><li>一个<code>&lt;</code>，如果你找不到一个后续的<code>&gt;</code>与之匹配，是不合法的。并且当你找到一个<code>&lt;</code>或<code>&lt;/</code>时，所有直到下一个<code>&gt;</code>的前的字符，都应当被解析为 TAG_NAME（不一定合法）。</li><li>cdata 有如下格式：<code>&lt;![CDATA[CDATA_CONTENT]]&gt;</code>。<code>CDATA_CONTENT</code> 的范围被定义成 <code>&lt;![CDATA[</code> 和后续的第一个 <code>]]&gt;</code>之间的字符。</li><li><code>CDATA_CONTENT</code> 可以包含<strong>任意字符</strong>。<code>cdata</code> 的功能是阻止验证器解析<code>CDATA_CONTENT</code>，所以即使其中有一些字符可以被解析为标签（无论合法还是不合法），也应该将它们视为<strong>常规字符</strong>。</li></ol><p><strong>合法代码的例子:</strong></p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">输入: "&lt;DIV&gt;This is the first line &lt;![CDATA[&lt;div&gt;]]&gt;&lt;/DIV&gt;"</span><br><span class="line">输出: True</span><br><span class="line">解释: </span><br><span class="line">代码被包含在了闭合的标签内： &lt;DIV&gt; 和 &lt;/DIV&gt; 。</span><br><span class="line">TAG_NAME 是合法的，TAG_CONTENT 包含了一些字符和 cdata 。 </span><br><span class="line">即使 CDATA_CONTENT 含有不匹配的起始标签和不合法的 TAG_NAME，它应该被视为普通的文本，而不是标签。</span><br><span class="line">所以 TAG_CONTENT 是合法的，因此代码是合法的。最终返回True。</span><br><span class="line"></span><br><span class="line">输入: "&lt;DIV&gt;&gt;&gt;  ![cdata[]] &lt;![CDATA[&lt;div&gt;]&gt;]]&gt;]]&gt;&gt;]&lt;/DIV&gt;"</span><br><span class="line">输出: True</span><br><span class="line">解释:</span><br><span class="line">我们首先将代码分割为： start_tag|tag_content|end_tag 。</span><br><span class="line">start_tag -&gt; "&lt;DIV&gt;"</span><br><span class="line">end_tag -&gt; "&lt;/DIV&gt;"</span><br><span class="line">tag_content 也可被分割为： text1|cdata|text2 。</span><br><span class="line">text1 -&gt; "&gt;&gt;  ![cdata[]] "</span><br><span class="line">cdata -&gt; "&lt;![CDATA[&lt;div&gt;]&gt;]]&gt;" ，其中 CDATA_CONTENT 为 "&lt;div&gt;]&gt;"</span><br><span class="line">text2 -&gt; "]]&gt;&gt;]"</span><br><span class="line">start_tag 不是 "&lt;DIV&gt;&gt;&gt;" 的原因参照规则 6 。</span><br><span class="line">cdata 不是 "&lt;![CDATA[&lt;div&gt;]&gt;]]&gt;]]&gt;" 的原因参照规则 7 。</span><br></pre></td></tr></tbody></table></figure><p><strong>不合法代码的例子:</strong></p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">输入: "&lt;A&gt;  &lt;B&gt; &lt;/A&gt;   &lt;/B&gt;"</span><br><span class="line">输出: False</span><br><span class="line">解释: 不合法。如果 "&lt;A&gt;" 是闭合的，那么 "&lt;B&gt;" 一定是不匹配的，反之亦然。</span><br><span class="line"></span><br><span class="line">输入: "&lt;DIV&gt;  div tag is not closed  &lt;DIV&gt;"</span><br><span class="line">输出: False</span><br><span class="line"></span><br><span class="line">输入: "&lt;DIV&gt;  unmatched &lt;  &lt;/DIV&gt;"</span><br><span class="line">输出: False</span><br><span class="line"></span><br><span class="line">输入: "&lt;DIV&gt; closed tags with invalid tag name  &lt;b&gt;123&lt;/b&gt; &lt;/DIV&gt;"</span><br><span class="line">输出: False</span><br><span class="line"></span><br><span class="line">输入: "&lt;DIV&gt; unmatched tags with invalid tag name  &lt;/1234567890&gt; and &lt;CDATA[[]]&gt;  &lt;/DIV&gt;"</span><br><span class="line">输出: False</span><br><span class="line"></span><br><span class="line">输入: "&lt;DIV&gt;  unmatched start tag &lt;B&gt;  and unmatched end tag &lt;/C&gt;  &lt;/DIV&gt;"</span><br><span class="line">输出: False</span><br></pre></td></tr></tbody></table></figure><p><strong>注意：</strong></p><ol><li>为简明起见，你可以假设输入的代码（包括提到的<strong>任意字符</strong>）只包含数字, 字母, <code>'&lt;'</code>,<code>'&gt;'</code>,<code>'/'</code>,<code>'!'</code>,<code>'['</code>,<code>']'</code>和<code>' '</code>。</li></ol><h2><span id="解题思路">解题思路</span></h2><p>本题是一道解析字符串的题目，涉及到标签的闭合。由于标签具有「最先开始的标签最后结束」的特性，因此我们可以考虑使用一个栈存储当前开放的标签。除此之外，我们还需要考虑 $\text{cdata}$ 以及一般的字符，二者都可以使用遍历 + 判断的方法直接进行验证。</p><p>我们可以对字符串 $\textit{code}$ 进行一次遍历。在遍历的过程中，根据遍历到位置 i 的当前字符，采取对应的判断：</p><ul><li>如果当前的字符为 $\texttt{&lt;}$，那么需要考虑下面的四种情况：<ul><li>如果下一个字符为 $\texttt{/}$，那么说明我们遇到了一个结束标签。我们需要定位下一个 $\texttt{&gt;}$ 的位置 $j$，此时 $\textit{code}[i+2..j-1]$ 就是该结束标签的名称。我们需要判断该名称与当前栈顶的名称是否匹配，如果匹配，说明名称的标签已经闭合，我们需要将当前栈顶的名称弹出。同时根据规则 1，我们需要保证整个 $\textit{code}$ 被闭合标签包围，因此如果栈中已经没有标签，但是 $j$ 并不是 $\textit{code}$ 的末尾，那么说明后续还会有字符，它们不被闭合标签包围。</li><li>如果下一个字符为 $\texttt{!}$，那么说明我们遇到了一个 $\text{cdata}$，我们需要继续往后读 7 个字符，判断其是否为 $\texttt{[CDATA[}$。在这之后，我们定位下一个 $\texttt{]]&gt;}$ 的位置 $j$，此时 $\textit{code}[i+9..j-1]$ 就是 $\text{cdata}$ 中的内容，它不需要被解析，所以我们也不必进行任何验证。需要注意的是，根据规则 1，栈中需要存在至少一个开放的标签。</li><li>如果下一个字符为大写字母，那么说明我们遇到了一个开始标签。我们需要定位下一个 $\texttt{&gt;}$ 的位置 $j$，此时 $\textit{code}[i+2..j-1]$ 就是该开始标签的名称。我们需要判断该名称是否恰好由 $1$ 至 $9$ 个大写字母组成，如果是，说明该标签合法，我们需要将该名称放入栈顶。</li><li>除此之外，如果不存在下一个字符，或者下一个字符不属于上述三种情况，那么 $\textit{code}$ 是不合法的。</li></ul></li><li>如果当前的字符为其它字符，那么根据规则 1，栈中需要存在至少一个开放的标签。</li></ul><p>在遍历完成后，我们还需要保证此时栈中没有任何（还没有结束的）标签。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">isValid</span>(<span class="params">self, code: <span class="built_in">str</span></span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        n = <span class="built_in">len</span>(code)</span><br><span class="line">        tags = []</span><br><span class="line">        i = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> i &lt; n:</span><br><span class="line">            <span class="keyword">if</span> code[i] == <span class="string">"&lt;"</span>:</span><br><span class="line">                <span class="keyword">if</span> i == n - <span class="number">1</span>:</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">                <span class="keyword">elif</span> code[i + <span class="number">1</span>] == <span class="string">"/"</span>:</span><br><span class="line">                    j = code.find(<span class="string">'&gt;'</span>, i)</span><br><span class="line">                    <span class="keyword">if</span> j == -<span class="number">1</span>:</span><br><span class="line">                        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">                    tagname = code[i + <span class="number">2</span>: j]</span><br><span class="line">                    <span class="keyword">if</span> <span class="keyword">not</span> tags <span class="keyword">or</span> tags[-<span class="number">1</span>] != tagname:</span><br><span class="line">                        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">                    tags.pop()</span><br><span class="line">                    i = j + <span class="number">1</span></span><br><span class="line">                    <span class="keyword">if</span> <span class="keyword">not</span> tags <span class="keyword">and</span> i != n:</span><br><span class="line">                        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">                <span class="keyword">elif</span> code[i + <span class="number">1</span>] == <span class="string">'!'</span>:</span><br><span class="line">                    <span class="keyword">if</span> <span class="keyword">not</span> tags:</span><br><span class="line">                        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">                    cdata = code[i + <span class="number">2</span>: i + <span class="number">9</span>]</span><br><span class="line">                    <span class="keyword">if</span> cdata != <span class="string">"[CDATA["</span>:</span><br><span class="line">                        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">                    j = code.find(<span class="string">"]]&gt;"</span>, i)</span><br><span class="line">                    <span class="keyword">if</span> j == -<span class="number">1</span>:</span><br><span class="line">                        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">                    i = j + <span class="number">3</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    j = code.find(<span class="string">'&gt;'</span>, i)</span><br><span class="line">                    <span class="keyword">if</span> j == -<span class="number">1</span>:</span><br><span class="line">                        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">                    tagname = code[i + <span class="number">1</span>: j]</span><br><span class="line">                    <span class="keyword">if</span> <span class="keyword">not</span> <span class="number">1</span> &lt;= <span class="built_in">len</span>(tagname) &lt;= <span class="number">9</span> <span class="keyword">or</span> <span class="keyword">not</span> <span class="built_in">all</span>(ch.isupper() <span class="keyword">for</span> ch <span class="keyword">in</span> tagname):</span><br><span class="line">                        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">                    tags.append(tagname)</span><br><span class="line">                    i = j + <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> tags:</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">not</span> tags</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> 难度-困难 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeetCode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>全局平均池化</title>
      <link href="/2022/05/02/machine-learning/juan-ji-shen-jing-wang-luo/quan-ju-ping-jun-chi-hua/"/>
      <url>/2022/05/02/machine-learning/juan-ji-shen-jing-wang-luo/quan-ju-ping-jun-chi-hua/</url>
      
        <content type="html"><![CDATA[<h1><span id="全局平均池化global-average-pooling">全局平均池化（global average pooling）</span></h1><h2><span id="1-解释">1. 解释</span></h2><p>如果有一批特征图，其尺寸为 [ B, C, H, W], 我们经过全局平均池化之后，尺寸变为[B, C, 1, 1]。也就是说，全局平均池化其实就是对每一个通道图所有像素值求平均值，然后得到一个新的1 * 1的通道图。</p><h2><span id="2-代码使用">2. 代码使用</span></h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">1</span>]: <span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">In [<span class="number">2</span>]: a = torch.rand([<span class="number">4</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">4</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">3</span>]: a.size()</span><br><span class="line">Out[<span class="number">3</span>]: torch.Size([<span class="number">4</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">4</span>]: b = torch.nn.functional.adaptive_avg_pool2d(a, (<span class="number">1</span>,<span class="number">1</span>))  <span class="comment"># 自适应池化，指定池化输出尺寸为 1 * 1</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">5</span>]: b.size()</span><br><span class="line">Out[<span class="number">5</span>]: torch.Size([<span class="number">4</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br></pre></td></tr></tbody></table></figure><h2><span id="3-作用优点">3. 作用+优点</span></h2><p><strong>作用：</strong>如果要预测K个类别，在卷积特征抽取部分的最后一层卷积层，就会生成K个特征图，然后通过全局平均池化就可以得到 K个1×1的特征图，将这些1×1的特征图输入到softmax layer之后，每一个输出结果代表着这K个类别的概率（或置信度 confidence），起到取代全连接层的效果。</p><p><strong>优点：</strong></p><ol><li>和全连接层相比，使用全局平均池化技术，对于建立特征图和类别之间的关系，是一种更朴素的卷积结构选择。</li><li>全局平均池化层不需要参数，避免在该层产生过拟合。</li><li>全局平均池化对空间信息进行求和，对输入的空间变化的鲁棒性更强。</li></ol><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pandas 常见函数</title>
      <link href="/2022/05/02/python-ji-chu-xue-xi-san-jian-tao/pandas-chang-jian-han-shu/"/>
      <url>/2022/05/02/python-ji-chu-xue-xi-san-jian-tao/pandas-chang-jian-han-shu/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="pandas-常见函数">pandas 常见函数</span></h1><h2><span id="1-concat">1. concat</span></h2><blockquote><p>pd.concat( objs, axis=0, join=’outer’, join_axes=None, ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False, sort=None, copy=True,)</p></blockquote><p>pd.concat()函数可以沿着指定的轴将多个dataframe或者series拼接到一起，这一点和另一个常用的pd.merge()函数不同，pd.merge()函数只能实现两个表的拼接。</p><h2><span id="2-shift">2. shift</span></h2><blockquote><p>DataFrame.shift(periods=1, freq=None, axis=0)</p><ul><li>periods：类型为int，表示移动的幅度，可以是正数，也可以是负数，默认值是1, 1就表示移动一次，注意这里移动的都是数据，而索引是不移动的，移动之后没有对应值的，就赋值为NaN。</li></ul></blockquote><p>shift函数是对数据进行移动的操作，假如现在有一个DataFrame数据df，如下所示：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">  index  value</span><br><span class="line"><span class="number">0</span>     A      <span class="number">0</span></span><br><span class="line"><span class="number">1</span>     B      <span class="number">1</span></span><br><span class="line"><span class="number">2</span>     C      <span class="number">2</span></span><br><span class="line"><span class="number">3</span>     D      <span class="number">3</span></span><br></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">df.shift(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">  index  value</span><br><span class="line"><span class="number">0</span>   NaN    NaN</span><br><span class="line"><span class="number">1</span>   NaN    NaN</span><br><span class="line"><span class="number">2</span>     A    <span class="number">0.0</span></span><br><span class="line"><span class="number">3</span>     B    <span class="number">1.0</span></span><br><span class="line"></span><br><span class="line">df.shift(-<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">  index  value</span><br><span class="line"><span class="number">0</span>     B    <span class="number">1.0</span></span><br><span class="line"><span class="number">1</span>     C    <span class="number">2.0</span></span><br><span class="line"><span class="number">2</span>     D    <span class="number">3.0</span></span><br><span class="line"><span class="number">3</span>   NaN    NaN</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> pandas </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>numpy 常见函数</title>
      <link href="/2022/05/02/python-ji-chu-xue-xi-san-jian-tao/numpy-chang-jian-han-shu/"/>
      <url>/2022/05/02/python-ji-chu-xue-xi-san-jian-tao/numpy-chang-jian-han-shu/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="numpy-常见函数">numpy 常见函数</span></h1><h2><span id="1-pad">1. pad</span></h2><blockquote><p>在<a href="https://so.csdn.net/so/search?q=卷积神经网络&amp;spm=1001.2101.3001.7020">卷积神经网络</a>中，为了避免因为卷积运算导致输出图像缩小和图像边缘信息丢失，常常采用图像边缘填充技术，即在图像四周边缘填充0，使得卷积运算后图像大小不会缩小，同时也不会丢失边缘和角落的信息。在Python的numpy库中，常常采用 <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.pad.html">numpy.pad()</a> 进行填充操作，具体分析如下：</p></blockquote><h3><span id="11-语法结构">1.1 语法结构</span></h3><blockquote><p>pad(array, pad_width, mode, **kwargs)</p><p>Parameters</p><ul><li><strong>array</strong>——表示需要填充的数组；</li><li><strong>pad_width</strong>——表示每个轴（axis）边缘需要填充的数值数目。<br>参数输入方式为：（(before_1, after_1), … (before_N, after_N)），其中(before_1, after_1)表示第1轴两边缘分别填充before_1个和after_1个数值。取值为：{sequence, array_like, int}</li><li><strong>mode</strong>——表示填充的方式（取值：str字符串或用户提供的函数）,总共有11种填充模式；</li></ul></blockquote><p>常用的填充方式：</p><ul><li>‘constant’——表示连续填充相同的值，每个轴可以分别指定填充值，constant_values=（x, y）时前面用x填充，后面用y填充，缺省值填充0；</li><li>‘edge’——表示用边缘值填充；</li><li>‘linear_ramp’——表示用边缘递减的方式填充；</li><li>‘maximum’——表示最大值填充；</li><li>‘mean’——表示均值填充；</li><li>‘median’——表示中位数填充；</li><li>‘minimum’——表示最小值填充；</li><li>‘reflect’——表示对称填充；</li><li>‘symmetric’——表示对称填充；</li><li>‘wrap’——表示用原数组后面的值填充前面，前面的值填充后面</li></ul><h3><span id="12-常数填充模式constant">1.2 常数填充模式——’constant’</span></h3><p>在数组A的边缘填充constant_values指定的数值</p><ol><li>（3,2）表示在A的第[0]轴填充（二维数组中，0轴表示行），即在0轴前面填充3个宽度的0，比如数组A中的95,96两个元素前面各填充了3个0；在后面填充2个0，比如数组A中的97,98两个元素后面各填充了2个0</li><li>（2,3）表示在A的第[1]轴填充（二维数组中，1轴表示列），即在1轴前面填充2个宽度的0，后面填充3个宽度的0</li></ol><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>A = np.arange(<span class="number">95</span>,<span class="number">99</span>).reshape(<span class="number">2</span>,<span class="number">2</span>)    <span class="comment">#原始输入数组</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>A</span><br><span class="line">array([[<span class="number">95</span>, <span class="number">96</span>],</span><br><span class="line">       [<span class="number">97</span>, <span class="number">98</span>]])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.pad(A,((<span class="number">3</span>,<span class="number">2</span>),(<span class="number">2</span>,<span class="number">3</span>)),<span class="string">'constant'</span>,constant_values = (<span class="number">0</span>,<span class="number">0</span>))  <span class="comment">#constant_values表示填充值，且(before，after)的填充值等于（0,0）</span></span><br><span class="line">array([[ <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>],</span><br><span class="line">       [ <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>],</span><br><span class="line">       [ <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>],</span><br><span class="line">       [ <span class="number">0</span>,  <span class="number">0</span>, <span class="number">95</span>, <span class="number">96</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>],</span><br><span class="line">       [ <span class="number">0</span>,  <span class="number">0</span>, <span class="number">97</span>, <span class="number">98</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>],</span><br><span class="line">       [ <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>],</span><br><span class="line">       [ <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>]])</span><br></pre></td></tr></tbody></table></figure><h3><span id="13-边缘值填充模式edge">1.3 边缘值填充模式——’edge’</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>B = np.arange(<span class="number">1</span>,<span class="number">5</span>).reshape(<span class="number">2</span>,<span class="number">2</span>)  <span class="comment">#原始输入数组</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>B</span><br><span class="line">array([[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.pad(B,((<span class="number">1</span>,<span class="number">2</span>),(<span class="number">2</span>,<span class="number">1</span>)),<span class="string">'edge'</span>)   <span class="comment">#注意先填充0轴，后面填充1轴，依次填充</span></span><br><span class="line">array([[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>]])</span><br></pre></td></tr></tbody></table></figure><h3><span id="14-边缘最大值填充模式maximum">1.4 边缘最大值填充模式——’maximum’</span></h3><p> maximum填充模式还有其他控制参数，比如stat_length，详细见numpy库</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>B = np.arange(<span class="number">1</span>,<span class="number">5</span>).reshape(<span class="number">2</span>,<span class="number">2</span>)  <span class="comment">#原始输入数组</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>B</span><br><span class="line">array([[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.pad(B,((<span class="number">1</span>,<span class="number">2</span>),(<span class="number">2</span>,<span class="number">1</span>)),<span class="string">'maximum'</span>)</span><br><span class="line">array([[<span class="number">4</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>],</span><br><span class="line">       [<span class="number">4</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">4</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">4</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>]])</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> numpy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode1305</title>
      <link href="/2022/05/01/leetcode/mei-ri-yi-ti/leetcode1305/"/>
      <url>/2022/05/01/leetcode/mei-ri-yi-ti/leetcode1305/</url>
      
        <content type="html"><![CDATA[<h1><span id="1305-两棵二叉搜索树中的所有元素">1305. 两棵二叉搜索树中的所有元素</span></h1><blockquote><ol><li>两棵二叉搜索树中的所有元素：<a href="https://leetcode-cn.com/problems/all-elements-in-two-binary-search-trees/">https://leetcode-cn.com/problems/all-elements-in-two-binary-search-trees/</a></li></ol></blockquote><p>给你 <code>root1</code> 和 <code>root2</code> 这两棵二叉搜索树。请你返回一个列表，其中包含 <strong>两棵树</strong> 中的所有整数并按 <strong>升序</strong> 排序。.</p><h2><span id="示例">示例</span></h2><p><img src="http://xiaomanzhan.com.cn/content/q2-e1.png" alt="img"><img src="http://xiaomanzhan.com.cn/content/q2-e5-.png" alt="img"></p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">示例 1：</span><br><span class="line">输入：root1 = [2,1,4], root2 = [1,0,3]</span><br><span class="line">输出：[0,1,1,2,3,4]</span><br><span class="line"></span><br><span class="line">示例 2：</span><br><span class="line">输入：root1 = [1,null,8], root2 = [8,1]</span><br><span class="line">输出：[1,1,8,8]</span><br></pre></td></tr></tbody></table></figure><h2><span id="解题思路">解题思路</span></h2><p>二叉树排序使用中序遍历的方式，先对二叉排序数进行中序遍历的操作进行排序，再进行合并操作</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">getAllElements</span>(<span class="params">self, root1: TreeNode, root2: TreeNode</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">inorder</span>(<span class="params">node: TreeNode, res: <span class="type">List</span>[<span class="built_in">int</span>]</span>):</span><br><span class="line">            <span class="keyword">if</span> node:</span><br><span class="line">                inorder(node.left, res)</span><br><span class="line">                res.append(node.val)</span><br><span class="line">                inorder(node.right, res)</span><br><span class="line"></span><br><span class="line">        nums1, nums2 = [], []</span><br><span class="line">        inorder(root1, nums1)</span><br><span class="line">        inorder(root2, nums2)</span><br><span class="line"></span><br><span class="line">        merged = []</span><br><span class="line">        p1, n1 = <span class="number">0</span>, <span class="built_in">len</span>(nums1)</span><br><span class="line">        p2, n2 = <span class="number">0</span>, <span class="built_in">len</span>(nums2)</span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            <span class="keyword">if</span> p1 == n1:</span><br><span class="line">                merged.extend(nums2[p2:])</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">if</span> p2 == n2:</span><br><span class="line">                merged.extend(nums1[p1:])</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">if</span> nums1[p1] &lt; nums2[p2]:</span><br><span class="line">                merged.append(nums1[p1])</span><br><span class="line">                p1 += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                merged.append(nums2[p2])</span><br><span class="line">                p2 += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> merged</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> 难度-中等 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeetCode </tag>
            
            <tag> 中序遍历 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tensorboardX</title>
      <link href="/2022/05/01/machine-learning/tensorboardx/"/>
      <url>/2022/05/01/machine-learning/tensorboardx/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="tensorboardx可视化">tensorboardX可视化</span></h1><h2><span id="1-安装相关的库">1. 安装相关的库</span></h2><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install tensorboardX</span><br><span class="line">pip install tensorboard</span><br></pre></td></tr></tbody></table></figure><h2><span id="2-使用过程">2. 使用过程</span></h2><ol><li>先通过<code>tensorboardX</code>下的<code>SummaryWriter</code>类获取一个日志编写器对象。</li><li>通过这个对象的一组方法往日志中添加事件，即生成相应的图片；</li><li>最后启动前端服务器，在localhost中就可以看到最终的结果了。</li></ol><h2><span id="3-训练网络并可视化">3. 训练网络并可视化</span></h2><p>网络训练过程的代码如下：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorboardX <span class="keyword">import</span> SummaryWriter</span><br><span class="line">logger = SummaryWriter(log_dir=<span class="string">"data/log"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取优化器和损失函数</span></span><br><span class="line">optimizer = torch.optim.Adam(MyConvNet.parameters(), lr=<span class="number">3e-4</span>)</span><br><span class="line">loss_func = nn.CrossEntropyLoss()</span><br><span class="line">log_step_interval = <span class="number">100</span>      <span class="comment"># 记录的步数间隔</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"epoch:"</span>, epoch)</span><br><span class="line">    <span class="comment"># 每一轮都遍历一遍数据加载器</span></span><br><span class="line">    <span class="keyword">for</span> step, (x, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        <span class="comment"># 前向计算-&gt;计算损失函数-&gt;(从损失函数)反向传播-&gt;更新网络</span></span><br><span class="line">        predict = MyConvNet(x)</span><br><span class="line">        loss = loss_func(predict, y)</span><br><span class="line">        optimizer.zero_grad()   <span class="comment"># 清空梯度（可以不写）</span></span><br><span class="line">        loss.backward()     <span class="comment"># 反向传播计算梯度</span></span><br><span class="line">        optimizer.step()    <span class="comment"># 更新网络</span></span><br><span class="line">        global_iter_num = epoch * <span class="built_in">len</span>(train_loader) + step + <span class="number">1</span>  <span class="comment"># 计算当前是从训练开始时的第几步(全局迭代次数)</span></span><br><span class="line">        <span class="keyword">if</span> global_iter_num % log_step_interval == <span class="number">0</span>:</span><br><span class="line">            <span class="comment"># 控制台输出一下</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">"global_step:{}, loss:{:.2}"</span>.<span class="built_in">format</span>(global_iter_num, loss.item()))</span><br><span class="line">            <span class="comment"># 添加的第一条日志：损失函数-全局迭代次数</span></span><br><span class="line">            logger.add_scalar(<span class="string">"train loss"</span>, loss.item() ,global_step=global_iter_num)</span><br><span class="line">            <span class="comment"># 在测试集上预测并计算正确率</span></span><br><span class="line">            test_predict = MyConvNet(test_data_x)</span><br><span class="line">            _, predict_idx = torch.<span class="built_in">max</span>(test_predict, <span class="number">1</span>)     <span class="comment"># 计算softmax后的最大值的索引，即预测结果</span></span><br><span class="line">            acc = accuracy_score(test_data_y, predict_idx)</span><br><span class="line">            <span class="comment"># 添加第二条日志：正确率-全局迭代次数</span></span><br><span class="line">            logger.add_scalar(<span class="string">"test accuary"</span>, acc.item(), global_step=global_iter_num)</span><br><span class="line">            <span class="comment"># 添加第三条日志：这个batch下的128张图像</span></span><br><span class="line">            img = vutils.make_grid(x, nrow=<span class="number">12</span>)</span><br><span class="line">            logger.add_image(<span class="string">"train image sample"</span>, img, global_step=global_iter_num)</span><br><span class="line">            <span class="comment"># 添加第三条日志：网络中的参数分布直方图</span></span><br><span class="line">            <span class="keyword">for</span> name, param <span class="keyword">in</span> MyConvNet.named_parameters():</span><br><span class="line">                logger.add_histogram(name, param.data.numpy(), global_step=global_iter_num)</span><br></pre></td></tr></tbody></table></figure><p>运行完后，我们通过cmd来到与代码同一级的目录（如果你使用的是pycharm，可以通过pycharm中的终端）输入指令<code>tensorboard --logdir="./data/log"</code>，启动服务器。</p><p><img src="http://xiaomanzhan.com.cn/content/image-20220501232115020.png" alt="image-20220501232115020" style="zoom:67%;"><img src="http://xiaomanzhan.com.cn/content/image-20220501231949281.png" alt="image-20220501231949281" style="zoom:67%;"></p><blockquote><p>logdir后面的参数是日志文件的文件夹的路径，通过访问url，便可得到可视化界面，点击上面的页面控件，可以查看我们通过<code>add_scalar</code>、<code>add_image</code>和<code>add_histogram</code>得到的图像，而且各方面做得都很丝滑。</p></blockquote><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 深度学习可视化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python 基础函数</title>
      <link href="/2022/05/01/python-ji-chu-xue-xi-san-jian-tao/python-nei-zhi-han-shu/"/>
      <url>/2022/05/01/python-ji-chu-xue-xi-san-jian-tao/python-nei-zhi-han-shu/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="python-内置函数">python 内置函数</span></h1><h2><span id="1-divmoda-b">1. divmod(a, b)</span></h2><p>python divmod() 函数把除数和余数运算结果结合起来，返回一个包含商和余数的元组(a // b, a % b)。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;<span class="built_in">divmod</span>(<span class="number">7</span>, <span class="number">2</span>)</span><br><span class="line">(<span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">divmod</span>(<span class="number">8</span>, <span class="number">2</span>)</span><br><span class="line">(<span class="number">4</span>, <span class="number">0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">divmod</span>(<span class="number">1</span>+<span class="number">2j</span>,<span class="number">1</span>+<span class="number">0.5j</span>)</span><br><span class="line">((<span class="number">1</span>+<span class="number">0j</span>), <span class="number">1.5j</span>)</span><br></pre></td></tr></tbody></table></figure><h2><span id="2-list常见操作">2. list常见操作</span></h2><h3><span id="21-栈">2.1 栈</span></h3><p>慢的方法直接使用列表进行操作</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>s = []</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s.append(<span class="string">'eat'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s.append(<span class="string">'sleep'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s.append(<span class="string">'code'</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s</span><br><span class="line">[<span class="string">'eat'</span>, <span class="string">'sleep'</span>, <span class="string">'code'</span>]</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s.pop()</span><br><span class="line"><span class="string">'code'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s.pop()</span><br><span class="line"><span class="string">'sleep'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s.pop()</span><br><span class="line"><span class="string">'eat'</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s.pop()</span><br><span class="line">IndexError: <span class="string">"pop from empty list"</span></span><br></pre></td></tr></tbody></table></figure><p> <code>collections.deque</code>——快速且稳健的栈</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> collections <span class="keyword">import</span> deque</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s = deque()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s.append(<span class="string">'eat'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s.append(<span class="string">'sleep'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s.append(<span class="string">'code'</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s</span><br><span class="line">deque([<span class="string">'eat'</span>, <span class="string">'sleep'</span>, <span class="string">'code'</span>])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s.pop()</span><br><span class="line"><span class="string">'code'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s.pop()</span><br><span class="line"><span class="string">'sleep'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s.pop()</span><br><span class="line"><span class="string">'eat'</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s.pop()</span><br><span class="line">IndexError: <span class="string">"pop from an empty deque"</span></span><br></pre></td></tr></tbody></table></figure><h3><span id="22-队列">2.2 队列</span></h3><p>慢的方法直接使用列表进行操作</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>q = []</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>q.append(<span class="string">'eat'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>q.append(<span class="string">'sleep'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>q.append(<span class="string">'code'</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>q</span><br><span class="line">[<span class="string">'eat'</span>, <span class="string">'sleep'</span>, <span class="string">'code'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 小心，这种操作很慢！</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>q.pop(<span class="number">0</span>)</span><br><span class="line"><span class="string">'eat'</span></span><br></pre></td></tr></tbody></table></figure><p> <code>collections.deque</code>——快速且稳健的队列</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> collections <span class="keyword">import</span> deque</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>q = deque()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>q.append(<span class="string">'eat'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>q.append(<span class="string">'sleep'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>q.append(<span class="string">'code'</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>q</span><br><span class="line">deque([<span class="string">'eat'</span>, <span class="string">'sleep'</span>, <span class="string">'code'</span>])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>q.popleft()</span><br><span class="line"><span class="string">'eat'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>q.popleft()</span><br><span class="line"><span class="string">'sleep'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>q.popleft()</span><br><span class="line"><span class="string">'code'</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>q.popleft()</span><br><span class="line">IndexError: <span class="string">"pop from an empty deque"</span></span><br></pre></td></tr></tbody></table></figure><h2><span id="3-map">3. map</span></h2><p><strong>map()</strong> 会根据提供的函数对指定序列做映射。map() 函数语法如下：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">map(function, iterable, ...)</span><br></pre></td></tr></tbody></table></figure><p>实例如下所示：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">square</span>(<span class="params">x</span>) :         <span class="comment"># 计算平方数</span></span><br><span class="line"><span class="meta">... </span>    <span class="keyword">return</span> x ** <span class="number">2</span></span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">map</span>(square, [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])    <span class="comment"># 计算列表各个元素的平方</span></span><br><span class="line">&lt;<span class="built_in">map</span> <span class="built_in">object</span> at <span class="number">0x100d3d550</span>&gt;     <span class="comment"># 返回迭代器</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(<span class="built_in">map</span>(square, [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]))   <span class="comment"># 使用 list() 转换为列表</span></span><br><span class="line">[<span class="number">1</span>, <span class="number">4</span>, <span class="number">9</span>, <span class="number">16</span>, <span class="number">25</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x: x ** <span class="number">2</span>, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]))   <span class="comment"># 使用 lambda 匿名函数</span></span><br><span class="line">[<span class="number">1</span>, <span class="number">4</span>, <span class="number">9</span>, <span class="number">16</span>, <span class="number">25</span>]</span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></tbody></table></figure><h2><span id="4-zip函数">4. zip函数</span></h2><p><strong>zip()</strong> 函数用于将可迭代的对象作为参数，将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的列表。如果各个迭代器的元素个数不一致，则返回列表长度与最短的对象相同，利用 * 号操作符，可以将元组解压为列表。</p><p>示例如下：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>zipped = <span class="built_in">zip</span>(a,b)     <span class="comment"># 返回一个对象</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>zipped</span><br><span class="line">&lt;<span class="built_in">zip</span> <span class="built_in">object</span> at <span class="number">0x103abc288</span>&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(zipped)  <span class="comment"># list() 转换为列表</span></span><br><span class="line">[(<span class="number">1</span>, <span class="number">4</span>), (<span class="number">2</span>, <span class="number">5</span>), (<span class="number">3</span>, <span class="number">6</span>)]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(<span class="built_in">zip</span>(a,c))              <span class="comment"># 元素个数与最短的列表一致</span></span><br><span class="line">[(<span class="number">1</span>, <span class="number">4</span>), (<span class="number">2</span>, <span class="number">5</span>), (<span class="number">3</span>, <span class="number">6</span>)]</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a1, a2 = <span class="built_in">zip</span>(*<span class="built_in">zip</span>(a,b))          <span class="comment"># 与 zip 相反，zip(*) 可理解为解压，返回二维矩阵式</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(a1)</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(a2)</span><br><span class="line">[<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]</span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></tbody></table></figure><h2><span id="5-nonlocal">5. nonlocal</span></h2><p>在函数内部创建一个函数，该函数使用变量 x 作为非局部变量。nonlocal 关键字用于在嵌套函数内部使用变量，其中变量不应属于内部函数。</p><p>使用 nonlocal：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">myfunc1</span>():</span><br><span class="line">  x = <span class="string">"Bill"</span></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">myfunc2</span>():</span><br><span class="line">    <span class="keyword">nonlocal</span> x</span><br><span class="line">    x = <span class="string">"hello"</span></span><br><span class="line">  myfunc2() </span><br><span class="line">  <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(myfunc1())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">hello</span><br></pre></td></tr></tbody></table></figure><p>不使用 nonlocal：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">myfunc1</span>():</span><br><span class="line">  x = <span class="string">"Bill"</span></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">myfunc2</span>():</span><br><span class="line">    x = <span class="string">"hello"</span></span><br><span class="line">  myfunc2() </span><br><span class="line">  <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(myfunc1())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">Bill</span><br></pre></td></tr></tbody></table></figure><h2><span id="6-choice">6. choice</span></h2><p><strong>choice()</strong> 方法返回一个列表，元组或字符串的随机项。语法如下：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line">random.choice( seq  )</span><br></pre></td></tr></tbody></table></figure><blockquote><p>choice()是不能直接访问的，需要导入 random 模块，然后通过 random 静态对象调用该方法。</p></blockquote><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">"choice([1, 2, 3, 5, 9]) : "</span>, random.choice([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">9</span>])</span><br><span class="line"><span class="built_in">print</span> <span class="string">"choice('A String') : "</span>, random.choice(<span class="string">'A String'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">choice([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">9</span>]) :  <span class="number">2</span></span><br><span class="line">choice(<span class="string">'A String'</span>) :  n</span><br></pre></td></tr></tbody></table></figure><h2><span id="7-hex">7. hex</span></h2><p><code>hex(x)</code>，将10进制整数转换成16进制，以字符串表示。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;<span class="built_in">hex</span>(<span class="number">255</span>)</span><br><span class="line"><span class="string">'0xff'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">hex</span>(-<span class="number">42</span>)</span><br><span class="line"><span class="string">'-0x2a'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">hex</span>(<span class="number">1L</span>)</span><br><span class="line"><span class="string">'0x1L'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">hex</span>(<span class="number">12</span>)</span><br><span class="line"><span class="string">'0xc'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">type</span>(<span class="built_in">hex</span>(<span class="number">12</span>))</span><br><span class="line">&lt;<span class="keyword">class</span> <span class="string">'str'</span>&gt; <span class="comment"># 字符串</span></span><br></pre></td></tr></tbody></table></figure><h2><span id="8-randint">8. randint</span></h2><p><code>random.randint(a, b)</code>，random模块里的randint()函数随机产生括号里两个参数之间的整数，且包括这两个参数，划定随机生成整数的范围（最小最大值）。</p><p>例如：</p><p>随机整数 1 ~ 100</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机整数</span></span><br><span class="line"><span class="built_in">print</span>(random.randint(<span class="number">1</span>, <span class="number">100</span>)</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Softmax回归+损失函数</title>
      <link href="/2022/04/30/machine-learning/softmax-hui-gui-and-sun-shi-han-shu/"/>
      <url>/2022/04/30/machine-learning/softmax-hui-gui-and-sun-shi-han-shu/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="softmax回归损失函数">Softmax回归+损失函数</span></h1><h2><span id="1-softmax回归">1. softmax回归</span></h2><p>softmax 是一个分类问题，不要因为名字而误解。</p><h3><span id="11-从回归到多分类">1.1 从回归到多分类</span></h3><p>因为对类别分类是进行 One-hot 编码，最大值为预测结果。</p><script type="math/tex; mode=display">\widehat{y}=argmax~o_i</script><p>所以我们在匹配时候，期望其匹配概率和为1，所以：</p><script type="math/tex; mode=display">\widehat{y}=softmax(o)</script><script type="math/tex; mode=display">\widehat{y}_i=\frac{\exp(o_i)}{\sum_k\exp(o_k)}</script><p>其概率 $y$ 和 $\widehat{y}$ 的区别作为损失。</p><blockquote><p>注意使用指数能够使其不存在负数。</p></blockquote><h3><span id="12-衡量损失-交叉熵">1.2 衡量损失-交叉熵</span></h3><p>一般情况下使用<strong>==交叉熵==</strong>来衡量两个概率的区别 </p><script type="math/tex; mode=display">H(p,q)=\sum-p_i\log(q_i)</script><p>将其作为损失变化如下，因为真实值 $y$，在分类任务中，只有一个为 1 ，其余全部为 0，所以公式变化如下：</p><script type="math/tex; mode=display">l(y,\hat{y})=-\sum_iy_i\log\hat{y}_y=-\log\hat{y}_y</script><p>则其梯度是真实概率和预测概率的区别，对上面求导：</p><script type="math/tex; mode=display">\delta_{o_i}l(y,\hat{y})=softmax(o)_i-y_i</script><h3><span id="13-代码实现">1.3 代码实现</span></h3><script type="math/tex; mode=display">softmax(X)_{ij}=\frac{\exp(X_{ij})}{\sum_k\exp(X_{ik})}</script><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">softmax</span>(<span class="params">X</span>):</span><br><span class="line">    X_exp = torch.exp(X)</span><br><span class="line">    partition = X_exp.<span class="built_in">sum</span>(<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> X_exp / partition</span><br></pre></td></tr></tbody></table></figure><p>我们将每个元素变成一个非负数。此外，依据概率原理，每行总和为1</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">X = torch.normal(<span class="number">0</span>, <span class="number">1</span>, (<span class="number">2</span>, <span class="number">5</span>))</span><br><span class="line">X_prob = softmax(X)</span><br><span class="line">X_prob, X_prob.<span class="built_in">sum</span>(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">(tensor([[<span class="number">0.0599</span>, <span class="number">0.1886</span>, <span class="number">0.5760</span>, <span class="number">0.1060</span>, <span class="number">0.0695</span>],</span><br><span class="line">         [<span class="number">0.3192</span>, <span class="number">0.2758</span>, <span class="number">0.0286</span>, <span class="number">0.0575</span>, <span class="number">0.3189</span>]]),</span><br><span class="line"> tensor([<span class="number">1.0000</span>, <span class="number">1.0000</span>]))</span><br></pre></td></tr></tbody></table></figure><p>实现 softmax 回归模型</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">net</span>(<span class="params">X</span>):</span><br><span class="line">    <span class="keyword">return</span> softmax(torch.matmul(X.reshape((-<span class="number">1</span>, W.shape[<span class="number">0</span>])), W) + b)</span><br></pre></td></tr></tbody></table></figure><p>创建一个数据<code>y_hat</code>，其中包含2个样本在3个类别的预测概率， 使用<code>y</code>作为<code>y_hat</code>中概率的索引</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">y = torch.tensor([<span class="number">0</span>, <span class="number">2</span>])</span><br><span class="line">y_hat = torch.tensor([[<span class="number">0.1</span>, <span class="number">0.3</span>, <span class="number">0.6</span>], [<span class="number">0.3</span>, <span class="number">0.2</span>, <span class="number">0.5</span>]])</span><br><span class="line">y_hat[[<span class="number">0</span>, <span class="number">1</span>], y]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">tensor([<span class="number">0.1000</span>, <span class="number">0.5000</span>])</span><br></pre></td></tr></tbody></table></figure><p>实现交叉熵损失函数</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">cross_entropy</span>(<span class="params">y_hat, y</span>):</span><br><span class="line">    <span class="keyword">return</span> -torch.log(y_hat[<span class="built_in">range</span>(<span class="built_in">len</span>(y_hat)), y])</span><br><span class="line"></span><br><span class="line">cross_entropy(y_hat, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">tensor([<span class="number">2.3026</span>, <span class="number">0.6931</span>])</span><br></pre></td></tr></tbody></table></figure><h3><span id="14-代码简洁实现">1.4 代码简洁实现</span></h3><p>在交叉熵损失函数中传递未归一化的预测，并同时计算softmax及其对数</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss = nn.CrossEntropyLoss()</span><br></pre></td></tr></tbody></table></figure><p>使用学习率为0.1的小批量随机梯度下降作为优化算法</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">trainer = torch.optim.SGD(net.parameters(), lr=<span class="number">0.1</span>)</span><br></pre></td></tr></tbody></table></figure><h2><span id="2-损失函数">2. 损失函数</span></h2><p>不同的损失函数绘图</p><p><img src="http://xiaomanzhan.com.cn/content/image-20220430223521672.png" alt="image-20220430223521672"></p><h3><span id="21-l2-loss">2.1 L2 Loss</span></h3><script type="math/tex; mode=display">l(y,y')=\frac{1}{2}(y-y')^2</script><p><img src="http://xiaomanzhan.com.cn/content/image-20220430223649352.png" alt="image-20220430223649352"></p><blockquote><p>蓝色是本函数，绿色是似然函数，橙色是损失函数的梯度</p></blockquote><p>由上图可以看出损失函数的导数是如何更新我们的参数的。</p><p>因为Loss的导数决定我们如何更新我们的参数，当predictions&lt;0时，导数为负数，所以更新参数靠右侧进行，反而反之，逐渐降低loss。</p><ol><li>当真实值 $y$ 与预测值 $y’$ 距离较大时，可以知道Loss的单次更新是比较多的，梯度的绝对值会较大；</li><li>当真实值 $y$ 与预测值 $y’$ 逐渐靠近的时候，梯度的绝对值会变得越来越小，这就会使得网络层参数更新的幅度越来越小。</li></ol><blockquote><p>注意：有时真实值 $y$ 与预测值 $y’$ 距离较大时，我们并不想要大幅度更新参数，所以需要考虑L1 Loss</p></blockquote><h3><span id="22-l1-loss">2.2 L1 Loss</span></h3><p>当离原理距离比较远的时候，我们可能不需要特别大的梯度来更新参数，所以有 L1 Loss</p><script type="math/tex; mode=display">l(y,y')=|y-y'|</script><p><img src="http://xiaomanzhan.com.cn/content/image-20220430224243110.png" alt="image-20220430224243110"></p><p>导数是常数</p><p>真实值 $y$ 与预测值 $y’$ 距离不管多远，梯度值永远是常数，权重更新不会特别大，能够带来稳定性上的好处。</p><ul><li>稳定性好；</li><li>零点处不可导；</li><li>因为靠近零点的时候会出现震荡，所以优化到末期，不会很稳定。</li></ul><h3><span id="23-huber-loss">2.3 Huber Loss</span></h3><p>结合上面 L1 和 L2 的优势</p><script type="math/tex; mode=display">l(y,y')=\begin{cases}|y-y'|-\frac{1}{2},\quad if~|y-y'|>0\\\frac{1}{2}(y-y')^2, \quad otherwise\end{cases}\tag{1}</script><p><img src="http://xiaomanzhan.com.cn/content/image-20220430224644222.png" alt="image-20220430224644222"></p><p>真实值 $y$ 与预测值 $y’$ 距离的绝对值 &lt;= 1的时候，梯度在变化的末期，能够逐渐平滑起来，梯度值逐渐降低，权重值更新变小。</p><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> Softmax </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>激活函数+数据稳定性</title>
      <link href="/2022/04/30/machine-learning/shu-ju-wen-ding-xing-and-ji-huo-han-shu/"/>
      <url>/2022/04/30/machine-learning/shu-ju-wen-ding-xing-and-ji-huo-han-shu/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="激活函数数据稳定性">激活函数+数据稳定性</span></h1><h2><span id="1-数值的稳定性">1. 数值的稳定性</span></h2><blockquote><p>在说激活函数之前，先介绍一下数据的稳定性</p></blockquote><p>当深度网络很深的时候，数据的数值信息是非常不稳定的，不利于模型参数的优化。</p><h3><span id="11-神经网络的梯度">1.1 神经网络的梯度</span></h3><p>一个 <code>d</code> 层的神经网络，$h^t=f_t(h^{t-1})$，$y=\ell\circ f_d\circ\dots\circ f_1(x)$</p><p>计算损失 $\ell$ 关于参数 $W_t$ 的梯度信息：</p><script type="math/tex; mode=display">\frac{\delta\ell}{\delta W^t}=\frac{\delta\ell}{\delta h^d}\frac{\delta h^d}{\delta h^{d-1}}\dots\frac{\delta h^{t+1}}{\delta h^{t}}\frac{\delta h^t}{\delta W^t}</script><h3><span id="12-数值稳定性的常见两个问题">1.2 数值稳定性的常见两个问题</span></h3><ol><li><p>梯度爆炸：</p><p>$1.5^{100}\approx4\times 10^{17}$</p></li><li><p>梯度消失：</p><p>$0.8^{100}\approx4\times 10^{17}$</p></li></ol><p>举例说明（MLP），计算第t层的导数：</p><ol><li>$ h^t=f_t(h^{t-1})=\sigma(W^th^{t-1})$，$\sigma$ 是激活函数；</li><li>$\frac{\delta h^{t}}{\delta h^{t-1}}=diag(\sigma’(W^th^{t-1}))(W^t)^T$ ，$\sigma’$ 是$\sigma$ 的导数函数，求导目的是计算梯度更新权重</li><li>$\prod_{i = t}^{d-1}\frac{\delta h^{i+1}}{\delta h^{i}}=\prod_{i=t}^{d-1}diag(\sigma’(W^ih^{i-1}))(W^i)^T$</li></ol><h4><span id="121-梯度爆炸">1.2.1 梯度爆炸</span></h4><p>简单来说就是梯度误差的积累（梯度误差总是$&gt;1$的）引起的梯度爆炸，假设我们此处使用 ReLU 作为激活函数 </p><script type="math/tex; mode=display">\sigma(x)=max(0,x)~~and~~\sigma'=\begin{cases}1,\quad if\quad x> 0 \\[2ex]0,\quad otherwise\end{cases}\tag{1}</script><p>使用上面激活函数在计算 $\prod_{i = t}^{d-1}\frac{\delta h^{i+1}}{\delta h^{i}}=\prod_{i=t}^{d-1}diag(\sigma’(W^ih^{i-1}))(W^i)^T$ 的一些元素会来自于 $\prod_{i = t}^{d-1}(W^i)^T$。如果 d-t 很大（即网络层数很深），假设W中存在很多大于1的数，那么最终结果值将会很大。</p><p><strong>导致的问题：</strong></p><ol><li><p>值超出值域 (infinity)</p><ol><li>对于 16 位浮点数尤为严重 (数值区间 6e-5 - 6e4)</li></ol></li><li><p>对学习率敏感</p><ol><li><p>如果学习率太大 -&gt; 大参数值 -&gt; 更大的梯度;</p><p>（解释：当学习率大了，取值大的参数会迅速变大，一个参数过大会导致同一层的别的参数也变大，进而是梯度更大）</p></li><li><p>如果学习率太小 -&gt; 训练无进展；</p><p>（解释：学习率太小的话，对参数$W$ 的更新就很小）</p></li><li><p>我们可能需要在训练过程中不断调整学习率</p></li></ol></li></ol><p>解决方式：</p><ol><li>重现设计神经网络：减少网络层数、减小batch szie、截断。</li><li>使用LSTM；</li><li>使用梯度裁剪：<code>clipnorm=1.0 clipvalue=0.5</code>；</li><li>使用权重正则：L1 &amp; L2</li></ol><h4><span id="122-梯度消失">1.2.2 梯度消失</span></h4><p>使用sigmoid 作为激活函数</p><script type="math/tex; mode=display">\sigma=\frac{1}{1+e^{-x}}\\\sigma'(x)=\sigma(x)(1-\sigma(x))</script><p><img src="http://xiaomanzhan.com.cn/content/image-20220430171424982.png" alt="image-20220430171424982" style="zoom:67%;"></p><p>使用上面激活函数在计算 $\prod_{i = t}^{d-1}\frac{\delta h^{i+1}}{\delta h^{i}}=\prod_{i=t}^{d-1}diag(\sigma’(W^ih^{i-1}))(W^i)^T$ 的元素值是 d-t 个小数值的乘积：$0.8^{100}\approx4\times 10^{17}$</p><p><strong>导致的问题</strong></p><ol><li>梯度值变为0<ol><li>对16位浮点数尤为严重</li></ol></li><li>训练没有进展<ol><li>不管如何选择学习率</li></ol></li><li>对底部层尤为严重<ol><li>仅仅顶层训练的较好；</li><li>无法让神经网络更深</li></ol></li></ol><h2><span id="2-让训练更加稳定">2. 让训练更加稳定</span></h2><p>想要让训练更加稳定就必须将梯度控制在合理的范围（我们的目标），解决方案如下：</p><ol><li>将乘法变加法：如ResNet、LSTM神经网络；</li><li>归一化：梯度归一化、梯度裁剪；</li><li>合理的权重初始化和激活函数</li></ol><h3><span id="21-让每层的方差是一个常数">2.1 让每层的方差是一个常数</span></h3><p>数据归一化：让每层的方差是一个常数。将每层的输出和梯度度看做随机变量，并且让他们的均值和方差保持一致。</p><h3><span id="22-权重初始化">2.2 权重初始化</span></h3><ul><li>在合理的区间里随机初始参数。</li><li>因为在训练开始的时候更容易有数值不稳定的情况<ul><li>在原理最优解的地方损失函数表面可能很复杂</li><li>最优解附近表面会比较评</li></ul></li><li>使用 $\N(0,0.01)$ 来初始化可能对小网络没问题，但是不能保证深度神经网络</li></ul><h3><span id="23-检测常用的激活函数">2.3 检测常用的激活函数</span></h3><p>使用泰勒展开：</p><script type="math/tex; mode=display">sigmoid(x)=\frac{1}{2}+\frac{x}{4}-\frac{x^3}{48}+O(x^5)</script><script type="math/tex; mode=display">\tanh(x)=0+x-\frac{x^3}{3}+O(x^5)</script><script type="math/tex; mode=display">relu(x)=0+x\quad for~x\geq0</script><p>调整之后的sigmoid函数（scaled sigmoid函数），变换之后能够解决之前带来的梯度消失的问题</p><script type="math/tex; mode=display">4\times sigmoid(x)-2</script><p><img src="http://xiaomanzhan.com.cn/content/image-20220430181715053.png" alt="image-20220430181715053"></p><h2><span id="3-激活函数">3. 激活函数</span></h2><p>激活函数（Activation Function）是一种添加到人工神经网络中的函数，旨在帮助网络学习数据中的复杂模式。类似于人类大脑中基于神经元的模型，激活函数最终决定了要发射给下一个神经元的内容。</p><ul><li>Softmax</li><li>Sigmoid</li><li>Tanh</li><li><strong>ReLU</strong>（以及基于ReLU的改进系列：Leaky ReLU、ELU、PReLU等）</li><li>Gelu（Gaussian Error Linear Unit，2016年被提出，直到2018年Bert开始使用才被重视）</li><li>Swish（2017年google提出）</li></ul><h3><span id="31-sigmoid">3.1 Sigmoid</span></h3><script type="math/tex; mode=display">f(x)=\frac{1}{1+e^{-x}}</script><p>如下图所示：</p><p><img src="http://xiaomanzhan.com.cn/content/nhi9swy8ln.png" alt="img" style="zoom:67%;"></p><p>在什么情况下适合使用 Sigmoid 激活函数呢？</p><ul><li>Sigmoid 函数的输出范围是 0 到 1。由于输出值限定在 0 到 1，因此它对每个神经元的输出进行了归一化；</li><li>用于将预测概率作为输出的模型。由于概率的取值范围是 0 到 1，因此 Sigmoid 函数非常合适；</li><li>梯度平滑，避免「跳跃」的输出值；</li><li>函数是可微的。这意味着可以找到任意两个点的 sigmoid 曲线的斜率；</li><li>明确的预测，即非常接近 1 或 0。</li></ul><h4><span id="311-sigmoid的变体">3.1.1 Sigmoid的变体</span></h4><p>对于 Sigmoid 可能存在的梯度消失的问题，可以考虑将Sigmoid输出的范围扩大到 <code>[-1, 1]</code> 之间，能够在一定程度上缓解梯度消失。即 Scale Sigmoid</p><script type="math/tex; mode=display">f(x)=\frac{4}{1+e^{-x}}-2</script><h3><span id="32-tanh">3.2 Tanh</span></h3><p>Tanh激活函数又名 双曲正切激活函数，公式如下所示：</p><script type="math/tex; mode=display">f(x)=tanh(x)=\frac{2}{1+e^{-2x}}-1</script><p>如下图所示：</p><p><img src="http://xiaomanzhan.com.cn/content/gm9p8du88z.png" alt="img"></p><p>与 sigmoid 的优缺点：</p><ol><li>当输入较大或较小时，输出几乎是平滑的并且梯度较小，这不利于权重更新。</li><li>二者的区别在于输出间隔，tanh 的输出间隔为 1，并且整个函数以 0 为中心，比 sigmoid 函数更好；</li><li>在 tanh 图中，负输入将被强映射为负，而零输入被映射为接近零。</li></ol><p><strong>注意：</strong>在一般的二元分类问题中，tanh 函数用于隐藏层，而 sigmoid 函数用于输出层，但这并不是固定的，需要根据特定问题进行调整。</p><h3><span id="33-relu">3.3 ReLU</span></h3><script type="math/tex; mode=display">\sigma(x)=max(0,x)</script><p><img src="http://xiaomanzhan.com.cn/content/ck888so4in.png" alt="img"></p><p>ReLU 函数是深度学习中较为流行的一种激活函数，相比于 sigmoid 函数和 tanh 函数，它具有如下优点：</p><ul><li>当输入为正时，不存在梯度饱和问题。</li><li>计算速度快得多。ReLU 函数中只存在线性关系，因此它的计算速度比 sigmoid 和 tanh 更快。</li></ul><p>当然，它也有缺点：</p><ol><li>Dead ReLU 问题（<strong>神经元“死亡”问题</strong>）。当输入为负时，ReLU 完全失效，在正向传播过程中，这不是问题。有些区域很敏感，有些则不敏感。但是在反向传播过程中，如果输入负数，则梯度将完全为零，sigmoid 函数和 tanh 函数也具有相同的问题；</li><li>我们发现 ReLU 函数的输出为 0 或正数，这意味着 ReLU 函数不是以 0 为中心的函数。</li></ol><h3><span id="34-leaky-relu">3.4 Leaky ReLU</span></h3><p>它是一种专门设计用于解决 Dead ReLU 问题的激活函数：</p><script type="math/tex; mode=display">f(y_i)=\begin{cases}y_i,\quad if~y_i> 0 \\[2ex]a_iy_i,\quad if~y_i\leq 0\end{cases}\tag{1}</script><p><img src="http://xiaomanzhan.com.cn/content/zdls8bt48h.png" alt="img"></p><p>Leaky ReLU 通过把 x 的非常小的线性分量给予负输入（0.01x）来调整负值的零梯度（zero gradients）问题；</p><ol><li>leak 有助于扩大 ReLU 函数的范围，通常 a 的值为 0.01 左右；</li><li>Leaky ReLU 的函数范围是（负无穷到正无穷）。</li></ol><p>注意：从理论上讲，Leaky ReLU 具有 ReLU 的所有优点，而且 Dead ReLU 不会有任何问题，但在实际操作中，尚未完全证明 Leaky ReLU 总是比 ReLU 更好。</p><h3><span id="35-elu">3.5 ELU</span></h3><script type="math/tex; mode=display">g(x)=ELU(x)=\begin{cases}x,\quad\quad\quad\quad if~y_i> 0 \\[2ex]\alpha(e^x-1),\quad if~y_i\leq 0\end{cases}\tag{1}</script><p>ELU 的提出也解决了 ReLU 的问题。与 ReLU 相比，ELU 有负值，这会使激活的平均值接近零。均值激活接近于零可以使学习更快，因为它们使梯度更接近自然梯度。</p><p><img src="http://xiaomanzhan.com.cn/content/ygenzy9ncs.png" alt="img"></p><p>显然，ELU 具有 ReLU 的所有优点，并且：</p><ul><li>没有 Dead ReLU 问题，输出的平均值接近 0，以 0 为中心；</li><li>ELU 通过减少偏置偏移的影响，使正常梯度更接近于单位自然梯度，从而使均值向零加速学习；</li><li>ELU 在较小的输入下会饱和至负值，从而减少前向传播的变异和信息。</li></ul><p>一个小问题是它的计算强度更高。与 Leaky ReLU 类似，尽管理论上比 ReLU 要好，但目前在实践中没有充分的证据表明 ELU 总是比 ReLU 好。</p><h3><span id="36-gelu">3.6 GELU</span></h3><p>高斯误差线性单元激活函数，在最近的Transformer模型（谷歌的BERT和OpenAI的GPT-2）中得到了应用,GELU的论文来自2016年，但是最近才引起关注，这种激活函数的形式为：</p><script type="math/tex; mode=display">GELU(x)=xP(X\leq{x})=x\Phi(x)\\</script><p>其中 $\Phi(x)$ 指的是 $x$ 的高斯正态分布的累积分布，完整形式如下：</p><script type="math/tex; mode=display">xP(X\leq{x})=x\int^x_{-\infty}\frac{e^{-\frac{(X-\mu)^2}{2\sigma^2}}}{\sqrt{2\pi\sigma}}dX\\=0.5x(1+tanh[\sqrt{\frac{2}{\pi}}(x+0.044715x^3)])=x\sigma(1.702x)</script><p>GELU的函数图像（左）及其导数图像（右）如下图所示：</p><p><img src="http://xiaomanzhan.com.cn/content/gelu_viz-1.png" alt="GELU"></p><p>可以看出，当x越大的时候，就越有可能被保留，x越小就越有可能被归置为0.</p><h3><span id="37-swish">3.7 Swish</span></h3><script type="math/tex; mode=display">f(x)=x\cdot sigmoid(\beta x)</script><p><img src="http://xiaomanzhan.com.cn/content/20200703101353980.png" alt="在这里插入图片描述" style="zoom:67%;"></p><ul><li><p>当 $\beta=0$ 时，Swish激活函数变为线性函数 $f(x) = x/2$ </p></li><li><p>当 $ \beta= \infty$ 时，Swish激活函数变为0或x，相当于 Relu，</p></li></ul><p>所以，Swish函数可以看作是介于线性函数与ReLU函数之间的平滑函数。</p><h2><span id="4-总结">4. 总结</span></h2><ol><li>权重的初始值和激活函数的选取可以提升数值稳定性；</li><li>Sigmoid和Tanh很相似，但后者的梯度更陡，都会存在梯度消失、梯度爆炸的风险。</li><li>ReLU函数一大优点是不会激活所有神经元，前向传播时如果输入是负值，则该神经元不会被激活，那么反向传播时梯度就是0，该神经元权重不会更新，就会变成死神经元。</li><li>基于ReLU死神经元的这种缺点，才提出了Leaky ReLU、ELU、PReLU等。</li><li>Gelu和Swish很相似，在论文中的对比结果也很相近，他们的区别在于前者固定了系数为1.702，后者的系数是可以选择固定为常数，也可以选择为可训练的参数。</li></ol><h2><span id="5-相关面试题">5. 相关面试题</span></h2><p><strong>1.什么是激活函数，为什么需要激活函数？</strong></p><p>激活函数是在神经网络层间输入与输出之间的一种函数变换，目的是为了加入非线性因素，增强模型的表达能力。</p><p>如果没有激活函数，那么模型就只有线性变换，可想而知线性模型能表达的空间是有限的。而激活函数引入了非线性因素，比线性模型拥有更大的模型空间。</p><p><strong>2.了解那些激活函数以及应用？</strong></p><p>回答主要分两类（饱和/非饱和），以及应用场景等。有时候可能特定到具体经典模型，比如LSTM用到Tanh，Transfromer中用到的ReLU，Bert中的GeLU，YOLO的Leaky ReLU等。</p><p><strong>3.梯度消失与梯度爆炸现象与原因以及解决办法？</strong></p><p>参看梯度消失与梯度爆炸部分。</p><p><strong>4.ReLU激活函数为什么会出现死神经元，解决办法？</strong></p><ol><li>除上文提到输入为负值时，ReLU的梯度为0造成神经元死亡。</li><li>还有Learning rate太高导致在训练过程中参数更新太大 。</li><li>初始化参数的问题。 —&gt; 采用Xavier初始化方法。</li></ol><p>解决办法主要有：</p><ol><li>优化参数。 </li><li>避免将learning rate设置太大，或者使用Adam等自动调节learning rate的方法。</li><li>更换激活函数。</li></ol><p><strong>5.如何选择激活函数？</strong></p><ol><li>除非在二分类问题中，否则请小心使用Sigmoid函数。</li><li>对于长序列的问题，隐藏层中尽量避免使用Sigmoid和Tanh，会造成梯度消失的问题；</li><li>可以试试Tanh，不过大多数情况下它的效果会比不上 ReLU 和 Maxout。</li><li>如果你不知道应该使用哪个激活函数， 那么请优先选择ReLU。</li><li>如果你使用了ReLU， 需要注意一下Dead ReLU问题， 此时你需要仔细选择 Learning rate， 避免出现大的梯度从而导致过多的神经元 “Dead” 。</li><li>如果发生了Dead ReLU问题， 可以尝试一下leaky ReLU，ELU等ReLU变体， 说不定会有很好效果。</li><li>Relu在Gelu出现之前在大多数情况下比较通用，但也只能在隐层中使用；</li><li>现在2021年了，隐藏层中主要的选择肯定优先是Gelu、Swish了。</li></ol><p><strong>6. transformer FFN层用的激活函数是什么？为什么？</strong></p><p>ReLU.</p><blockquote><p>可以把ReLU的优点提一下，然后提一下解决ReLU死神经元问题的方案。</p></blockquote><p>ReLU的优点是收敛速度快、不会出现梯度消失or爆炸的问题、计算复杂度低。</p><p>出现死神经元的原因及解决方案：</p><ul><li>初始化参数的问题。 —&gt; 采用Xavier初始化方法。</li><li>learning rate太高导致在训练过程中参数更新太大 。==&gt;避免将learning rate设置太大，或者使用Adam等自动调节learning rate的方法。</li><li>更换激活函数。 —&gt; Leaky ReLU、PReLU、ELU等都是为了解决死神经元的问题。</li></ul><p><strong>7. Bert、GPT、GPT2中用的激活函数是什么？为什么？</strong></p><p>Gelu.</p><blockquote><p>使用Gelu时，一般优化器都会选择动态更新lr的方法。</p></blockquote><p>Bert、GPT、GPT2、RoBERTa、ALBERT都是用的Gelu。</p><p>直观理解：x做为神经元的输入，P(X&lt;=x)越大，x就越有可能被保留；否则越小，激活函数输出就趋近于0.</p><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 数据稳定性 </tag>
            
            <tag> 激活函数 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据预处理-数据归一化</title>
      <link href="/2022/04/30/machine-learning/shu-ju-yu-chu-li-shu-ju-gui-yi-hua/"/>
      <url>/2022/04/30/machine-learning/shu-ju-yu-chu-li-shu-ju-gui-yi-hua/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="数据预处理-数据归一化">数据预处理-数据归一化</span></h1><h2><span id="1-为什么归一化">1. 为什么归一化</span></h2><p>我们知道在机器学习的一些树模型中是不需要进行数据归一化的，例如：<code>GBDT、XGBoost、CatBoost</code> 等，但是当我们使用 <strong>梯度下降（Gradient Descent GD）</strong> 的方法对模型（例如：LR、NN等）进行更新时，会使得模型的精度不足，训练速度慢。</p><h3><span id="11-树模型构造">1.1 树模型构造</span></h3><p>树模型是以点的分裂进行构建模型的，而数值的缩放是不影响分裂点的位置，对数据进行缩放预处理并不会对树模型造成任何影响。分裂点的位置是和特征值的相对分布相关的。</p><h3><span id="12-其他模型">1.2 其他模型</span></h3><p>以 <code>KNN</code> 为例，我们需要计算样本之间的欧式距离，如果样本两个属性的量纲差距过大，则大量纲的属性在距离计算中就占据了主导地位。而现实中，可能恰恰相反。所以，加入归一化，将数据的特征属性 <code>scale</code>到统一量纲，可以一定程度解决这个问题。</p><h2><span id="2-归一化优势">2. 归一化优势</span></h2><p>下面我们谈一谈归一化的好处：</p><ol><li><p>能够在一定程度上提高模型的精度，在深度学习或者深度学习时，很多模型<code>loss</code> 的计算都是假定所有特征都是在零均值并且具有同一方差的，这能够使得所有的特征进行统一处理。</p></li><li><p>提升模型的收敛速度，以下面两个图为例，可以看到左边模型（未使用归一化）的更新是一个“之”字型，而不是直线接近中心点（最优参数）的；而右边的模型（使用归一化）的参数的更新是呈现一条直线的，参数信息收敛速度快。</p><p><img src="http://xiaomanzhan.com.cn/content/20200805221327218.png" alt="未使用归一化" style="zoom:67%;"><img src="http://xiaomanzhan.com.cn/content/20200805221357566.png" alt="使用归一化" style="zoom:67%;"></p></li></ol><h2><span id="3-归一化方法">3. 归一化方法</span></h2><h3><span id="31-标准化">3.1 标准化</span></h3><p>将数据转化为 均值为0，方差为1 的正态分布， $x=(x-\mu)/\sigma$</p><p>在构建数据集时，我们会将训练集的均值和方差记录下来，在后续 model 使用或者测试时，对数据预处理时使用。</p><p><strong>优点：</strong>这种方法对离群点的鲁棒性较高，但是离群点数量太多的时候，会影响性能。</p><h3><span id="32-max-min-归一化">3.2 max-min 归一化</span></h3><p>将数据缩放到 <code>[0,1]</code>之间，$x=(x-\min)/(\max-\min)$ </p><p>这种方法可以保留稀疏特征中的0， 并且可以解决到特征的方差很小的情况时的数据。但是此方法对噪音敏感。</p><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
          <category> 数据预处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 归一化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode908</title>
      <link href="/2022/04/30/leetcode/mei-ri-yi-ti/leetcode908/"/>
      <url>/2022/04/30/leetcode/mei-ri-yi-ti/leetcode908/</url>
      
        <content type="html"><![CDATA[<h1><span id="908-最小差值-i">908. 最小差值 I</span></h1><blockquote><ol><li>最小差值 I：<a href="https://leetcode-cn.com/problems/smallest-range-i/">https://leetcode-cn.com/problems/smallest-range-i/</a></li></ol></blockquote><h2><span id="题目">题目</span></h2><p>给你一个整数数组 <code>nums</code>，和一个整数 <code>k</code> 。</p><p>在一个操作中，您可以选择 <code>0 &lt;= i &lt; nums.length</code> 的任何索引 <code>i</code> 。将 <code>nums[i]</code> 改为 <code>nums[i] + x</code> ，其中 <code>x</code> 是一个范围为 <code>[-k, k]</code> 的整数。对于每个索引 <code>i</code> ，最多 只能 应用 一次 此操作。<code>nums</code> 的 分数 是 <code>nums</code> 中最大和最小元素的差值。 在对  <code>nums</code> 中的每个索引最多应用一次上述操作后，返回 <code>nums</code> 的最低 分数 。</p><h2><span id="示例">示例</span></h2><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">示例 1：</span><br><span class="line">输入：nums = [1], k = 0</span><br><span class="line">输出：0</span><br><span class="line">解释：分数是 max(nums) - min(nums) = 1 - 1 = 0。</span><br><span class="line"></span><br><span class="line">示例 2：</span><br><span class="line">输入：nums = [0,10], k = 2</span><br><span class="line">输出：6</span><br><span class="line">解释：将 nums 改为 [2,8]。分数是 max(nums) - min(nums) = 8 - 2 = 6。</span><br><span class="line"></span><br><span class="line">示例 3：</span><br><span class="line">输入：nums = [1,3,6], k = 3</span><br><span class="line">输出：0</span><br><span class="line">解释：将 nums 改为 [4,4,4]。分数是 max(nums) - min(nums) = 4 - 4 = 0。</span><br></pre></td></tr></tbody></table></figure><h2><span id="解题思路">解题思路</span></h2><p>分情况讨论即可：</p><ol><li><code>len(nums)==1</code> 时，返回<code>0</code> 即可；</li><li>当 <code>max(nums) - min(nums)&gt;=2*|k|</code> 的时候，返回 <code>max(nums) - min(nums) - 2*|k|</code>；</li><li>当 <code>max(nums) - min(nums)&lt; 2*|k|</code> 的时候，返回 <code>0</code>；</li></ol><h3><span id="题解">题解</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">smallestRangeI</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], k: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(nums) == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        max_num, min_num = <span class="built_in">max</span>(nums), <span class="built_in">min</span>(nums)</span><br><span class="line">        <span class="keyword">if</span> max_num - min_num &gt;= k * <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">return</span> max_num - min_num - k * <span class="number">2</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> 难度-简单 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeetCode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode427</title>
      <link href="/2022/04/29/leetcode/mei-ri-yi-ti/leetcode427/"/>
      <url>/2022/04/29/leetcode/mei-ri-yi-ti/leetcode427/</url>
      
        <content type="html"><![CDATA[<h1><span id="427-建立四叉树">427. 建立四叉树</span></h1><blockquote><ol><li>建立四叉树：<a href="https://leetcode-cn.com/problems/construct-quad-tree/">https://leetcode-cn.com/problems/construct-quad-tree/</a></li></ol></blockquote><h2><span id="题目">题目</span></h2><p>给你一个 <code>n * n</code> 矩阵 <code>grid</code> ，矩阵由若干 <code>0</code> 和 <code>1</code> 组成。请你用四叉树表示该矩阵 <code>grid</code> 。你需要返回能表示矩阵的 四叉树 的根结点。</p><p><strong>注意</strong>，当 <code>isLeaf</code> 为 <code>False</code> 时，你可以把 <code>True</code> 或者 <code>False</code> 赋值给节点，两种值都会被判题机制 接受 。</p><p>四叉树数据结构中，每个内部节点只有四个子节点。此外，每个节点都有两个属性：</p><ul><li>val：储存叶子结点所代表的区域的值。1 对应 True，0 对应 False；</li><li>isLeaf: 当这个节点是一个叶子结点时为 True，如果它有 4 个子节点则为 False 。</li></ul><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">class Node {</span><br><span class="line">    public boolean val;</span><br><span class="line">    public boolean isLeaf;</span><br><span class="line">    public Node topLeft;</span><br><span class="line">    public Node topRight;</span><br><span class="line">    public Node bottomLeft;</span><br><span class="line">    public Node bottomRight;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>我们可以按以下步骤为二维区域构建四叉树：</p><ol><li>如果当前网格的值相同（即，全为 <code>0</code> 或者全为 <code>1</code>），将 <code>isLeaf</code> 设为 <code>True</code>，将 <code>val</code> 设为网格相应的值，并将四个子节点都设为 <code>Null</code> 然后停止。</li><li>如果当前网格的值不同，将 <code>isLeaf</code> 设为 <code>False</code>， 将 <code>val</code> 设为任意值，然后如下图所示，将当前网格划分为四个子网格。</li><li>使用适当的子网格递归每个子节点。</li></ol><p><img src="http://xiaomanzhan.com.cn/content/new_top.png" alt="img"></p><p><strong>四叉树格式：</strong></p><p>输出为使用层序遍历后四叉树的序列化形式，其中 <code>null</code> 表示路径终止符，其下面不存在节点。</p><p>它与二叉树的序列化非常相似。唯一的区别是节点以列表形式表示 <code>[isLeaf, val]</code> 。</p><p>如果 <code>isLeaf</code> 或者 <code>val</code> 的值为 <code>True</code> ，则表示它在列表 <code>[isLeaf, val]</code> 中的值为 <code>1</code> ；如果 <code>isLeaf</code> 或者 <code>val</code> 的值为 <code>False</code> ，则表示值为 <code>0</code> 。</p><h2><span id="示例">示例</span></h2><p>示例一：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">输入：grid = [[<span class="number">0</span>,<span class="number">1</span>],[<span class="number">1</span>,<span class="number">0</span>]]</span><br><span class="line">输出：[[<span class="number">0</span>,<span class="number">1</span>],[<span class="number">1</span>,<span class="number">0</span>],[<span class="number">1</span>,<span class="number">1</span>],[<span class="number">1</span>,<span class="number">1</span>],[<span class="number">1</span>,<span class="number">0</span>]]</span><br><span class="line">解释：此示例的解释如下：</span><br><span class="line">请注意，在下面四叉树的图示中，<span class="number">0</span> 表示 false，<span class="number">1</span> 表示 <span class="literal">True</span> 。</span><br></pre></td></tr></tbody></table></figure><p><img src="http://xiaomanzhan.com.cn/content/e1tree.png" alt="img"></p><p>示例二：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">输入：grid = [[1,1,1,1,0,0,0,0],[1,1,1,1,0,0,0,0],[1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1],[1,1,1,1,0,0,0,0],[1,1,1,1,0,0,0,0],[1,1,1,1,0,0,0,0],[1,1,1,1,0,0,0,0]]</span><br><span class="line">输出：[[0,1],[1,1],[0,1],[1,1],[1,0],null,null,null,null,[1,0],[1,0],[1,1],[1,1]]</span><br><span class="line">解释：网格中的所有值都不相同。我们将网格划分为四个子网格。</span><br><span class="line">topLeft，bottomLeft 和 bottomRight 均具有相同的值。</span><br><span class="line">topRight 具有不同的值，因此我们将其再分为 4 个子网格，这样每个子网格都具有相同的值。</span><br><span class="line">解释如下图所示：</span><br></pre></td></tr></tbody></table></figure><p><img src="http://xiaomanzhan.com.cn/content/e2tree.png" alt="img"></p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">示例 3：</span><br><span class="line">输入：grid = [[1,1],[1,1]]</span><br><span class="line">输出：[[1,1]]</span><br><span class="line"></span><br><span class="line">示例 4：</span><br><span class="line">输入：grid = [[0]]</span><br><span class="line">输出：[[1,0]]</span><br><span class="line"></span><br><span class="line">示例 5：</span><br><span class="line">输入：grid = [[1,1,0,0],[1,1,0,0],[0,0,1,1],[0,0,1,1]]</span><br><span class="line">输出：[[0,1],[1,1],[1,0],[1,0],[1,1]]</span><br></pre></td></tr></tbody></table></figure><h2><span id="解题思路">解题思路</span></h2><p>使用深度优先搜索的方式进行遍历，当访问最后层时应该时一个单元格，深度优先搜索此时返回此单元格构成的节点。返回上一层，由此可以得到 <code>topLeft</code>、<code>topRight</code>、<code>bottomLeft</code>、<code>bottomRight</code> 四个区域的信息，如果这四个区域都是叶子节点，而且都有一样的值，则当前四个区域组成的大区域也是叶子节点，进行返回。</p><h3><span id="题解">题解</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string"># Definition for a QuadTree node.</span></span><br><span class="line"><span class="string">class Node:</span></span><br><span class="line"><span class="string">    def __init__(self, val, isLeaf, topLeft, topRight, bottomLeft, bottomRight):</span></span><br><span class="line"><span class="string">        self.val = val</span></span><br><span class="line"><span class="string">        self.isLeaf = isLeaf</span></span><br><span class="line"><span class="string">        self.topLeft = topLeft</span></span><br><span class="line"><span class="string">        self.topRight = topRight</span></span><br><span class="line"><span class="string">        self.bottomLeft = bottomLeft</span></span><br><span class="line"><span class="string">        self.bottomRight = bottomRight</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">construct</span>(<span class="params">self, grid: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]</span>) -&gt; <span class="string">'Node'</span>:</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">dfs</span>(<span class="params">x1, y1, x2, y2</span>):</span><br><span class="line">            <span class="keyword">if</span> x1 == x2 <span class="keyword">and</span> y1 == y2:</span><br><span class="line">                <span class="keyword">return</span> Node(grid[x1][y1], <span class="literal">True</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>)</span><br><span class="line">            topLNode = dfs(x1, y1, (x1 + x2 - <span class="number">1</span>) // <span class="number">2</span>, (y1 + y2 - <span class="number">1</span>) // <span class="number">2</span>)</span><br><span class="line">            topRNode = dfs(x1, (y1 + y2 + <span class="number">1</span>) // <span class="number">2</span>, (x1 + x2 - <span class="number">1</span>) // <span class="number">2</span>, y2)</span><br><span class="line">            bottomLNode = dfs((x1 + x2 + <span class="number">1</span>) // <span class="number">2</span>, y1, x2, (y1 + y2 - <span class="number">1</span>) // <span class="number">2</span>)</span><br><span class="line">            bottomRNode = dfs((x1 + x2 + <span class="number">1</span>) // <span class="number">2</span>, (y1 + y2 + <span class="number">1</span>) // <span class="number">2</span>, x2, y2)</span><br><span class="line">            <span class="keyword">if</span> topLNode.val == topRNode.val == bottomLNode.val == bottomRNode.val <span class="keyword">and</span> topLNode.val != <span class="number">2</span>:</span><br><span class="line">                <span class="keyword">return</span> Node(topLNode.val, <span class="literal">True</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>)</span><br><span class="line">            <span class="keyword">return</span> Node(<span class="number">2</span>, <span class="literal">False</span>, topLNode, topRNode, bottomLNode, bottomRNode)</span><br><span class="line">        <span class="keyword">return</span> dfs(<span class="number">0</span>, <span class="number">0</span>, <span class="built_in">len</span>(grid) - <span class="number">1</span>, <span class="built_in">len</span>(grid) - <span class="number">1</span>)</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> 难度-中等 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeetCode </tag>
            
            <tag> 深度优先搜索 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode905</title>
      <link href="/2022/04/28/leetcode/mei-ri-yi-ti/leetcode905/"/>
      <url>/2022/04/28/leetcode/mei-ri-yi-ti/leetcode905/</url>
      
        <content type="html"><![CDATA[<h1><span id="905-按奇偶排序数组">905. 按奇偶排序数组</span></h1><blockquote><p><a href="https://leetcode-cn.com/problems/sort-array-by-parity/">905. 按奇偶排序数组</a></p></blockquote><h2><span id="题目">题目</span></h2><p>给你一个整数数组 <code>nums</code>，将 <code>nums</code> 中的的所有偶数元素移动到数组的前面，后跟所有奇数元素。返回满足此条件的 <strong>任一数组</strong> 作为答案。</p><h2><span id="示例">示例</span></h2><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">示例 1：</span><br><span class="line">输入：nums = [3,1,2,4]</span><br><span class="line">输出：[2,4,3,1]</span><br><span class="line">解释：[4,2,3,1]、[2,4,1,3] 和 [4,2,1,3] 也会被视作正确答案。</span><br><span class="line"></span><br><span class="line">示例 2：</span><br><span class="line">输入：nums = [0]</span><br><span class="line">输出：[0]</span><br></pre></td></tr></tbody></table></figure><h2><span id="解题思路">解题思路</span></h2><p>从左右双方开始进行遍历，出现奇数或者偶数进行交换位置，再次进行交换。</p><h3><span id="题解">题解</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sortArrayByParity</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        l, r = <span class="number">0</span>, <span class="built_in">len</span>(nums) - <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> l &lt; r:</span><br><span class="line">            <span class="keyword">if</span> nums[l] % <span class="number">2</span> != <span class="number">0</span>:</span><br><span class="line">                k = nums[r]</span><br><span class="line">                nums[r] = nums[l]</span><br><span class="line">                nums[l] = k</span><br><span class="line">                r -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                l += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> nums</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> 难度-中等 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeetCode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode417</title>
      <link href="/2022/04/27/leetcode/mei-ri-yi-ti/leetcode417/"/>
      <url>/2022/04/27/leetcode/mei-ri-yi-ti/leetcode417/</url>
      
        <content type="html"><![CDATA[<h1><span id="417-太平洋大西洋水流问题">417. 太平洋大西洋水流问题</span></h1><blockquote><p><a href="https://leetcode-cn.com/problems/pacific-atlantic-water-flow/">417. 太平洋大西洋水流问题</a></p></blockquote><h2><span id="题目">题目</span></h2><p>有一个 <code>m × n</code> 的矩形岛屿，与 太平洋 和 大西洋 相邻。 “太平洋” 处于大陆的左边界和上边界，而 “大西洋” 处于大陆的右边界和下边界。</p><p>这个岛被分割成一个由若干方形单元格组成的网格。给定一个 <code>m x n</code> 的整数矩阵 <code>heights</code> ， <code>heights[r][c]</code> 表示坐标 <code>(r, c)</code> 上单元格 高于海平面的高度 。</p><p>岛上雨水较多，如果相邻单元格的高度 小于或等于 当前单元格的高度，雨水可以直接向北、南、东、西流向相邻单元格。水可以从海洋附近的任何单元格流入海洋。</p><p>返回网格坐标 <code>result</code> 的 <code>2D</code> 列表 ，其中 <code>result[i] = [ri, ci]</code> 表示雨水从单元格 <code>(ri, ci)</code> 流动 既可流向太平洋也可流向大西洋 。</p><h2><span id="示例">示例</span></h2><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">示例 1：</span><br><span class="line">输入: heights = [[1,2,2,3,5],[3,2,3,4,4],[2,4,5,3,1],[6,7,1,4,5],[5,1,1,2,4]]</span><br><span class="line">输出: [[0,4],[1,3],[1,4],[2,2],[3,0],[3,1],[4,0]]</span><br><span class="line"></span><br><span class="line">示例 2：</span><br><span class="line">输入: heights = [[2,1],[1,2]]</span><br><span class="line">输出: [[0,0],[0,1],[1,0],[1,1]]</span><br></pre></td></tr></tbody></table></figure><h2><span id="解题思路一">解题思路一</span></h2><p>使用深度有限搜索或者广度有限搜索的方案，分别从太平洋或大西洋沿岸的点开始遍历，从低向高处走，将从太平洋或大西洋开始所经过的点分别做一个Set集合，做交集即最终解。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">pacificAtlantic</span>(<span class="params">self, heights: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span><br><span class="line">        m, n = <span class="built_in">len</span>(heights), <span class="built_in">len</span>(heights[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">search</span>(<span class="params">starts: <span class="type">List</span>[<span class="type">Tuple</span>[<span class="built_in">int</span>, <span class="built_in">int</span>]]</span>) -&gt; <span class="type">Set</span>[<span class="type">Tuple</span>[<span class="built_in">int</span>, <span class="built_in">int</span>]]:</span><br><span class="line">            visited = <span class="built_in">set</span>()</span><br><span class="line">            <span class="keyword">def</span> <span class="title function_">dfs</span>(<span class="params">x: <span class="built_in">int</span>, y: <span class="built_in">int</span></span>):</span><br><span class="line">                <span class="keyword">if</span> (x, y) <span class="keyword">in</span> visited:</span><br><span class="line">                    <span class="keyword">return</span></span><br><span class="line">                visited.add((x, y))</span><br><span class="line">                <span class="keyword">for</span> nx, ny <span class="keyword">in</span> ((x, y + <span class="number">1</span>), (x, y - <span class="number">1</span>), (x - <span class="number">1</span>, y), (x + <span class="number">1</span>, y)):</span><br><span class="line">                    <span class="keyword">if</span> <span class="number">0</span> &lt;= nx &lt; m <span class="keyword">and</span> <span class="number">0</span> &lt;= ny &lt; n <span class="keyword">and</span> heights[nx][ny] &gt;= heights[x][y]:</span><br><span class="line">                        dfs(nx, ny)</span><br><span class="line">            <span class="keyword">for</span> x, y <span class="keyword">in</span> starts:</span><br><span class="line">                dfs(x, y)</span><br><span class="line">            <span class="keyword">return</span> visited</span><br><span class="line"></span><br><span class="line">        pacific = [(<span class="number">0</span>, i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)] + [(i, <span class="number">0</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, m)]</span><br><span class="line">        atlantic = [(m - <span class="number">1</span>, i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)] + [(i, n - <span class="number">1</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m - <span class="number">1</span>)]</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">list</span>, search(pacific) &amp; search(atlantic)))</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> 难度-中等 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeetCode </tag>
            
            <tag> 广度优先搜索 </tag>
            
            <tag> 深度优先搜索 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode883</title>
      <link href="/2022/04/26/leetcode/mei-ri-yi-ti/leetcode883/"/>
      <url>/2022/04/26/leetcode/mei-ri-yi-ti/leetcode883/</url>
      
        <content type="html"><![CDATA[<h1><span id="883-三维形体投影面积">883. 三维形体投影面积</span></h1><blockquote><p><a href="https://leetcode-cn.com/problems/projection-area-of-3d-shapes/">883. 三维形体投影面积</a></p></blockquote><h2><span id="题目">题目</span></h2><p>在 <code>n x n</code> 的网格 <code>grid</code> 中，我们放置了一些与 <code>x</code>，<code>y</code>，<code>z</code> 三轴对齐的 <code>1 x 1 x 1</code> 立方体。每个值 <code>v = grid[i][j]</code> 表示 <code>v</code> 个正方体叠放在单元格 <code>(i, j)</code> 上。现在，我们查看这些立方体在 <code>xy</code> 、<code>yz</code> 和 <code>zx</code> 平面上的投影。</p><p>投影就像影子，将三维形体映射到一个二维平面上。从顶部、前面和侧面看立方体时，我们会看到“影子”。返回所有三个投影的总面积 。</p><h2><span id="示例">示例</span></h2><p><img src="http://xiaomanzhan.com.cn/content/shadow.png" alt="img"></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">示例 <span class="number">1</span>:</span><br><span class="line">输入：[[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]]</span><br><span class="line">输出：<span class="number">17</span></span><br><span class="line">解释：这里有该形体在三个轴对齐平面上的三个投影(“阴影部分”)。</span><br><span class="line"></span><br><span class="line">示例 <span class="number">2</span>:</span><br><span class="line">输入：grid = [[<span class="number">2</span>]]</span><br><span class="line">输出：<span class="number">5</span></span><br><span class="line"></span><br><span class="line">示例 <span class="number">3</span>：</span><br><span class="line">输入：[[<span class="number">1</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">2</span>]]</span><br><span class="line">输出：<span class="number">8</span></span><br></pre></td></tr></tbody></table></figure><h2><span id="解题思路">解题思路</span></h2><ol><li><code>xy</code> 平面的投影面积等于网格上非零数值的数目；</li><li><code>yz</code> 平面的投影面积等于网格上每一列最大数值之和；</li><li><code>zx</code> 平面的投影面积等于网格上每一行最大数值之和。</li></ol><h3><span id="题解">题解</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">projectionArea</span>(<span class="params">self, grid: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        areax = <span class="built_in">sum</span>([i &gt; <span class="number">0</span> <span class="keyword">for</span> g <span class="keyword">in</span> grid <span class="keyword">for</span> i <span class="keyword">in</span> g])</span><br><span class="line">        areay = <span class="built_in">sum</span>(<span class="built_in">map</span>(<span class="built_in">max</span>, <span class="built_in">zip</span>(*grid)))</span><br><span class="line">        areaz = <span class="built_in">sum</span>(<span class="built_in">map</span>(<span class="built_in">max</span>, grid))</span><br><span class="line">        <span class="keyword">return</span> areax + areay + areaz</span><br></pre></td></tr></tbody></table></figure><blockquote><p>学会熟练使用 map 和 zip 方法</p></blockquote><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeetCode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode298</title>
      <link href="/2022/04/25/leetcode/mei-ri-yi-ti/leetcode298/"/>
      <url>/2022/04/25/leetcode/mei-ri-yi-ti/leetcode298/</url>
      
        <content type="html"><![CDATA[<h1><span id="398-随机数索引">398. 随机数索引</span></h1><blockquote><p><a href="https://leetcode-cn.com/problems/random-pick-index/">398. 随机数索引</a></p></blockquote><h2><span id="题目">题目</span></h2><p>给你一个可能含有 重复元素 的整数数组 <code>nums</code> ，请你随机输出给定的目标数字 <code>target</code> 的索引。你可以假设给定的数字一定存在于数组中。</p><p>实现 <code>Solution</code> 类：</p><ul><li><code>Solution(int[] nums)</code> 用数组 <code>nums</code> 初始化对象。</li><li><code>int pick(int target)</code> 从 <code>nums</code> 中选出一个满足 <code>nums[i] == target</code> 的随机索引 <code>i</code> 。如果存在多个有效的索引，则每个索引的返回概率应当相等。</li></ul><h2><span id="示例">示例</span></h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">输入</span><br><span class="line">[<span class="string">"Solution"</span>, <span class="string">"pick"</span>, <span class="string">"pick"</span>, <span class="string">"pick"</span>]</span><br><span class="line">[[[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>]], [<span class="number">3</span>], [<span class="number">1</span>], [<span class="number">3</span>]]</span><br><span class="line">输出</span><br><span class="line">[null, <span class="number">4</span>, <span class="number">0</span>, <span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">解释</span><br><span class="line">Solution solution = new Solution([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>]);</span><br><span class="line">solution.pick(<span class="number">3</span>); // 随机返回索引 <span class="number">2</span>, <span class="number">3</span> 或者 <span class="number">4</span> 之一。每个索引的返回概率应该相等。</span><br><span class="line">solution.pick(<span class="number">1</span>); // 返回 <span class="number">0</span> 。因为只有 nums[<span class="number">0</span>] 等于 <span class="number">1</span> 。</span><br><span class="line">solution.pick(<span class="number">3</span>); // 随机返回索引 <span class="number">2</span>, <span class="number">3</span> 或者 <span class="number">4</span> 之一。每个索引的返回概率应该相等。</span><br></pre></td></tr></tbody></table></figure><h2><span id="解题思路一">解题思路一</span></h2><p>构建 dict 字典格式的数据，key位数组中的元素，value为key在nums数组中的位置信息。</p><h3><span id="题解">题解</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>):</span><br><span class="line">        self.pos = defaultdict(<span class="built_in">list</span>)</span><br><span class="line">        <span class="keyword">for</span> i, num <span class="keyword">in</span> <span class="built_in">enumerate</span>(nums):</span><br><span class="line">            self.pos[num].append(i)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">pick</span>(<span class="params">self, target: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="keyword">return</span> choice(self.pos[target])</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> 难度-中等 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeetCode </tag>
            
            <tag> 哈希表 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode868</title>
      <link href="/2022/04/24/leetcode/mei-ri-yi-ti/leetcode868/"/>
      <url>/2022/04/24/leetcode/mei-ri-yi-ti/leetcode868/</url>
      
        <content type="html"><![CDATA[<h1><span id="868-二进制间距">868. 二进制间距</span></h1><blockquote><p><a href="https://leetcode-cn.com/problems/binary-gap/">868. 二进制间距</a></p></blockquote><h2><span id="题目">题目</span></h2><p>给定一个正整数 <code>n</code>，找到并返回 <code>n</code> 的二进制表示中两个相邻 <code>1</code> 之间的最长距离 。如果不存在两个相邻的 <code>1</code>，返回 <code>0</code> 。如果只有<code>0</code> 将两个 <code>1</code> 分隔开（可能不存在 <code>0</code> ），则认为这两个 <code>1</code> 彼此相邻 。两个 <code>1</code> 之间的距离是它们的二进制表示中位置的绝对差。例如，<code>"1001"</code> 中的两个 <code>1</code> 的距离为 <code>3</code> 。</p><h2><span id="示例">示例</span></h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">示例 <span class="number">1</span>：</span><br><span class="line">输入：n = <span class="number">22</span></span><br><span class="line">输出：<span class="number">2</span></span><br><span class="line">解释：<span class="number">22</span> 的二进制是 <span class="string">"10110"</span> 。</span><br><span class="line">在 <span class="number">22</span> 的二进制表示中，有三个 <span class="number">1</span>，组成两对相邻的 <span class="number">1</span> 。</span><br><span class="line">第一对相邻的 <span class="number">1</span> 中，两个 <span class="number">1</span> 之间的距离为 <span class="number">2</span> 。</span><br><span class="line">第二对相邻的 <span class="number">1</span> 中，两个 <span class="number">1</span> 之间的距离为 <span class="number">1</span> 。</span><br><span class="line">答案取两个距离之中最大的，也就是 <span class="number">2</span> 。</span><br><span class="line"></span><br><span class="line">示例 <span class="number">2</span>：</span><br><span class="line">输入：n = <span class="number">8</span></span><br><span class="line">输出：<span class="number">0</span></span><br><span class="line">解释：<span class="number">8</span> 的二进制是 <span class="string">"1000"</span> 。</span><br><span class="line">在 <span class="number">8</span> 的二进制表示中没有相邻的两个 <span class="number">1</span>，所以返回 <span class="number">0</span> 。</span><br><span class="line"></span><br><span class="line">示例 <span class="number">3</span>：</span><br><span class="line">输入：n = <span class="number">5</span></span><br><span class="line">输出：<span class="number">2</span></span><br><span class="line">解释：<span class="number">5</span> 的二进制是 <span class="string">"101"</span> 。</span><br></pre></td></tr></tbody></table></figure><h2><span id="解题思路">解题思路</span></h2><p>明确题目的意思，时需要我们使用位运算解题，使用p记录前一个1的位置，q记录当前位置，当前位为1是，更新答案。</p><p>在每次循环中，我们使用位运算 <code>n &amp; 1</code> 来获取当前位，判断其是否位 <code>1</code>，之后更新 <code>n</code> 进行 <code>n &gt;&gt;= 1</code> 的操作。</p><h3><span id="题解">题解</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">binaryGap</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        p, q, ans = -<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> n:</span><br><span class="line">            <span class="keyword">if</span> n &amp; <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">if</span> p != -<span class="number">1</span>:</span><br><span class="line">                    ans = <span class="built_in">max</span>(ans, q - p)</span><br><span class="line">                p = q</span><br><span class="line">            n &gt;&gt;= <span class="number">1</span></span><br><span class="line">            q += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeetCode </tag>
            
            <tag> 位运算 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorch模型构造常用函数介绍</title>
      <link href="/2022/04/24/machine-learning/pytorch/pytorch-mo-xing-gou-zao-chang-yong-han-shu-jie-shao/"/>
      <url>/2022/04/24/machine-learning/pytorch/pytorch-mo-xing-gou-zao-chang-yong-han-shu-jie-shao/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="pytorch模型构造常用函数介绍">PyTorch模型构造常用函数介绍</span></h1><h2><span id="1-view-和reshape的比较">1. view() 和reshape()的比较</span></h2><ol><li>view() 会将tensor转换为指定的shape，但是原始数据没有变化，只是数据表现形式发生了变化；</li><li>reshape() 指定shape之后，不只是数据表现形式发生变化，原始数据会发生变化。</li></ol><h2><span id="2-运算">2. @ 运算</span></h2><p><code>H = relu(x @ W1 + b1)</code>、<code>H = relu(torch.mm(x, W1) + b1)</code></p><p>上面两种矩阵相乘的写法的效果是一样的，<code>@</code> 算是<code>torch.mm</code> 方法的简写。</p><h2><span id="3-pytorch-矩阵相乘与点乘">3. pytorch 矩阵相乘与点乘</span></h2><h3><span id="31-矩阵点乘">3.1 矩阵点乘</span></h3><p><code>torch.mul(a, b)</code>  表示矩阵点乘，矩阵点乘要求两个矩阵==<strong>维度</strong>==符合一定要求</p><ul><li><code>a</code>的形状是<code>(x,y)</code>;</li><li><code>b</code>的形状是<code>(x,y)</code>，那么得到<code>(x,y)</code>形状的矩阵;</li><li><code>b</code>的形状是<code>(x,1)</code>，那么得到<code>(x,y)</code>形状的矩阵，从<code>2</code>到<code>y</code>列的值与第一列的值相乘；</li><li><code>y=1</code>，<code>b</code>的形状是<code>(1,x)</code>，那么得到<code>(x,x)</code>形状的矩阵;</li><li>点乘，再求和就是卷积</li></ul><h3><span id="32-矩阵相乘">3.2 矩阵相乘</span></h3><p><code>torch.mm(a,b)</code> 矩阵相乘</p><ul><li><code>a</code>的形状是<code>(x,y)</code>，<code>b</code>的形状是<code>(y,z)</code>，得到<code>(x,z)</code>形状的矩阵</li><li>只能计算二维矩阵的相乘。</li></ul><p><code>nn.Linear</code>线性变化，是进行矩阵相乘（矩阵乘）的操作对权重。</p><h2><span id="4-numel函数">4. numel函数</span></h2><p>获取 tensor 中一共包含多少个元素</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">x = torch.randn(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"number elements of x is "</span>,x.numel())</span><br><span class="line">y = torch.randn(<span class="number">3</span>,<span class="number">10</span>,<span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"number elements of y is "</span>,y.numel())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">number elements of x <span class="keyword">is</span>  <span class="number">9</span></span><br><span class="line">number elements of y <span class="keyword">is</span>  <span class="number">150</span></span><br></pre></td></tr></tbody></table></figure><h2><span id="5-加法操作">5. 加法操作</span></h2><h3><span id="51-方法一">5.1 方法一</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a = torch.Tensor([<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>])</span><br><span class="line">b = torch.Tensor([<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line">c = a + b</span><br><span class="line"><span class="built_in">print</span>(c)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">tensor([<span class="number">3.</span>, <span class="number">4.</span>, <span class="number">5.</span>])</span><br></pre></td></tr></tbody></table></figure><h3><span id="52-方法二">5.2 方法二</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">c = torch.add(a, b)</span><br><span class="line"><span class="built_in">print</span>(c)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">tensor([<span class="number">3.</span>, <span class="number">4.</span>, <span class="number">5.</span>])</span><br></pre></td></tr></tbody></table></figure><h2><span id="6-detach-amp-clone">6. detach &amp; clone</span></h2><h3><span id="61-tensorclone">6.1 tensor.clone()</span></h3><blockquote><p><code>clone</code>(<em>memory_format=torch.preserve_format</em>)→ Tensor</p></blockquote><p>返回tensor的拷贝，返回的新tensor和原来的tensor具有同样的大小和数据类型。</p><ol><li>当原tensor的requires_grad=True 时，梯度会流向原tensor，即返回的tensor的梯度会叠加在原tensor上。</li></ol><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> torch</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = torch.tensor(<span class="number">1.0</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = a.clone()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">id</span>(a), <span class="built_in">id</span>(b)  <span class="comment"># a和b不是同一个对象</span></span><br><span class="line">(<span class="number">140191154302240</span>, <span class="number">140191145593424</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.data_ptr(), b.data_ptr()  <span class="comment"># 也不指向同一块内存地址</span></span><br><span class="line">(<span class="number">94724518544960</span>, <span class="number">94724519185792</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.requires_grad, b.requires_grad  <span class="comment"># 但b的requires_grad属性和a的一样，同样是True</span></span><br><span class="line">(<span class="literal">True</span>, <span class="literal">True</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = a * <span class="number">2</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c.backward()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.grad</span><br><span class="line">tensor(<span class="number">2.</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>d = b * <span class="number">3</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>d.backward()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b.grad  <span class="comment"># b的梯度值为None，因为是中间节点，梯度值不会被保存</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.grad  <span class="comment"># b的梯度叠加在a上</span></span><br><span class="line">tensor(<span class="number">5.</span>)</span><br></pre></td></tr></tbody></table></figure><ol><li>原tensor的requires_grad=False 时</li></ol><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> torch</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = torch.tensor(<span class="number">1.0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = a.clone()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">id</span>(a), <span class="built_in">id</span>(b)  <span class="comment"># a和b不是同一个对象</span></span><br><span class="line">(<span class="number">140191169099168</span>, <span class="number">140191154762208</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.data_ptr(), b.data_ptr()  <span class="comment"># 也不指向同一块内存地址</span></span><br><span class="line">(<span class="number">94724519502912</span>, <span class="number">94724519533952</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.requires_grad, b.requires_grad  <span class="comment"># 但b的requires_grad属性和a的一样，同样是False</span></span><br><span class="line">(<span class="literal">False</span>, <span class="literal">False</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b.requires_grad_()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = b * <span class="number">2</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c.backward()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b.grad</span><br><span class="line">tensor(<span class="number">2.</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.grad  <span class="comment"># None</span></span><br></pre></td></tr></tbody></table></figure><h3><span id="62-tensordetach">6.2 tensor.detach()</span></h3><p>从计算图中脱离出来。detach()的官方说明如下：</p><blockquote><p>Returns a new Tensor, detached from the current graph. The result will never require gradient.</p></blockquote><p>假设有模型A和模型B，我们需要将A的输出作为B的输入，但训练时我们只训练模型B. 那么可以这样做：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">input_B = output_A.detach()</span><br></pre></td></tr></tbody></table></figure><p>它可以使两个计算图的梯度传递断开，从而实现我们所需的功能。返回一个新的tensor，新的tensor和原来的tensor共享数据内存，但不涉及梯度计算，即requires_grad=False。修改其中一个tensor的值，另一个也会改变，因为是共享同一块内存，但如果对其中一个tensor执行某些内置操作，则会报错，例如<code>resize_、resize_as_、set_、transpose_</code>。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> torch</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = torch.rand((<span class="number">3</span>, <span class="number">4</span>), requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = a.detach()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">id</span>(a), <span class="built_in">id</span>(b)  <span class="comment"># a和b不是同一个对象了</span></span><br><span class="line">(<span class="number">140191157657504</span>, <span class="number">140191161442944</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.data_ptr(), b.data_ptr()  <span class="comment"># 但指向同一块内存地址</span></span><br><span class="line">(<span class="number">94724518609856</span>, <span class="number">94724518609856</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.requires_grad, b.requires_grad  <span class="comment"># b的requires_grad为False</span></span><br><span class="line">(<span class="literal">True</span>, <span class="literal">False</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b[<span class="number">0</span>][<span class="number">0</span>] = <span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a[<span class="number">0</span>][<span class="number">0</span>]  <span class="comment"># 修改b的值，a的值也会改变</span></span><br><span class="line">tensor(<span class="number">1.</span>, grad_fn=&lt;SelectBackward&gt;)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b.resize_((<span class="number">4</span>, <span class="number">3</span>))  <span class="comment"># 报错</span></span><br><span class="line">RuntimeError: set_sizes_contiguous <span class="keyword">is</span> <span class="keyword">not</span> allowed on a Tensor created <span class="keyword">from</span> .data <span class="keyword">or</span> .detach().</span><br></pre></td></tr></tbody></table></figure><h3><span id="63-tensorclonedetach-还是-tensordetachclone">6.3 tensor.clone().detach() 还是 tensor.detach().clone()</span></h3><p>两者的结果是一样的，即返回的tensor和原tensor在梯度上或者数据上没有任何关系，一般用前者。</p><h2><span id="7-repeat-amp-repeat_interleave">7. repeat &amp; repeat_interleave</span></h2><p>repeat的参数是每一个维度上重复的次数，repeat_interleave的参数是重复的次数和维度。repeat相当于将该张量复制，然后在某一维度concat起来，而repeat_interleave是将张量中的元素沿某一维度复制n次，即复制后的张量沿该维度相邻的n个元素是相同的。</p><blockquote><p>repeat(*sizes) -&gt; Tensor</p><p>repeat_interleave(repeats, dim=None, *, output_size=None) -&gt; Tensor</p></blockquote><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">a = np.arange(<span class="number">0</span>, <span class="number">10</span>).reshape(<span class="number">2</span>, -<span class="number">1</span>)</span><br><span class="line">a = torch.from_numpy(a)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">tensor([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">        [<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]], dtype=torch.int32)</span><br><span class="line"></span><br><span class="line">b = a.repeat(<span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(b)</span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">tensor([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">        [<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">        [<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]], dtype=torch.int32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 沿着维度1复制两遍</span></span><br><span class="line">c = a.repeat_interleave(<span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(c)</span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">tensor([[<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>],</span><br><span class="line">        [<span class="number">5</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">9</span>]], dtype=torch.int32)</span><br><span class="line"></span><br><span class="line">d = a.repeat(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(d)</span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">tensor([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">        [<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]], dtype=torch.int32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 沿着维度0复制两遍</span></span><br><span class="line">e = a.repeat_interleave(<span class="number">2</span>, <span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(e)</span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">tensor([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">        [<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>],</span><br><span class="line">        [<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]], dtype=torch.int32)</span><br></pre></td></tr></tbody></table></figure><h2><span id="8-tril">8. tril</span></h2><blockquote><p>torch.tril(input, diagonal=0, *, out=None) -&gt; Tensor</p><p>返回矩阵（2-D张量）或矩阵 <code>input</code> 批次的下三角部分，结果张量 <code>out</code> 的其他元素设置为0。</p><p>Parameters</p><ul><li><strong>input</strong>（Tensor)）–输入张量。</li><li><strong>diagonal</strong>（int，可选）–要考虑的对角线</li><li><strong>out</strong>（Tensor，可选）–输出张量。</li></ul></blockquote><p>矩阵的下三角元素被定义为对角线上和下的元素。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = torch.randn(<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">tensor([[-<span class="number">1.0813</span>, -<span class="number">0.8619</span>,  <span class="number">0.7105</span>],</span><br><span class="line">        [ <span class="number">0.0935</span>,  <span class="number">0.1380</span>,  <span class="number">2.2112</span>],</span><br><span class="line">        [-<span class="number">0.3409</span>, -<span class="number">0.9828</span>,  <span class="number">0.0289</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.tril(a)</span><br><span class="line">tensor([[-<span class="number">1.0813</span>,  <span class="number">0.0000</span>,  <span class="number">0.0000</span>],</span><br><span class="line">        [ <span class="number">0.0935</span>,  <span class="number">0.1380</span>,  <span class="number">0.0000</span>],</span><br><span class="line">        [-<span class="number">0.3409</span>, -<span class="number">0.9828</span>,  <span class="number">0.0289</span>]])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = torch.randn(<span class="number">4</span>, <span class="number">6</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b</span><br><span class="line">tensor([[ <span class="number">1.2219</span>,  <span class="number">0.5653</span>, -<span class="number">0.2521</span>, -<span class="number">0.2345</span>,  <span class="number">1.2544</span>,  <span class="number">0.3461</span>],</span><br><span class="line">        [ <span class="number">0.4785</span>, -<span class="number">0.4477</span>,  <span class="number">0.6049</span>,  <span class="number">0.6368</span>,  <span class="number">0.8775</span>,  <span class="number">0.7145</span>],</span><br><span class="line">        [ <span class="number">1.1502</span>,  <span class="number">3.2716</span>, -<span class="number">1.1243</span>, -<span class="number">0.5413</span>,  <span class="number">0.3615</span>,  <span class="number">0.6864</span>],</span><br><span class="line">        [-<span class="number">0.0614</span>, -<span class="number">0.7344</span>, -<span class="number">1.3164</span>, -<span class="number">0.7648</span>, -<span class="number">1.4024</span>,  <span class="number">0.0978</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.tril(b, diagonal=<span class="number">1</span>)</span><br><span class="line">tensor([[ <span class="number">1.2219</span>,  <span class="number">0.5653</span>,  <span class="number">0.0000</span>,  <span class="number">0.0000</span>,  <span class="number">0.0000</span>,  <span class="number">0.0000</span>],</span><br><span class="line">        [ <span class="number">0.4785</span>, -<span class="number">0.4477</span>,  <span class="number">0.6049</span>,  <span class="number">0.0000</span>,  <span class="number">0.0000</span>,  <span class="number">0.0000</span>],</span><br><span class="line">        [ <span class="number">1.1502</span>,  <span class="number">3.2716</span>, -<span class="number">1.1243</span>, -<span class="number">0.5413</span>,  <span class="number">0.0000</span>,  <span class="number">0.0000</span>],</span><br><span class="line">        [-<span class="number">0.0614</span>, -<span class="number">0.7344</span>, -<span class="number">1.3164</span>, -<span class="number">0.7648</span>, -<span class="number">1.4024</span>,  <span class="number">0.0000</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.tril(b, diagonal=-<span class="number">1</span>)</span><br><span class="line">tensor([[ <span class="number">0.0000</span>,  <span class="number">0.0000</span>,  <span class="number">0.0000</span>,  <span class="number">0.0000</span>,  <span class="number">0.0000</span>,  <span class="number">0.0000</span>],</span><br><span class="line">        [ <span class="number">0.4785</span>,  <span class="number">0.0000</span>,  <span class="number">0.0000</span>,  <span class="number">0.0000</span>,  <span class="number">0.0000</span>,  <span class="number">0.0000</span>],</span><br><span class="line">        [ <span class="number">1.1502</span>,  <span class="number">3.2716</span>,  <span class="number">0.0000</span>,  <span class="number">0.0000</span>,  <span class="number">0.0000</span>,  <span class="number">0.0000</span>],</span><br><span class="line">        [-<span class="number">0.0614</span>, -<span class="number">0.7344</span>, -<span class="number">1.3164</span>,  <span class="number">0.0000</span>,  <span class="number">0.0000</span>,  <span class="number">0.0000</span>]])</span><br></pre></td></tr></tbody></table></figure><h2><span id="9-squeeze-amp-unsqueeze">9. squeeze &amp; unsqueeze</span></h2><h3><span id="91-squeeze">9.1 squeeze</span></h3><blockquote><p><code>torch.squeeze(input, dim=None, *, out=None) → Tensor</code></p><p>Parameters</p><ul><li><strong>input</strong> (Tensor) – the input tensor.</li><li><strong>dim</strong> (int, <em>optional</em>) – if given, the input will be squeezed only in this dimension</li><li><strong>out</strong> (Tensor, <em>optional</em>) – the output tensor.</li></ul></blockquote><ol><li>squeeze()函数的功能是维度压缩。返回一个<strong>tensor</strong>（张量），其中 <strong>input</strong> 中大小为1的所有维都已删除。举个例子：如果 <strong>input</strong> 的形状为 (A×1×B×C×1×D)，那么返回的<strong>tensor</strong>的形状则为 <strong>(A×B×C×D)</strong>；</li><li>当给定 dim 时，那么只在给定的维度（dimension）上进行压缩操作。举个例子：如果 <strong>input</strong> 的形状为 <strong>(A×1×B)</strong>，squeeze(input, 0)后，返回的tensor不变；squeeze(input, 1)后，返回的tensor将被压缩为 <strong>(A×B)</strong></li></ol><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.zeros(<span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.size()</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = torch.squeeze(x)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y.size()</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = torch.squeeze(x, <span class="number">0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y.size()</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = torch.squeeze(x, <span class="number">1</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y.size()</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br></pre></td></tr></tbody></table></figure><h3><span id="92-unsqueeze">9.2 unsqueeze</span></h3><blockquote><p><code>torch.nsqueeze(input, dim) → Tensor</code></p><p>Parameters</p><ul><li><strong>input</strong> (Tensor) – the input tensor.</li><li><strong>dim</strong> (int) – the index at which to insert the singleton dimension</li></ul></blockquote><p>在特定维度位置增加一个尺寸为1 的维度。返回的张量和这个张量共享数据。可以使用范围<code>[-input.dim() - 1, input.dim() + 1)</code>内的dim值。负dim将对应于应用于<code>dim = dim + input.dim() + 1</code>的unsqueeze()。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.unsqueeze(x, <span class="number">0</span>)</span><br><span class="line">tensor([[ <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>,  <span class="number">4</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.unsqueeze(x, <span class="number">1</span>)</span><br><span class="line">tensor([[ <span class="number">1</span>],</span><br><span class="line">        [ <span class="number">2</span>],</span><br><span class="line">        [ <span class="number">3</span>],</span><br><span class="line">        [ <span class="number">4</span>]])</span><br></pre></td></tr></tbody></table></figure><h2><span id="10-cat-amp-stack">10. cat &amp; stack</span></h2><h3><span id="101-cat">10.1 cat</span></h3><blockquote><p><code>outputs = torch.cat(inputs, dim=?) → Tensor</code></p><p>Parameters</p><ul><li><strong>inputs</strong> : 待连接的张量序列，可以是任意相同<code>Tensor</code>类型的python 序列</li><li><strong>dim</strong> : 选择的扩维, 必须在<code>0</code>到<code>len(inputs[0])</code>之间，沿着此维连接张量序列。</li></ul></blockquote><ol><li>输入数据必须是序列，序列中数据是任意相同的<code>shape</code>的同类型<code>tensor</code></li><li>维度不可以超过输入数据的任一个张量的维度</li></ol><p><strong>举例</strong></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># x1</span></span><br><span class="line">x1 = torch.tensor([[<span class="number">11</span>,<span class="number">21</span>,<span class="number">31</span>],[<span class="number">21</span>,<span class="number">31</span>,<span class="number">41</span>]],dtype=torch.<span class="built_in">int</span>)</span><br><span class="line">x1.shape <span class="comment"># torch.Size([2, 3])</span></span><br><span class="line"><span class="comment"># x2</span></span><br><span class="line">x2 = torch.tensor([[<span class="number">12</span>,<span class="number">22</span>,<span class="number">32</span>],[<span class="number">22</span>,<span class="number">32</span>,<span class="number">42</span>]],dtype=torch.<span class="built_in">int</span>)</span><br><span class="line">x2.shape  <span class="comment"># torch.Size([2, 3])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 'inputs为２个形状为[2 , 3]的矩阵 '</span></span><br><span class="line">inputs = [x1, x2]</span><br><span class="line"><span class="built_in">print</span>(inputs)</span><br><span class="line"><span class="comment"># '打印查看'</span></span><br><span class="line">[tensor([[<span class="number">11</span>, <span class="number">21</span>, <span class="number">31</span>],</span><br><span class="line">         [<span class="number">21</span>, <span class="number">31</span>, <span class="number">41</span>]], dtype=torch.int32),</span><br><span class="line"> tensor([[<span class="number">12</span>, <span class="number">22</span>, <span class="number">32</span>],</span><br><span class="line">         [<span class="number">22</span>, <span class="number">32</span>, <span class="number">42</span>]], dtype=torch.int32)]</span><br><span class="line"><span class="comment"># 测试不同的dim拼接结果</span></span><br><span class="line">torch.cat(inputs, dim=<span class="number">0</span>).shape</span><br><span class="line"><span class="comment"># torch.Size([4,  3])</span></span><br><span class="line"></span><br><span class="line">torch.cat(inputs, dim=<span class="number">1</span>).shape</span><br><span class="line"><span class="comment"># Out[2]: torch.Size([2, 6])</span></span><br><span class="line"></span><br><span class="line">torch.cat(inputs, dim=<span class="number">2</span>).shape</span><br><span class="line"><span class="comment"># IndexError: Dimension out of range (expected to be in range of [-2, 1], but got 2)</span></span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
          <category> PyTorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>构建模型基础</title>
      <link href="/2022/04/23/machine-learning/pytorch/gou-jian-mo-xing-ji-chu/"/>
      <url>/2022/04/23/machine-learning/pytorch/gou-jian-mo-xing-ji-chu/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="构建模型基础">构建模型基础</span></h1><h2><span id="1-模型构造">1. 模型构造</span></h2><h3><span id="11-nnsequential">1.1 nn.Sequential</span></h3><p>利用<code>nn.Sequential</code>定义<code>Module</code></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">net = nn.Sequential(nn.Linear(<span class="number">20</span>, <span class="number">256</span>), nn.ReLU(), nn.Linear(<span class="number">256</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">X = torch.rand(<span class="number">2</span>, <span class="number">20</span>)</span><br><span class="line">net(X)</span><br></pre></td></tr></tbody></table></figure><h3><span id="12-自定义块">1.2 自定义块</span></h3><p>通过构建类来定义模型</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MLP</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.hidden = nn.Linear(<span class="number">20</span>, <span class="number">256</span>)</span><br><span class="line">        self.out = nn.Linear(<span class="number">256</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="keyword">return</span> self.out(F.relu(self.hidden(X)))</span><br></pre></td></tr></tbody></table></figure><h3><span id="13-构建顺序块">1.3 构建顺序块</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MySequential</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, *args</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="keyword">for</span> block <span class="keyword">in</span> args:</span><br><span class="line">            self._modules[block] = block</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="keyword">for</span> block <span class="keyword">in</span> self._modules.values():</span><br><span class="line">            X = block(X)</span><br><span class="line">        <span class="keyword">return</span> X</span><br><span class="line"></span><br><span class="line">net = MySequential(nn.Linear(<span class="number">20</span>, <span class="number">256</span>), nn.ReLU(), nn.Linear(<span class="number">256</span>, <span class="number">10</span>))</span><br><span class="line">net(x).shape</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">10</span>])</span><br></pre></td></tr></tbody></table></figure><h3><span id="14-自定义层">1.4 自定义层</span></h3><p>在正向传播函数中执行代码</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FixedHiddenMLP</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.rand_weight = torch.rand((<span class="number">20</span>, <span class="number">20</span>), requires_grad=<span class="literal">False</span>)</span><br><span class="line">        self.linear = nn.Linear(<span class="number">20</span>, <span class="number">20</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X</span>):</span><br><span class="line">        X = self.linear(X)</span><br><span class="line">        <span class="comment"># X = F.relu(X @ self.rand_weight + 1) 书写方式一样</span></span><br><span class="line">        X = F.relu(torch.mm(X, self.rand_weight) + <span class="number">1</span>)</span><br><span class="line">        X = self.linear(X)</span><br><span class="line">        <span class="keyword">while</span> X.<span class="built_in">abs</span>().<span class="built_in">sum</span>() &gt; <span class="number">1</span>:</span><br><span class="line">            X /= <span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> X.<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line">net = FixedHiddenMLP()</span><br><span class="line">net(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出：</span></span><br><span class="line">tensor(<span class="number">0.0058</span>, grad_fn=&lt;SumBackward0&gt;)</span><br></pre></td></tr></tbody></table></figure><h3><span id="15-混合搭配各种组合块">1.5 混合搭配各种组合块</span></h3><p>混合搭配各种组合块的方法</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">NestMLP</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.net = nn.Sequential(nn.Linear(<span class="number">20</span>, <span class="number">64</span>), nn.ReLU(),</span><br><span class="line">                                 nn.Linear(<span class="number">64</span>, <span class="number">32</span>), nn.ReLU())</span><br><span class="line">        self.linear = nn.Linear(<span class="number">32</span>, <span class="number">16</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="keyword">return</span> self.linear(self.net(X))</span><br><span class="line"></span><br><span class="line">chimera = nn.Sequential(NestMLP(), nn.Linear(<span class="number">16</span>, <span class="number">20</span>), FixedHiddenMLP())</span><br><span class="line">chimera(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出：</span></span><br><span class="line">tensor(-<span class="number">0.1374</span>, grad_fn=&lt;SumBackward0&gt;)</span><br></pre></td></tr></tbody></table></figure><h2><span id="2参数管理">2.参数管理</span></h2><h3><span id="21-参数访问">2.1 参数访问</span></h3><h4><span id="211-参数的访问方式">2.1.1 参数的访问方式</span></h4><p>先构建一个简单模型</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line">net = nn.Sequential(nn.Linear(<span class="number">4</span>, <span class="number">8</span>), nn.ReLU(), nn.Linear(<span class="number">8</span>, <span class="number">1</span>))</span><br><span class="line">X = torch.rand(size=(<span class="number">2</span>, <span class="number">4</span>))</span><br><span class="line">net(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">tensor([[-<span class="number">0.5876</span>],</span><br><span class="line">        [-<span class="number">0.5556</span>]], grad_fn=&lt;AddmmBackward&gt;)</span><br></pre></td></tr></tbody></table></figure><p>获取参数信息</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(net[<span class="number">2</span>].state_dict())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">OrderedDict(</span><br><span class="line">    [(<span class="string">'weight'</span>, tensor([[ <span class="number">0.0181</span>,  <span class="number">0.0557</span>,  <span class="number">0.0219</span>, -<span class="number">0.3431</span>,  <span class="number">0.1738</span>, -<span class="number">0.0249</span>,  <span class="number">0.1345</span>, -<span class="number">0.2593</span>]])), </span><br><span class="line">     (<span class="string">'bias'</span>, tensor([-<span class="number">0.3221</span>]))</span><br><span class="line">    ]</span><br><span class="line">)</span><br></pre></td></tr></tbody></table></figure><p>获取目标参数</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(net[<span class="number">2</span>].bias))</span><br><span class="line"><span class="built_in">print</span>(net[<span class="number">2</span>].bias)</span><br><span class="line"><span class="built_in">print</span>(net[<span class="number">2</span>].bias.data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出：</span></span><br><span class="line">&lt;<span class="keyword">class</span> <span class="string">'torch.nn.parameter.Parameter'</span>&gt;</span><br><span class="line">Parameter containing:</span><br><span class="line">tensor([-<span class="number">0.3221</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line">tensor([-<span class="number">0.3221</span>])</span><br></pre></td></tr></tbody></table></figure><blockquote><p>在初始化参数时，梯度为 None，判断方式如下：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">net[<span class="number">2</span>].weight.grad == <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出：</span></span><br><span class="line"><span class="literal">True</span></span><br></pre></td></tr></tbody></table></figure></blockquote><h4><span id="212-一次性访问所有参数">2.1.2 一次性访问所有参数</span></h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(*[(name, param.shape) <span class="keyword">for</span> name, param <span class="keyword">in</span> net[<span class="number">0</span>].named_parameters()])</span><br><span class="line"><span class="built_in">print</span>(*[(name, param.shape) <span class="keyword">for</span> name, param <span class="keyword">in</span> net.named_parameters()])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出：</span></span><br><span class="line">(<span class="string">'weight'</span>, torch.Size([<span class="number">8</span>, <span class="number">4</span>])) (<span class="string">'bias'</span>, torch.Size([<span class="number">8</span>]))</span><br><span class="line">(<span class="string">'0.weight'</span>, torch.Size([<span class="number">8</span>, <span class="number">4</span>])) (<span class="string">'0.bias'</span>, torch.Size([<span class="number">8</span>])) (<span class="string">'2.weight'</span>, torch.Size([<span class="number">1</span>, <span class="number">8</span>])) (<span class="string">'2.bias'</span>, torch.Size([<span class="number">1</span>]))</span><br></pre></td></tr></tbody></table></figure><h4><span id="213-查看参数具体数值-当前">2.1.3 查看参数具体数值-当前</span></h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">net.state_dict()[<span class="string">'2.bias'</span>].data</span><br><span class="line"></span><br><span class="line">输出：</span><br><span class="line">tensor([-<span class="number">0.3221</span>])</span><br></pre></td></tr></tbody></table></figure><h4><span id="214-从嵌套块收集参数">2.1.4 从嵌套块收集参数</span></h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">block1</span>():</span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(nn.Linear(<span class="number">4</span>, <span class="number">8</span>), nn.ReLU(), nn.Linear(<span class="number">8</span>, <span class="number">4</span>),</span><br><span class="line">                         nn.ReLU())</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">block2</span>():</span><br><span class="line">    net = nn.Sequential()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">        net.add_module(<span class="string">f'block <span class="subst">{i}</span>'</span>, block1())</span><br><span class="line">    <span class="keyword">return</span> net</span><br><span class="line"></span><br><span class="line">rgnet = nn.Sequential(block2(), nn.Linear(<span class="number">4</span>, <span class="number">1</span>))</span><br><span class="line">rgnet(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出：</span></span><br><span class="line">tensor([[<span class="number">0.2755</span>],</span><br><span class="line">        [<span class="number">0.2755</span>]], grad_fn=&lt;AddmmBackward&gt;)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(rgnet)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出：</span></span><br><span class="line">Sequential(</span><br><span class="line">  (<span class="number">0</span>): Sequential(</span><br><span class="line">    (block <span class="number">0</span>): Sequential(</span><br><span class="line">      (<span class="number">0</span>): Linear(in_features=<span class="number">4</span>, out_features=<span class="number">8</span>, bias=<span class="literal">True</span>)</span><br><span class="line">      (<span class="number">1</span>): ReLU()</span><br><span class="line">      (<span class="number">2</span>): Linear(in_features=<span class="number">8</span>, out_features=<span class="number">4</span>, bias=<span class="literal">True</span>)</span><br><span class="line">      (<span class="number">3</span>): ReLU()</span><br><span class="line">    )</span><br><span class="line">    (block <span class="number">1</span>): Sequential(</span><br><span class="line">      (<span class="number">0</span>): Linear(in_features=<span class="number">4</span>, out_features=<span class="number">8</span>, bias=<span class="literal">True</span>)</span><br><span class="line">      (<span class="number">1</span>): ReLU()</span><br><span class="line">      (<span class="number">2</span>): Linear(in_features=<span class="number">8</span>, out_features=<span class="number">4</span>, bias=<span class="literal">True</span>)</span><br><span class="line">      (<span class="number">3</span>): ReLU()</span><br><span class="line">    )</span><br><span class="line">    (block <span class="number">2</span>): Sequential(</span><br><span class="line">      (<span class="number">0</span>): Linear(in_features=<span class="number">4</span>, out_features=<span class="number">8</span>, bias=<span class="literal">True</span>)</span><br><span class="line">      (<span class="number">1</span>): ReLU()</span><br><span class="line">      (<span class="number">2</span>): Linear(in_features=<span class="number">8</span>, out_features=<span class="number">4</span>, bias=<span class="literal">True</span>)</span><br><span class="line">      (<span class="number">3</span>): ReLU()</span><br><span class="line">    )</span><br><span class="line">    (block <span class="number">3</span>): Sequential(</span><br><span class="line">      (<span class="number">0</span>): Linear(in_features=<span class="number">4</span>, out_features=<span class="number">8</span>, bias=<span class="literal">True</span>)</span><br><span class="line">      (<span class="number">1</span>): ReLU()</span><br><span class="line">      (<span class="number">2</span>): Linear(in_features=<span class="number">8</span>, out_features=<span class="number">4</span>, bias=<span class="literal">True</span>)</span><br><span class="line">      (<span class="number">3</span>): ReLU()</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (<span class="number">1</span>): Linear(in_features=<span class="number">4</span>, out_features=<span class="number">1</span>, bias=<span class="literal">True</span>)</span><br><span class="line">)</span><br></pre></td></tr></tbody></table></figure><p>所以访问具体参数</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rgnet[<span class="number">0</span>][<span class="number">1</span>][<span class="number">0</span>].bias.data</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">tensor([-<span class="number">0.0178</span>,  <span class="number">0.4432</span>,  <span class="number">0.4543</span>, -<span class="number">0.3561</span>, -<span class="number">0.0851</span>, -<span class="number">0.4227</span>,  <span class="number">0.3945</span>, -<span class="number">0.4169</span>])</span><br></pre></td></tr></tbody></table></figure><h3><span id="22-参数初始化">2.2 参数初始化</span></h3><h4><span id="221-内置参数初始化">2.2.1 内置参数初始化</span></h4><p>权重初始化为 均值为0，方差为0.01的正态分布随机数，偏差初始化为0</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">init_normal</span>(<span class="params">m</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">type</span>(m) == nn.Linear:</span><br><span class="line">        nn.init.normal_(m.weight, mean=<span class="number">0</span>, std=<span class="number">0.01</span>)</span><br><span class="line">        nn.init.zeros_(m.bias)</span><br><span class="line"></span><br><span class="line">net.apply(init_normal)</span><br><span class="line">net[<span class="number">0</span>].weight.data[<span class="number">0</span>], net[<span class="number">0</span>].bias.data[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">(tensor([-<span class="number">0.0013</span>,  <span class="number">0.0037</span>, -<span class="number">0.0172</span>,  <span class="number">0.0156</span>]), tensor(<span class="number">0.</span>))</span><br></pre></td></tr></tbody></table></figure><p>权重初始化为 1，偏差初始化为0</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">init_constant</span>(<span class="params">m</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">type</span>(m) == nn.Linear:</span><br><span class="line">        nn.init.constant_(m.weight, <span class="number">1</span>)</span><br><span class="line">        nn.init.zeros_(m.bias)</span><br><span class="line"></span><br><span class="line">net.apply(init_constant)</span><br><span class="line">net[<span class="number">0</span>].weight.data[<span class="number">0</span>], net[<span class="number">0</span>].bias.data[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">(tensor([<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>]), tensor(<span class="number">0.</span>))</span><br></pre></td></tr></tbody></table></figure><h4><span id="222-对某些块应用不同的初始化方法">2.2.2 对某些块应用不同的初始化方法</span></h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">xavier</span>(<span class="params">m</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">type</span>(m) == nn.Linear:</span><br><span class="line">        nn.init.xavier_uniform_(m.weight)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">init_42</span>(<span class="params">m</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">type</span>(m) == nn.Linear:</span><br><span class="line">        nn.init.constant_(m.weight, <span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">net[<span class="number">0</span>].apply(xavier)</span><br><span class="line">net[<span class="number">2</span>].apply(init_42)</span><br><span class="line"><span class="built_in">print</span>(net[<span class="number">0</span>].weight.data[<span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(net[<span class="number">2</span>].weight.data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">tensor([-<span class="number">0.0453</span>, -<span class="number">0.3169</span>,  <span class="number">0.3091</span>, -<span class="number">0.2077</span>])</span><br><span class="line">tensor([[<span class="number">42.</span>, <span class="number">42.</span>, <span class="number">42.</span>, <span class="number">42.</span>, <span class="number">42.</span>, <span class="number">42.</span>, <span class="number">42.</span>, <span class="number">42.</span>]])</span><br></pre></td></tr></tbody></table></figure><h4><span id="223-自定义初始化">2.2.3 自定义初始化</span></h4><h5><span id="通过函数操作权重">通过函数操作权重</span></h5><p>下面函数做到 对<code>Linear</code>层的权重进行处理，先对权重赋值 <code>(-10, 10)</code> 之间的随机数，将绝对值 <code>&gt;=5</code>的保留，<code>&lt;5</code>的权重值置位<code>0</code>。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">my_init</span>(<span class="params">m</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">type</span>(m) == nn.Linear:</span><br><span class="line">        <span class="built_in">print</span>(</span><br><span class="line">            <span class="string">"Init"</span>,</span><br><span class="line">            *[(name, param.shape) <span class="keyword">for</span> name, param <span class="keyword">in</span> m.named_parameters()][<span class="number">0</span>])</span><br><span class="line">        nn.init.uniform_(m.weight, -<span class="number">10</span>, <span class="number">10</span>)</span><br><span class="line">        m.weight.data *= m.weight.data.<span class="built_in">abs</span>() &gt;= <span class="number">5</span></span><br><span class="line"></span><br><span class="line">net.apply(my_init)</span><br><span class="line">net[<span class="number">0</span>].weight[:<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">Init weight torch.Size([<span class="number">8</span>, <span class="number">4</span>])</span><br><span class="line">Init weight torch.Size([<span class="number">1</span>, <span class="number">8</span>])</span><br><span class="line">tensor([[ <span class="number">0.0000</span>, -<span class="number">9.6254</span>,  <span class="number">0.0000</span>,  <span class="number">6.0600</span>],</span><br><span class="line">        [ <span class="number">0.0000</span>,  <span class="number">7.9085</span>, -<span class="number">0.0000</span>, -<span class="number">0.0000</span>]], grad_fn=&lt;SliceBackward&gt;)</span><br></pre></td></tr></tbody></table></figure><h5><span id="直接对权重进行操作">直接对权重进行操作</span></h5><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">net[<span class="number">0</span>].weight.data[:] += <span class="number">1</span></span><br><span class="line">net[<span class="number">0</span>].weight.data[<span class="number">0</span>, <span class="number">0</span>] = <span class="number">42</span></span><br><span class="line">net[<span class="number">0</span>].weight.data[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">tensor([<span class="number">42.0000</span>, -<span class="number">8.6254</span>,  <span class="number">1.0000</span>,  <span class="number">7.0600</span>])</span><br></pre></td></tr></tbody></table></figure><h4><span id="224-参数共享">2.2.4 参数共享</span></h4><p>初始化一个网络结构，放在神经网络的多个位置</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">shared = nn.Linear(<span class="number">8</span>, <span class="number">8</span>)</span><br><span class="line">net = nn.Sequential(nn.Linear(<span class="number">4</span>, <span class="number">8</span>), nn.ReLU(), shared, nn.ReLU(), shared,</span><br><span class="line">                    nn.ReLU(), nn.Linear(<span class="number">8</span>, <span class="number">1</span>))</span><br><span class="line">net(X)</span><br><span class="line"><span class="built_in">print</span>(net[<span class="number">2</span>].weight.data[<span class="number">0</span>] == net[<span class="number">4</span>].weight.data[<span class="number">0</span>])</span><br><span class="line">net[<span class="number">2</span>].weight.data[<span class="number">0</span>, <span class="number">0</span>] = <span class="number">100</span></span><br><span class="line"><span class="built_in">print</span>(net[<span class="number">2</span>].weight.data[<span class="number">0</span>] == net[<span class="number">4</span>].weight.data[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">tensor([<span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>])</span><br><span class="line">tensor([<span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>])</span><br></pre></td></tr></tbody></table></figure><h2><span id="3-自定义层">3. 自定义层</span></h2><h3><span id="31-无参数的自定义层">3.1 无参数的自定义层</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CenteredLayer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="keyword">return</span> X - X.mean()</span><br><span class="line"></span><br><span class="line">layer = CenteredLayer()</span><br><span class="line">layer(torch.FloatTensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">tensor([-<span class="number">2.</span>, -<span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">2.</span>])</span><br></pre></td></tr></tbody></table></figure><p>将层作为组件合并到构建更复杂的模型中</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">net = nn.Sequential(nn.Linear(<span class="number">8</span>, <span class="number">128</span>), CenteredLayer())</span><br><span class="line"></span><br><span class="line">Y = net(torch.rand(<span class="number">4</span>, <span class="number">8</span>))</span><br><span class="line">Y.mean()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">tensor(<span class="number">4.6566e-10</span>, grad_fn=&lt;MeanBackward0&gt;)</span><br></pre></td></tr></tbody></table></figure><h3><span id="32-构建带参数的层">3.2 构建带参数的层</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyLinear</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_units, units</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.weight = nn.Parameter(torch.randn(in_units, units))</span><br><span class="line">        self.bias = nn.Parameter(torch.randn(units,))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X</span>):</span><br><span class="line">        linear = torch.matmul(X, self.weight.data) + self.bias.data</span><br><span class="line">        <span class="keyword">return</span> F.relu(linear)</span><br><span class="line"></span><br><span class="line">linear = MyLinear(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line">linear.weight</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">Parameter containing:</span><br><span class="line">tensor([[-<span class="number">0.5359</span>,  <span class="number">0.1707</span>,  <span class="number">0.1999</span>],</span><br><span class="line">        [-<span class="number">1.7083</span>,  <span class="number">0.9041</span>,  <span class="number">0.1031</span>],</span><br><span class="line">        [-<span class="number">0.9424</span>, -<span class="number">0.7027</span>,  <span class="number">0.7929</span>],</span><br><span class="line">        [ <span class="number">0.3570</span>, -<span class="number">0.8159</span>, -<span class="number">1.0664</span>],</span><br><span class="line">        [-<span class="number">2.1450</span>, -<span class="number">0.1423</span>,  <span class="number">1.0392</span>]], requires_grad=<span class="literal">True</span>)</span><br></pre></td></tr></tbody></table></figure><p>使用自定义层构建模型</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">net = nn.Sequential(MyLinear(<span class="number">64</span>, <span class="number">8</span>), MyLinear(<span class="number">8</span>, <span class="number">1</span>))</span><br><span class="line">net(torch.rand(<span class="number">2</span>, <span class="number">64</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">tensor([[<span class="number">0.</span>],</span><br><span class="line">        [<span class="number">0.</span>]])</span><br></pre></td></tr></tbody></table></figure><h3><span id="33-矩阵相乘">3.3 矩阵相乘</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">H = relu(x @ W1 + b1)</span><br><span class="line"></span><br><span class="line">H = relu(torch.mm(x, W1) + b1)</span><br></pre></td></tr></tbody></table></figure><p>上面写两种矩阵相乘的方式是一样的。</p><h2><span id="4-读写文件">4. 读写文件</span></h2><h3><span id="41-加载保存张量">4.1 加载保存张量</span></h3><p>保存张量信息</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line">x = torch.arange(<span class="number">4</span>)</span><br><span class="line">torch.save(x, <span class="string">'x-file'</span>)</span><br><span class="line"></span><br><span class="line">x2 = torch.load(<span class="string">'x-file'</span>)</span><br><span class="line">x2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">tensor([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br></pre></td></tr></tbody></table></figure><p>保存一个张量列表</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">y = torch.zeros(<span class="number">4</span>)</span><br><span class="line">torch.save([x, y], <span class="string">'x-files'</span>)</span><br><span class="line">x2, y2 = torch.load(<span class="string">'x-files'</span>)</span><br><span class="line">(x2, y2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">(tensor([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]), tensor([<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>]))</span><br></pre></td></tr></tbody></table></figure><p>写入或读取从字符串映射到张量的字典</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mydict = {<span class="string">'x'</span>: x, <span class="string">'y'</span>: y}</span><br><span class="line">torch.save(mydict, <span class="string">'mydict'</span>)</span><br><span class="line">mydict2 = torch.load(<span class="string">'mydict'</span>)</span><br><span class="line">mydict2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">{<span class="string">'x'</span>: tensor([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]), <span class="string">'y'</span>: tensor([<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>])}</span><br></pre></td></tr></tbody></table></figure><h3><span id="42-加载和保存模型参数">4.2 加载和保存模型参数</span></h3><p>构建简单的神经网络模型</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MLP</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.hidden = nn.Linear(<span class="number">20</span>, <span class="number">256</span>)</span><br><span class="line">        self.output = nn.Linear(<span class="number">256</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.output(F.relu(self.hidden(x)))</span><br><span class="line"></span><br><span class="line">net = MLP()</span><br><span class="line">X = torch.randn(size=(<span class="number">2</span>, <span class="number">20</span>))</span><br><span class="line">Y = net(X)</span><br></pre></td></tr></tbody></table></figure><p>保存模型参数文件，将模型的参数存储为一个叫做“mlp.params”的文件</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.save(net.state_dict(), <span class="string">'mlp.params'</span>)</span><br></pre></td></tr></tbody></table></figure><p>加载模型时需要先实例化模型。再读取文件中存储的参数</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">clone = MLP()</span><br><span class="line">clone.load_state_dict(torch.load(<span class="string">'mlp.params'</span>))</span><br><span class="line">clone.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">MLP(</span><br><span class="line">  (hidden): Linear(in_features=<span class="number">20</span>, out_features=<span class="number">256</span>, bias=<span class="literal">True</span>)</span><br><span class="line">  (output): Linear(in_features=<span class="number">256</span>, out_features=<span class="number">10</span>, bias=<span class="literal">True</span>)</span><br><span class="line">)</span><br></pre></td></tr></tbody></table></figure><p>判断初始化的两个模型是否参数一致</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Y_clone = clone(X)</span><br><span class="line">Y_clone == Y</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">tensor([[<span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>],</span><br><span class="line">        [<span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>]])</span><br></pre></td></tr></tbody></table></figure><h2><span id="5-gpu">5. GPU</span></h2><h3><span id="52-查看显卡信息">5.2 查看显卡信息</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">!nvidia-smi</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">Tue Jun  <span class="number">1</span> <span class="number">15</span>:<span class="number">40</span>:<span class="number">45</span> <span class="number">2021</span>       </span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI <span class="number">418.67</span>       Driver Version: <span class="number">418.67</span>       CUDA Version: <span class="number">10.1</span>     |</span><br><span class="line">|-------------------------------+----------------------+----------------------+</span><br><span class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|===============================+======================+======================|</span><br><span class="line">|   <span class="number">0</span>  Tesla V100-SXM2...  Off  | <span class="number">00000000</span>:<span class="number">00</span>:1B<span class="number">.0</span> Off |                    <span class="number">0</span> |</span><br><span class="line">| N/A   56C    P0    55W / 300W |   8124MiB / 16130MiB |      <span class="number">0</span>%      Default |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line">|   <span class="number">1</span>  Tesla V100-SXM2...  Off  | <span class="number">00000000</span>:<span class="number">00</span>:1C<span class="number">.0</span> Off |                    <span class="number">0</span> |</span><br><span class="line">| N/A   43C    P0    51W / 300W |   4252MiB / 16130MiB |      <span class="number">0</span>%      Default |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line">|   <span class="number">2</span>  Tesla V100-SXM2...  Off  | <span class="number">00000000</span>:<span class="number">00</span>:1D<span class="number">.0</span> Off |                    <span class="number">0</span> |</span><br><span class="line">| N/A   41C    P0    40W / 300W |     11MiB / 16130MiB |      <span class="number">0</span>%      Default |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line">|   <span class="number">3</span>  Tesla V100-SXM2...  Off  | <span class="number">00000000</span>:<span class="number">00</span>:1E<span class="number">.0</span> Off |                    <span class="number">0</span> |</span><br><span class="line">| N/A   62C    P0    62W / 300W |   1582MiB / 16130MiB |      <span class="number">0</span>%      Default |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line">                                                                               </span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| Processes:                                                       GPU Memory |</span><br><span class="line">|  GPU       PID   <span class="type">Type</span>   Process name                             Usage      |</span><br><span class="line">|=============================================================================|</span><br><span class="line">|    <span class="number">0</span>      <span class="number">2277</span>      C   ...buntu/miniconda3/envs/d2l-en/<span class="built_in">bin</span>/python  3289MiB |</span><br><span class="line">|    <span class="number">0</span>    <span class="number">127232</span>      C   ...buntu/miniconda3/envs/d2l-en/<span class="built_in">bin</span>/python  1389MiB |</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br></pre></td></tr></tbody></table></figure><h3><span id="52-获取计算设备">5.2 获取计算设备</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line">torch.device(<span class="string">'cpu'</span>), torch.cuda.device(<span class="string">'cuda'</span>), torch.cuda.device(<span class="string">'cuda:1'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">(device(<span class="built_in">type</span>=<span class="string">'cpu'</span>),</span><br><span class="line"> &lt;torch.cuda.device at <span class="number">0x7f723468cdc0</span>&gt;,</span><br><span class="line"> &lt;torch.cuda.device at <span class="number">0x7f7234655310</span>&gt;)</span><br></pre></td></tr></tbody></table></figure><p>查询可用gpu的数量</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">torch.cuda.device_count()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line"><span class="number">2</span></span><br></pre></td></tr></tbody></table></figure><h3><span id="53-构建函数">5.3 构建函数</span></h3><p>这两个函数允许我们在请求的GPU不存在的情况下运行代码</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">try_gpu</span>(<span class="params">i=<span class="number">0</span></span>):  </span><br><span class="line">    <span class="string">"""如果存在，则返回gpu(i)，否则返回cpu()。"""</span></span><br><span class="line">    <span class="keyword">if</span> torch.cuda.device_count() &gt;= i + <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> torch.device(<span class="string">f'cuda:<span class="subst">{i}</span>'</span>)</span><br><span class="line">    <span class="keyword">return</span> torch.device(<span class="string">'cpu'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">try_all_gpus</span>():  </span><br><span class="line">    <span class="string">"""返回所有可用的GPU，如果没有GPU，则返回[cpu(),]。"""</span></span><br><span class="line">    devices = [</span><br><span class="line">        torch.device(<span class="string">f'cuda:<span class="subst">{i}</span>'</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(torch.cuda.device_count())]</span><br><span class="line">    <span class="keyword">return</span> devices <span class="keyword">if</span> devices <span class="keyword">else</span> [torch.device(<span class="string">'cpu'</span>)]</span><br><span class="line"></span><br><span class="line">try_gpu(), try_gpu(<span class="number">10</span>), try_all_gpus()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">(device(<span class="built_in">type</span>=<span class="string">'cuda'</span>, index=<span class="number">0</span>),</span><br><span class="line"> device(<span class="built_in">type</span>=<span class="string">'cpu'</span>),</span><br><span class="line"> [device(<span class="built_in">type</span>=<span class="string">'cuda'</span>, index=<span class="number">0</span>), device(<span class="built_in">type</span>=<span class="string">'cuda'</span>, index=<span class="number">1</span>)])</span><br></pre></td></tr></tbody></table></figure><h3><span id="54-查询张量所在设备">5.4 查询张量所在设备</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">x.device</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">device(<span class="built_in">type</span>=<span class="string">'cpu'</span>)</span><br></pre></td></tr></tbody></table></figure><h3><span id="55-将张量存储在gpu上">5.5 将张量存储在GPU上</span></h3><p>默认使用第一个GPU</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">X = torch.ones(<span class="number">2</span>, <span class="number">3</span>, device=try_gpu())</span><br><span class="line">X</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>]], device=<span class="string">'cuda:0'</span>)</span><br></pre></td></tr></tbody></table></figure><p>第二个GPU上创建一个随机张量</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Y = torch.rand(<span class="number">2</span>, <span class="number">3</span>, device=try_gpu(<span class="number">1</span>))</span><br><span class="line">Y</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">tensor([[<span class="number">0.9333</span>, <span class="number">0.8735</span>, <span class="number">0.7784</span>],</span><br><span class="line">        [<span class="number">0.3453</span>, <span class="number">0.5509</span>, <span class="number">0.3475</span>]], device=<span class="string">'cuda:1'</span>)</span><br></pre></td></tr></tbody></table></figure><h3><span id="56-不同设备上张量运算">5.6 不同设备上张量运算</span></h3><p>要计算<code>X + Y</code>，我们需要决定在哪里执行这个操作，如下所示可以看到x、y 不在同一个设备中，需要将其放置在同一个设备上才可以进行运算。将x放置在 <code>cuda:1</code> 上，是进行了 <code>clone</code>的操作，所以x、z不是相同的张量</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Z = X.cuda(<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(X)</span><br><span class="line"><span class="built_in">print</span>(Z)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>]], device=<span class="string">'cuda:0'</span>)</span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>]], device=<span class="string">'cuda:1'</span>)</span><br></pre></td></tr></tbody></table></figure><p>在放置在相同的设备之后，在进行相加操作</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Y + Z</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">tensor([[<span class="number">1.9333</span>, <span class="number">1.8735</span>, <span class="number">1.7784</span>],</span><br><span class="line">        [<span class="number">1.3453</span>, <span class="number">1.5509</span>, <span class="number">1.3475</span>]], device=<span class="string">'cuda:1'</span>)</span><br></pre></td></tr></tbody></table></figure><p>当在相同的设备下进行更换，比如：从<code>cuda:1</code> 更换到 <code>cuda:1</code> ，是不会创建新的张量的。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Z.cuda(<span class="number">1</span>) <span class="keyword">is</span> Z</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line"><span class="literal">True</span></span><br></pre></td></tr></tbody></table></figure><h3><span id="57-神经网络布置在gpu上">5.7 神经网络布置在GPU上</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">net = nn.Sequential(nn.Linear(<span class="number">3</span>, <span class="number">1</span>))</span><br><span class="line">net = net.to(device=try_gpu())</span><br><span class="line"></span><br><span class="line">net(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">tensor([[-<span class="number">0.8412</span>],</span><br><span class="line">        [-<span class="number">0.8412</span>]], device=<span class="string">'cuda:0'</span>, grad_fn=&lt;AddmmBackward&gt;)</span><br></pre></td></tr></tbody></table></figure><p>确认模型参数存储在同一个GPU上</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">net[<span class="number">0</span>].weight.data.device</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">device(<span class="built_in">type</span>=<span class="string">'cuda'</span>, index=<span class="number">0</span>)</span><br></pre></td></tr></tbody></table></figure><h3><span id="58购买gpu">5.8购买GPU</span></h3><p>在购买GPU时，先看显存和计算的能力，再看价格。</p><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
          <category> PyTorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>实战Kaggle比赛：预测房价</title>
      <link href="/2022/04/23/machine-learning/shi-zhan-kaggle-bi-sai-yu-ce-fang-jie/"/>
      <url>/2022/04/23/machine-learning/shi-zhan-kaggle-bi-sai-yu-ce-fang-jie/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="实战kaggle比赛预测房价">实战Kaggle比赛：预测房价</span></h1><h2><span id="1-下载数据">1. 下载数据</span></h2><p>实现几个函数来方便下载数据</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> hashlib</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> tarfile</span><br><span class="line"><span class="keyword">import</span> zipfile</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">DATA_HUB = <span class="built_in">dict</span>()</span><br><span class="line">DATA_URL = <span class="string">'http://d2l-data.s3-accelerate.amazonaws.com/'</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">download</span>(<span class="params">name, cache_dir=os.path.join(<span class="params"><span class="string">'..'</span>, <span class="string">'data'</span></span>)</span>):  </span><br><span class="line">    <span class="string">"""下载一个DATA_HUB中的文件，返回本地文件名。"""</span></span><br><span class="line">    <span class="keyword">assert</span> name <span class="keyword">in</span> DATA_HUB, <span class="string">f"<span class="subst">{name}</span> 不存在于 <span class="subst">{DATA_HUB}</span>."</span></span><br><span class="line">    url, sha1_hash = DATA_HUB[name]</span><br><span class="line">    os.makedirs(cache_dir, exist_ok=<span class="literal">True</span>)</span><br><span class="line">    fname = os.path.join(cache_dir, url.split(<span class="string">'/'</span>)[-<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">if</span> os.path.exists(fname):</span><br><span class="line">        sha1 = hashlib.sha1()</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(fname, <span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">                data = f.read(<span class="number">1048576</span>)</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> data:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">                sha1.update(data)</span><br><span class="line">        <span class="keyword">if</span> sha1.hexdigest() == sha1_hash:</span><br><span class="line">            <span class="keyword">return</span> fname</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f'正在从<span class="subst">{url}</span>下载<span class="subst">{fname}</span>...'</span>)</span><br><span class="line">    r = requests.get(url, stream=<span class="literal">True</span>, verify=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(fname, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(r.content)</span><br><span class="line">    <span class="keyword">return</span> fname</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">download_extract</span>(<span class="params">name, folder=<span class="literal">None</span></span>):  </span><br><span class="line">    <span class="string">"""下载并解压zip/tar文件。"""</span></span><br><span class="line">    fname = download(name)</span><br><span class="line">    base_dir = os.path.dirname(fname)</span><br><span class="line">    data_dir, ext = os.path.splitext(fname)</span><br><span class="line">    <span class="keyword">if</span> ext == <span class="string">'.zip'</span>:</span><br><span class="line">        fp = zipfile.ZipFile(fname, <span class="string">'r'</span>)</span><br><span class="line">    <span class="keyword">elif</span> ext <span class="keyword">in</span> (<span class="string">'.tar'</span>, <span class="string">'.gz'</span>):</span><br><span class="line">        fp = tarfile.<span class="built_in">open</span>(fname, <span class="string">'r'</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">assert</span> <span class="literal">False</span>, <span class="string">'只有zip/tar文件可以被解压缩。'</span></span><br><span class="line">    fp.extractall(base_dir)</span><br><span class="line">    <span class="keyword">return</span> os.path.join(base_dir, folder) <span class="keyword">if</span> folder <span class="keyword">else</span> data_dir</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">download_all</span>():  </span><br><span class="line">    <span class="string">"""下载DATA_HUB中的所有文件。"""</span></span><br><span class="line">    <span class="keyword">for</span> name <span class="keyword">in</span> DATA_HUB:</span><br><span class="line">        download(name)</span><br></pre></td></tr></tbody></table></figure><p>使用pandas读入并处理数据</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line">DATA_HUB[<span class="string">'kaggle_house_train'</span>] = (  </span><br><span class="line">    DATA_URL + <span class="string">'kaggle_house_pred_train.csv'</span>,</span><br><span class="line">    <span class="string">'585e9cc93e70b39160e7921475f9bcd7d31219ce'</span>)</span><br><span class="line"></span><br><span class="line">DATA_HUB[<span class="string">'kaggle_house_test'</span>] = (  </span><br><span class="line">    DATA_URL + <span class="string">'kaggle_house_pred_test.csv'</span>,</span><br><span class="line">    <span class="string">'fa19780a7b011d9b009e8bff8e99922a8ee2eb90'</span>)</span><br><span class="line"></span><br><span class="line">train_data = pd.read_csv(download(<span class="string">'kaggle_house_train'</span>))</span><br><span class="line">test_data = pd.read_csv(download(<span class="string">'kaggle_house_test'</span>))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(train_data.shape)</span><br><span class="line"><span class="built_in">print</span>(test_data.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">(<span class="number">1460</span>, <span class="number">81</span>)</span><br><span class="line">(<span class="number">1459</span>, <span class="number">80</span>)</span><br></pre></td></tr></tbody></table></figure><h2><span id="2-查看数据">2. 查看数据</span></h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(train_data.iloc[<span class="number">0</span>:<span class="number">4</span>, [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, -<span class="number">3</span>, -<span class="number">2</span>, -<span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出：</span></span><br><span class="line">   Id  MSSubClass MSZoning  LotFrontage SaleType SaleCondition  SalePrice</span><br><span class="line"><span class="number">0</span>   <span class="number">1</span>          <span class="number">60</span>       RL         <span class="number">65.0</span>       WD        Normal     <span class="number">208500</span></span><br><span class="line"><span class="number">1</span>   <span class="number">2</span>          <span class="number">20</span>       RL         <span class="number">80.0</span>       WD        Normal     <span class="number">181500</span></span><br><span class="line"><span class="number">2</span>   <span class="number">3</span>          <span class="number">60</span>       RL         <span class="number">68.0</span>       WD        Normal     <span class="number">223500</span></span><br><span class="line"><span class="number">3</span>   <span class="number">4</span>          <span class="number">70</span>       RL         <span class="number">60.0</span>       WD       Abnorml     <span class="number">140000</span></span><br></pre></td></tr></tbody></table></figure><p>在每个样本中，第一个特征是ID， 我们将其从数据集中删除</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">all_features = pd.concat((train_data.iloc[:, <span class="number">1</span>:-<span class="number">1</span>], test_data.iloc[:, <span class="number">1</span>:]))</span><br></pre></td></tr></tbody></table></figure><h2><span id="3-数据预处理">3. 数据预处理</span></h2><p>将所有缺失的值替换为相应特征的平均值。 通过将特征重新缩放到零均值和单位方差来标准化数据</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">numeric_features = all_features.dtypes[all_features.dtypes != <span class="string">'object'</span>].index</span><br><span class="line">all_features[numeric_features] = all_features[numeric_features].apply(</span><br><span class="line">    <span class="keyword">lambda</span> x: (x - x.mean()) / (x.std()))</span><br><span class="line">all_features[numeric_features] = all_features[numeric_features].fillna(<span class="number">0</span>)</span><br></pre></td></tr></tbody></table></figure><p>处理离散值。 我们用一次独热编码替换它们</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">all_features = pd.get_dummies(all_features, dummy_na=<span class="literal">True</span>)</span><br><span class="line">all_features.shape</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出：</span></span><br><span class="line">(<span class="number">2919</span>, <span class="number">331</span>)</span><br></pre></td></tr></tbody></table></figure><p>从<code>pandas</code>格式中提取NumPy格式，并将其转换为张量表示</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">n_train = train_data.shape[<span class="number">0</span>]</span><br><span class="line">train_features = torch.tensor(all_features[:n_train].values,</span><br><span class="line">                              dtype=torch.float32)</span><br><span class="line">test_features = torch.tensor(all_features[n_train:].values,</span><br><span class="line">                             dtype=torch.float32)</span><br><span class="line">train_labels = torch.tensor(train_data.SalePrice.values.reshape(-<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                            dtype=torch.float32)</span><br></pre></td></tr></tbody></table></figure><h2><span id="4-训练模型">4. 训练模型</span></h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">loss = nn.MSELoss()</span><br><span class="line">in_features = train_features.shape[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_net</span>():</span><br><span class="line">    net = nn.Sequential(nn.Linear(in_features, <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">return</span> net</span><br></pre></td></tr></tbody></table></figure><p>我们更关心相对误差 $\frac{y−\hat{y}}{y}$ ， 解决这个问题的一种方法是用价格预测的 <strong>对数</strong> 来衡量差异</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">log_rmse</span>(<span class="params">net, features, labels</span>):</span><br><span class="line">    clipped_preds = torch.clamp(net(features), <span class="number">1</span>, <span class="built_in">float</span>(<span class="string">'inf'</span>))</span><br><span class="line">    rmse = torch.sqrt(loss(torch.log(clipped_preds), torch.log(labels)))</span><br><span class="line">    <span class="keyword">return</span> rmse.item()</span><br></pre></td></tr></tbody></table></figure><p>我们的训练函数将借助 <code>Adam</code> 优化器，计算训练和验证的 <code>log rmse</code></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">net, train_features, train_labels, test_features, test_labels,</span></span><br><span class="line"><span class="params">          num_epochs, learning_rate, weight_decay, batch_size</span>):</span><br><span class="line">    train_ls, test_ls = [], []</span><br><span class="line">    train_iter = d2l.load_array((train_features, train_labels), batch_size)</span><br><span class="line">    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate,</span><br><span class="line">                                 weight_decay=weight_decay)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> train_iter:</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            l = loss(net(X), y)</span><br><span class="line">            l.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">        train_ls.append(log_rmse(net, train_features, train_labels))</span><br><span class="line">        <span class="keyword">if</span> test_labels <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            test_ls.append(log_rmse(net, test_features, test_labels))</span><br><span class="line">    <span class="keyword">return</span> train_ls, test_ls</span><br></pre></td></tr></tbody></table></figure><p>K折交叉验证</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_k_fold_data</span>(<span class="params">k, i, X, y</span>):</span><br><span class="line">    <span class="keyword">assert</span> k &gt; <span class="number">1</span></span><br><span class="line">    fold_size = X.shape[<span class="number">0</span>] // k</span><br><span class="line">    X_train, y_train = <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">        idx = <span class="built_in">slice</span>(j * fold_size, (j + <span class="number">1</span>) * fold_size)</span><br><span class="line">        X_part, y_part = X[idx, :], y[idx]</span><br><span class="line">        <span class="keyword">if</span> j == i:</span><br><span class="line">            X_valid, y_valid = X_part, y_part</span><br><span class="line">        <span class="keyword">elif</span> X_train <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            X_train, y_train = X_part, y_part</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            X_train = torch.cat([X_train, X_part], <span class="number">0</span>)</span><br><span class="line">            y_train = torch.cat([y_train, y_part], <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> X_train, y_train, X_valid, y_valid</span><br></pre></td></tr></tbody></table></figure><p>返回训练和验证误差的平均值</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">k_fold</span>(<span class="params">k, X_train, y_train, num_epochs, learning_rate, weight_decay,</span></span><br><span class="line"><span class="params">           batch_size</span>):</span><br><span class="line">    train_l_sum, valid_l_sum = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">        data = get_k_fold_data(k, i, X_train, y_train)</span><br><span class="line">        net = get_net()</span><br><span class="line">        train_ls, valid_ls = train(net, *data, num_epochs, learning_rate,</span><br><span class="line">                                   weight_decay, batch_size)</span><br><span class="line">        train_l_sum += train_ls[-<span class="number">1</span>]</span><br><span class="line">        valid_l_sum += valid_ls[-<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">            d2l.plot(<span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">1</span>, num_epochs + <span class="number">1</span>)), [train_ls, valid_ls],</span><br><span class="line">                     xlabel=<span class="string">'epoch'</span>, ylabel=<span class="string">'rmse'</span>, xlim=[<span class="number">1</span>, num_epochs],</span><br><span class="line">                     legend=[<span class="string">'train'</span>, <span class="string">'valid'</span>], yscale=<span class="string">'log'</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f'fold <span class="subst">{i + <span class="number">1</span>}</span>, train log rmse <span class="subst">{<span class="built_in">float</span>(train_ls[-<span class="number">1</span>]):f}</span>, '</span></span><br><span class="line">              <span class="string">f'valid log rmse <span class="subst">{<span class="built_in">float</span>(valid_ls[-<span class="number">1</span>]):f}</span>'</span>)</span><br><span class="line">    <span class="keyword">return</span> train_l_sum / k, valid_l_sum / k</span><br></pre></td></tr></tbody></table></figure><h2><span id="5-模型结果">5. 模型结果</span></h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">k, num_epochs, lr, weight_decay, batch_size = <span class="number">5</span>, <span class="number">100</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">64</span></span><br><span class="line">train_l, valid_l = k_fold(k, train_features, train_labels, num_epochs, lr,</span><br><span class="line">                          weight_decay, batch_size)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f'<span class="subst">{k}</span>-折验证: 平均训练log rmse: <span class="subst">{<span class="built_in">float</span>(train_l):f}</span>, '</span></span><br><span class="line">      <span class="string">f'平均验证log rmse: <span class="subst">{<span class="built_in">float</span>(valid_l):f}</span>'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出：</span></span><br><span class="line">fold <span class="number">1</span>, train log rmse <span class="number">0.170478</span>, valid log rmse <span class="number">0.157071</span></span><br><span class="line">fold <span class="number">2</span>, train log rmse <span class="number">0.162220</span>, valid log rmse <span class="number">0.190368</span></span><br><span class="line">fold <span class="number">3</span>, train log rmse <span class="number">0.163924</span>, valid log rmse <span class="number">0.168422</span></span><br><span class="line">fold <span class="number">4</span>, train log rmse <span class="number">0.168025</span>, valid log rmse <span class="number">0.154744</span></span><br><span class="line">fold <span class="number">5</span>, train log rmse <span class="number">0.162936</span>, valid log rmse <span class="number">0.182541</span></span><br><span class="line"><span class="number">5</span>-折验证: 平均训练log rmse: <span class="number">0.165517</span>, 平均验证log rmse: <span class="number">0.170629</span></span><br></pre></td></tr></tbody></table></figure><h2><span id="6-提交结果">6. 提交结果</span></h2><p>前面属于整个调参过程，所以需要训练集和测试集的参与，但是在提交结果的过程是不需要测试集的，构建函数如下：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_and_pred</span>(<span class="params">train_features, test_feature, train_labels, test_data,</span></span><br><span class="line"><span class="params">                   num_epochs, lr, weight_decay, batch_size</span>):</span><br><span class="line">    net = get_net()</span><br><span class="line">    train_ls, _ = train(net, train_features, train_labels, <span class="literal">None</span>, <span class="literal">None</span>,</span><br><span class="line">                        num_epochs, lr, weight_decay, batch_size)</span><br><span class="line">    d2l.plot(np.arange(<span class="number">1</span>, num_epochs + <span class="number">1</span>), [train_ls], xlabel=<span class="string">'epoch'</span>,</span><br><span class="line">             ylabel=<span class="string">'log rmse'</span>, xlim=[<span class="number">1</span>, num_epochs], yscale=<span class="string">'log'</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f'train log rmse <span class="subst">{<span class="built_in">float</span>(train_ls[-<span class="number">1</span>]):f}</span>'</span>)</span><br><span class="line">    preds = net(test_features).detach().numpy()</span><br><span class="line">    test_data[<span class="string">'SalePrice'</span>] = pd.Series(preds.reshape(<span class="number">1</span>, -<span class="number">1</span>)[<span class="number">0</span>])</span><br><span class="line">    submission = pd.concat([test_data[<span class="string">'Id'</span>], test_data[<span class="string">'SalePrice'</span>]], axis=<span class="number">1</span>)</span><br><span class="line">    submission.to_csv(<span class="string">'submission.csv'</span>, index=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">train_and_pred(train_features, test_features, train_labels, test_data,</span><br><span class="line">               num_epochs, lr, weight_decay, batch_size)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出：</span></span><br><span class="line">train log rmse <span class="number">0.162603</span></span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 回归模型 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据预处理方式</title>
      <link href="/2022/04/23/machine-learning/pytorch/shu-ju-yu-chu-li-fang-shi/"/>
      <url>/2022/04/23/machine-learning/pytorch/shu-ju-yu-chu-li-fang-shi/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="数据预处理">数据预处理</span></h1><h2><span id="1-区分数值型和文本型特征">1. 区分数值型和文本型特征</span></h2><p>区分数值型特征和文本型特征，将缺失值替换为相应的特征的平均值，将特征重新缩放到零均值和单位方差来标准化数据。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 区分数值型特征和文本型特征 ,将缺失值替换为相应的特征的平均值，</span></span><br><span class="line"><span class="comment"># 将特征重新缩放到零均值和单位方差来标准化数据</span></span><br><span class="line">numeric_features = all_features.dtypes[all_features.dtypes != <span class="string">'object'</span>].index</span><br><span class="line">all_features[numeric_features] = all_features[numeric_features].apply(</span><br><span class="line">    <span class="keyword">lambda</span> x: (x - x.mean()) / (x.std())</span><br><span class="line">)</span><br><span class="line">all_features[numeric_features] = all_features[numeric_features].fillna(<span class="number">0</span>)</span><br></pre></td></tr></tbody></table></figure><h2><span id="2-独热编码">2. 独热编码</span></h2><p>处理离散值。 我们用一次独热编码替换它们</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">all_features = pd.get_dummies(all_features, dummy_na=<span class="literal">True</span>)</span><br><span class="line">all_features.shape</span><br></pre></td></tr></tbody></table></figure><h2><span id="3-转换为张量表示">3. 转换为张量表示</span></h2><p>从<code>pandas</code>格式中提取<code>NumPy</code>格式，并将其转换为<code>张量</code>表示</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 替换为张量表示</span></span><br><span class="line">n_train = train_data.shape[<span class="number">0</span>]</span><br><span class="line">train_features = torch.tensors(all_fatures[:n_train].values, dtype=torch.float32)</span><br><span class="line">test_features = torch.tensors(all_fatures[n_train:].values, dtype=torch.float32)</span><br><span class="line">train_labels = torch.tensor(train_data[<span class="string">'SalePrice'</span>].values.reshape(-<span class="number">1</span>, <span class="number">1</span>), </span><br><span class="line">                            dtype=torch.float32)</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> PyTorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
            <tag> 数据预处理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>nn常用自构造函数</title>
      <link href="/2022/04/23/machine-learning/pytorch/nn-chang-yong-zi-gou-zao-han-shu/"/>
      <url>/2022/04/23/machine-learning/pytorch/nn-chang-yong-zi-gou-zao-han-shu/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="nn常用自构造函数">nn常用自构造函数</span></h1><h2><span id="1-权重初始化函数">1. 权重初始化函数</span></h2><p>在构建神经网络模型的时候，<code>nn.Linear()</code> 层一般都需要自己初始化，初始化函数如下：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">net = nn.Sequential(nn.Flatten(), nn.Linear(<span class="number">784</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">init_weights</span>(<span class="params">m</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">type</span>(m) == nn.Linear:</span><br><span class="line">        nn.init.normal_(m.weight, std=<span class="number">0.01</span>)</span><br><span class="line">        </span><br><span class="line">net.apply(init_weights)</span><br></pre></td></tr></tbody></table></figure><h2><span id="2-交叉验证">2. 交叉验证</span></h2><p>第<code>i</code>折交叉验证的实现</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># K 折交叉验证 (第i折验证)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_k_fold_data</span>(<span class="params">k, i, X, y</span>):</span><br><span class="line">    <span class="keyword">assert</span> k &gt; <span class="number">1</span></span><br><span class="line">    fold_size = X.shape[<span class="number">0</span>] // k</span><br><span class="line">    X_train, y_train = <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">        idx = <span class="built_in">slice</span>(j * fold_size, (j + <span class="number">1</span>) * fold_size)</span><br><span class="line">        X_part, y_part = X[idx, :], y[idx]</span><br><span class="line">        <span class="keyword">if</span> j == i:</span><br><span class="line">            X_valid, y_valid = X_part, y_part</span><br><span class="line">        <span class="keyword">elif</span> X_train <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            X_train, y_train = X_part, y_part</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            X_train = torch.cat([X_train, X_part], <span class="number">0</span>)</span><br><span class="line">            y_train = torch.cat([y_train, y_part], <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> X_train, y_train, X_valid, y_valid</span><br></pre></td></tr></tbody></table></figure><p><code>k</code> 折交叉验证</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># K 折交叉验证</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">k_fold</span>(<span class="params">k, x_train, y_train, num_epochs, learning_rate, weight_decay, </span></span><br><span class="line"><span class="params">           batch_size</span>):</span><br><span class="line">    train_l_sum, valid_l_sum = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">        data = get_k_fold_data(k, i, x_train, y_train)</span><br><span class="line">        net = get_net()</span><br><span class="line">        <span class="comment"># 注意*变量的使用方式，简化</span></span><br><span class="line">        train_ls, valid_ls = train(net, *data, num_epochs, learning_rate, </span><br><span class="line">                                   weight_decay, batch_size)</span><br><span class="line">        train_l_sum += train_ls[-<span class="number">1</span>]</span><br><span class="line">        valid_l_sum += valid_ls[-<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">            d2l.plot(<span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">1</span>, num_epochs + <span class="number">1</span>)), [train_ls, valid_ls], </span><br><span class="line">                     xlabel=<span class="string">'epoch'</span>, ylabel=<span class="string">'rmse'</span>, xlim=[<span class="number">1</span>, num_epochs], </span><br><span class="line">                     legend=[<span class="string">'train'</span>, <span class="string">'valid'</span>], yscale=<span class="string">'log'</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f"fold <span class="subst">{i + <span class="number">1</span>}</span>, train log rmse <span class="subst">{<span class="built_in">float</span>(train_ls[-<span class="number">1</span>]):f}</span>"</span>, </span><br><span class="line">              <span class="string">f"valid log rmse <span class="subst">{<span class="built_in">float</span>(valid_ls[-<span class="number">1</span>]):f}</span>"</span>)</span><br><span class="line">    <span class="keyword">return</span> train_l_sum / k, valid_l_sum / k</span><br><span class="line"></span><br><span class="line">k, num_epochs, lr, weight_decay, batch_size = <span class="number">5</span>, <span class="number">100</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">64</span></span><br><span class="line">train_l, valid_l = k_fold(k, train_features, train_labels, num_epochs, lr, </span><br><span class="line">                          weight_decay, batch_size)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f'<span class="subst">{k}</span>-折验证：平均log rmse：<span class="subst">{<span class="built_in">float</span>(train_l):f}</span>, '</span></span><br><span class="line">      <span class="string">f'平均验证log rmse：<span class="subst">{<span class="built_in">float</span>(valid_l):f}</span>'</span>)</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
          <category> PyTorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>查看torch构建的DataSet数据集的读取速度</title>
      <link href="/2022/04/23/machine-learning/pytorch/xun-lian-mo-xing-shu-ju-du-qu-su-du/"/>
      <url>/2022/04/23/machine-learning/pytorch/xun-lian-mo-xing-shu-ju-du-qu-su-du/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="查看torch构建的dataset数据集的读取速度">查看torch构建的DataSet数据集的读取速度</span></h1><h2><span id="1-构架timer类">1. 构架Timer类</span></h2><p>利用下面构建的类（<code>d2l</code>包中<code>Timer</code>类）能够实现多个运行时间的记录。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Timer</span>:</span><br><span class="line">    <span class="string">"""Record multiple running times."""</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">"""Defined in :numref:`subsec_linear_model`"""</span></span><br><span class="line">        self.times = []</span><br><span class="line">        self.start()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">start</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">"""Start the timer."""</span></span><br><span class="line">        self.tik = time.time()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">stop</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">"""Stop the timer and record the time in a list."""</span></span><br><span class="line">        self.times.append(time.time() - self.tik)</span><br><span class="line">        <span class="keyword">return</span> self.times[-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">avg</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">"""Return the average time."""</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">sum</span>(self.times) / <span class="built_in">len</span>(self.times)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sum</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">"""Return the sum of time."""</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">sum</span>(self.times)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">cumsum</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">"""Return the accumulated time."""</span></span><br><span class="line">        <span class="keyword">return</span> np.array(self.times).cumsum().tolist()</span><br></pre></td></tr></tbody></table></figure><h2><span id="2-构建数据集并查看读取时长">2. 构建数据集并查看读取时长</span></h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils <span class="keyword">import</span> data</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br></pre></td></tr></tbody></table></figure><p>读取 <code>MNIST</code> 数据集，获取<code>DataSet</code>。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 能够通过ToTensor实例将图像数据从PIL类型转换为32位浮点数格式</span></span><br><span class="line"><span class="comment"># 并除以255使得所有的数值均在0到1之间</span></span><br><span class="line">trans = transforms.ToTensor()</span><br><span class="line">mnist_train = torchvision.datasets.FashionMNIST(</span><br><span class="line">    root=<span class="string">"./data"</span>, train=<span class="literal">True</span>, transform=trans, download=<span class="literal">True</span>)</span><br><span class="line">mnist_test = torchvision.datasets.FashionMNIST(</span><br><span class="line">    root=<span class="string">"./data"</span>, train=<span class="literal">False</span>, transform=trans, download=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">len</span>(mnist_train), <span class="built_in">len</span>(mnist_test)</span><br></pre></td></tr></tbody></table></figure><p> 构建 <code>DataLoader</code>，通过函数 <code>get_dataloader_worker</code> 来调整数据读取的进程数。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> multiprocessing</span><br><span class="line">multiprocessing.freeze_support()</span><br><span class="line"><span class="comment"># 获取第一个</span></span><br><span class="line">x, y = <span class="built_in">next</span>(<span class="built_in">iter</span>(data.DataLoader(mnist_train, batch_size=<span class="number">18</span>)))</span><br><span class="line"><span class="comment"># 查看第一个batch_size</span></span><br><span class="line"><span class="built_in">print</span>(x.shape, y.shape)</span><br><span class="line"><span class="comment"># num_workers，使用4个进程来读取数据，根据CPU来进行选择；</span></span><br><span class="line"><span class="comment"># shuffle是否进行随机，一般情况下训练集进行随机，测试集不用</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_dataloader_worker</span>():</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">train_iter = data.DataLoader(mnist_train, batch_size=<span class="number">18</span>, shuffle=<span class="literal">True</span>, </span><br><span class="line">                             num_workers=get_dataloader_worker())</span><br><span class="line"><span class="comment"># 判断读取数据时间的变化，训练模型之前需要看一下数据读取的速度有多快</span></span><br><span class="line">timer = d2l.Timer()</span><br><span class="line"><span class="keyword">for</span> x, y <span class="keyword">in</span>  train_iter:</span><br><span class="line"><span class="comment">#     print(x.shape)</span></span><br><span class="line">    <span class="keyword">continue</span></span><br><span class="line"><span class="string">f'<span class="subst">{timer.stop():<span class="number">.2</span>f}</span> sec'</span></span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> PyTorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
            <tag> 数据读取速度 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>凸包算法</title>
      <link href="/2022/04/23/basic-algorithm/tu-bao-suan-fa/"/>
      <url>/2022/04/23/basic-algorithm/tu-bao-suan-fa/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="凸包算法">凸包算法</span></h1><p>在一个实数向量空间 $V$ 中，对于给定集合 $X$，所有包含 $X$ 的凸集的交集$S$ 被称为 $X$ 的<strong>凸包</strong>。</p><script type="math/tex; mode=display">S:=\bigcap_{\begin{array}{}X\subseteq K\subseteq V \\K~is~convex\end{array}}K.</script><p>$X$ 的凸包可以用$X$ 内所有点 $(x_1,\dots,x_n)$ 的线性组合来构造。</p><script type="math/tex; mode=display">S:=\{\sum^n_{j=1}t_jx_j|x_j\in X,\sum^n_{j=1}t_j=1, t_j\in[0,1]\}</script><p>在二维欧几里得空间中，凸包可想象为一条刚好包着所有点的橡皮圈。</p><p><img src="http://xiaomanzhan.com.cn/content/image-20220423203046412.png" alt="image-20220423203046412"></p><h2><span id="例题587-安装栅栏">例题：</span></h2><p>在一个二维的花园中，有一些用 (x, y) 坐标表示的树。由于安装费用十分昂贵，你的任务是先用最短的绳子围起所有的树。只有当所有的树都被绳子包围时，花园才能围好栅栏。你需要找到正好位于栅栏边界上的树的坐标。</p><h2><span id="1-包裹法jarvis步进法">1. 包裹法（Jarvis步进法）</span></h2><p>首先由一点必定在凸包的点开始，例如最左的一点 $A_1$。然后选择 $A_2$ 使得所有的点都在 $A_1A_2$ 的右方，这步骤的时间复杂度是 $O(n)$，要比较所有点以 $A_1$ 为原点的极坐标角度。以 $A_2$ 为原点，重复这个步骤，依次找到 $A_3,A_4,\dots,A_k,A_1$。总共有 $k$ 步，因此时间复杂度为 $O(kn)/O(n^2)$。</p><h3><span id="11-详细步骤">1.1 <strong>详细步骤：</strong></span></h3><p>给定原点 $p$，如何找到点 $q$，满足其余的点 $r$ 均在向量 $\vec{pq}$ 的左边，我们使用「<strong>向量叉积</strong>」来进行判别。我们可以知道两个向量 $\vec{pq},\vec{qr} $ 的叉积大于 $0$ 时，则两个向量之间的夹角小于 $180 \degree$，两个向量之间构成的旋转方向为逆时针，此时可以知道 $r$ 一定在 $\vec{pq}$ 的左边；叉积等于 $0$ 时，则表示两个向量之间平行，$p,q,r$ 在同一条直线上；叉积小于 $0$ 时，则表示两个向量之间的夹角大于 $ 180\degree$，两个向量之间构成的旋转方向为顺时针，此时可以知道 $r$ 一定在 $\vec{pq}$ 的右边。为了找到点 $q$，我们使用函数 $\texttt{cross}()$ ，这个函数有 $3$ 个参数，分别是当前凸包上的点 $p$，下一个会加到凸包里的点 $q$，其他点空间内的任何一个点 $r$，通过计算向量 $\vec{pq},\vec{qr}$ 的叉积来判断旋转方向，如果剩余所有的点 $r$ 均满足在向量 $\vec{pq}$ 的左边，则此时我们将 $q$ 加入凸包中。</p><p>下图说明了这样的关系，点 $r$ 在向量 $\vec{pq} $的左边。</p><p><img src="http://xiaomanzhan.com.cn/content/587_1.png" alt="1"></p><p>从上图中，我们可以观察到点 p，q 和 r 形成的向量相应地都是逆时针方向，向量 $ \vec{pq} $  和 $\vec{qr}$ 旋转方向为逆时针，函数 $\texttt{cross}(p,q,r)$ 返回值大于 0。</p><script type="math/tex; mode=display">cross(p,q,r)=\vec{pq}\times\vec{qr}\\=\begin{vmatrix}(q_x-p_x)&(q_y-p_y)\\(r_x-q_x)&(r_y-q_y)\end{vmatrix}\\=(q_x-p_x)\times(r_y-q_y)-(q_y-p_y)\times(r_x-q_x)</script><p>我们遍历所有点 r，找到对于点 p 来说逆时针方向最靠外的点 q，把它加入凸包。如果存在 2 个点相对点 p 在同一条线上，我们应当将 q 和 p 同一线段上的边界点都考虑进来，此时需要进行标记，防止重复添加。</p><h3><span id="12-模板">1.2 模板：</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">outerTrees</span>(<span class="params">self, trees: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">cross</span>(<span class="params">p: <span class="type">List</span>[<span class="built_in">int</span>], q: <span class="type">List</span>[<span class="built_in">int</span>], r: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">            <span class="keyword">return</span> (q[<span class="number">0</span>] - p[<span class="number">0</span>]) * (r[<span class="number">1</span>] - q[<span class="number">1</span>]) - (q[<span class="number">1</span>] - p[<span class="number">1</span>]) * (r[<span class="number">0</span>] - q[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">        n = <span class="built_in">len</span>(trees)</span><br><span class="line">        <span class="keyword">if</span> n &lt; <span class="number">4</span>:</span><br><span class="line">            <span class="keyword">return</span> trees</span><br><span class="line"></span><br><span class="line">        leftMost = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i, tree <span class="keyword">in</span> <span class="built_in">enumerate</span>(trees):</span><br><span class="line">            <span class="keyword">if</span> tree[<span class="number">0</span>] &lt; trees[leftMost][<span class="number">0</span>]:</span><br><span class="line">                leftMost = i</span><br><span class="line"></span><br><span class="line">        ans = []</span><br><span class="line">        vis = [<span class="literal">False</span>] * n</span><br><span class="line">        p = leftMost</span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            q = (p + <span class="number">1</span>) % n</span><br><span class="line">            <span class="keyword">for</span> r, tree <span class="keyword">in</span> <span class="built_in">enumerate</span>(trees):</span><br><span class="line">                <span class="comment"># // 如果 r 在 pq 的右侧，则 q = r</span></span><br><span class="line">                <span class="keyword">if</span> cross(trees[p], trees[q], tree) &lt; <span class="number">0</span>:</span><br><span class="line">                    q = r</span><br><span class="line">            <span class="comment"># 是否存在点 i, 使得 p q i 在同一条直线上</span></span><br><span class="line">            <span class="keyword">for</span> i, b <span class="keyword">in</span> <span class="built_in">enumerate</span>(vis):</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> b <span class="keyword">and</span> i != p <span class="keyword">and</span> i != q <span class="keyword">and</span> cross(trees[p], trees[q], trees[i]) == <span class="number">0</span>:</span><br><span class="line">                    ans.append(trees[i])</span><br><span class="line">                    vis[i] = <span class="literal">True</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> vis[q]:</span><br><span class="line">                ans.append(trees[q])</span><br><span class="line">                vis[q] = <span class="literal">True</span></span><br><span class="line">            p = q</span><br><span class="line">            <span class="keyword">if</span> p == leftMost:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></tbody></table></figure><h2><span id="2-葛立恒graham扫描法">2. 葛立恒（Graham）扫描法</span></h2><p>由最底的一点 ${\displaystyle A_{1}}$ 开始（如果有多个这样的点，那么选择最左边的），计算它跟其他各点的连线和x轴正向的角度，按小至大将这些点排序，称它们的对应点为 $ A_2,A_3,\dots,A_n $。这里的时间复杂度可达 $O(nlogn)$。</p><p>考虑最小的角度对应的点 $A_3$。若由 ${\displaystyle A_{2}}$ 到 ${\displaystyle A_{3}}$ 的路径相对${\displaystyle A_{1}}$到$A_2$ 的路径是向右转的（可以想象一个人沿 ${\displaystyle A_{1}}$ 走到${\displaystyle A_{2}}$ ，他站在 ${\displaystyle A_{2}}$时，是向哪边改变方向），表示 $A_3$ 不可能是凸包上的一点，考虑下一点由 ${\displaystyle A_{2}}$ 到 $A_4$ 的路径；否则就考虑 $A_3$ 到 $A_4$ 的路径是否向右转……直到回到 ${\displaystyle A_{1}}$。</p><p>这个算法的整体时间复杂度是 $O(nlogn)$，注意每点只会被考虑一次，而不像 Jarvis 步进法中会考虑多次。</p><blockquote><p>缺点是不能推广到二维以上的情况。</p></blockquote><h3><span id="21-模板">2.1 模板</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">outerTrees</span>(<span class="params">self, trees: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">cross</span>(<span class="params">p: <span class="type">List</span>[<span class="built_in">int</span>], q: <span class="type">List</span>[<span class="built_in">int</span>], r: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">            <span class="keyword">return</span> (q[<span class="number">0</span>] - p[<span class="number">0</span>]) * (r[<span class="number">1</span>] - q[<span class="number">1</span>]) - (q[<span class="number">1</span>] - p[<span class="number">1</span>]) * (r[<span class="number">0</span>] - q[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">distance</span>(<span class="params">p: <span class="type">List</span>[<span class="built_in">int</span>], q: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">            <span class="keyword">return</span> (p[<span class="number">0</span>] - q[<span class="number">0</span>]) * (p[<span class="number">0</span>] - q[<span class="number">0</span>]) + (p[<span class="number">1</span>] - q[<span class="number">1</span>]) * (p[<span class="number">1</span>] - q[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        n = <span class="built_in">len</span>(trees)</span><br><span class="line">        <span class="keyword">if</span> n &lt; <span class="number">4</span>:</span><br><span class="line">            <span class="keyword">return</span> trees</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 找到 y 最小的点 bottom</span></span><br><span class="line">        bottom = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i, tree <span class="keyword">in</span> <span class="built_in">enumerate</span>(trees):</span><br><span class="line">            <span class="keyword">if</span> tree[<span class="number">1</span>] &lt; trees[bottom][<span class="number">1</span>]:</span><br><span class="line">                bottom = i</span><br><span class="line">        trees[bottom], trees[<span class="number">0</span>] = trees[<span class="number">0</span>], trees[bottom]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 以 bottom 原点，按照极坐标的角度大小进行排序</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">cmp</span>(<span class="params">a: <span class="type">List</span>[<span class="built_in">int</span>], b: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">            diff = cross(trees[<span class="number">0</span>], b, a) - cross(trees[<span class="number">0</span>], a, b)</span><br><span class="line">            <span class="keyword">return</span> diff <span class="keyword">if</span> diff <span class="keyword">else</span> distance(trees[<span class="number">0</span>], a) - distance(trees[<span class="number">0</span>], b)</span><br><span class="line">        trees[<span class="number">1</span>:] = <span class="built_in">sorted</span>(trees[<span class="number">1</span>:], key=cmp_to_key(cmp))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 对于凸包最后且在同一条直线的元素按照距离从小到大进行排序</span></span><br><span class="line">        r = n - <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> r &gt;= <span class="number">0</span> <span class="keyword">and</span> cross(trees[<span class="number">0</span>], trees[n - <span class="number">1</span>], trees[r]) == <span class="number">0</span>:</span><br><span class="line">            r -= <span class="number">1</span></span><br><span class="line">        l, h = r + <span class="number">1</span>, n - <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> l &lt; h:</span><br><span class="line">            trees[l], trees[h] = trees[h], trees[l]</span><br><span class="line">            l += <span class="number">1</span></span><br><span class="line">            h -= <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        stack = [<span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, n):</span><br><span class="line">            <span class="comment"># 如果当前元素与栈顶的两个元素构成的向量顺时针旋转，则弹出栈顶元素</span></span><br><span class="line">            <span class="keyword">while</span> <span class="built_in">len</span>(stack) &gt; <span class="number">1</span> <span class="keyword">and</span> cross(trees[stack[-<span class="number">2</span>]], trees[stack[-<span class="number">1</span>]], trees[i]) &lt; <span class="number">0</span>:</span><br><span class="line">                stack.pop()</span><br><span class="line">            stack.append(i)</span><br><span class="line">        <span class="keyword">return</span> [trees[i] <span class="keyword">for</span> i <span class="keyword">in</span> stack]</span><br></pre></td></tr></tbody></table></figure><h2><span id="3-单调链andrew算法">3. 单调链（Andrew）算法</span></h2><p>将点按 $x$ 坐标的值排列，再按 $y$ 坐标的值排列。</p><p>选择 x 坐标为最小值的点，在这些点中找出 y 坐标的值最大和 y 坐标的值最小的点。对于 x 坐标为最大值也是这样处理。将两组点中 y 坐标值较小的点连起。在这条线段下的点，找出它们之中 y 坐标值最大的点，又在它们之间找 x 坐标值再最小和最大的点……如此类推。</p><h3><span id="31-模板">3.1 模板</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">outerTrees</span>(<span class="params">self, trees: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">cross</span>(<span class="params">p: <span class="type">List</span>[<span class="built_in">int</span>], q: <span class="type">List</span>[<span class="built_in">int</span>], r: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">            <span class="keyword">return</span> (q[<span class="number">0</span>] - p[<span class="number">0</span>]) * (r[<span class="number">1</span>] - q[<span class="number">1</span>]) - (q[<span class="number">1</span>] - p[<span class="number">1</span>]) * (r[<span class="number">0</span>] - q[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">        n = <span class="built_in">len</span>(trees)</span><br><span class="line">        <span class="keyword">if</span> n &lt; <span class="number">4</span>:</span><br><span class="line">            <span class="keyword">return</span> trees</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 按照 x 从小到大排序，如果 x 相同，则按照 y 从小到大排序</span></span><br><span class="line">        trees.sort()</span><br><span class="line"></span><br><span class="line">        hull = [<span class="number">0</span>]  <span class="comment"># hull[0] 需要入栈两次，不标记</span></span><br><span class="line">        used = [<span class="literal">False</span>] * n</span><br><span class="line">        <span class="comment"># 求凸包的下半部分</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n):</span><br><span class="line">            <span class="keyword">while</span> <span class="built_in">len</span>(hull) &gt; <span class="number">1</span> <span class="keyword">and</span> cross(trees[hull[-<span class="number">2</span>]], trees[hull[-<span class="number">1</span>]], trees[i]) &lt; <span class="number">0</span>:</span><br><span class="line">                used[hull.pop()] = <span class="literal">False</span></span><br><span class="line">            used[i] = <span class="literal">True</span></span><br><span class="line">            hull.append(i)</span><br><span class="line">        <span class="comment"># 求凸包的上半部分</span></span><br><span class="line">        m = <span class="built_in">len</span>(hull)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n - <span class="number">2</span>, -<span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> used[i]:</span><br><span class="line">                <span class="keyword">while</span> <span class="built_in">len</span>(hull) &gt; m <span class="keyword">and</span> cross(trees[hull[-<span class="number">2</span>]], trees[hull[-<span class="number">1</span>]], trees[i]) &lt; <span class="number">0</span>:</span><br><span class="line">                    used[hull.pop()] = <span class="literal">False</span></span><br><span class="line">                used[i] = <span class="literal">True</span></span><br><span class="line">                hull.append(i)</span><br><span class="line">        <span class="comment"># hull[0] 同时参与凸包的上半部分检测，因此需去掉重复的 hull[0]</span></span><br><span class="line">        hull.pop()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> [trees[i] <span class="keyword">for</span> i <span class="keyword">in</span> hull]</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> 凸包算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode587</title>
      <link href="/2022/04/23/leetcode/mei-ri-yi-ti/leetcode587/"/>
      <url>/2022/04/23/leetcode/mei-ri-yi-ti/leetcode587/</url>
      
        <content type="html"><![CDATA[<h1><span id="587-安装栅栏">587. 安装栅栏</span></h1><blockquote><p><a href="https://leetcode-cn.com/problems/erect-the-fence/">587. 安装栅栏</a></p></blockquote><h2><span id="题目">题目</span></h2><p>在一个二维的花园中，有一些用 (x, y) 坐标表示的树。由于安装费用十分昂贵，你的任务是先用 <strong>最短</strong> 的绳子围起所有的树。只有当所有的树都被绳子包围时，花园才能围好栅栏。你需要找到正好位于栅栏边界上的树的坐标。</p><h2><span id="示例">示例</span></h2><p>示例 1:</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入: [[<span class="number">1</span>,<span class="number">1</span>],[<span class="number">2</span>,<span class="number">2</span>],[<span class="number">2</span>,<span class="number">0</span>],[<span class="number">2</span>,<span class="number">4</span>],[<span class="number">3</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">2</span>]]</span><br><span class="line">输出: [[<span class="number">1</span>,<span class="number">1</span>],[<span class="number">2</span>,<span class="number">0</span>],[<span class="number">4</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">3</span>],[<span class="number">2</span>,<span class="number">4</span>]]</span><br></pre></td></tr></tbody></table></figure><p>解释:</p><p><img src="http://xiaomanzhan.com.cn/content/erect_the_fence_1.png" alt="img" style="zoom:67%;"></p><p>示例 2:</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入: [[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">2</span>,<span class="number">2</span>],[<span class="number">4</span>,<span class="number">2</span>]]</span><br><span class="line">输出: [[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">2</span>,<span class="number">2</span>],[<span class="number">4</span>,<span class="number">2</span>]]</span><br></pre></td></tr></tbody></table></figure><p>解释:</p><p><img src="http://xiaomanzhan.com.cn/content/erect_the_fence_2.png" alt="img" style="zoom:67%;"></p><p>即使树都在一条直线上，你也需要先用绳子包围它们。</p><h2><span id="解题思路一">解题思路（一）</span></h2><p>此题为经典的 <strong>凸包算法</strong> ，可用方法介绍三种 <code>Jarvis</code> 算法、<code>Graham</code> 算法、 <code>Andrew</code> 算法。</p><p>先介绍 <code>Jarvis</code> 算法求解：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">outerTrees</span>(<span class="params">self, trees: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">cross</span>(<span class="params">p: <span class="type">List</span>[<span class="built_in">int</span>], q: <span class="type">List</span>[<span class="built_in">int</span>], r: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">            <span class="keyword">return</span> (q[<span class="number">0</span>] - p[<span class="number">0</span>]) * (r[<span class="number">1</span>] - q[<span class="number">1</span>]) - (q[<span class="number">1</span>] - p[<span class="number">1</span>]) * (r[<span class="number">0</span>] - q[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">        n = <span class="built_in">len</span>(trees)</span><br><span class="line">        <span class="keyword">if</span> n &lt; <span class="number">4</span>:</span><br><span class="line">            <span class="keyword">return</span> trees</span><br><span class="line"></span><br><span class="line">        leftMost = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i, tree <span class="keyword">in</span> <span class="built_in">enumerate</span>(trees):</span><br><span class="line">            <span class="keyword">if</span> tree[<span class="number">0</span>] &lt; trees[leftMost][<span class="number">0</span>]:</span><br><span class="line">                leftMost = i</span><br><span class="line"></span><br><span class="line">        ans = []</span><br><span class="line">        vis = [<span class="literal">False</span>] * n</span><br><span class="line">        p = leftMost</span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            q = (p + <span class="number">1</span>) % n</span><br><span class="line">            <span class="keyword">for</span> r, tree <span class="keyword">in</span> <span class="built_in">enumerate</span>(trees):</span><br><span class="line">                <span class="comment"># // 如果 r 在 pq 的右侧，则 q = r</span></span><br><span class="line">                <span class="keyword">if</span> cross(trees[p], trees[q], tree) &lt; <span class="number">0</span>:</span><br><span class="line">                    q = r</span><br><span class="line">            <span class="comment"># 是否存在点 i, 使得 p q i 在同一条直线上</span></span><br><span class="line">            <span class="keyword">for</span> i, b <span class="keyword">in</span> <span class="built_in">enumerate</span>(vis):</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> b <span class="keyword">and</span> i != p <span class="keyword">and</span> i != q <span class="keyword">and</span> cross(trees[p], trees[q], trees[i]) == <span class="number">0</span>:</span><br><span class="line">                    ans.append(trees[i])</span><br><span class="line">                    vis[i] = <span class="literal">True</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> vis[q]:</span><br><span class="line">                ans.append(trees[q])</span><br><span class="line">                vis[q] = <span class="literal">True</span></span><br><span class="line">            p = q</span><br><span class="line">            <span class="keyword">if</span> p == leftMost:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></tbody></table></figure><h2><span id="解题思路二">解题思路（二）</span></h2><p>使用 <code>Graham</code> 算法解题</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">outerTrees</span>(<span class="params">self, trees: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">cross</span>(<span class="params">p: <span class="type">List</span>[<span class="built_in">int</span>], q: <span class="type">List</span>[<span class="built_in">int</span>], r: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">            <span class="keyword">return</span> (q[<span class="number">0</span>] - p[<span class="number">0</span>]) * (r[<span class="number">1</span>] - q[<span class="number">1</span>]) - (q[<span class="number">1</span>] - p[<span class="number">1</span>]) * (r[<span class="number">0</span>] - q[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">distance</span>(<span class="params">p: <span class="type">List</span>[<span class="built_in">int</span>], q: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">            <span class="keyword">return</span> (p[<span class="number">0</span>] - q[<span class="number">0</span>]) * (p[<span class="number">0</span>] - q[<span class="number">0</span>]) + (p[<span class="number">1</span>] - q[<span class="number">1</span>]) * (p[<span class="number">1</span>] - q[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        n = <span class="built_in">len</span>(trees)</span><br><span class="line">        <span class="keyword">if</span> n &lt; <span class="number">4</span>:</span><br><span class="line">            <span class="keyword">return</span> trees</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 找到 y 最小的点 bottom</span></span><br><span class="line">        bottom = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i, tree <span class="keyword">in</span> <span class="built_in">enumerate</span>(trees):</span><br><span class="line">            <span class="keyword">if</span> tree[<span class="number">1</span>] &lt; trees[bottom][<span class="number">1</span>]:</span><br><span class="line">                bottom = i</span><br><span class="line">        trees[bottom], trees[<span class="number">0</span>] = trees[<span class="number">0</span>], trees[bottom]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 以 bottom 原点，按照极坐标的角度大小进行排序</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">cmp</span>(<span class="params">a: <span class="type">List</span>[<span class="built_in">int</span>], b: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">            diff = cross(trees[<span class="number">0</span>], b, a) - cross(trees[<span class="number">0</span>], a, b)</span><br><span class="line">            <span class="keyword">return</span> diff <span class="keyword">if</span> diff <span class="keyword">else</span> distance(trees[<span class="number">0</span>], a) - distance(trees[<span class="number">0</span>], b)</span><br><span class="line">        trees[<span class="number">1</span>:] = <span class="built_in">sorted</span>(trees[<span class="number">1</span>:], key=cmp_to_key(cmp))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 对于凸包最后且在同一条直线的元素按照距离从小到大进行排序</span></span><br><span class="line">        r = n - <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> r &gt;= <span class="number">0</span> <span class="keyword">and</span> cross(trees[<span class="number">0</span>], trees[n - <span class="number">1</span>], trees[r]) == <span class="number">0</span>:</span><br><span class="line">            r -= <span class="number">1</span></span><br><span class="line">        l, h = r + <span class="number">1</span>, n - <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> l &lt; h:</span><br><span class="line">            trees[l], trees[h] = trees[h], trees[l]</span><br><span class="line">            l += <span class="number">1</span></span><br><span class="line">            h -= <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        stack = [<span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, n):</span><br><span class="line">            <span class="comment"># 如果当前元素与栈顶的两个元素构成的向量顺时针旋转，则弹出栈顶元素</span></span><br><span class="line">            <span class="keyword">while</span> <span class="built_in">len</span>(stack) &gt; <span class="number">1</span> <span class="keyword">and</span> cross(trees[stack[-<span class="number">2</span>]], trees[stack[-<span class="number">1</span>]], trees[i]) &lt; <span class="number">0</span>:</span><br><span class="line">                stack.pop()</span><br><span class="line">            stack.append(i)</span><br><span class="line">        <span class="keyword">return</span> [trees[i] <span class="keyword">for</span> i <span class="keyword">in</span> stack]</span><br></pre></td></tr></tbody></table></figure><h2><span id="解题思路三">解题思路（三）</span></h2><p>使用 <code>Andrew</code> 算法解题</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">outerTrees</span>(<span class="params">self, trees: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">cross</span>(<span class="params">p: <span class="type">List</span>[<span class="built_in">int</span>], q: <span class="type">List</span>[<span class="built_in">int</span>], r: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">            <span class="keyword">return</span> (q[<span class="number">0</span>] - p[<span class="number">0</span>]) * (r[<span class="number">1</span>] - q[<span class="number">1</span>]) - (q[<span class="number">1</span>] - p[<span class="number">1</span>]) * (r[<span class="number">0</span>] - q[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">        n = <span class="built_in">len</span>(trees)</span><br><span class="line">        <span class="keyword">if</span> n &lt; <span class="number">4</span>:</span><br><span class="line">            <span class="keyword">return</span> trees</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 按照 x 从小到大排序，如果 x 相同，则按照 y 从小到大排序</span></span><br><span class="line">        trees.sort()</span><br><span class="line"></span><br><span class="line">        hull = [<span class="number">0</span>]  <span class="comment"># hull[0] 需要入栈两次，不标记</span></span><br><span class="line">        used = [<span class="literal">False</span>] * n</span><br><span class="line">        <span class="comment"># 求凸包的下半部分</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n):</span><br><span class="line">            <span class="keyword">while</span> <span class="built_in">len</span>(hull) &gt; <span class="number">1</span> <span class="keyword">and</span> cross(trees[hull[-<span class="number">2</span>]], trees[hull[-<span class="number">1</span>]], trees[i]) &lt; <span class="number">0</span>:</span><br><span class="line">                used[hull.pop()] = <span class="literal">False</span></span><br><span class="line">            used[i] = <span class="literal">True</span></span><br><span class="line">            hull.append(i)</span><br><span class="line">        <span class="comment"># 求凸包的上半部分</span></span><br><span class="line">        m = <span class="built_in">len</span>(hull)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n - <span class="number">2</span>, -<span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> used[i]:</span><br><span class="line">                <span class="keyword">while</span> <span class="built_in">len</span>(hull) &gt; m <span class="keyword">and</span> cross(trees[hull[-<span class="number">2</span>]], trees[hull[-<span class="number">1</span>]], trees[i]) &lt; <span class="number">0</span>:</span><br><span class="line">                    used[hull.pop()] = <span class="literal">False</span></span><br><span class="line">                used[i] = <span class="literal">True</span></span><br><span class="line">                hull.append(i)</span><br><span class="line">        <span class="comment"># hull[0] 同时参与凸包的上半部分检测，因此需去掉重复的 hull[0]</span></span><br><span class="line">        hull.pop()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> [trees[i] <span class="keyword">for</span> i <span class="keyword">in</span> hull]</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> 难度-困难 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeetCode </tag>
            
            <tag> 凸包算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode396</title>
      <link href="/2022/04/22/leetcode/mei-ri-yi-ti/leetcode396/"/>
      <url>/2022/04/22/leetcode/mei-ri-yi-ti/leetcode396/</url>
      
        <content type="html"><![CDATA[<h1><span id="396-旋转函数">396. 旋转函数</span></h1><blockquote><p><a href="https://leetcode-cn.com/problems/rotate-function/">396. 旋转函数</a></p></blockquote><h2><span id="题目">题目</span></h2><p>给定一个长度为 <code>n</code>的整数数组 <code>nums</code> 。</p><p>假设 <code>arrk</code> 是数组 <code>nums</code> 顺时针旋转 <code>k</code> 个位置后的数组，我们定义 <code>nums</code> 的旋转函数  <code>F</code> 为：</p><p><code>F(k) = 0 * arrk[0] + 1 * arrk[1] + ... + (n - 1) * arrk[n - 1]</code><br>返回 <code>F(0), F(1), ..., F(n-1)</code>中的最大值 。</p><p>生成的测试用例让答案符合 <strong>32 位</strong> 整数。</p><h2><span id="示例">示例</span></h2><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">示例 1:</span><br><span class="line">输入: nums = [4,3,2,6]</span><br><span class="line">输出: 26</span><br><span class="line">解释:</span><br><span class="line">F(0) = (0 * 4) + (1 * 3) + (2 * 2) + (3 * 6) = 0 + 3 + 4 + 18 = 25</span><br><span class="line">F(1) = (0 * 6) + (1 * 4) + (2 * 3) + (3 * 2) = 0 + 4 + 6 + 6 = 16</span><br><span class="line">F(2) = (0 * 2) + (1 * 6) + (2 * 4) + (3 * 3) = 0 + 6 + 8 + 9 = 23</span><br><span class="line">F(3) = (0 * 3) + (1 * 2) + (2 * 6) + (3 * 4) = 0 + 2 + 12 + 12 = 26</span><br><span class="line">所以 F(0), F(1), F(2), F(3) 中的最大值是 F(3) = 26 。</span><br><span class="line"></span><br><span class="line">示例 2:</span><br><span class="line">输入: nums = [100]</span><br><span class="line">输出: 0</span><br></pre></td></tr></tbody></table></figure><h2><span id="解题思路">解题思路</span></h2><p>暴力解题：</p><p>数组 $nums$ 的元素之和为 $numSum$。根据公式，可以得到：</p><ul><li>$F(0) = 0 \times nums[0] + 1 \times nums[1] + \ldots + (n-1) \times nums[n-1]$</li><li>$F(1) = 1 \times nums[0] + 2 \times nums[1] + \ldots + 0 \times nums[n-1] = F(0) + numSum - n \times nums[n-1]$</li></ul><p>更一般地，当 $1 \le k \lt n$ 时，$F(k) = F(k-1) + numSum - n \times nums[n-k]$。我们可以不停迭代计算出不同的 $F(k)$，并求出最大值。</p><h3><span id="题解">题解</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">maxRotateFunction</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        f, n, numSum = <span class="number">0</span>, <span class="built_in">len</span>(nums), <span class="built_in">sum</span>(nums)</span><br><span class="line">        <span class="keyword">for</span> i, num <span class="keyword">in</span> <span class="built_in">enumerate</span>(nums):</span><br><span class="line">            f += i * num</span><br><span class="line">        res = f</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n - <span class="number">1</span>, <span class="number">0</span>, -<span class="number">1</span>):</span><br><span class="line">            f = f + numSum - n * nums[i]</span><br><span class="line">            res = <span class="built_in">max</span>(res, f)</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> 难度-中等 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeetCode </tag>
            
            <tag> 找规律 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode824</title>
      <link href="/2022/04/21/leetcode/mei-ri-yi-ti/leetcode824/"/>
      <url>/2022/04/21/leetcode/mei-ri-yi-ti/leetcode824/</url>
      
        <content type="html"><![CDATA[<h1><span id="824-山羊拉丁文">824. 山羊拉丁文</span></h1><blockquote><p><a href="https://leetcode-cn.com/problems/goat-latin/">824. 山羊拉丁文</a></p></blockquote><h2><span id="题目">题目</span></h2><p>给你一个由若干单词组成的句子 <code>sentence</code> ，单词间由空格分隔。每个单词仅由大写和小写英文字母组成。</p><p>请你将句子转换为 “山羊拉丁文（<code>Goat Latin</code>）”（一种类似于 猪拉丁文 - <code>Pig Latin</code> 的虚构语言）。山羊拉丁文的规则如下：</p><p>如果单词以元音开头（<code>'a'</code>, <code>'e'</code>, <code>'i'</code>, <code>'o'</code>, <code>'u'</code>），在单词后添加<code>"ma"</code>。<br>例如，单词 <code>"apple"</code> 变为 <code>"applema"</code> 。<br>如果单词以辅音字母开头（即，非元音字母），移除第一个字符并将它放到末尾，之后再添加<code>"ma"</code>。<br>例如，单词 <code>"goat"</code> 变为 <code>"oatgma"</code> 。<br>根据单词在句子中的索引，在单词最后添加与索引相同数量的字母<code>'a'</code>，索引从 <code>1</code> 开始。<br>例如，在第一个单词后添加 <code>"a"</code> ，在第二个单词后添加 <code>"aa"</code> ，以此类推。<br>返回将 <code>sentence</code> 转换为山羊拉丁文后的句子。</p><h2><span id="示例">示例</span></h2><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">示例 1：</span><br><span class="line">输入：sentence = "I speak Goat Latin"</span><br><span class="line">输出："Imaa peaksmaaa oatGmaaaa atinLmaaaaa"</span><br><span class="line"></span><br><span class="line">示例 2：</span><br><span class="line">输入：sentence = "The quick brown fox jumped over the lazy dog"</span><br><span class="line">输出："heTmaa uickqmaaa rownbmaaaa oxfmaaaaa umpedjmaaaaaa overmaaaaaaa hetmaaaaaaaa azylmaaaaaaaaa ogdmaaaaaaaaaa"</span><br></pre></td></tr></tbody></table></figure><h2><span id="解题思路">解题思路</span></h2><p>直接暴力求解</p><h3><span id="题解">题解</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">toGoatLatin</span>(<span class="params">self, sentence: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        res = []</span><br><span class="line">        <span class="keyword">for</span> i, word <span class="keyword">in</span> <span class="built_in">enumerate</span>(sentence.split()):</span><br><span class="line">            <span class="keyword">if</span> word[<span class="number">0</span>] <span class="keyword">in</span> <span class="string">"AaEeIiOoUu"</span>:</span><br><span class="line">                res.append(word + <span class="string">"ma"</span> + <span class="string">"a"</span> * (i + <span class="number">1</span>))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                res.append(word[<span class="number">1</span>:] + word[<span class="number">0</span>] + <span class="string">"ma"</span> + <span class="string">'a'</span> * (i + <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">return</span> <span class="string">" "</span>.join(res)</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeetCode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode388</title>
      <link href="/2022/04/20/leetcode/mei-ri-yi-ti/leetcode388/"/>
      <url>/2022/04/20/leetcode/mei-ri-yi-ti/leetcode388/</url>
      
        <content type="html"><![CDATA[<h1><span id="388-文件的最长绝对路径">388. 文件的最长绝对路径</span></h1><blockquote><p><a href="https://leetcode-cn.com/problems/longest-absolute-file-path/">388. 文件的最长绝对路径</a></p></blockquote><h2><span id="题目">题目</span></h2><p>假设有一个同时存储文件和目录的文件系统。这里将<code>dir</code> 作为根目录中的唯一目录。<code>dir</code> 包含两个子目录 <code>subdir1</code> 和 <code>subdir2</code> 。<code>subdir1</code> 包含文件 <code>file1.ext</code> 和子目录 <code>subsubdir1</code>；<code>subdir2</code> 包含子目录 <code>subsubdir2</code>，该子目录下包含文件 <code>file2.ext</code> 。</p><p>在文本格式中，如下所示(⟶表示制表符)：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">dir</span><br><span class="line">⟶ subdir1</span><br><span class="line">⟶ ⟶ file1.ext</span><br><span class="line">⟶ ⟶ subsubdir1</span><br><span class="line">⟶ subdir2</span><br><span class="line">⟶ ⟶ subsubdir2</span><br><span class="line">⟶ ⟶ ⟶ file2.ext</span><br></pre></td></tr></tbody></table></figure><p>如果是代码表示，上面的文件系统可以写为 <code>"dir\n\tsubdir1\n\t\tfile1.ext\n\t\tsubsubdir1\n\tsubdir2\n\t\tsubsubdir2\n\t\t\tfile2.ext"</code> 。<code>'\n'</code>和 <code>'\t'</code> 分别是换行符和制表符。</p><p>文件系统中的每个文件和文件夹都有一个唯一的 绝对路径 ，即必须打开才能到达文件/目录所在位置的目录顺序，所有路径用 ‘/‘ 连接。上面例子中，指向 <code>file2.ext</code> 的 绝对路径 是 <code>"dir/subdir2/subsubdir2/file2.ext"</code> 。每个目录名由字母、数字和/或空格组成，每个文件名遵循 <code>name.extension</code> 的格式，其中 <code>name</code> 和 <code>extension</code>由字母、数字和/或空格组成。</p><p>给定一个以上述格式表示文件系统的字符串 <code>input</code> ，返回文件系统中指向文件的最长绝对路径的长度 。 如果系统中没有文件，返回 <code>0</code>。</p><h2><span id="示例">示例</span></h2><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">示例 1：</span><br><span class="line">输入：input = "dir\n\tsubdir1\n\tsubdir2\n\t\tfile.ext"</span><br><span class="line">输出：20</span><br><span class="line">解释：只有一个文件，绝对路径为 "dir/subdir2/file.ext" ，路径长度 20</span><br><span class="line"></span><br><span class="line">示例 2：</span><br><span class="line">输入：input = "dir\n\tsubdir1\n\t\tfile1.ext\n\t\tsubsubdir1\n\tsubdir2\n\t\tsubsubdir2\n\t\t\tfile2.ext"</span><br><span class="line">输出：32</span><br><span class="line">解释：存在两个文件：</span><br><span class="line">"dir/subdir1/file1.ext" ，路径长度 21</span><br><span class="line">"dir/subdir2/subsubdir2/file2.ext" ，路径长度 32</span><br><span class="line">返回 32 ，因为这是最长的路径</span><br><span class="line"></span><br><span class="line">示例 3：</span><br><span class="line">输入：input = "a"</span><br><span class="line">输出：0</span><br><span class="line">解释：不存在任何文件</span><br><span class="line"></span><br><span class="line">示例 4：</span><br><span class="line">输入：input = "file1.txt\nfile2.txt\nlongfile.txt"</span><br><span class="line">输出：12</span><br><span class="line">解释：根目录下有 3 个文件。</span><br><span class="line">因为根目录中任何东西的绝对路径只是名称本身，所以答案是 "longfile.txt" ，路径长度为 12</span><br></pre></td></tr></tbody></table></figure><h2><span id="解题思路">解题思路</span></h2><p>很明显需要使用深度有限搜索的方法，方法如下：</p><ol><li>将输入字符串按照 <code>\n</code> 来进行拆分行，从第一行进行深度优先搜索。</li><li>每次深度优先搜索的时候遍历到当前行时，需要将 <code>\t</code> 去除再计算长度，同时根据 <code>\t</code> 的个数来判断深度；</li><li>使用一个 <code>path</code> 数组来维护当前的路径，每次访问到文件时，利用当前路径判断最长路径的长度。</li></ol><h3><span id="题解">题解</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">lengthLongestPath</span>(<span class="params">self, <span class="built_in">input</span>: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        inputs = <span class="built_in">input</span>.split(<span class="string">'\n'</span>)</span><br><span class="line">        path, max_len = [inputs[<span class="number">0</span>]], <span class="built_in">len</span>(inputs[<span class="number">0</span>]) <span class="keyword">if</span> inputs[<span class="number">0</span>].__contains__(<span class="string">'.'</span>) <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">dfs</span>(<span class="params">i, layer</span>):</span><br><span class="line">            <span class="string">"""i表示第i行，layer表示深度"""</span></span><br><span class="line">            <span class="keyword">nonlocal</span> inputs, path, max_len</span><br><span class="line">            <span class="keyword">if</span> i &gt;= <span class="built_in">len</span>(inputs):</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">            s = inputs[i].replace(<span class="string">'\t'</span>, <span class="string">''</span>)</span><br><span class="line">            <span class="keyword">if</span> inputs[i].startswith(<span class="string">'\t'</span> * (layer + <span class="number">1</span>)):</span><br><span class="line">                path.append(s)</span><br><span class="line">                <span class="keyword">if</span> s.__contains__(<span class="string">'.'</span>):</span><br><span class="line">                    max_len = <span class="built_in">max</span>(max_len, <span class="built_in">len</span>(<span class="string">"/"</span>.join(path)))</span><br><span class="line">                dfs(i + <span class="number">1</span>, layer + <span class="number">1</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">while</span> layer &gt;= <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">if</span> inputs[i].startswith(<span class="string">'\t'</span> * (layer)):</span><br><span class="line">                        path.pop()</span><br><span class="line">                        path.append(s)</span><br><span class="line">                        <span class="keyword">if</span> s.__contains__(<span class="string">'.'</span>):</span><br><span class="line">                            max_len = <span class="built_in">max</span>(max_len, <span class="built_in">len</span>(<span class="string">"/"</span>.join(path)))</span><br><span class="line">                        dfs(i + <span class="number">1</span>, layer)</span><br><span class="line">                        <span class="keyword">break</span></span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        path.pop()</span><br><span class="line">                        layer -= <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        dfs(<span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> max_len</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> 难度-中等 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeetCode </tag>
            
            <tag> 深度优先搜索 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode821</title>
      <link href="/2022/04/19/leetcode/mei-ri-yi-ti/leetcode821/"/>
      <url>/2022/04/19/leetcode/mei-ri-yi-ti/leetcode821/</url>
      
        <content type="html"><![CDATA[<h1><span id="821-字符的最短距离">821. 字符的最短距离</span></h1><h2><span id="题目">题目</span></h2><p>给你一个字符串 <code>s</code> 和一个字符 <code>c</code> ，且 <code>c</code> 是 <code>s</code> 中出现过的字符。返回一个整数数组 <code>answer</code> ，其中 <code>answer.length == s.length</code> 且 <code>answer[i]</code> 是 <code>s</code> 中从下标 <code>i</code> 到离它最近的字符 <code>c</code> 的距离。两个下标 <code>i</code> 和 <code>j</code> 之间的 距离 为 <code>abs(i - j)</code> ，其中 <code>abs</code> 是绝对值函数。</p><h2><span id="示例">示例</span></h2><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">示例 1：</span><br><span class="line">输入：s = "loveleetcode", c = "e"</span><br><span class="line">输出：[3,2,1,0,1,0,0,1,2,2,1,0]</span><br><span class="line">解释：字符 'e' 出现在下标 3、5、6 和 11 处（下标从 0 开始计数）。</span><br><span class="line">距下标 0 最近的 'e' 出现在下标 3 ，所以距离为 abs(0 - 3) = 3 。</span><br><span class="line">距下标 1 最近的 'e' 出现在下标 3 ，所以距离为 abs(1 - 3) = 2 。</span><br><span class="line">对于下标 4 ，出现在下标 3 和下标 5 处的 'e' 都离它最近，但距离是一样的 abs(4 - 3) == abs(4 - 5) = 1 。</span><br><span class="line">距下标 8 最近的 'e' 出现在下标 6 ，所以距离为 abs(8 - 6) = 2 。</span><br><span class="line"></span><br><span class="line">示例 2：</span><br><span class="line">输入：s = "aaab", c = "b"</span><br><span class="line">输出：[3,2,1,0]</span><br></pre></td></tr></tbody></table></figure><h2><span id="解题思路">解题思路</span></h2><p>因为查看距离近的元素的最短距离，需要看每个元素的左右两边的元素，所以如果使用暴力的方式，每次遍历一个元素需要对其寻找最近的元素，时间复杂度在 $O(n^2)$，我们可以考虑牺牲空间换时间的方式，遍历两次数组实现寻找最短。步骤如下：</p><ol><li>初始化一个数组 <code>index_l</code>，记录每个元素距离左边最近的元素 <code>c</code> 的距离，从左到右遍历，若起始元素不是字符 <code>c</code>， <code>index_l</code> 中保存一个超大数（我使用的是<code>1e5</code>）；</li><li>初始化一个数组 <code>index_r</code>，记录每个元素距离右边最近的元素 <code>c</code> 的距离，从右到左遍历，若起始元素不是字符 <code>c</code>， <code>index_r</code> 中保存一个超大数（我使用的是<code>1e5</code>）；</li><li>比较相同位置下两个数组的最小值进行返回。</li></ol><h3><span id="题解">题解</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">shortestToChar</span>(<span class="params">self, s: <span class="built_in">str</span>, c: <span class="built_in">str</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        res1, res2 = [], []</span><br><span class="line">        index_l, index_r = <span class="number">100000</span>, <span class="number">100000</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(s)):</span><br><span class="line">            <span class="keyword">if</span> s[i] == c:</span><br><span class="line">                index_l = i</span><br><span class="line">            <span class="keyword">if</span> index_l != <span class="number">100000</span>:</span><br><span class="line">                res1.append(i - index_l)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                res1.append(<span class="number">100000</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(s), <span class="number">0</span>, -<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> s[i - <span class="number">1</span>] == c:</span><br><span class="line">                index_r = i - <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> index_r != <span class="number">100000</span>:</span><br><span class="line">                res2.insert(<span class="number">0</span>, index_r - i + <span class="number">1</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                res2.insert(<span class="number">0</span>, <span class="number">100000</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> [<span class="built_in">min</span>(res1[i], res2[i]) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(s))]</span><br><span class="line">    </span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> 难度-简单 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeetCode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode386</title>
      <link href="/2022/04/18/leetcode/mei-ri-yi-ti/leetcode386/"/>
      <url>/2022/04/18/leetcode/mei-ri-yi-ti/leetcode386/</url>
      
        <content type="html"><![CDATA[<h1><span id="386-字典序排数">386. 字典序排数</span></h1><blockquote><p><a href="https://leetcode-cn.com/problems/lexicographical-numbers/">386. 字典序排数</a></p></blockquote><h2><span id="题目">题目</span></h2><p>给你一个整数 <code>n</code> ，按字典序返回范围 <code>[1, n]</code> 内所有整数，设计一个时间复杂度为 <code>O(n)</code> 且使用 <code>O(1)</code> 额外空间的算法。</p><h2><span id="示例">示例</span></h2><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">示例 1：</span><br><span class="line">输入：n = 13</span><br><span class="line">输出：[1,10,11,12,13,2,3,4,5,6,7,8,9]</span><br><span class="line"></span><br><span class="line">示例 2：</span><br><span class="line">输入：n = 2</span><br><span class="line">输出：[1,2]</span><br></pre></td></tr></tbody></table></figure><h2><span id="解题思路">解题思路</span></h2><p>使用深度优先搜索的方式，向下遍历（x*10），向右遍历（x+1），注意向右遍历的时候需要注意（x&lt;9），当（x=9）的时候不再向右，返归上一层</p><h3><span id="题解">题解</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">lexicalOrder</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        res = []</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">dfs</span>(<span class="params">k</span>):</span><br><span class="line">            <span class="keyword">if</span> k &lt;= n:</span><br><span class="line">                res.append(k)</span><br><span class="line">                dfs(k * <span class="number">10</span>)</span><br><span class="line">                <span class="keyword">if</span> k % <span class="number">10</span> != <span class="number">9</span>:</span><br><span class="line">                    dfs(k + <span class="number">1</span>)</span><br><span class="line">        dfs(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> 难度-中等 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeetCode </tag>
            
            <tag> 深度优先搜索 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Transformer</title>
      <link href="/2022/04/18/machine-learning/zhu-yi-li-ji-zhi/5.transformer/"/>
      <url>/2022/04/18/machine-learning/zhu-yi-li-ji-zhi/5.transformer/</url>
      
        <content type="html"><![CDATA[<h1><span id="transformer">Transformer</span></h1><h2><span id="1-transformer架构">1. Transformer架构</span></h2><p>基于编码器-解码器架构来处理序列对，跟使用注意力的seq2seq不同，Transformer是纯基于注意力的</p><p><img src="http://xiaomanzhan.com.cn/content/transformer.svg" alt="../_images/transformer.svg"></p><h2><span id="2-多头注意力">2. 多头注意力</span></h2><p>对同一key、value、query。希望抽取不同的信息，例如短距离关系和长距离关系。因此提出多头注意力的思路；</p><p>多头注意力使用 $h$ 个独立的注意力池化，通过合并各个头（head） 输出得到最终输出。</p><p><img src="http://xiaomanzhan.com.cn/content/multi-head-attention.svg" alt="../_images/multi-head-attention.svg"></p><h3><span id="21-参数信息">2.1 参数信息</span></h3><ul><li><p>query、key、value矩阵为 $q\in\R^{d_q},k\in\R^{d_k},v\in\R^{d_v}$。</p></li><li><p>对于头 $i$ 的可学习参数 $W_i^{(q)}\in\R^{p_q\times d_q}, W_i^{(k)}\in\R^{p_k\times d_k}, W_i^{(v)}\in\R^{p_v\times d_v}$</p></li><li><p>头 $i$ 的输出为 $h_i=f(W_i^{(q)}q,W_i^{(k)}k,W_i^{(v)}v)\in\R^{p_v}$</p></li><li><p>输出的可学习参数 $W_o\in\R^{p_o\times hp_v}$</p></li><li><p>多头注意力的输出 (concat) 为</p><script type="math/tex; mode=display">W_o\begin{bmatrix}h_1\\\vdots\\h_h\end{bmatrix}\in\R^{p_o}</script></li></ul><h2><span id="3-有掩码的多头注意力">3. 有掩码的多头注意力</span></h2><p>解码器对序列中一个元素输出时，不应该考虑该元素之后的元素，可以通过掩码来实现，也就是在计算 $x_i$ 输出时，假装当前序列长度为 $i$ ，在计算softmax的时候只计算当前长度为 $i$ 的序列。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#@save</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">masked_softmax</span>(<span class="params">X, valid_lens</span>):</span><br><span class="line">    <span class="string">"""通过在最后一个轴上掩蔽元素来执行softmax操作"""</span></span><br><span class="line">    <span class="comment"># X:3D张量，valid_lens:1D或2D张量</span></span><br><span class="line">    <span class="keyword">if</span> valid_lens <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> nn.functional.softmax(X, dim=-<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        shape = X.shape</span><br><span class="line">        <span class="keyword">if</span> valid_lens.dim() == <span class="number">1</span>:</span><br><span class="line">            valid_lens = torch.repeat_interleave(valid_lens, shape[<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            valid_lens = valid_lens.reshape(-<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 最后一轴上被掩蔽的元素使用一个非常大的负值替换，从而其softmax输出为0</span></span><br><span class="line">        X = d2l.sequence_mask(X.reshape(-<span class="number">1</span>, shape[-<span class="number">1</span>]), valid_lens,</span><br><span class="line">                              value=-<span class="number">1e6</span>)</span><br><span class="line">        <span class="keyword">return</span> nn.functional.softmax(X.reshape(shape), dim=-<span class="number">1</span>)</span><br></pre></td></tr></tbody></table></figure><h2><span id="4-基于位置的前馈网络">4. 基于位置的前馈网络</span></h2><p>基于位置的前馈网络对序列中的所有位置的表示进行变换时使用的是同一个多层感知机（MLP），这就是称前馈网络是<em>基于位置的</em>（positionwise）的原因。在下面的实现中，输入<code>X</code>的形状（批量大小，时间步数或序列长度，隐单元数或特征维度）将被一个两层的感知机转换成形状为（批量大小，时间步数，<code>ffn_num_outputs</code>）的输出张量。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#@save</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PositionWiseFFN</span>(nn.Module):</span><br><span class="line">    <span class="string">"""基于位置的前馈网络"""</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs,</span></span><br><span class="line"><span class="params">                 **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>(PositionWiseFFN, self).__init__(**kwargs)</span><br><span class="line">        self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens)</span><br><span class="line">        self.relu = nn.ReLU()</span><br><span class="line">        self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="keyword">return</span> self.dense2(self.relu(self.dense1(X)))</span><br><span class="line">    </span><br><span class="line">ffn = PositionWiseFFN(<span class="number">4</span>, <span class="number">4</span>, <span class="number">8</span>)</span><br><span class="line">ffn.<span class="built_in">eval</span>()</span><br><span class="line">ffn(torch.ones((<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)))[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">tensor([[ <span class="number">0.3128</span>,  <span class="number">0.4583</span>,  <span class="number">0.2831</span>, -<span class="number">0.2723</span>,  <span class="number">0.2353</span>,  <span class="number">0.0556</span>, -<span class="number">0.2287</span>, -<span class="number">0.4535</span>],</span><br><span class="line">        [ <span class="number">0.3128</span>,  <span class="number">0.4583</span>,  <span class="number">0.2831</span>, -<span class="number">0.2723</span>,  <span class="number">0.2353</span>,  <span class="number">0.0556</span>, -<span class="number">0.2287</span>, -<span class="number">0.4535</span>],</span><br><span class="line">        [ <span class="number">0.3128</span>,  <span class="number">0.4583</span>,  <span class="number">0.2831</span>, -<span class="number">0.2723</span>,  <span class="number">0.2353</span>,  <span class="number">0.0556</span>, -<span class="number">0.2287</span>, -<span class="number">0.4535</span>]],</span><br><span class="line">       grad_fn=&lt;SelectBackward0&gt;)</span><br></pre></td></tr></tbody></table></figure><h2><span id="5-残差连接和层规范化">5. 残差连接和层规范化</span></h2><p>层规范化和批量规范化的目标相同，但层规范化是基于特征维度进行规范化。尽管批量规范化在计算机视觉中被广泛应用，但在自然语言处理任务中（输入通常是变长序列）批量规范化通常不如层规范化的效果好。</p><p>使用残差连接和层规范化来实现<code>AddNorm</code>类。暂退法也被作为正则化方法使用。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#@save</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AddNorm</span>(nn.Module):</span><br><span class="line">    <span class="string">"""残差连接后进行层规范化"""</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, normalized_shape, dropout, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>(AddNorm, self).__init__(**kwargs)</span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line">        self.ln = nn.LayerNorm(normalized_shape)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X, Y</span>):</span><br><span class="line">        <span class="keyword">return</span> self.ln(self.dropout(Y) + X)</span><br><span class="line">    </span><br><span class="line">add_norm = AddNorm([<span class="number">3</span>, <span class="number">4</span>], <span class="number">0.5</span>)</span><br><span class="line">add_norm.<span class="built_in">eval</span>()</span><br><span class="line">add_norm(torch.ones((<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)), torch.ones((<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>))).shape</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br></pre></td></tr></tbody></table></figure><h3><span id="51-层归一化">5.1 层归一化</span></h3><p>批量归一化对每个特征/通道里元素进行归一化的方式，不适合序列长度会变的NLP应用。</p><p>层归一化对每个样本里的元素进行归一化。</p><p><img src="http://xiaomanzhan.com.cn/content/image-20220418163842922.png" alt="image-20220418163842922"></p><h2><span id="6-编码器和解码器">6. 编码器和解码器</span></h2><h3><span id="61-编码器">6.1 编码器</span></h3><p>有了组成transformer编码器的基础组件，现在可以先实现编码器中的一个层。下面的<code>EncoderBlock</code>类包含两个子层：多头自注意力和基于位置的前馈网络，这两个子层都使用了残差连接和紧随的层规范化。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#@save</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">EncoderBlock</span>(nn.Module):</span><br><span class="line">    <span class="string">"""transformer编码器块"""</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, key_size, query_size, value_size, num_hiddens,</span></span><br><span class="line"><span class="params">                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,</span></span><br><span class="line"><span class="params">                 dropout, use_bias=<span class="literal">False</span>, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>(EncoderBlock, self).__init__(**kwargs)</span><br><span class="line">        self.attention = d2l.MultiHeadAttention(</span><br><span class="line">            key_size, query_size, value_size, num_hiddens, num_heads, dropout,</span><br><span class="line">            use_bias)</span><br><span class="line">        self.addnorm1 = AddNorm(norm_shape, dropout)</span><br><span class="line">        self.ffn = PositionWiseFFN(</span><br><span class="line">            ffn_num_input, ffn_num_hiddens, num_hiddens)</span><br><span class="line">        self.addnorm2 = AddNorm(norm_shape, dropout)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X, valid_lens</span>):</span><br><span class="line">        Y = self.addnorm1(X, self.attention(X, X, X, valid_lens))</span><br><span class="line">        <span class="keyword">return</span> self.addnorm2(Y, self.ffn(Y))</span><br></pre></td></tr></tbody></table></figure><p>正如我们所看到的，transformer编码器中的任何层都不会改变其输入的形状。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">X = torch.ones((<span class="number">2</span>, <span class="number">100</span>, <span class="number">24</span>))</span><br><span class="line">valid_lens = torch.tensor([<span class="number">3</span>, <span class="number">2</span>])</span><br><span class="line">encoder_blk = EncoderBlock(<span class="number">24</span>, <span class="number">24</span>, <span class="number">24</span>, <span class="number">24</span>, [<span class="number">100</span>, <span class="number">24</span>], <span class="number">24</span>, <span class="number">48</span>, <span class="number">8</span>, <span class="number">0.5</span>)</span><br><span class="line">encoder_blk.<span class="built_in">eval</span>()</span><br><span class="line">encoder_blk(X, valid_lens).shape</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">100</span>, <span class="number">24</span>])</span><br></pre></td></tr></tbody></table></figure><p>transformer编码器的代码中，我们堆叠了<code>num_layers</code>个<code>EncoderBlock</code>类的实例。由于我们使用的是值范围在−1和1之间的固定位置编码，因此通过学习得到的输入的嵌入表示的值需要先乘以嵌入维度的平方根进行重新缩放，然后再与位置编码相加。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#@save</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TransformerEncoder</span>(d2l.Encoder):</span><br><span class="line">    <span class="string">"""transformer编码器"""</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, vocab_size, key_size, query_size, value_size,</span></span><br><span class="line"><span class="params">                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,</span></span><br><span class="line"><span class="params">                 num_heads, num_layers, dropout, use_bias=<span class="literal">False</span>, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>(TransformerEncoder, self).__init__(**kwargs)</span><br><span class="line">        self.num_hiddens = num_hiddens</span><br><span class="line">        self.embedding = nn.Embedding(vocab_size, num_hiddens)</span><br><span class="line">        self.pos_encoding = d2l.PositionalEncoding(num_hiddens, dropout)</span><br><span class="line">        self.blks = nn.Sequential()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_layers):</span><br><span class="line">            self.blks.add_module(<span class="string">"block"</span>+<span class="built_in">str</span>(i),</span><br><span class="line">                EncoderBlock(key_size, query_size, value_size, num_hiddens,</span><br><span class="line">                             norm_shape, ffn_num_input, ffn_num_hiddens,</span><br><span class="line">                             num_heads, dropout, use_bias))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X, valid_lens, *args</span>):</span><br><span class="line">        <span class="comment"># 因为位置编码值在-1和1之间，</span></span><br><span class="line">        <span class="comment"># 因此嵌入值乘以嵌入维度的平方根进行缩放，</span></span><br><span class="line">        <span class="comment"># 然后再与位置编码相加。</span></span><br><span class="line">        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))</span><br><span class="line">        self.attention_weights = [<span class="literal">None</span>] * <span class="built_in">len</span>(self.blks)</span><br><span class="line">        <span class="keyword">for</span> i, blk <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.blks):</span><br><span class="line">            X = blk(X, valid_lens)</span><br><span class="line">            self.attention_weights[</span><br><span class="line">                i] = blk.attention.attention.attention_weights</span><br><span class="line">        <span class="keyword">return</span> X</span><br><span class="line">    </span><br><span class="line">encoder = TransformerEncoder(</span><br><span class="line">    <span class="number">200</span>, <span class="number">24</span>, <span class="number">24</span>, <span class="number">24</span>, <span class="number">24</span>, [<span class="number">100</span>, <span class="number">24</span>], <span class="number">24</span>, <span class="number">48</span>, <span class="number">8</span>, <span class="number">2</span>, <span class="number">0.5</span>)</span><br><span class="line">encoder.<span class="built_in">eval</span>()</span><br><span class="line">encoder(torch.ones((<span class="number">2</span>, <span class="number">100</span>), dtype=torch.long), valid_lens).shape</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">100</span>, <span class="number">24</span>])</span><br></pre></td></tr></tbody></table></figure><h3><span id="62-解码器">6.2 解码器</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">DecoderBlock</span>(nn.Module):</span><br><span class="line">    <span class="string">"""解码器中第i个块"""</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, key_size, query_size, value_size, num_hiddens,</span></span><br><span class="line"><span class="params">                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,</span></span><br><span class="line"><span class="params">                 dropout, i, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>(DecoderBlock, self).__init__(**kwargs)</span><br><span class="line">        self.i = i</span><br><span class="line">        self.attention1 = d2l.MultiHeadAttention(</span><br><span class="line">            key_size, query_size, value_size, num_hiddens, num_heads, dropout)</span><br><span class="line">        self.addnorm1 = AddNorm(norm_shape, dropout)</span><br><span class="line">        self.attention2 = d2l.MultiHeadAttention(</span><br><span class="line">            key_size, query_size, value_size, num_hiddens, num_heads, dropout)</span><br><span class="line">        self.addnorm2 = AddNorm(norm_shape, dropout)</span><br><span class="line">        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens,</span><br><span class="line">                                   num_hiddens)</span><br><span class="line">        self.addnorm3 = AddNorm(norm_shape, dropout)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X, state</span>):</span><br><span class="line">        enc_outputs, enc_valid_lens = state[<span class="number">0</span>], state[<span class="number">1</span>]</span><br><span class="line">        <span class="comment"># 训练阶段，输出序列的所有词元都在同一时间处理，</span></span><br><span class="line">        <span class="comment"># 因此state[2][self.i]初始化为None。</span></span><br><span class="line">        <span class="comment"># 预测阶段，输出序列是通过词元一个接着一个解码的，</span></span><br><span class="line">        <span class="comment"># 因此state[2][self.i]包含着直到当前时间步第i个块解码的输出表示</span></span><br><span class="line">        <span class="keyword">if</span> state[<span class="number">2</span>][self.i] <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            key_values = X</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            key_values = torch.cat((state[<span class="number">2</span>][self.i], X), axis=<span class="number">1</span>)</span><br><span class="line">        state[<span class="number">2</span>][self.i] = key_values</span><br><span class="line">        <span class="keyword">if</span> self.training:</span><br><span class="line">            batch_size, num_steps, _ = X.shape</span><br><span class="line">            <span class="comment"># dec_valid_lens的开头:(batch_size,num_steps),</span></span><br><span class="line">            <span class="comment"># 其中每一行是[1,2,...,num_steps]</span></span><br><span class="line">            dec_valid_lens = torch.arange(</span><br><span class="line">                <span class="number">1</span>, num_steps + <span class="number">1</span>, device=X.device).repeat(batch_size, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            dec_valid_lens = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 自注意力</span></span><br><span class="line">        X2 = self.attention1(X, key_values, key_values, dec_valid_lens)</span><br><span class="line">        Y = self.addnorm1(X, X2)</span><br><span class="line">        <span class="comment"># 编码器－解码器注意力。</span></span><br><span class="line">        <span class="comment"># enc_outputs的开头:(batch_size,num_steps,num_hiddens)</span></span><br><span class="line">        Y2 = self.attention2(Y, enc_outputs, enc_outputs, enc_valid_lens)</span><br><span class="line">        Z = self.addnorm2(Y, Y2)</span><br><span class="line">        <span class="keyword">return</span> self.addnorm3(Z, self.ffn(Z)), state</span><br></pre></td></tr></tbody></table></figure><p>为了便于在“编码器－解码器”注意力中进行缩放点积计算和残差连接中进行加法计算，编码器和解码器的特征维度都是<code>num_hiddens</code>。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">decoder_blk = DecoderBlock(<span class="number">24</span>, <span class="number">24</span>, <span class="number">24</span>, <span class="number">24</span>, [<span class="number">100</span>, <span class="number">24</span>], <span class="number">24</span>, <span class="number">48</span>, <span class="number">8</span>, <span class="number">0.5</span>, <span class="number">0</span>)</span><br><span class="line">decoder_blk.<span class="built_in">eval</span>()</span><br><span class="line">X = torch.ones((<span class="number">2</span>, <span class="number">100</span>, <span class="number">24</span>))</span><br><span class="line">state = [encoder_blk(X, valid_lens), valid_lens, [<span class="literal">None</span>]]</span><br><span class="line">decoder_blk(X, state)[<span class="number">0</span>].shape</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">100</span>, <span class="number">24</span>])</span><br></pre></td></tr></tbody></table></figure><p>现在我们构建了由<code>num_layers</code>个<code>DecoderBlock</code>实例组成的完整的transformer解码器。最后，通过一个全连接层计算所有<code>vocab_size</code>个可能的输出词元的预测值。解码器的自注意力权重和编码器解码器注意力权重都被存储下来，方便日后可视化的需要。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TransformerDecoder</span>(d2l.AttentionDecoder):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, vocab_size, key_size, query_size, value_size,</span></span><br><span class="line"><span class="params">                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,</span></span><br><span class="line"><span class="params">                 num_heads, num_layers, dropout, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>(TransformerDecoder, self).__init__(**kwargs)</span><br><span class="line">        self.num_hiddens = num_hiddens</span><br><span class="line">        self.num_layers = num_layers</span><br><span class="line">        self.embedding = nn.Embedding(vocab_size, num_hiddens)</span><br><span class="line">        self.pos_encoding = d2l.PositionalEncoding(num_hiddens, dropout)</span><br><span class="line">        self.blks = nn.Sequential()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_layers):</span><br><span class="line">            self.blks.add_module(<span class="string">"block"</span>+<span class="built_in">str</span>(i),</span><br><span class="line">                DecoderBlock(key_size, query_size, value_size, num_hiddens,</span><br><span class="line">                             norm_shape, ffn_num_input, ffn_num_hiddens,</span><br><span class="line">                             num_heads, dropout, i))</span><br><span class="line">        self.dense = nn.Linear(num_hiddens, vocab_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_state</span>(<span class="params">self, enc_outputs, enc_valid_lens, *args</span>):</span><br><span class="line">        <span class="keyword">return</span> [enc_outputs, enc_valid_lens, [<span class="literal">None</span>] * self.num_layers]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X, state</span>):</span><br><span class="line">        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))</span><br><span class="line">        self._attention_weights = [[<span class="literal">None</span>] * <span class="built_in">len</span>(self.blks) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span> (<span class="number">2</span>)]</span><br><span class="line">        <span class="keyword">for</span> i, blk <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.blks):</span><br><span class="line">            X, state = blk(X, state)</span><br><span class="line">            <span class="comment"># 解码器自注意力权重</span></span><br><span class="line">            self._attention_weights[<span class="number">0</span>][</span><br><span class="line">                i] = blk.attention1.attention.attention_weights</span><br><span class="line">            <span class="comment"># “编码器－解码器”自注意力权重</span></span><br><span class="line">            self._attention_weights[<span class="number">1</span>][</span><br><span class="line">                i] = blk.attention2.attention.attention_weights</span><br><span class="line">        <span class="keyword">return</span> self.dense(X), state</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">attention_weights</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self._attention_weights</span><br></pre></td></tr></tbody></table></figure><h2><span id="6-信息传递">6. 信息传递</span></h2><p>编码器中的输出 $y_1,\cdots,y_n$ ，将其作为解码中第 $i$ 个Transformer块中多头注意力的 key 和 value，它的 query 来自目标序列。</p><p>这意味着编码器和解码器中块的个数和输出维度都是一样的。</p><h2><span id="7-预测">7. 预测</span></h2><p>预测第 $t+1$ 个输出时，解码器中输入前 $t$ 个预测值，在自注意力中，前 $t $ 个预测值作为 key 和 value，第 $t$ 个预测值还作为 query。</p><p><img src="http://xiaomanzhan.com.cn/content/image-20220418164721341.png" alt="image-20220418164721341"></p><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 注意力机制 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Transformer </tag>
            
            <tag> 注意力机制 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode819</title>
      <link href="/2022/04/17/leetcode/mei-ri-yi-ti/leetcode819/"/>
      <url>/2022/04/17/leetcode/mei-ri-yi-ti/leetcode819/</url>
      
        <content type="html"><![CDATA[<h1><span id="819-最常见的单词">819. 最常见的单词</span></h1><blockquote><p><a href="https://leetcode-cn.com/problems/most-common-word/">819. 最常见的单词</a></p></blockquote><h2><span id="题目">题目</span></h2><p>给定一个段落 (paragraph) 和一个禁用单词列表 (banned)。返回出现次数最多，同时不在禁用列表中的单词。题目保证至少有一个词不在禁用列表中，而且答案唯一。禁用列表中的单词用小写字母表示，不含标点符号。段落中的单词不区分大小写。答案都是小写字母。</p><p>示例：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">输入: </span><br><span class="line">paragraph = "Bob hit a ball, the hit BALL flew far after it was hit."</span><br><span class="line">banned = ["hit"]</span><br><span class="line">输出: "ball"</span><br><span class="line">解释: </span><br><span class="line">"hit" 出现了3次，但它是一个禁用的单词。</span><br><span class="line">"ball" 出现了2次 (同时没有其他单词出现2次)，所以它是段落里出现次数最多的，且不在禁用列表中的单词。 </span><br><span class="line">注意，所有这些单词在段落里不区分大小写，标点符号需要忽略（即使是紧挨着单词也忽略， 比如 "ball,"）， </span><br><span class="line">"hit"不是最终的答案，虽然它出现次数更多，但它在禁用单词列表中。</span><br></pre></td></tr></tbody></table></figure><h2><span id="解题思路">解题思路</span></h2><ol><li>先将字符串中大写转化为小写；</li><li>将字符串中字符替换为空格；</li><li>将字符串按照空格进行切分；</li><li>使用哈希表统计切分后单词（统计的单词不包含在banned里面）；</li><li>对哈希表里面的值进行排序，找到最大的值；</li><li>找到哈希表中最大的值对应的key，输出</li></ol><h3><span id="题解">题解</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">mostCommonWord</span>(<span class="params">self, paragraph: <span class="built_in">str</span>, banned: <span class="type">List</span>[<span class="built_in">str</span>]</span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        paragraph = paragraph.lower()</span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> <span class="string">"!?',;."</span>:</span><br><span class="line">            paragraph = paragraph.replace(c, <span class="string">" "</span>)</span><br><span class="line">        words = paragraph.split()</span><br><span class="line">        words_dict = Counter()</span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">            <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> banned:</span><br><span class="line">                words_dict[word] += <span class="number">1</span></span><br><span class="line">        max_len = <span class="built_in">max</span>(words_dict.values())</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">next</span>(word <span class="keyword">for</span> word, val <span class="keyword">in</span> words_dict.items() <span class="keyword">if</span> val == max_len)</span><br></pre></td></tr></tbody></table></figure><blockquote><p>注意：</p><ol><li>使用Counter，不用Counter(words)是因为需要剔除某些单词；</li><li>使用next()函数能够方便的取序列或者数组的第一个元素。</li></ol></blockquote><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> 难度-简单 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeetCode </tag>
            
            <tag> 哈希表 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>自注意力</title>
      <link href="/2022/04/17/machine-learning/zhu-yi-li-ji-zhi/4.zi-zhu-yi-li/"/>
      <url>/2022/04/17/machine-learning/zhu-yi-li-ji-zhi/4.zi-zhu-yi-li/</url>
      
        <content type="html"><![CDATA[<h1><span id="自注意力">自注意力</span></h1><h2><span id="1-自注意力">1. 自注意力</span></h2><p>给定序列 $x_1,…,x_n,\forall x_i\in\R^d$，自注意力层将 $x_i$ 当做 <code>key,value,query</code> 来对序列抽取特征得到 $y_1,…,y_n$， 这里</p><script type="math/tex; mode=display">y_i=f(x_i,(x_1,x_1),...,(x_n,x_n))\in\R^d</script><p><img src="http://xiaomanzhan.com.cn/content/image-20220417204336143.png" alt="image-20220417204336143"></p><blockquote><p>注意：<code>key,value,query</code> 全部是一样的</p></blockquote><h2><span id="2-比较卷积神经网络-循环神经网络和自注意力">2. 比较卷积神经网络、循环神经网络和自注意力</span></h2><p>我们比较下面几个架构，目标都是将由 n 个词元组成的序列映射到另一个长度相等的序列，其中的每个输入词元或输出词元都由 d 维向量表示。具体来说，我们将比较的是卷积神经网络、循环神经网络和自注意力这几个架构的计算复杂性、顺序操作和最大路径长度。请注意，顺序操作会妨碍并行计算，而任意的序列位置组合之间的路径越短，则能更轻松地学习序列中的远距离依赖关系</p><p><img src="http://xiaomanzhan.com.cn/content/cnn-rnn-self-attention.svg" alt="../_images/cnn-rnn-self-attention.svg"></p><p>复杂度对比：</p><div class="table-container"><table><thead><tr><th></th><th>CNN</th><th>RNN</th><th>自注意力</th></tr></thead><tbody><tr><td>计算复杂度</td><td>$O(knd^2)$</td><td>$O(nd^2)$</td><td>$O(n^{2d})$</td></tr><tr><td>并行度</td><td>$O(n)$</td><td>$O(1)$</td><td>$O(n)$</td></tr><tr><td>最长路径</td><td>$O(n/k)$</td><td>$O(n)$</td><td>$O(1)$</td></tr></tbody></table></div><p>由上面观察可以看到，自注意力机制适合长度比较长的文本。</p><p>GBT、Transformer、BERT都是基于自注意力机制实现的，都有很长的序列</p><h2><span id="3-位置编码">3. 位置编码</span></h2><p>跟CNN/RNN不同，自注意力并没有记录位置信息 ，所以需要位置编码将位置信息注入到输入里：</p><ul><li>假设长度为 $n$ 的序列 $X\in\R^{n\times d}$ ，那么使用位置编码矩阵 $P\in\R^{n\times d}$ 来输出 $X+P$ 作为自编码输入。</li></ul><p>$P$ 的元素计算如下：</p><script type="math/tex; mode=display">p_{i,2j}=\sin(\frac{i}{10000^{2j/d}}),~~~p_{i,2j+1}=\cos(\frac{i}{10000^{2j/d}})</script><h3><span id="31-位置编码矩阵">3.1 位置编码矩阵</span></h3><p>$P\in\R^{n\times d}:p_{i,2j}=\sin(\frac{i}{10000^{2j/d}}),~~~p_{i,2j+1}=\cos(\frac{i}{10000^{2j/d}})$</p><p><img src="http://xiaomanzhan.com.cn/content/output_self-attention-and-positional-encoding_d76d5a_43_0.svg" alt="../_images/output_self-attention-and-positional-encoding_d76d5a_43_0.svg"></p><p>上图，x坐标表示行数，表示对i个序列（第i个单词）加的值是什么，上图表示从第6位到第9位的变化曲线，第i个序列的信息编码为列项的序列信息</p><h3><span id="32-绝对位置信息">3.2 绝对位置信息</span></h3><p>计算机使用二进制编码，3.1编码类似只是用另外一种形式记录信息。</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">0-000</span><br><span class="line">1-001</span><br><span class="line">2-010</span><br><span class="line">3-011</span><br><span class="line">4-100</span><br><span class="line">5-101</span><br><span class="line">6-110</span><br><span class="line">7-111</span><br></pre></td></tr></tbody></table></figure><p>位置编码信息如图所示，将3.1中图 (x,y) 交换位置，每行表示一个单词的位置编码。：</p><p><img src="http://xiaomanzhan.com.cn/content/output_self-attention-and-positional-encoding_d76d5a_67_0.svg" alt="../_images/output_self-attention-and-positional-encoding_d76d5a_67_0.svg"></p><h3><span id="33-相对位置信息">3.3 相对位置信息</span></h3><p>位置处于 $i+\delta$ 处的位置编码可以线性投影位置 $i$ 处的位置编码来表示，记 $\omega_j=1/10000^{2j/d}$，那么</p><script type="math/tex; mode=display">\begin{bmatrix}\cos(\delta\omega_j) & \sin(\delta\omega_j)\\\sin(\delta\omega_j) & \cos(\delta\omega_j)\end{bmatrix}\begin{bmatrix}p_{i,2j}\\p_{i,2j+1}\end{bmatrix}=\begin{bmatrix}p_{i+\delta,2j}\\p_{i\delta,2j+1}\end{bmatrix}</script><p>可以看到投影矩阵跟i无关。</p><h2><span id="4-多头注意力机制">4. 多头注意力机制</span></h2><p>当给定相同的查询、键和值的集合时， 我们希望模型可以基于相同的注意力机制学习到不同的行为， 然后将不同的行为作为知识组合起来， 捕获序列内各种范围的依赖关系 （例如，短距离依赖和长距离依赖关系）。 独立学习得到的 $h$ 组不同的注意力函数即可，最后拼接在一起。</p><p><img src="http://xiaomanzhan.com.cn/content/multi-head-attention.svg" alt="../_images/multi-head-attention.svg"></p><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 注意力机制 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 注意力机制 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用注意力机制的seq2seq</title>
      <link href="/2022/04/17/machine-learning/zhu-yi-li-ji-zhi/3.shi-yong-zhu-yi-li-ji-zhi-de-seq2seq/"/>
      <url>/2022/04/17/machine-learning/zhu-yi-li-ji-zhi/3.shi-yong-zhu-yi-li-ji-zhi-de-seq2seq/</url>
      
        <content type="html"><![CDATA[<h1><span id="使用注意力机制的seq2seq">使用注意力机制的seq2seq</span></h1><h2><span id="1-动机">1. 动机</span></h2><p>在机器翻译中，每个生成的词可能相关于源句子中不同的词，对此seq2seq模型中不能对此直接建模。</p><p><img src="http://xiaomanzhan.com.cn/content/image-20220417171400069.png" alt="image-20220417171400069"></p><h2><span id="2-加入注意力">2. 加入注意力</span></h2><p>编码器对每次词的输出作为 key 和 value ，解码器 RNN 对上一个词的输出是 query，注意力的输出和下一个词的词嵌入合并进入解码器。</p><p><img src="http://xiaomanzhan.com.cn/content/seq2seq-attention-details.svg" alt="../_images/seq2seq-attention-details.svg"></p><p>注意力机制可以根据解码器 RNN 的输出来匹配到合适的编码器RNN的输出来更有效的传递信息。</p><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 注意力机制 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 注意力机制 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>注意力机制</title>
      <link href="/2022/04/17/machine-learning/zhu-yi-li-ji-zhi/1.zhu-yi-li-ji-zhi/"/>
      <url>/2022/04/17/machine-learning/zhu-yi-li-ji-zhi/1.zhu-yi-li-ji-zhi/</url>
      
        <content type="html"><![CDATA[<h1><span id="注意力机制">注意力机制</span></h1><p>为了在复杂的环境下关注值得注意的点，提出注意力机制</p><h2><span id="1-注意力机制">1. 注意力机制</span></h2><p>卷积、全连接、池化层都只考虑不随意线索；</p><p>注意力机制则显示的考虑随意线索：</p><ul><li>随意线索被称为查询（query）；</li><li>每一个输入是一个值（value）和不随意线索（key）的对；</li><li>通过注意力池化层来有偏向性的选择某些输入。</li></ul><p><img src="http://xiaomanzhan.com.cn/content/qkv.svg" alt="../_images/qkv.svg"></p><h2><span id="2-注意力汇聚">2. 注意力汇聚</span></h2><p>生成数据，举例说明</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line">n_train = <span class="number">50</span>  <span class="comment"># 训练样本数</span></span><br><span class="line">x_train, _ = torch.sort(torch.rand(n_train) * <span class="number">5</span>)   <span class="comment"># 排序后的训练样本</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">f</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">2</span> * torch.sin(x) + x**<span class="number">0.8</span></span><br><span class="line"></span><br><span class="line">y_train = f(x_train) + torch.normal(<span class="number">0.0</span>, <span class="number">0.5</span>, (n_train,))  <span class="comment"># 训练样本的输出</span></span><br><span class="line">x_test = torch.arange(<span class="number">0</span>, <span class="number">5</span>, <span class="number">0.1</span>)  <span class="comment"># 测试样本</span></span><br><span class="line">y_truth = f(x_test)  <span class="comment"># 测试样本的真实输出</span></span><br><span class="line">n_test = <span class="built_in">len</span>(x_test)  <span class="comment"># 测试样本数</span></span><br></pre></td></tr></tbody></table></figure><p>下面的函数将绘制所有的训练样本（样本由圆圈表示）， 不带噪声项的真实数据生成函数f（标记为“Truth”）， 以及学习得到的预测函数（标记为“Pred”）。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">plot_kernel_reg</span>(<span class="params">y_hat</span>):</span><br><span class="line">    d2l.plot(x_test, [y_truth, y_hat], <span class="string">'x'</span>, <span class="string">'y'</span>, legend=[<span class="string">'Truth'</span>, <span class="string">'Pred'</span>],</span><br><span class="line">             xlim=[<span class="number">0</span>, <span class="number">5</span>], ylim=[-<span class="number">1</span>, <span class="number">5</span>])</span><br><span class="line">    d2l.plt.plot(x_train, y_train, <span class="string">'o'</span>, alpha=<span class="number">0.5</span>);</span><br></pre></td></tr></tbody></table></figure><h3><span id="21-平均汇聚">2.1 平均汇聚</span></h3><p>平均汇聚是一种非参注意力池化层，给定数据 $(x_i,y_i),i=1,..,n$，平均池化是最简单的方案 $f(x)=\frac{1}{n}\sum_iy_i$。</p><p>更好的方案是60年代提出的 Nadaeaya-Watson核回归 $f(x)=\sum_{i=1}^n\frac{K(x-x_i)}{\sum_{j=1}^nK(x-x_j)}y_i$</p><blockquote><p>注意：没有需要学习的参数</p></blockquote><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y_hat = torch.repeat_interleave(y_train.mean(), n_test)</span><br><span class="line">plot_kernel_reg(y_hat)</span><br></pre></td></tr></tbody></table></figure><p><img src="http://xiaomanzhan.com.cn/content/output_nadaraya-waston_736177_32_0.svg" alt="../_images/output_nadaraya-waston_736177_32_0.svg"></p><h3><span id="22-非参数注意力汇聚">2.2 非参数注意力汇聚</span></h3><p>使用Nadaeaya-Watson核回归，K使用高斯核时，$K(u)=\frac{1}{\sqrt{2\pi}}exp(-\frac{u^2}{2})$，那么</p><script type="math/tex; mode=display">f(x)=\sum_{i=1}^n\frac{exp(-\frac{1}{2}(x-x_i)^2)}{\sum_{j=1}^nexp(-\frac{1}{2}(x-x_j)^2}y_i\\~~~~~~~=\sum_{i=1}^nsoftmax(-\frac{1}{2}(x-x_i)^2)y_i</script><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># X_repeat的形状:(n_test,n_train),</span></span><br><span class="line"><span class="comment"># 每一行都包含着相同的测试输入（例如：同样的查询）</span></span><br><span class="line">X_repeat = x_test.repeat_interleave(n_train).reshape((-<span class="number">1</span>, n_train))</span><br><span class="line"><span class="comment"># x_train包含着键。attention_weights的形状：(n_test,n_train),</span></span><br><span class="line"><span class="comment"># 每一行都包含着要在给定的每个查询的值（y_train）之间分配的注意力权重</span></span><br><span class="line">attention_weights = nn.functional.softmax(-(X_repeat - x_train)**<span class="number">2</span> / <span class="number">2</span>, dim=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># y_hat的每个元素都是值的加权平均值，其中的权重是注意力权重</span></span><br><span class="line">y_hat = torch.matmul(attention_weights, y_train)</span><br><span class="line">plot_kernel_reg(y_hat)</span><br></pre></td></tr></tbody></table></figure><p><img src="http://xiaomanzhan.com.cn/content/output_nadaraya-waston_736177_44_0.svg" alt="../_images/output_nadaraya-waston_736177_44_0.svg"></p><p>因为两个输入都是经过排序的，因此由观察可知“查询-键”对越接近， 注意力汇聚的注意力权重就越高。查看注意力的权重。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">d2l.show_heatmaps(attention_weights.unsqueeze(<span class="number">0</span>).unsqueeze(<span class="number">0</span>),</span><br><span class="line">                  xlabel=<span class="string">'Sorted training inputs'</span>,</span><br><span class="line">                  ylabel=<span class="string">'Sorted testing inputs'</span>)</span><br></pre></td></tr></tbody></table></figure><p><img src="http://xiaomanzhan.com.cn/content/output_nadaraya-waston_736177_56_0.svg" alt="../_images/output_nadaraya-waston_736177_56_0.svg"></p><h3><span id="23-参数化的注意力机制">2.3 参数化的注意力机制</span></h3><p>在前面基础上引入可以学习的参数 $w$</p><script type="math/tex; mode=display">f(x)=\sum_{i=1}^nsoftmax(-\frac{1}{2}((x-x_i)w)^2)y_i</script><p>为了注意力机制的训练参数，我们需要使用小批量数据的矩阵乘法。带参数注意力汇聚 假定两个张量的形状分别是 $(𝑛,𝑎,𝑏)$ 和 $(n,b,c)$ ，它们的批量矩阵乘法输出的形状为 $(𝑛,𝑎,𝑐)$</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">X = torch.ones((<span class="number">2</span>, <span class="number">1</span>, <span class="number">4</span>))</span><br><span class="line">Y = torch.ones((<span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>))</span><br><span class="line">torch.bmm(X, Y).shape <span class="comment"># torch.Size([2, 1, 6])</span></span><br></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">weights = torch.ones((<span class="number">2</span>, <span class="number">10</span>)) * <span class="number">0.1</span></span><br><span class="line">values = torch.arange(<span class="number">20.0</span>).reshape((<span class="number">2</span>, <span class="number">10</span>))</span><br><span class="line">torch.bmm(weights.unsqueeze(<span class="number">1</span>), values.unsqueeze(-<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">tensor([[[ <span class="number">4.5000</span>]],</span><br><span class="line">        [[<span class="number">14.5000</span>]]])</span><br></pre></td></tr></tbody></table></figure><p>定义模型</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">NWKernelRegression</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(**kwargs)</span><br><span class="line">        self.w = nn.Parameter(torch.rand((<span class="number">1</span>,), requires_grad=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, queries, keys, values</span>):</span><br><span class="line">        <span class="comment"># queries和attention_weights的形状为(查询个数，“键－值”对个数)</span></span><br><span class="line">        queries = queries.repeat_interleave(keys.shape[<span class="number">1</span>]).reshape((-<span class="number">1</span>, keys.shape[<span class="number">1</span>]))</span><br><span class="line">        self.attention_weights = nn.functional.softmax(</span><br><span class="line">            -((queries - keys) * self.w)**<span class="number">2</span> / <span class="number">2</span>, dim=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># values的形状为(查询个数，“键－值”对个数)</span></span><br><span class="line">        <span class="keyword">return</span> torch.bmm(self.attention_weights.unsqueeze(<span class="number">1</span>),</span><br><span class="line">                         values.unsqueeze(-<span class="number">1</span>)).reshape(-<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># X_tile的形状:(n_train，n_train)，每一行都包含着相同的训练输入</span></span><br><span class="line">X_tile = x_train.repeat((n_train, <span class="number">1</span>))</span><br><span class="line"><span class="comment"># Y_tile的形状:(n_train，n_train)，每一行都包含着相同的训练输出</span></span><br><span class="line">Y_tile = y_train.repeat((n_train, <span class="number">1</span>))</span><br><span class="line"><span class="comment"># keys的形状:('n_train'，'n_train'-1)</span></span><br><span class="line">keys = X_tile[(<span class="number">1</span> - torch.eye(n_train)).<span class="built_in">type</span>(torch.<span class="built_in">bool</span>)].reshape((n_train, -<span class="number">1</span>))</span><br><span class="line"><span class="comment"># values的形状:('n_train'，'n_train'-1)</span></span><br><span class="line">values = Y_tile[(<span class="number">1</span> - torch.eye(n_train)).<span class="built_in">type</span>(torch.<span class="built_in">bool</span>)].reshape((n_train, -<span class="number">1</span>))</span><br></pre></td></tr></tbody></table></figure><p>训练带参数的注意力汇聚模型时，使用平方损失函数和随机梯度下降。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">net = NWKernelRegression()</span><br><span class="line">loss = nn.MSELoss(reduction=<span class="string">'none'</span>)</span><br><span class="line">trainer = torch.optim.SGD(net.parameters(), lr=<span class="number">0.5</span>)</span><br><span class="line">animator = d2l.Animator(xlabel=<span class="string">'epoch'</span>, ylabel=<span class="string">'loss'</span>, xlim=[<span class="number">1</span>, <span class="number">5</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">    trainer.zero_grad()</span><br><span class="line">    l = loss(net(x_train, keys, values), y_train)</span><br><span class="line">    l.<span class="built_in">sum</span>().backward()</span><br><span class="line">    trainer.step()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f'epoch <span class="subst">{epoch + <span class="number">1</span>}</span>, loss <span class="subst">{<span class="built_in">float</span>(l.<span class="built_in">sum</span>()):<span class="number">.6</span>f}</span>'</span>)</span><br><span class="line">    animator.add(epoch + <span class="number">1</span>, <span class="built_in">float</span>(l.<span class="built_in">sum</span>()))</span><br></pre></td></tr></tbody></table></figure><p><img src="http://xiaomanzhan.com.cn/content/output_nadaraya-waston_736177_116_0.svg" alt="../_images/output_nadaraya-waston_736177_116_0.svg"></p><p>如下所示，训练完带参数的注意力汇聚模型后，我们发现： 在尝试拟合带噪声的训练数据时， 预测结果绘制的线不如之前非参数模型的平滑。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># keys的形状:(n_test，n_train)，每一行包含着相同的训练输入（例如，相同的键）</span></span><br><span class="line">keys = x_train.repeat((n_test, <span class="number">1</span>))</span><br><span class="line"><span class="comment"># value的形状:(n_test，n_train)</span></span><br><span class="line">values = y_train.repeat((n_test, <span class="number">1</span>))</span><br><span class="line">y_hat = net(x_test, keys, values).unsqueeze(<span class="number">1</span>).detach()</span><br><span class="line">plot_kernel_reg(y_hat)</span><br></pre></td></tr></tbody></table></figure><p><img src="http://xiaomanzhan.com.cn/content/output_nadaraya-waston_736177_128_0.svg" alt="../_images/output_nadaraya-waston_736177_128_0.svg"></p><p>查看注意力权重</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">d2l.show_heatmaps(net.attention_weights.unsqueeze(<span class="number">0</span>).unsqueeze(<span class="number">0</span>),</span><br><span class="line">                  xlabel=<span class="string">'Sorted training inputs'</span>,</span><br><span class="line">                  ylabel=<span class="string">'Sorted testing inputs'</span>)</span><br></pre></td></tr></tbody></table></figure><p><img src="http://xiaomanzhan.com.cn/content/output_nadaraya-waston_736177_140_0.svg" alt="../_images/output_nadaraya-waston_736177_140_0.svg"></p><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 注意力机制 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 注意力机制 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>束搜索（bean search）</title>
      <link href="/2022/04/17/machine-learning/xun-huan-shen-jing-wang-luo/11.shu-sou-suo/"/>
      <url>/2022/04/17/machine-learning/xun-huan-shen-jing-wang-luo/11.shu-sou-suo/</url>
      
        <content type="html"><![CDATA[<h1><span id="束搜索">束搜索</span></h1><p>用于选取最优的输出</p><h2><span id="1-贪心搜索">1. 贪心搜索</span></h2><p>在seq2seq中我们使用了贪心搜索来预测序列，将当前时刻预测概率最大的词输出，但是贪心有可能不是最优的，但是贪心搜索是效率最高的，局部最优。</p><p>贪心：$0.5\times 0.4\times0.4\times0.6=0.048$</p><div class="table-container"><table><thead><tr><th>Time step</th><th>1</th><th>2</th><th>3</th><th>4</th></tr></thead><tbody><tr><td>A</td><td><strong>==0.5==</strong></td><td>0.1</td><td>0.2</td><td>0.0</td></tr><tr><td>B</td><td>0.2</td><td>==<strong>0.4</strong>==</td><td>0.2</td><td>0.2</td></tr><tr><td>C</td><td>0.2</td><td>0.3</td><td>==<strong>0.4</strong>==</td><td>0.2</td></tr><tr><td><eos></eos></td><td>0.1</td><td>0.2</td><td>0.2</td><td>==<strong>0.6</strong>==</td></tr></tbody></table></div><p>其他可能比较好的选项：$0.5\times0.3\times0.6\times0.6=0.054$</p><div class="table-container"><table><thead><tr><th>Time step</th><th>1</th><th>2</th><th>3</th><th>4</th></tr></thead><tbody><tr><td>A</td><td><strong>==0.5==</strong></td><td>0.1</td><td>0.1</td><td>0.1</td></tr><tr><td>B</td><td>0.2</td><td>0.4</td><td>==<strong>0.6</strong>==</td><td>0.2</td></tr><tr><td>C</td><td>0.2</td><td>==<strong>0.3</strong>==</td><td>0.2</td><td>0.1</td></tr><tr><td><eos></eos></td><td>0.1</td><td>0.2</td><td>0.1</td><td>==<strong>0.6</strong>==</td></tr></tbody></table></div><h2><span id="2-穷举搜索">2. 穷举搜索</span></h2><p>最优算法：对所有可能的序列，计算它的概率，然后取最好的那个。</p><p>如果输出字典大小为 $n$，序列最长为 $T$，那么我们需要考察 $n^T$个序列，比如 $n=10000,T=10:~~n^T=10^{40}$，计算上是不可行的</p><h2><span id="3-束搜索">3. 束搜索</span></h2><p>保存最好的 $k$个候选，在每个时刻，对每个候选新加一项 (n 种可能)，在 $kn$ 个选项中选出最好的 $k$ 个。</p><p><img src="http://xiaomanzhan.com.cn/content/image-20220417150613282.png" alt="image-20220417150613282"></p><p>时间复杂度：$O(knT)$，比如：$k=5,n=10000,T=10:~~~knT=5\times10^5$</p><p>每个候选的最终分数是，通常 $\alpha=0.75$：</p><script type="math/tex; mode=display">\frac{1}{L^\alpha}\log p(y_1,...,y_L)=\frac{1}{L^\alpha}\log p(y_{t'}|y_1,...,y_{t'-1})</script><h2><span id="4-总结">4. 总结</span></h2><p>束搜索在每次搜索时保存 $k$ 个最好的候选</p><ul><li>$k=1$ 时是贪心搜索</li><li>$k=n$ 时算是当前步的穷举，并非全部的穷举</li></ul><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 循环神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 循环神经网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>seq2seq</title>
      <link href="/2022/04/16/machine-learning/xun-huan-shen-jing-wang-luo/10.seq2seq/"/>
      <url>/2022/04/16/machine-learning/xun-huan-shen-jing-wang-luo/10.seq2seq/</url>
      
        <content type="html"><![CDATA[<h1><span id="序列到序列学习seq2seq">序列到序列学习（seq2seq）</span></h1><p>seq2seq：最早使用是做机器翻译，给定一个源语言的句子，自动翻译成目标语言，翻译前后的句子可以有不同的长度。</p><h2><span id="1-seq2seq">1. Seq2seq</span></h2><p>编码器是一个RNN，读取输入句子，可以是双向的，解码器使用另外一个RNN来输出。</p><p><img src="http://xiaomanzhan.com.cn/content/image-20220416195756123.png" alt="image-20220416195756123"></p><h2><span id="2-编码器-解码器细节">2. 编码器-解码器细节</span></h2><p>编码器是没有输出的RNN，编码器最后时间步的隐状态用作解码器的初始隐状态。</p><p><img src="http://xiaomanzhan.com.cn/content/image-20220416200155458.png" alt="image-20220416200155458"></p><h2><span id="3-训练">3. 训练</span></h2><p>训练时解码器使用目标句子作为输入。</p><p><img src="http://xiaomanzhan.com.cn/content/image-20220416200447650.png" alt="image-20220416200447650"></p><blockquote><p>注意：<strong>推理</strong>的时候只能使用上一时刻的输出作为下一时刻的输入。</p></blockquote><p><img src="http://xiaomanzhan.com.cn/content/image-20220416195756123.png" alt="image-20220416195756123"></p><h2><span id="4-bleu">4. BLEU</span></h2><p>BLEU: 用来衡量生成序列的好坏</p><p>使用 $p_n$ 作为预测中所有 $n-gram$ 的精度，加入有标签序列 <code>A B C D E F</code> 和预测序列 <code>A B B C D</code>，可以得到 $p_n$的具体分数，有 $p_1=\frac{4}{5},p_2=\frac{3}{4},p_3=\frac{1}{3},p_4=0$</p><p>BLEU 函数的定义如下：</p><script type="math/tex; mode=display">exp(min(0,1-\frac{len_{label}}{len_{pred}}))\prod_{n=1}^kp_n^{1/2^n}</script><p>$exp(min(0,1-\frac{len_{label}}{len_{pred}}))$ 表示惩罚过短的预测，当预测结果过短时，$min(0,1-\frac{len_{label}}{len_{pred}})$ 为负数，$exp(…)$ 只能是一个很小的数，所以预测结果越短越差，完美的时候，$exp(…) = 1$</p><p>$p_n^{1/2^n}$ 表示长匹配有高权重，n越大的时候 $\frac{1}{2^n}$越小，而$p_n\lt 1$，所以n越大时，权重越大。</p><blockquote><p>n-gram 表示标签序列中长度为 n的子串与预测序列中长度为 n的子串一样的概率条件。</p><p>例如：</p><p>target seq: ABCDEF, pre seq:ABBCD</p><p>当 n-gram为 1-gram时，pre存在5种（A,B,B,C,D），预测序列和标签序列一样的只有 4种，所以概率 $p_1=\frac{4}{5}$</p><p>当 n-gram为 2-gram时，pre存在4种（AB,BB,BC,CD），预测序列和标签序列一样的只有 3种，所以概率 $p_2=\frac{3}{4}$</p><p>当 n-gram为 3-gram时，pre存在3种（ABB,BBC,BCD），预测序列和标签序列一样的只有 1种，所以概率 $p_3=\frac{1}{3}$</p><p>当 n-gram为 4-gram时，pre存在2种（ABBC,BBCD），预测序列和标签序列一样的只有 0种，所以概率 $p_4=\frac{0}{2}$</p></blockquote><h2><span id="5code">5.CODE</span></h2><h3><span id="51-编码器">5.1 编码器</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Seq2SeqEncoder</span>(d2l.Encoder):</span><br><span class="line">    <span class="string">"""用于序列到序列学习的循环神经网络编码器。"""</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, vocab_size, embed_size, num_hiddens, num_layers,</span></span><br><span class="line"><span class="params">                 dropout=<span class="number">0</span>, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>(Seq2SeqEncoder, self).__init__(**kwargs)</span><br><span class="line">        self.embedding = nn.Embedding(vocab_size, embed_size)</span><br><span class="line">        self.rnn = nn.GRU(embed_size, num_hiddens, num_layers,</span><br><span class="line">                          dropout=dropout)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X, *args</span>):</span><br><span class="line">        X = self.embedding(X)</span><br><span class="line">        X = X.permute(<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>)</span><br><span class="line">        output, state = self.rnn(X)</span><br><span class="line">        <span class="keyword">return</span> output, state</span><br></pre></td></tr></tbody></table></figure><p>上述编码器的实现</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">encoder = Seq2SeqEncoder(vocab_size=<span class="number">10</span>, embed_size=<span class="number">8</span>, num_hiddens=<span class="number">16</span>,</span><br><span class="line">                         num_layers=<span class="number">2</span>)</span><br><span class="line">encoder.<span class="built_in">eval</span>()</span><br><span class="line">X = torch.zeros((<span class="number">4</span>, <span class="number">7</span>), dtype=torch.long)</span><br><span class="line">output, state = encoder(X)</span><br><span class="line">output.shape, state.shape</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">(torch.Size([<span class="number">7</span>, <span class="number">4</span>, <span class="number">16</span>]), torch.Size([<span class="number">2</span>, <span class="number">4</span>, <span class="number">16</span>]))</span><br></pre></td></tr></tbody></table></figure><h3><span id="52-解码器">5.2 解码器</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Seq2SeqDecoder</span>(d2l.Decoder):</span><br><span class="line">    <span class="string">"""用于序列到序列学习的循环神经网络解码器。"""</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, vocab_size, embed_size, num_hiddens, num_layers,</span></span><br><span class="line"><span class="params">                 dropout=<span class="number">0</span>, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>(Seq2SeqDecoder, self).__init__(**kwargs)</span><br><span class="line">        self.embedding = nn.Embedding(vocab_size, embed_size)</span><br><span class="line">        self.rnn = nn.GRU(embed_size + num_hiddens, num_hiddens, num_layers,</span><br><span class="line">                          dropout=dropout)</span><br><span class="line">        self.dense = nn.Linear(num_hiddens, vocab_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_state</span>(<span class="params">self, enc_outputs, *args</span>):</span><br><span class="line">        <span class="keyword">return</span> enc_outputs[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X, state</span>):</span><br><span class="line">        X = self.embedding(X).permute(<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>)</span><br><span class="line">        context = state[-<span class="number">1</span>].repeat(X.shape[<span class="number">0</span>], <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        X_and_context = torch.cat((X, context), <span class="number">2</span>)</span><br><span class="line">        output, state = self.rnn(X_and_context, state)</span><br><span class="line">        output = self.dense(output).permute(<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>)</span><br><span class="line">        <span class="keyword">return</span> output, state</span><br></pre></td></tr></tbody></table></figure><p>解码器实例化</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">decoder = Seq2SeqDecoder(vocab_size=<span class="number">10</span>, embed_size=<span class="number">8</span>, num_hiddens=<span class="number">16</span>,</span><br><span class="line">                         num_layers=<span class="number">2</span>)</span><br><span class="line">decoder.<span class="built_in">eval</span>()</span><br><span class="line">state = decoder.init_state(encoder(X))</span><br><span class="line">output, state = decoder(X, state)</span><br><span class="line">output.shape, state.shape</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">(torch.Size([<span class="number">4</span>, <span class="number">7</span>, <span class="number">10</span>]), torch.Size([<span class="number">2</span>, <span class="number">4</span>, <span class="number">16</span>]))</span><br></pre></td></tr></tbody></table></figure><h3><span id="53-屏蔽不相关的项">5.3 屏蔽不相关的项</span></h3><p>通过零值化屏蔽不相关的项</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">sequence_mask</span>(<span class="params">X, valid_len, value=<span class="number">0</span></span>):</span><br><span class="line">    <span class="string">"""在序列中屏蔽不相关的项。"""</span></span><br><span class="line">    maxlen = X.size(<span class="number">1</span>)</span><br><span class="line">    mask = torch.arange((maxlen), dtype=torch.float32,</span><br><span class="line">                        device=X.device)[<span class="literal">None</span>, :] &lt; valid_len[:, <span class="literal">None</span>]</span><br><span class="line">    X[~mask] = value</span><br><span class="line">    <span class="keyword">return</span> X</span><br><span class="line"></span><br><span class="line">X = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line">sequence_mask(X, torch.tensor([<span class="number">1</span>, <span class="number">2</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">tensor([[<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">        [<span class="number">4</span>, <span class="number">5</span>, <span class="number">0</span>]])</span><br></pre></td></tr></tbody></table></figure><p>我们还可以使用此函数屏蔽最后几个轴上的所有项</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">X = torch.ones(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">sequence_mask(X, torch.tensor([<span class="number">1</span>, <span class="number">2</span>]), value=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">tensor([[[ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>],</span><br><span class="line">         [-<span class="number">1.</span>, -<span class="number">1.</span>, -<span class="number">1.</span>, -<span class="number">1.</span>],</span><br><span class="line">         [-<span class="number">1.</span>, -<span class="number">1.</span>, -<span class="number">1.</span>, -<span class="number">1.</span>]],</span><br><span class="line"></span><br><span class="line">        [[ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>],</span><br><span class="line">         [ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>],</span><br><span class="line">         [-<span class="number">1.</span>, -<span class="number">1.</span>, -<span class="number">1.</span>, -<span class="number">1.</span>]]])</span><br></pre></td></tr></tbody></table></figure><h3><span id="54-带遮蔽的softmax交叉熵损失">5.4 带遮蔽的softmax交叉熵损失</span></h3><p>通过扩展softmax交叉熵损失函数来遮蔽不相关的预测</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MaskedSoftmaxCELoss</span>(nn.CrossEntropyLoss):</span><br><span class="line">    <span class="string">"""带遮蔽的softmax交叉熵损失函数"""</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, pred, label, valid_len</span>):</span><br><span class="line">        weights = torch.ones_like(label)</span><br><span class="line">        weights = sequence_mask(weights, valid_len)</span><br><span class="line">        self.reduction = <span class="string">'none'</span></span><br><span class="line">        unweighted_loss = <span class="built_in">super</span>(MaskedSoftmaxCELoss,</span><br><span class="line">                                self).forward(pred.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>), label)</span><br><span class="line">        weighted_loss = (unweighted_loss * weights).mean(dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> weighted_loss</span><br></pre></td></tr></tbody></table></figure><p>代码健壮性检查</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">loss = MaskedSoftmaxCELoss()</span><br><span class="line">loss(torch.ones(<span class="number">3</span>, <span class="number">4</span>, <span class="number">10</span>), torch.ones((<span class="number">3</span>, <span class="number">4</span>), dtype=torch.long),</span><br><span class="line">     torch.tensor([<span class="number">4</span>, <span class="number">2</span>, <span class="number">0</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">tensor([<span class="number">2.3026</span>, <span class="number">1.1513</span>, <span class="number">0.0000</span>])</span><br></pre></td></tr></tbody></table></figure><h3><span id="55-训练模型">5.5 训练模型</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_seq2seq</span>(<span class="params">net, data_iter, lr, num_epochs, tgt_vocab, device</span>):</span><br><span class="line">    <span class="string">"""训练序列到序列模型。"""</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">xavier_init_weights</span>(<span class="params">m</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">type</span>(m) == nn.Linear:</span><br><span class="line">            nn.init.xavier_uniform_(m.weight)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">type</span>(m) == nn.GRU:</span><br><span class="line">            <span class="keyword">for</span> param <span class="keyword">in</span> m._flat_weights_names:</span><br><span class="line">                <span class="keyword">if</span> <span class="string">"weight"</span> <span class="keyword">in</span> param:</span><br><span class="line">                    nn.init.xavier_uniform_(m._parameters[param])</span><br><span class="line"></span><br><span class="line">    net.apply(xavier_init_weights)</span><br><span class="line">    net.to(device)</span><br><span class="line">    optimizer = torch.optim.Adam(net.parameters(), lr=lr)</span><br><span class="line">    loss = MaskedSoftmaxCELoss()</span><br><span class="line">    net.train()</span><br><span class="line">    animator = d2l.Animator(xlabel=<span class="string">'epoch'</span>, ylabel=<span class="string">'loss'</span>,</span><br><span class="line">                            xlim=[<span class="number">10</span>, num_epochs])</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        timer = d2l.Timer()</span><br><span class="line">        metric = d2l.Accumulator(<span class="number">2</span>)</span><br><span class="line">        <span class="keyword">for</span> batch <span class="keyword">in</span> data_iter:</span><br><span class="line">            X, X_valid_len, Y, Y_valid_len = [x.to(device) <span class="keyword">for</span> x <span class="keyword">in</span> batch]</span><br><span class="line">            bos = torch.tensor([tgt_vocab[<span class="string">'&lt;bos&gt;'</span>]] * Y.shape[<span class="number">0</span>],</span><br><span class="line">                               device=device).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">            dec_input = torch.cat([bos, Y[:, :-<span class="number">1</span>]], <span class="number">1</span>)</span><br><span class="line">            Y_hat, _ = net(X, dec_input, X_valid_len)</span><br><span class="line">            l = loss(Y_hat, Y, Y_valid_len)</span><br><span class="line">            l.<span class="built_in">sum</span>().backward()</span><br><span class="line">            d2l.grad_clipping(net, <span class="number">1</span>)</span><br><span class="line">            num_tokens = Y_valid_len.<span class="built_in">sum</span>()</span><br><span class="line">            optimizer.step()</span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                metric.add(l.<span class="built_in">sum</span>(), num_tokens)</span><br><span class="line">        <span class="keyword">if</span> (epoch + <span class="number">1</span>) % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">            animator.add(epoch + <span class="number">1</span>, (metric[<span class="number">0</span>] / metric[<span class="number">1</span>],))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f'loss <span class="subst">{metric[<span class="number">0</span>] / metric[<span class="number">1</span>]:<span class="number">.3</span>f}</span>, <span class="subst">{metric[<span class="number">1</span>] / timer.stop():<span class="number">.1</span>f}</span> '</span></span><br><span class="line">          <span class="string">f'tokens/sec on <span class="subst">{<span class="built_in">str</span>(device)}</span>'</span>)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="comment"># 创建和训练一个循环神经网络“编码器－解码器”模型    </span></span><br><span class="line">embed_size, num_hiddens, num_layers, dropout = <span class="number">32</span>, <span class="number">32</span>, <span class="number">2</span>, <span class="number">0.1</span></span><br><span class="line">batch_size, num_steps = <span class="number">64</span>, <span class="number">10</span></span><br><span class="line">lr, num_epochs, device = <span class="number">0.005</span>, <span class="number">300</span>, d2l.try_gpu()</span><br><span class="line"></span><br><span class="line">train_iter, src_vocab, tgt_vocab = d2l.load_data_nmt(batch_size, num_steps)</span><br><span class="line">encoder = Seq2SeqEncoder(<span class="built_in">len</span>(src_vocab), embed_size, num_hiddens, num_layers,</span><br><span class="line">                         dropout)</span><br><span class="line">decoder = Seq2SeqDecoder(<span class="built_in">len</span>(tgt_vocab), embed_size, num_hiddens, num_layers,</span><br><span class="line">                         dropout)</span><br><span class="line">net = d2l.EncoderDecoder(encoder, decoder)</span><br><span class="line">train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">loss <span class="number">0.020</span>, <span class="number">11178.7</span> tokens/sec on cuda:<span class="number">0</span></span><br></pre></td></tr></tbody></table></figure><p><img src="http://xiaomanzhan.com.cn/content/image-20220504142146123.png" alt="image-20220504142146123"></p><h3><span id="56-预测">5.6 预测</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">predict_seq2seq</span>(<span class="params">net, src_sentence, src_vocab, tgt_vocab, num_steps,</span></span><br><span class="line"><span class="params">                    device, save_attention_weights=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="string">"""序列到序列模型的预测"""</span></span><br><span class="line">    net.<span class="built_in">eval</span>()</span><br><span class="line">    src_tokens = src_vocab[src_sentence.lower().split(<span class="string">' '</span>)] + [</span><br><span class="line">        src_vocab[<span class="string">'&lt;eos&gt;'</span>]]</span><br><span class="line">    enc_valid_len = torch.tensor([<span class="built_in">len</span>(src_tokens)], device=device)</span><br><span class="line">    src_tokens = d2l.truncate_pad(src_tokens, num_steps, src_vocab[<span class="string">'&lt;pad&gt;'</span>])</span><br><span class="line">    enc_X = torch.unsqueeze(</span><br><span class="line">        torch.tensor(src_tokens, dtype=torch.long, device=device), dim=<span class="number">0</span>)</span><br><span class="line">    enc_outputs = net.encoder(enc_X, enc_valid_len)</span><br><span class="line">    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)</span><br><span class="line">    dec_X = torch.unsqueeze(</span><br><span class="line">        torch.tensor([tgt_vocab[<span class="string">'&lt;bos&gt;'</span>]], dtype=torch.long, device=device),</span><br><span class="line">        dim=<span class="number">0</span>)</span><br><span class="line">    output_seq, attention_weight_seq = [], []</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_steps):</span><br><span class="line">        Y, dec_state = net.decoder(dec_X, dec_state)</span><br><span class="line">        dec_X = Y.argmax(dim=<span class="number">2</span>)</span><br><span class="line">        pred = dec_X.squeeze(dim=<span class="number">0</span>).<span class="built_in">type</span>(torch.int32).item()</span><br><span class="line">        <span class="keyword">if</span> save_attention_weights:</span><br><span class="line">            attention_weight_seq.append(net.decoder.attention_weights)</span><br><span class="line">        <span class="keyword">if</span> pred == tgt_vocab[<span class="string">'&lt;eos&gt;'</span>]:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        output_seq.append(pred)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">' '</span>.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq</span><br></pre></td></tr></tbody></table></figure><h3><span id="57-bleu的代码实现">5.7 BLEU的代码实现</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">bleu</span>(<span class="params">pred_seq, label_seq, k</span>):  </span><br><span class="line">    <span class="string">"""计算 BLEU"""</span></span><br><span class="line">    pred_tokens, label_tokens = pred_seq.split(<span class="string">' '</span>), label_seq.split(<span class="string">' '</span>)</span><br><span class="line">    len_pred, len_label = <span class="built_in">len</span>(pred_tokens), <span class="built_in">len</span>(label_tokens)</span><br><span class="line">    score = math.exp(<span class="built_in">min</span>(<span class="number">0</span>, <span class="number">1</span> - len_label / len_pred))</span><br><span class="line">    <span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, k + <span class="number">1</span>):</span><br><span class="line">        num_matches, label_subs = <span class="number">0</span>, collections.defaultdict(<span class="built_in">int</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(len_label - n + <span class="number">1</span>):</span><br><span class="line">            label_subs[<span class="string">''</span>.join(label_tokens[i:i + n])] += <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(len_pred - n + <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> label_subs[<span class="string">''</span>.join(pred_tokens[i:i + n])] &gt; <span class="number">0</span>:</span><br><span class="line">                num_matches += <span class="number">1</span></span><br><span class="line">                label_subs[<span class="string">''</span>.join(pred_tokens[i:i + n])] -= <span class="number">1</span></span><br><span class="line">        score *= math.<span class="built_in">pow</span>(num_matches / (len_pred - n + <span class="number">1</span>), math.<span class="built_in">pow</span>(<span class="number">0.5</span>, n))</span><br><span class="line">    <span class="keyword">return</span> score</span><br></pre></td></tr></tbody></table></figure><h3><span id="58-翻译">5.8 翻译</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">engs = [<span class="string">'go .'</span>, <span class="string">"i lost ."</span>, <span class="string">'he\'s calm .'</span>, <span class="string">'i\'m home .'</span>]</span><br><span class="line">fras = [<span class="string">'va !'</span>, <span class="string">'j\'ai perdu .'</span>, <span class="string">'il est calme .'</span>, <span class="string">'je suis chez moi .'</span>]</span><br><span class="line"><span class="keyword">for</span> eng, fra <span class="keyword">in</span> <span class="built_in">zip</span>(engs, fras):</span><br><span class="line">    translation, attention_weight_seq = predict_seq2seq(</span><br><span class="line">        net, eng, src_vocab, tgt_vocab, num_steps, device)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f'<span class="subst">{eng}</span> =&gt; <span class="subst">{translation}</span>, bleu <span class="subst">{bleu(translation, fra, k=<span class="number">2</span>):<span class="number">.3</span>f}</span>'</span>)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">go . =&gt; va !, bleu <span class="number">1.000</span></span><br><span class="line">i lost . =&gt; j<span class="string">'ai perdu détendu ., bleu 0.658</span></span><br><span class="line"><span class="string">he'</span>s calm . =&gt; soyez calmes &lt;unk&gt; ., bleu <span class="number">0.000</span></span><br><span class="line">i<span class="string">'m home . =&gt; je suis chez moi ., bleu 1.000</span></span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 循环神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 循环神经网络 </tag>
            
            <tag> seq2seq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>注意力分数</title>
      <link href="/2022/04/16/machine-learning/zhu-yi-li-ji-zhi/2.zhu-yi-li-fen-shu/"/>
      <url>/2022/04/16/machine-learning/zhu-yi-li-ji-zhi/2.zhu-yi-li-fen-shu/</url>
      
        <content type="html"><![CDATA[<h1><span id="注意力分数">注意力分数</span></h1><h2><span id="1-注意力分数">1. 注意力分数</span></h2><p>根据 $q,k,v$ 得到的注意力分数，计算注意力权重。</p><script type="math/tex; mode=display">f(x)=\sum_i\alpha(x,x_i)y_i=\sum^n_{i=1}softmax(-\frac{1}{2}(x-x_i)^2)y_i</script><p>上式中，$\alpha(x,x_i)$ 表示注意力权重，$-\frac{1}{2}(x-x_i)^2$ 表示注意力分数</p><p><img src="http://xiaomanzhan.com.cn/content/attention-output.svg" alt="../_images/attention-output.svg"></p><p>用数学语言描述，假设有一个查询 $q\in\R^q$和 $m$个“键－值”对$ (k1,v1),…,(km,vm)$，其中$k_i\in\R^k$，$v_i\in\R^v$。 注意力汇聚函数 $f$ 就被表示成值的加权和：</p><script type="math/tex; mode=display">f(q,(k_1,v_1),\dots,(k_m,v_m))=\sum^{m}_{i=1}\alpha(q,k_i)v_i\in\R^v</script><p>其中查询 $q$ 和键 $k_i$ 的注意力权重（标量） 是通过注意力评分函数 $a$ 将两个向量映射成标量， 再经过 $softmax$ 运算得到的：</p><script type="math/tex; mode=display">\alpha(q,k_i)=softmax(a(q,k_i))=\frac{\exp(a(q,k_i))}{\sum_{j=1}^m\exp(a(q,k_j))}</script><h2><span id="2-两种注意力方法实现">2. 两种注意力方法实现</span></h2><h3><span id="21-addititive-attention">2.1 Addititive Attention</span></h3><p><strong>加性注意力</strong>，可学参数：</p><script type="math/tex; mode=display">W_k\in\R^{h\times k},W_q\in\R^{h\times q},v\in\R^h\\</script><p>下面操作能够将矩阵信息转换为一个值。</p><script type="math/tex; mode=display">a(k,q)=v^Ttanh(W_kk+W_qq)</script><p>等价于将 <code>key</code>  和 <code>value</code> 合并起来后放入到一个隐藏大小为  <code>h</code>，输出大小为 <code>1</code> 的单隐藏层 <code>MLP</code>。</p><h3><span id="22-scaled-dot-product-attention">2.2 Scaled Dot-Product Attention</span></h3><p>如果 query 和 key 都是相同的长度 $q,k_i\in\R^d$，那么可以 </p><script type="math/tex; mode=display">a(q,k_i)=<q,k_i>/\sqrt{d}</script><p>注意：除以 $\sqrt{d}$ 是因为当 $k$ 的长度过长时，注意力结果也不会过于敏感。</p><p>向量化的版本可以表示为</p><ul><li>参数信息：$Q\in\R^{n\times d},K\in\R^{m\times d},V\in\R^{m\times v}$</li><li>注意力分数：$a(Q,K)=QK^T/\sqrt{d}\in\R^{n\times m}$</li><li>注意力池化：$f=softmax(a(Q,K))~V\in\R^{n\times v}$</li></ul><h2><span id="3-code">3. CODE</span></h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br></pre></td></tr></tbody></table></figure><h3><span id="31-掩蔽softmax操作">3.1 掩蔽softmax操作</span></h3><p>softmax 操作用于输出一个概率分布作为注意力权重。 在某些情况下，并非所有的值都应该被纳入到注意力汇聚中。 我们可以指定一个有效序列长度（即词元的个数）， 以便在计算softmax时过滤掉超出指定范围的位置。 通过这种方式，我们可以在下面的 <code>masked_softmax</code> 函数中实现这样的<strong>掩蔽softmax操作</strong>（masked softmax operation）， 其中任何超出有效长度的位置都被掩蔽并置为0。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#@save</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">masked_softmax</span>(<span class="params">X, valid_lens</span>):</span><br><span class="line">    <span class="string">"""通过在最后一个轴上掩蔽元素来执行softmax操作"""</span></span><br><span class="line">    <span class="comment"># X:3D张量，valid_lens:1D或2D张量</span></span><br><span class="line">    <span class="keyword">if</span> valid_lens <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> nn.functional.softmax(X, dim=-<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        shape = X.shape</span><br><span class="line">        <span class="keyword">if</span> valid_lens.dim() == <span class="number">1</span>:</span><br><span class="line">            valid_lens = torch.repeat_interleave(valid_lens, shape[<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            valid_lens = valid_lens.reshape(-<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 最后一轴上被掩蔽的元素使用一个非常大的负值替换，从而其softmax输出为0</span></span><br><span class="line">        X = d2l.sequence_mask(X.reshape(-<span class="number">1</span>, shape[-<span class="number">1</span>]), valid_lens,</span><br><span class="line">                              value=-<span class="number">1e6</span>)</span><br><span class="line">        <span class="keyword">return</span> nn.functional.softmax(X.reshape(shape), dim=-<span class="number">1</span>)</span><br></pre></td></tr></tbody></table></figure><p>为了演示此函数是如何工作的， 考虑由两个2×4矩阵表示的样本， 这两个样本的有效长度分别为2和3。 经过掩蔽softmax操作，超出有效长度的值都被掩蔽为0。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">masked_softmax(torch.rand(<span class="number">2</span>, <span class="number">2</span>, <span class="number">4</span>), torch.tensor([<span class="number">2</span>, <span class="number">3</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">tensor([[[<span class="number">0.5693</span>, <span class="number">0.4307</span>, <span class="number">0.0000</span>, <span class="number">0.0000</span>],</span><br><span class="line">         [<span class="number">0.3105</span>, <span class="number">0.6895</span>, <span class="number">0.0000</span>, <span class="number">0.0000</span>]],</span><br><span class="line">        [[<span class="number">0.2806</span>, <span class="number">0.3276</span>, <span class="number">0.3918</span>, <span class="number">0.0000</span>],</span><br><span class="line">         [<span class="number">0.3250</span>, <span class="number">0.3172</span>, <span class="number">0.3579</span>, <span class="number">0.0000</span>]]])</span><br></pre></td></tr></tbody></table></figure><p>同样，我们也可以使用二维张量，为矩阵样本中的每一行指定有效长度。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">masked_softmax(torch.rand(<span class="number">2</span>, <span class="number">2</span>, <span class="number">4</span>), torch.tensor([[<span class="number">1</span>, <span class="number">3</span>], [<span class="number">2</span>, <span class="number">4</span>]]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">tensor([[[<span class="number">1.0000</span>, <span class="number">0.0000</span>, <span class="number">0.0000</span>, <span class="number">0.0000</span>],</span><br><span class="line">         [<span class="number">0.3339</span>, <span class="number">0.2598</span>, <span class="number">0.4063</span>, <span class="number">0.0000</span>]],</span><br><span class="line">        [[<span class="number">0.4451</span>, <span class="number">0.5549</span>, <span class="number">0.0000</span>, <span class="number">0.0000</span>],</span><br><span class="line">         [<span class="number">0.2778</span>, <span class="number">0.2798</span>, <span class="number">0.2302</span>, <span class="number">0.2122</span>]]])</span><br></pre></td></tr></tbody></table></figure><h3><span id="32-加性注意力">3.2 加性注意力</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#@save</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AdditiveAttention</span>(nn.Module):</span><br><span class="line">    <span class="string">"""加性注意力"""</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, key_size, query_size, num_hiddens, dropout, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>(AdditiveAttention, self).__init__(**kwargs)</span><br><span class="line">        self.W_k = nn.Linear(key_size, num_hiddens, bias=<span class="literal">False</span>)</span><br><span class="line">        self.W_q = nn.Linear(query_size, num_hiddens, bias=<span class="literal">False</span>)</span><br><span class="line">        self.w_v = nn.Linear(num_hiddens, <span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, queries, keys, values, valid_lens</span>):</span><br><span class="line">        queries, keys = self.W_q(queries), self.W_k(keys)</span><br><span class="line">        <span class="comment"># 在维度扩展后，</span></span><br><span class="line">        <span class="comment"># queries的形状：(batch_size，查询的个数，1，num_hidden)</span></span><br><span class="line">        <span class="comment"># key的形状：(batch_size，1，“键－值”对的个数，num_hiddens)</span></span><br><span class="line">        <span class="comment"># 使用广播方式进行求和</span></span><br><span class="line">        features = queries.unsqueeze(<span class="number">2</span>) + keys.unsqueeze(<span class="number">1</span>)</span><br><span class="line">        features = torch.tanh(features)</span><br><span class="line">        <span class="comment"># self.w_v仅有一个输出，因此从形状中移除最后那个维度。</span></span><br><span class="line">        <span class="comment"># scores的形状：(batch_size，查询的个数，“键-值”对的个数)</span></span><br><span class="line">        scores = self.w_v(features).squeeze(-<span class="number">1</span>)</span><br><span class="line">        self.attention_weights = masked_softmax(scores, valid_lens)</span><br><span class="line">        <span class="comment"># values的形状：(batch_size，“键－值”对的个数，值的维度)</span></span><br><span class="line">        <span class="keyword">return</span> torch.bmm(self.dropout(self.attention_weights), values)</span><br></pre></td></tr></tbody></table></figure><h3><span id="33-缩放点积注意力">3.3 缩放点积注意力</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#@save</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DotProductAttention</span>(nn.Module):</span><br><span class="line">    <span class="string">"""缩放点积注意力"""</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dropout, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>(DotProductAttention, self).__init__(**kwargs)</span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># queries的形状：(batch_size，查询的个数，d)</span></span><br><span class="line">    <span class="comment"># keys的形状：(batch_size，“键－值”对的个数，d)</span></span><br><span class="line">    <span class="comment"># values的形状：(batch_size，“键－值”对的个数，值的维度)</span></span><br><span class="line">    <span class="comment"># valid_lens的形状:(batch_size，)或者(batch_size，查询的个数)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, queries, keys, values, valid_lens=<span class="literal">None</span></span>):</span><br><span class="line">        d = queries.shape[-<span class="number">1</span>]</span><br><span class="line">        <span class="comment"># 设置transpose_b=True为了交换keys的最后两个维度</span></span><br><span class="line">        scores = torch.bmm(queries, keys.transpose(<span class="number">1</span>,<span class="number">2</span>)) / math.sqrt(d)</span><br><span class="line">        self.attention_weights = masked_softmax(scores, valid_lens)</span><br><span class="line">        <span class="keyword">return</span> torch.bmm(self.dropout(self.attention_weights), values)</span><br></pre></td></tr></tbody></table></figure><h2><span id="4-总结">4. 总结</span></h2><p>注意力分数是 query 和 key 的相似度，注意力权重是分数的 softmax 的结果，能够使权重在(0,1)之间。</p><p>常见的两种分数的计算方式：</p><ul><li>将 query和key合并起来进入一个单输出隐藏层的MLP；</li><li>直接讲query和key做内积</li></ul><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 注意力机制 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 注意力机制 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>编码器-解码器结构</title>
      <link href="/2022/04/16/machine-learning/xun-huan-shen-jing-wang-luo/9.bian-ma-qi-jie-ma-qi-jie-gou/"/>
      <url>/2022/04/16/machine-learning/xun-huan-shen-jing-wang-luo/9.bian-ma-qi-jie-ma-qi-jie-gou/</url>
      
        <content type="html"><![CDATA[<h1><span id="编码器-解码器结构">编码器-解码器结构</span></h1><h2><span id="1-参考">1. 参考</span></h2><h3><span id="11-参考cnn">1.1 参考CNN</span></h3><p><img src="http://xiaomanzhan.com.cn/content/image-20220416121836903.png" alt="image-20220416121836903"></p><p>可以看做<strong>编码器</strong>是将输入编程成中间表达形式（特征），<strong>解码器</strong>就是将中间表示解码成输出。</p><h3><span id="12-参考rnn">1.2 参考RNN</span></h3><p><strong>编码器</strong>可以看做成将文本表示成向量，<strong>解码器</strong>可以看做向量表示成输出</p><p><img src="http://xiaomanzhan.com.cn/content/image-20220416122108390.png" alt="image-20220416122108390"></p><h2><span id="2-编码器-解码器架构">2. 编码器-解码器架构</span></h2><p>一个模型被分为两块：<strong>编码器</strong>处理输出；<strong>解码器</strong>生成输，解码器也可以额外拿到输入。</p><p><img src="http://xiaomanzhan.com.cn/content/image-20220416151709377.png" alt="image-20220416151709377"></p><h2><span id="3-code">3. CODE</span></h2><h3><span id="31-机器翻译与数据集">3.1 机器翻译与数据集</span></h3><h4><span id="311-下载和预处理数据集">3.1.1 下载和预处理数据集</span></h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line">d2l.DATA_HUB[<span class="string">'fra-eng'</span>] = (d2l.DATA_URL + <span class="string">'fra-eng.zip'</span>,</span><br><span class="line">                           <span class="string">'94646ad1522d915e7b0f9296181140edcf86a4f5'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">read_data_nmt</span>():</span><br><span class="line">    <span class="string">"""载入 “英语－法语” 数据集。"""</span></span><br><span class="line">    data_dir = d2l.download_extract(<span class="string">'fra-eng'</span>)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(data_dir, <span class="string">'fra.txt'</span>), <span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">return</span> f.read()</span><br><span class="line"></span><br><span class="line">raw_text = read_data_nmt()</span><br><span class="line"><span class="built_in">print</span>(raw_text[:<span class="number">75</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">Go.Va !</span><br><span class="line">Hi.Salut !</span><br><span class="line">Run!Cours !</span><br><span class="line">Run!Courez !</span><br><span class="line">Who?Qui ?</span><br><span class="line">Wow!Ça alors !</span><br></pre></td></tr></tbody></table></figure><h4><span id="312-几个预处理步骤">3.1.2 几个预处理步骤</span></h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess_nmt</span>(<span class="params">text</span>):</span><br><span class="line">    <span class="string">"""预处理“英语－法语”数据集。"""</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">no_space</span>(<span class="params">char, prev_char</span>):</span><br><span class="line">        <span class="keyword">return</span> char <span class="keyword">in</span> <span class="built_in">set</span>(<span class="string">',.!?'</span>) <span class="keyword">and</span> prev_char != <span class="string">' '</span></span><br><span class="line"></span><br><span class="line">    text = text.replace(<span class="string">'\u202f'</span>, <span class="string">' '</span>).replace(<span class="string">'\xa0'</span>, <span class="string">' '</span>).lower()</span><br><span class="line">    out = [</span><br><span class="line">        <span class="string">' '</span> + char <span class="keyword">if</span> i &gt; <span class="number">0</span> <span class="keyword">and</span> no_space(char, text[i - <span class="number">1</span>]) <span class="keyword">else</span> char</span><br><span class="line">        <span class="keyword">for</span> i, char <span class="keyword">in</span> <span class="built_in">enumerate</span>(text)]</span><br><span class="line">    <span class="keyword">return</span> <span class="string">''</span>.join(out)</span><br><span class="line"></span><br><span class="line">text = preprocess_nmt(raw_text)</span><br><span class="line"><span class="built_in">print</span>(text[:<span class="number">80</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出：</span></span><br><span class="line">go .va !</span><br><span class="line">hi .salut !</span><br><span class="line">run !cours !</span><br><span class="line">run !courez !</span><br><span class="line">who ?qui ?</span><br><span class="line">wow !ça alors !</span><br></pre></td></tr></tbody></table></figure><h4><span id="313-词元化">3.1.3 词元化</span></h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">tokenize_nmt</span>(<span class="params">text, num_examples=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">"""词元化“英语－法语”数据数据集。"""</span></span><br><span class="line">    source, target = [], []</span><br><span class="line">    <span class="keyword">for</span> i, line <span class="keyword">in</span> <span class="built_in">enumerate</span>(text.split(<span class="string">'\n'</span>)):</span><br><span class="line">        <span class="keyword">if</span> num_examples <span class="keyword">and</span> i &gt; num_examples:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        parts = line.split(<span class="string">'\t'</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(parts) == <span class="number">2</span>:</span><br><span class="line">            source.append(parts[<span class="number">0</span>].split(<span class="string">' '</span>))</span><br><span class="line">            target.append(parts[<span class="number">1</span>].split(<span class="string">' '</span>))</span><br><span class="line">    <span class="keyword">return</span> source, target</span><br><span class="line"></span><br><span class="line">source, target = tokenize_nmt(text)</span><br><span class="line">source[:<span class="number">6</span>], target[:<span class="number">6</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">([[<span class="string">'go'</span>, <span class="string">'.'</span>],</span><br><span class="line">  [<span class="string">'hi'</span>, <span class="string">'.'</span>],</span><br><span class="line">  [<span class="string">'run'</span>, <span class="string">'!'</span>],</span><br><span class="line">  [<span class="string">'run'</span>, <span class="string">'!'</span>],</span><br><span class="line">  [<span class="string">'who'</span>, <span class="string">'?'</span>],</span><br><span class="line">  [<span class="string">'wow'</span>, <span class="string">'!'</span>]],</span><br><span class="line"> [[<span class="string">'va'</span>, <span class="string">'!'</span>],</span><br><span class="line">  [<span class="string">'salut'</span>, <span class="string">'!'</span>],</span><br><span class="line">  [<span class="string">'cours'</span>, <span class="string">'!'</span>],</span><br><span class="line">  [<span class="string">'courez'</span>, <span class="string">'!'</span>],</span><br><span class="line">  [<span class="string">'qui'</span>, <span class="string">'?'</span>],</span><br><span class="line">  [<span class="string">'ça'</span>, <span class="string">'alors'</span>, <span class="string">'!'</span>]])</span><br></pre></td></tr></tbody></table></figure><h4><span id="314-利用直方图查看效果">3.1.4 利用直方图查看效果</span></h4><p>绘制每个文本序列所包含的标记数量的直方图</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">d2l.set_figsize()</span><br><span class="line">_, _, patches = d2l.plt.hist([[<span class="built_in">len</span>(l) <span class="keyword">for</span> l <span class="keyword">in</span> source], [<span class="built_in">len</span>(l) <span class="keyword">for</span> l <span class="keyword">in</span> target]],</span><br><span class="line">                             label=[<span class="string">'source'</span>, <span class="string">'target'</span>])</span><br><span class="line"><span class="keyword">for</span> patch <span class="keyword">in</span> patches[<span class="number">1</span>].patches:</span><br><span class="line">    patch.set_hatch(<span class="string">'/'</span>)</span><br><span class="line">d2l.plt.legend(loc=<span class="string">'upper right'</span>);</span><br></pre></td></tr></tbody></table></figure><p><img src="http://xiaomanzhan.com.cn/content/image-20220504132837149.png" alt="image-20220504132837149"></p><h4><span id="315-构建词汇表">3.1.5 构建词汇表</span></h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">src_vocab = d2l.Vocab(source, min_freq=<span class="number">2</span>,</span><br><span class="line">                      reserved_tokens=[<span class="string">'&lt;pad&gt;'</span>, <span class="string">'&lt;bos&gt;'</span>, <span class="string">'&lt;eos&gt;'</span>])</span><br><span class="line"><span class="built_in">len</span>(src_vocab)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line"><span class="number">10012</span></span><br></pre></td></tr></tbody></table></figure><p>序列样本都有一个固定的长度 截断或填充文本序列</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">truncate_pad</span>(<span class="params">line, num_steps, padding_token</span>):</span><br><span class="line">    <span class="string">"""截断或填充文本序列。"""</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(line) &gt; num_steps:</span><br><span class="line">        <span class="keyword">return</span> line[:num_steps]</span><br><span class="line">    <span class="keyword">return</span> line + [padding_token] * (num_steps - <span class="built_in">len</span>(line))</span><br><span class="line"></span><br><span class="line">truncate_pad(src_vocab[source[<span class="number">0</span>]], <span class="number">10</span>, src_vocab[<span class="string">'&lt;pad&gt;'</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">[<span class="number">47</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]</span><br></pre></td></tr></tbody></table></figure><h4><span id="316-构建数据集">3.1.6 构建数据集</span></h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">build_array_nmt</span>(<span class="params">lines, vocab, num_steps</span>):</span><br><span class="line">    <span class="string">"""将机器翻译的文本序列转换成小批量。"""</span></span><br><span class="line">    lines = [vocab[l] <span class="keyword">for</span> l <span class="keyword">in</span> lines]</span><br><span class="line">    lines = [l + [vocab[<span class="string">'&lt;eos&gt;'</span>]] <span class="keyword">for</span> l <span class="keyword">in</span> lines]</span><br><span class="line">    array = torch.tensor([</span><br><span class="line">        truncate_pad(l, num_steps, vocab[<span class="string">'&lt;pad&gt;'</span>]) <span class="keyword">for</span> l <span class="keyword">in</span> lines])</span><br><span class="line">    valid_len = (array != vocab[<span class="string">'&lt;pad&gt;'</span>]).<span class="built_in">type</span>(torch.int32).<span class="built_in">sum</span>(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> array, valid_len</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_data_nmt</span>(<span class="params">batch_size, num_steps, num_examples=<span class="number">600</span></span>):</span><br><span class="line">    <span class="string">"""返回翻译数据集的迭代器和词汇表。"""</span></span><br><span class="line">    text = preprocess_nmt(read_data_nmt())</span><br><span class="line">    source, target = tokenize_nmt(text, num_examples)</span><br><span class="line">    src_vocab = d2l.Vocab(source, min_freq=<span class="number">2</span>,</span><br><span class="line">                          reserved_tokens=[<span class="string">'&lt;pad&gt;'</span>, <span class="string">'&lt;bos&gt;'</span>, <span class="string">'&lt;eos&gt;'</span>])</span><br><span class="line">    tgt_vocab = d2l.Vocab(target, min_freq=<span class="number">2</span>,</span><br><span class="line">                          reserved_tokens=[<span class="string">'&lt;pad&gt;'</span>, <span class="string">'&lt;bos&gt;'</span>, <span class="string">'&lt;eos&gt;'</span>])</span><br><span class="line">    src_array, src_valid_len = build_array_nmt(source, src_vocab, num_steps)</span><br><span class="line">    tgt_array, tgt_valid_len = build_array_nmt(target, tgt_vocab, num_steps)</span><br><span class="line">    data_arrays = (src_array, src_valid_len, tgt_array, tgt_valid_len)</span><br><span class="line">    data_iter = d2l.load_array(data_arrays, batch_size)</span><br><span class="line">    <span class="keyword">return</span> data_iter, src_vocab, tgt_vocab</span><br></pre></td></tr></tbody></table></figure><p>读出“英语－法语”数据集中的第一个小批量数据</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">train_iter, src_vocab, tgt_vocab = load_data_nmt(batch_size=<span class="number">2</span>, num_steps=<span class="number">8</span>)</span><br><span class="line"><span class="keyword">for</span> X, X_valid_len, Y, Y_valid_len <span class="keyword">in</span> train_iter:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">'X:'</span>, X.<span class="built_in">type</span>(torch.int32))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">'valid lengths for X:'</span>, X_valid_len)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">'Y:'</span>, Y.<span class="built_in">type</span>(torch.int32))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">'valid lengths for Y:'</span>, Y_valid_len)</span><br><span class="line">    <span class="keyword">break</span></span><br><span class="line">    </span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">X: tensor([[ <span class="number">24</span>, <span class="number">160</span>,   <span class="number">4</span>,   <span class="number">3</span>,   <span class="number">1</span>,   <span class="number">1</span>,   <span class="number">1</span>,   <span class="number">1</span>],</span><br><span class="line">        [ <span class="number">16</span>,  <span class="number">60</span>,   <span class="number">4</span>,   <span class="number">3</span>,   <span class="number">1</span>,   <span class="number">1</span>,   <span class="number">1</span>,   <span class="number">1</span>]], dtype=torch.int32)</span><br><span class="line">valid lengths <span class="keyword">for</span> X: tensor([<span class="number">4</span>, <span class="number">4</span>])</span><br><span class="line">Y: tensor([[<span class="number">13</span>, <span class="number">29</span>,  <span class="number">0</span>,  <span class="number">4</span>,  <span class="number">3</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>],</span><br><span class="line">        [<span class="number">41</span>, <span class="number">53</span>,  <span class="number">4</span>,  <span class="number">3</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>]], dtype=torch.int32)</span><br><span class="line">valid lengths <span class="keyword">for</span> Y: tensor([<span class="number">5</span>, <span class="number">4</span>])</span><br></pre></td></tr></tbody></table></figure><h3><span id="32-编码器-解码器结构">3.2 编码器-解码器结构</span></h3><h4><span id="321-编码器-amp-解码器">3.2.1 编码器 &amp; 解码器</span></h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Encoder</span>(nn.Module):</span><br><span class="line">    <span class="string">"""编码器-解码器结构的基本编码器接口。"""</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>(Encoder, self).__init__(**kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X, *args</span>):</span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br></pre></td></tr></tbody></table></figure><h4><span id="322-解码器">3.2.2 解码器</span></h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Decoder</span>(nn.Module):</span><br><span class="line">    <span class="string">"""编码器-解码器结构的基本解码器接口。"""</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>(Decoder, self).__init__(**kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_state</span>(<span class="params">self, enc_outputs, *args</span>):</span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X, state</span>):</span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br></pre></td></tr></tbody></table></figure><h4><span id="323-合并编码器和解码器">3.2.3 合并编码器和解码器</span></h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">EncoderDecoder</span>(nn.Module):</span><br><span class="line">    <span class="string">"""编码器-解码器结构的基类。"""</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, encoder, decoder, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>(EncoderDecoder, self).__init__(**kwargs)</span><br><span class="line">        self.encoder = encoder</span><br><span class="line">        self.decoder = decoder</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, enc_X, dec_X, *args</span>):</span><br><span class="line">        enc_outputs = self.encoder(enc_X, *args)</span><br><span class="line">        dec_state = self.decoder.init_state(enc_outputs, *args)</span><br><span class="line">        <span class="keyword">return</span> self.decoder(dec_X, dec_state)</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 循环神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 循环神经网络 </tag>
            
            <tag> 编码器-解码器 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode479</title>
      <link href="/2022/04/16/leetcode/mei-ri-yi-ti/leetcode479/"/>
      <url>/2022/04/16/leetcode/mei-ri-yi-ti/leetcode479/</url>
      
        <content type="html"><![CDATA[<h1><span id="479-最大回文数乘积">479. 最大回文数乘积</span></h1><blockquote><p><a href="https://leetcode-cn.com/problems/largest-palindrome-product/">479. 最大回文数乘积</a></p></blockquote><h2><span id="题目">题目</span></h2><p>给定一个整数 n ，返回 可表示为两个 n 位整数乘积的最大回文整数 。因为答案可能非常大，所以返回它对 1337 取余 。</p><h2><span id="示例">示例：</span></h2><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">示例 1:</span><br><span class="line">输入：n = 2</span><br><span class="line">输出：987</span><br><span class="line">解释：99 x 91 = 9009, 9009 % 1337 = 987</span><br><span class="line"></span><br><span class="line">示例 2:</span><br><span class="line">输入： n = 1</span><br><span class="line">输出： 9</span><br></pre></td></tr></tbody></table></figure><h2><span id="解题思路">解题思路</span></h2><p>反向思考，因为两个整数乘积的结果是回文数，而两个整数乘积的结果必定是 $2n$ 位数，所以回文数必定是偶数，可以考虑构建回文数的左半部分，右半部分由左半部分构建完成。具体思路：</p><ol><li>遍历实现左半部分的构建；</li><li>根据左半部分实现整个回文数的构建；</li><li>寻找位数为 $n$ 的整数 $x$ 能完成，回文数除以 $x$ 无余数即可判定回文数为最大回文数；</li><li>回文数除以1337，取余数返回</li></ol><h3><span id="题解">题解：</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">largestPalindrome</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="keyword">if</span> n == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">9</span></span><br><span class="line">        up = <span class="number">10</span> ** n - <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> l <span class="keyword">in</span> <span class="built_in">range</span>(up, up // <span class="number">10</span>, -<span class="number">1</span>):</span><br><span class="line">            p, x = l, l</span><br><span class="line">            <span class="keyword">while</span> x:</span><br><span class="line">                p = p * <span class="number">10</span> + x % <span class="number">10</span></span><br><span class="line">                x //= <span class="number">10</span></span><br><span class="line">            x = up</span><br><span class="line">            <span class="keyword">while</span> x * x &gt;= p:</span><br><span class="line">                <span class="keyword">if</span> p % x == <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">return</span> p % <span class="number">1337</span></span><br><span class="line">                x -= <span class="number">1</span></span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> 难度-困难 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeetCode </tag>
            
            <tag> 找规律 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode385</title>
      <link href="/2022/04/15/leetcode/mei-ri-yi-ti/leetcode385/"/>
      <url>/2022/04/15/leetcode/mei-ri-yi-ti/leetcode385/</url>
      
        <content type="html"><![CDATA[<h1><span id="385-迷你语法分析器">385. 迷你语法分析器</span></h1><blockquote><p><a href="https://leetcode-cn.com/problems/mini-parser/">385. 迷你语法分析器</a></p></blockquote><h2><span id="题目">题目</span></h2><p>给定一个字符串 s 表示一个整数嵌套列表，实现一个解析它的语法分析器并返回解析的结果 NestedInteger。列表中的每个元素只可能是整数或整数嵌套列表</p><h2><span id="示例">示例</span></h2><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">示例 1：</span><br><span class="line">输入：s = "324",</span><br><span class="line">输出：324</span><br><span class="line">解释：你应该返回一个 NestedInteger 对象，其中只包含整数值 324。</span><br><span class="line"></span><br><span class="line">示例 2：</span><br><span class="line">输入：s = "[123,[456,[789]]]",</span><br><span class="line">输出：[123,[456,[789]]]</span><br><span class="line">解释：返回一个 NestedInteger 对象包含一个有两个元素的嵌套列表：</span><br><span class="line"></span><br><span class="line">1. 一个 integer 包含值 123</span><br><span class="line">2. 一个包含两个元素的嵌套列表：</span><br><span class="line">   i.  一个 integer 包含值 456</span><br><span class="line">   ii. 一个包含一个元素的嵌套列表</span><br><span class="line">        a. 一个 integer 包含值 789</span><br></pre></td></tr></tbody></table></figure><h2><span id="解题思路一">解题思路一</span></h2><p>根据题意，一个 $NestedInteger$ 实例只能包含下列两部分之一：1）一个整数；2）一个列表，列表中的每个元素都是一个 $NestedInteger$ 实例。据此，$NestedInteger$ 是通过递归定义的，因此也可以用递归的方式来解析。</p><p>使用<strong>深度优先搜索</strong>的方法，从左至右遍历 $s$，</p><ul><li>如果第一位是 <code>'['</code> 字符，则表示待解析的是一个列表，我们仍调用<code>DFS</code>解析函数来解析列表的元素，调用结束后如果遇到的是 <code>','</code> 字符，表示列表仍有其他元素，需要继续调用。如果是 <code>']'</code> 字符，表示这个列表已经解析完毕，可以返回<code>NestedInteger</code> 实例。</li><li>否则，则表示待解析的 <code>NestedInteger</code> 只包含一个整数。我们可以从左至右解析这个整数，并注意是否是负数，直到遍历完或者遇到非数字字符（<code>']'</code> 或 <code>','</code>），并返回 <code>NestedInteger</code> 实例。</li></ul><h3><span id="题解">题解</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">deserialize</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; NestedInteger:</span><br><span class="line">        index = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">dfs</span>() -&gt; NestedInteger:</span><br><span class="line">            <span class="keyword">nonlocal</span> index</span><br><span class="line">            <span class="keyword">if</span> s[index] == <span class="string">'['</span>:</span><br><span class="line">                index += <span class="number">1</span></span><br><span class="line">                ni = NestedInteger()</span><br><span class="line">                <span class="keyword">while</span> s[index] != <span class="string">']'</span>:</span><br><span class="line">                    ni.add(dfs())</span><br><span class="line">                    <span class="keyword">if</span> s[index] == <span class="string">','</span>:</span><br><span class="line">                        index += <span class="number">1</span></span><br><span class="line">                index += <span class="number">1</span></span><br><span class="line">                <span class="keyword">return</span> ni</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                negative = <span class="literal">False</span></span><br><span class="line">                <span class="keyword">if</span> s[index] == <span class="string">'-'</span>:</span><br><span class="line">                    negative = <span class="literal">True</span></span><br><span class="line">                    index += <span class="number">1</span></span><br><span class="line">                num = <span class="number">0</span></span><br><span class="line">                <span class="keyword">while</span> index &lt; <span class="built_in">len</span>(s) <span class="keyword">and</span> s[index].isdigit():</span><br><span class="line">                    num *= <span class="number">10</span></span><br><span class="line">                    num += <span class="built_in">int</span>(s[index])</span><br><span class="line">                    index += <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> negative:</span><br><span class="line">                    num = -num</span><br><span class="line">                <span class="keyword">return</span> NestedInteger(num)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> dfs()</span><br></pre></td></tr></tbody></table></figure><h2><span id="解题思路二">解题思路二</span></h2><p>用<strong>栈</strong>来模拟递归的思路。从左至右遍历 <code>s</code>，如果遇到 <code>'['</code>，则表示是一个新的<code>NestedInteger</code> 实例，需要将其入栈。如果遇到 <code>']'</code> 或 <code>','</code>，则表示是一个数字或者 <code>NestedInteger</code> 实例的结束，需要将其添加入栈顶的 <code>NestedInteger</code> 实例。最后需返回栈顶的实例。</p><h2><span id="题解">题解</span></h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">deserialize</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; NestedInteger:</span><br><span class="line">        <span class="keyword">if</span> s[<span class="number">0</span>] != <span class="string">'['</span>:</span><br><span class="line">            <span class="keyword">return</span> NestedInteger(<span class="built_in">int</span>(s))</span><br><span class="line">        stack, num, negative = [], <span class="number">0</span>, <span class="literal">False</span></span><br><span class="line">        <span class="keyword">for</span> i, c <span class="keyword">in</span> <span class="built_in">enumerate</span>(s):</span><br><span class="line">            <span class="keyword">if</span> c == <span class="string">'-'</span>:</span><br><span class="line">                negative = <span class="literal">True</span></span><br><span class="line">            <span class="keyword">elif</span> c.isdigit():</span><br><span class="line">                num = num * <span class="number">10</span> + <span class="built_in">int</span>(c)</span><br><span class="line">            <span class="keyword">elif</span> c == <span class="string">'['</span>:</span><br><span class="line">                stack.append(NestedInteger())</span><br><span class="line">            <span class="keyword">elif</span> c <span class="keyword">in</span> <span class="string">',]'</span>:</span><br><span class="line">                <span class="keyword">if</span> s[i-<span class="number">1</span>].isdigit():</span><br><span class="line">                    <span class="keyword">if</span> negative:</span><br><span class="line">                        num = -num</span><br><span class="line">                    stack[-<span class="number">1</span>].add(NestedInteger(num))</span><br><span class="line">                num, negative = <span class="number">0</span>, <span class="literal">False</span></span><br><span class="line">                <span class="keyword">if</span> c == <span class="string">']'</span> <span class="keyword">and</span> <span class="built_in">len</span>(stack) &gt; <span class="number">1</span>:</span><br><span class="line">                    stack[-<span class="number">2</span>].add(stack.pop())</span><br><span class="line">        <span class="keyword">return</span> stack.pop()</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> 难度-中等 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeetCode </tag>
            
            <tag> 深度优先搜索 </tag>
            
            <tag> 栈 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>双向循环神经网络</title>
      <link href="/2022/04/15/machine-learning/xun-huan-shen-jing-wang-luo/8.shuang-xiang-xun-huan-shen-jing-wang-luo/"/>
      <url>/2022/04/15/machine-learning/xun-huan-shen-jing-wang-luo/8.shuang-xiang-xun-huan-shen-jing-wang-luo/</url>
      
        <content type="html"><![CDATA[<h1><span id="双向循环神经网络">双向循环神经网络</span></h1><p>如果需要考虑未来的信息</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">I am ____</span><br><span class="line">I am ____ very hungry,</span><br><span class="line">I am ____ very hungry, I could eat half a pig.</span><br><span class="line"></span><br><span class="line">可以填写：</span><br><span class="line">happy</span><br><span class="line">not</span><br><span class="line">very</span><br></pre></td></tr></tbody></table></figure><p>需求：能够根据过去和未来的上下文，填写不一样的词</p><p>当前RNN存在问题：只能看到过去的信息，但是我们在填空的时候，我们也可以看到未来。</p><h2><span id="1-双向rnn">1. 双向RNN</span></h2><p>包含三点：</p><ul><li>一个向前的RNN隐层；</li><li>一个向后的RNN隐层；</li><li>合并两个隐状态得到输出。</li></ul><p><img src="http://xiaomanzhan.com.cn/content/image-20220415212538546.png" alt="image-20220415212538546"></p><script type="math/tex; mode=display">\vec H_t=\phi(X_tW_{xh}^{(f)}+\vec H_{t-1}W_{hh}^{(f)}+b_h^{(f)}),\\\vec H_t'=\phi(X_tW_{xh}^{(b)}+\vec H_{t-1}'W_{hh}^{(b)}+b_h^{(b)}),\\H_t=[\vec H_t, \vec H_t']\\O_t = H_tW_{hq}+b_q</script><p>双向循环神经网络通过反向更新的隐藏层来利用方向时间信息，通常用来对序列抽取特征、填空，而不是预测未来。</p><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 循环神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 循环神经网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度循环神经网络</title>
      <link href="/2022/04/15/machine-learning/xun-huan-shen-jing-wang-luo/7.shen-du-xun-huan-shen-jing-wang-luo/"/>
      <url>/2022/04/15/machine-learning/xun-huan-shen-jing-wang-luo/7.shen-du-xun-huan-shen-jing-wang-luo/</url>
      
        <content type="html"><![CDATA[<h1><span id="深度循环神经网络">深度循环神经网络</span></h1><blockquote><p><strong>注意：</strong>当输入时间序列数据过长时，神经网络容易过拟合（overfiting），深度指的是神经网络的层数</p></blockquote><h2><span id="1-更深的网络结构">1. 更深的网络结构</span></h2><p><img src="http://xiaomanzhan.com.cn/content/image-20220415203516274.png" alt="image-20220415203516274"></p><p>公式上的变化：</p><script type="math/tex; mode=display">H_t^1=f_1(H_{t-1}^1, X_t)\\...\\H_t^j=f_j(H_{t-1}^j,H_t^{j-1})\\...\\O_t=g(H_t^L)</script><p>深度循环神经网络使用多个隐藏层来获得更多的非线性性</p><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 循环神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 循环神经网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>长短期记忆网络（LSTM）</title>
      <link href="/2022/04/15/machine-learning/xun-huan-shen-jing-wang-luo/6.lstm/"/>
      <url>/2022/04/15/machine-learning/xun-huan-shen-jing-wang-luo/6.lstm/</url>
      
        <content type="html"><![CDATA[<h1><span id="长短期记忆网络lstm">长短期记忆网络（LSTM）</span></h1><h2><span id="1-长短期记忆网络">1. 长短期记忆网络</span></h2><p>提出了门机制：</p><ul><li>忘记门：将值朝0减少；</li><li>输入门：决定不是忽略掉输入数据；</li><li>输出门：决定是不是使用隐状态</li></ul><p><strong>注意：</strong>在一个序列中，可能只是某些关键字或者时间序列的某个节点比较重要，其他的并不是很重要，所以才需要门机制</p><h2><span id="2-门">2. 门</span></h2><h3><span id="21-忘记门-输入门amp输出门">2.1 忘记门、输入门&amp;输出门</span></h3><script type="math/tex; mode=display">I_t=\sigma(X_tW_{xi}+H_{t-1}W_{hi}+b_i)\\F_t=\sigma(X_tW_{xf}+H_{t-1}W_{hf}+b_f)\\O_t=\sigma(X_tW_{xo}+H_{t-1}W_{ho}+b_o)</script><ul><li>忘记门：将值朝0减少；</li><li>输入门：决定不是忽略掉输入数据；</li><li>输出门：决定是不是使用隐藏状态</li></ul><p><img src="http://xiaomanzhan.com.cn/content/image-20220415195858632.png" alt="image-20220415195858632"></p><h3><span id="22-候选记忆单元">2.2 候选记忆单元</span></h3><script type="math/tex; mode=display">\tilde{C_t}=tanh(X_tW_{xc}+H_{t-1}W_{hc}+b_c)</script><p><img src="http://xiaomanzhan.com.cn/content/image-20220415200147652.png" alt="image-20220415200147652"></p><h3><span id="23-记忆单元">2.3 记忆单元</span></h3><p>由上一个记忆单元、遗忘门、输入门、候选记忆单元组成。</p><script type="math/tex; mode=display">C_t=F_t\odot C_{t-1}+I_t\odot\tilde C_t</script><p><img src="http://xiaomanzhan.com.cn/content/image-20220415200326469.png" alt="image-20220415200326469"></p><h3><span id="24-隐藏状态">2.4 隐藏状态</span></h3><p>将隐藏状态放置在 (-1, +1)之间，可以有效防止梯度爆炸，能够使隐藏状态存储的东西更多。由记忆单元和输出门组成</p><script type="math/tex; mode=display">H_t=O_t\odot \tanh(C_t)</script><p><img src="http://xiaomanzhan.com.cn/content/image-20220415200617678.png" alt="image-20220415200617678"></p><h2><span id="3-总结">3. 总结</span></h2><script type="math/tex; mode=display">I_t=\sigma(X_tW_{xi}+H_{t-1}W_{hi}+b_i)\\F_t=\sigma(X_tW_{xf}+H_{t-1}W_{hf}+b_f)\\O_t=\sigma(X_tW_{xo}+H_{t-1}W_{ho}+b_o)\\\tilde{C_t}=tanh(X_tW_{xc}+H_{t-1}W_{hc}+b_c)\\C_t=F_t\odot C_{t-1}+I_t\odot\tilde C_t\\H_t=O_t\odot \tanh(C_t)</script><p>隐藏状态可以更新为输出数据。</p><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 循环神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 循环神经网络 </tag>
            
            <tag> LSTM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GRU</title>
      <link href="/2022/04/15/machine-learning/xun-huan-shen-jing-wang-luo/5.gru/"/>
      <url>/2022/04/15/machine-learning/xun-huan-shen-jing-wang-luo/5.gru/</url>
      
        <content type="html"><![CDATA[<h1><span id="门控循环单元gru">门控循环单元（GRU）</span></h1><h2><span id="1-关注一个序列">1. 关注一个序列</span></h2><p>每个观测的值都是同等重要的，在GRU模型中，设计主要需要两个机制：</p><ul><li>能够对观测值关注的机制（更新门）</li><li>能够遗忘的机制（重置门）</li></ul><p><strong>注意：</strong>在一个序列中，可能只是某些关键字或者时间序列的某个节点比较重要，其他的并不是很重要，所以才需要门机制</p><h2><span id="2-门">2. 门</span></h2><h3><span id="21-重置门和更新门">2.1 重置门和更新门</span></h3><p><strong>重置门</strong>：用户更新候选隐藏状态</p><script type="math/tex; mode=display">R_t=\sigma(X_tW_{xr}+H_{t-1}W_{hr}+b_r)</script><p><strong>更新门</strong>：用于更新隐藏状态</p><script type="math/tex; mode=display">Z_t=\sigma(X_tW_{xz}+H_{t-1}W_{hz}+b_z)</script><p><img src="http://xiaomanzhan.com.cn/content/image-20220415164731821.png" alt="image-20220415164731821"></p><h3><span id="22-候选隐藏状态">2.2 候选隐藏状态</span></h3><script type="math/tex; mode=display">\tilde{H_t}=tanh(X_tW_{xh}+(R_t\odot H_{t-1})W_{hh}+b_h)</script><p><img src="http://xiaomanzhan.com.cn/content/image-20220415170714316.png" alt="image-20220415170714316"></p><p><strong>注意：</strong>$(R_t\odot H_{t-1})$ 按元素做乘法，$R_t$ 用来更新上一时刻 $H_{t-1}$ 的信息控制。</p><h3><span id="23-隐状态">2.3 隐状态</span></h3><script type="math/tex; mode=display">H_t=Z_t\odot H_{t-1}+(1-Z_t)\odot\tilde{H_t}</script><p><img src="http://xiaomanzhan.com.cn/content/image-20220415171045301.png" alt="image-20220415171045301"></p><p><strong>注意：</strong>当 $Z_t$ 等于0时，等价于 RNN 序列，不使用之前的信息状态，只使用当前的信息状态</p><h2><span id="总结">总结</span></h2><script type="math/tex; mode=display">R_t=\sigma(X_tW_{xr}+H_{t-1}W_{hr}+b_r)\\Z_t=\sigma(X_tW_{xz}+H_{t-1}W_{hz}+b_z)\\\tilde{H_t}=tanh(X_tW_{xh}+(R_t\odot H_{t-1})W_{hh}+b_h)\\H_t=Z_t\odot H_{t-1}+(1-Z_t)\odot\tilde{H_t}</script><p><img src="http://xiaomanzhan.com.cn/content/image-20220415171045301.png" alt="image-20220415171045301"></p><p>隐藏状态可以更新为输出数据。</p><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 循环神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 循环神经网络 </tag>
            
            <tag> GRU </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode1672</title>
      <link href="/2022/04/14/leetcode/mei-ri-yi-ti/leetcode1672/"/>
      <url>/2022/04/14/leetcode/mei-ri-yi-ti/leetcode1672/</url>
      
        <content type="html"><![CDATA[<h1><span id="1672-最富有客户的资产总量">1672. 最富有客户的资产总量</span></h1><blockquote><p><a href="https://leetcode-cn.com/problems/richest-customer-wealth/">1672. 最富有客户的资产总量</a></p></blockquote><h2><span id="题目">题目</span></h2><p>给你一个 <code>m x n</code> 的整数网格 <code>accounts</code>，其中 <code>accounts[i][j]</code>是第 <code>i</code> 位客户在第 <code>j</code> 家银行托管的资产数量。返回最富有客户所拥有的 资产总量 。</p><p>客户的 资产总量 就是他们在各家银行托管的资产数量之和。最富有客户就是资产总量 最大的客户。</p><h2><span id="示例">示例</span></h2><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">输入：accounts = [[1,2,3],[3,2,1]]</span><br><span class="line">输出：6</span><br><span class="line">解释：</span><br><span class="line">第 1 位客户的资产总量 = 1 + 2 + 3 = 6</span><br><span class="line">第 2 位客户的资产总量 = 3 + 2 + 1 = 6</span><br><span class="line">两位客户都是最富有的，资产总量都是 6 ，所以返回 6 。</span><br><span class="line"></span><br><span class="line">输入：accounts = [[1,5],[7,3],[3,5]]</span><br><span class="line">输出：10</span><br><span class="line">解释：</span><br><span class="line">第 1 位客户的资产总量 = 6</span><br><span class="line">第 2 位客户的资产总量 = 10 </span><br><span class="line">第 3 位客户的资产总量 = 8</span><br><span class="line">第 2 位客户是最富有的，资产总量是 10</span><br></pre></td></tr></tbody></table></figure><h2><span id="解题思路">解题思路</span></h2><p>使用数组求和的方式，找到每行和的最大值</p><h3><span id="题解">题解</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">maximumWealth</span>(<span class="params">self, accounts: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        res = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> account <span class="keyword">in</span> accounts:</span><br><span class="line">            res = <span class="built_in">max</span>(<span class="built_in">sum</span>(account), res)</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> 难度-中等 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeetCode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>循环神经网络</title>
      <link href="/2022/04/14/machine-learning/xun-huan-shen-jing-wang-luo/4.xun-huan-shen-jing-wang-luo/"/>
      <url>/2022/04/14/machine-learning/xun-huan-shen-jing-wang-luo/4.xun-huan-shen-jing-wang-luo/</url>
      
        <content type="html"><![CDATA[<h1><span id="循环神经网络">循环神经网络</span></h1><h2><span id="1-潜变量自回归模型">1. 潜变量自回归模型</span></h2><p>使用潜变量 $h_t$ 总结过去的信息</p><p><img src="http://xiaomanzhan.com.cn/content/image-20220414215750235.png" alt="image-20220414215750235"></p><h2><span id="2-循环神经网络">2. 循环神经网络</span></h2><p><img src="http://xiaomanzhan.com.cn/content/image-20220414220034988.png" alt="image-20220414220034988"></p><p>更新隐藏状态：$h_t=\phi(W_{hh}h_{t-1} + W_{hx}x_{t-1}+b_h)$，注意与 MLP 的区别，$\phi$ 是激活函数</p><p>输出：$o_t=W_{ho}h_t+b_o$</p><h2><span id="3-衡量模型好坏程度">3. 衡量模型好坏程度</span></h2><p>困惑度 (perplexity)：衡量一个语言模型的好坏可以用平均交叉熵</p><script type="math/tex; mode=display">\pi=\frac{1}{n}\sum_{i=1}^n-log\ p(x_t|x_{t-1},...)</script><p>$p$ 是语言模型的概率，$x_t$ 是真实词</p><p>NLP使用困惑度 $exp(\pi)$ 来衡量，是平均每次可能选项：1表示完美，无穷大是最差情况</p><h2><span id="4-梯度剪裁">4. 梯度剪裁</span></h2><p>原因：迭代中计算 $T$ 时间步上的梯度，在反向传播过程中产生长度为 $O(T)$ 的矩阵乘法链，导致数值不稳定。</p><p>梯度裁剪能有效预防梯度爆炸，如果梯度长度超过 $\theta$ ，那么拖影回长度 $\theta$ </p><script type="math/tex; mode=display">g\leftarrow min(1,\frac{\theta}{||g||})g</script><h2><span id="5-更多的应用-rnns">5. 更多的应用 RNNs</span></h2><p><img src="http://xiaomanzhan.com.cn/content/image-20220414222418240.png" alt="image-20220414222418240"></p><h2><span id="6-代码实现">6. 代码实现</span></h2><h3><span id="61-加载数据">6.1 加载数据</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 循环神经网络的简洁实现</span></span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> multiprocessing</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.utils <span class="keyword">import</span> data</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line">d2l.use_svg_display() <span class="comment"># 使用svg显示图片，图像清晰度高</span></span><br><span class="line">multiprocessing.freeze_support() <span class="comment"># 终止进程</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据</span></span><br><span class="line">batch_size, num_steps = <span class="number">32</span>, <span class="number">35</span></span><br><span class="line">train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)</span><br></pre></td></tr></tbody></table></figure><h3><span id="62-定义模型">6.2 定义模型</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义模型</span></span><br><span class="line">num_hiddens = <span class="number">256</span></span><br><span class="line">rnn_layer = nn.RNN(<span class="built_in">len</span>(vocab), num_hiddens)</span><br></pre></td></tr></tbody></table></figure><p>通过一个隐藏状态和一个输入，我们就可以用更新后的隐藏状态计算输出</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用张量初始化隐藏状态</span></span><br><span class="line">state = torch.zeros((<span class="number">1</span>, batch_size, num_hiddens))</span><br><span class="line"><span class="comment"># state.shape: torch.Size([1, 32, 256])</span></span><br><span class="line"><span class="comment"># 通过一个隐藏状态和一个输入，我们就可以用更新后的隐藏状态计算输出</span></span><br><span class="line">X = torch.rand(size=(num_steps, batch_size, <span class="built_in">len</span>(vocab)))</span><br><span class="line">Y, state_new = rnn_layer(X, state)</span><br><span class="line">Y.shape, state_new.shape</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出：</span></span><br><span class="line">(torch.Size([<span class="number">35</span>, <span class="number">32</span>, <span class="number">256</span>]), torch.Size([<span class="number">1</span>, <span class="number">32</span>, <span class="number">256</span>]))</span><br></pre></td></tr></tbody></table></figure><h3><span id="63-定义一个完整的网络">6.3 定义一个完整的网络</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义一个完整的循环神经网络模型，定义一个RNNModel类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RNNModel</span>(nn.Module):</span><br><span class="line">    <span class="string">"""循环神经网络模型。"""</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, rnn_layer, vocab_size, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>(RNNModel, self).__init__(**kwargs)</span><br><span class="line">        self.rnn = rnn_layer</span><br><span class="line">        self.vocab_size = vocab_size</span><br><span class="line">        self.num_hiddens = self.rnn.hidden_size</span><br><span class="line">        <span class="comment"># 需要构建自己的输出层，先判断是否使用双向</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.rnn.bidirectional:</span><br><span class="line">            self.num_directions = <span class="number">1</span></span><br><span class="line">            self.linear = nn.Linear(self.num_hiddens, self.vocab_size)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.num_directions = <span class="number">2</span></span><br><span class="line">            self.linear = nn.Linear(self.num_hiddens * <span class="number">2</span>, self.vocab_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs, state</span>):</span><br><span class="line">        X = F.one_hot(inputs.T.long(), self.vocab_size)</span><br><span class="line">        X = X.to(torch.float32)</span><br><span class="line">        Y, state = self.rnn(X, state)</span><br><span class="line">        output = self.linear(Y.reshape((-<span class="number">1</span>, Y.shape[-<span class="number">1</span>])))</span><br><span class="line">        <span class="keyword">return</span> output, state</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">begin_state</span>(<span class="params">self, device, batch_size=<span class="number">1</span></span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(self.rnn, nn.LSTM):</span><br><span class="line">            <span class="keyword">return</span> torch.zeros((self.num_directions * self.rnn.num_layers,</span><br><span class="line">                                batch_size, self.num_hiddens), device=device)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> (torch.zeros((self.num_directions * self.rnn.num_layers,</span><br><span class="line">                                 batch_size, self.num_hiddens),</span><br><span class="line">                                device=device),</span><br><span class="line">                    torch.zeros((self.num_directions * self.rnn.num_layers,</span><br><span class="line">                                 batch_size, self.num_hiddens),</span><br><span class="line">                                device=device))</span><br><span class="line">        </span><br><span class="line"><span class="comment"># 基于一个具有随机权重的模型进行预测</span></span><br><span class="line">device = d2l.try_gpu()</span><br><span class="line">net = RNNModel(rnn_layer, vocab_size=<span class="built_in">len</span>(vocab))</span><br><span class="line">net = net.to(device)</span><br><span class="line">d2l.predict_ch8(<span class="string">'time traveller'</span>, <span class="number">10</span>, net, vocab, device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line"><span class="string">'time travellerolllllllll'</span></span><br></pre></td></tr></tbody></table></figure><h3><span id="64-训练模型">6.4 训练模型</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">num_epochs, lr = <span class="number">500</span>, <span class="number">1</span></span><br><span class="line">train_ch8(net, train_iter, vocab, lr, num_epochs, d2l.try_gpu())</span><br></pre></td></tr></tbody></table></figure><h2><span id="总结">总结</span></h2><ol><li>循环神经网络的输出取决于当下的输入和前一时间的隐变量；</li><li>应用到语言模型中时，循环神经网络根据当前词下一次时刻词；</li><li>通常使用困惑度来衡量语言模型的好坏。</li></ol><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 循环神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 循环神经网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>语言模型</title>
      <link href="/2022/04/14/machine-learning/xun-huan-shen-jing-wang-luo/3.yu-yan-mo-xing/"/>
      <url>/2022/04/14/machine-learning/xun-huan-shen-jing-wang-luo/3.yu-yan-mo-xing/</url>
      
        <content type="html"><![CDATA[<h1><span id="语言模型">语言模型</span></h1><h2><span id="1-定义">1. 定义</span></h2><p>给定文本序列 $x1,…,x_t$，语言模型的目标是估计联合概率 $p(x_1,…,x_T)$</p><p>它应该包括：</p><ul><li>做预训练模型（eg BERT，GPT-3）；</li><li>生成文本，给定前面几个词，不断的使用 $x_t\sim p(x_t|x_1,…,x_{t-1})$ 来生成后续文本；</li><li>判断多个序列中哪个更常见。</li></ul><h2><span id="2-使用计数来建模">2. 使用计数来建模</span></h2><p>假设序列长度为2，我们预测 $p(x,x’)=p(x)p(x’|x)=\frac{n(x)}{n}\frac{n(x,x’)}{n(x)}$，这里 $n$ 是总词数，$n(x), n(x,x’)$ 是单个单词和连续单词对的出现次数</p><p>很容易拓展到长为3的情况</p><p>$p(x,x’,x’’)=p(x)p(x’|x)p(x’’|x,x’)=\frac{n(x)}{n}\frac{n(x,x’)}{n(x)}\frac{n(x,x’,x’’)}{n(x,x’)}$ </p><h2><span id="3-n元语法">3. N元语法</span></h2><p>当序列很长时，因为文本量不够大，很可能 $n(x_1,…,x_T)\le1$，我们使用马尔科夫假设能够缓解这个问题：</p><ul><li>一元语法：$p(x_1,x_2,x_3,x_4)=p(x_1)p(x_2)p(x_3)p(x_4)=\frac{n(x_1)}{n}\frac{n(x_2)}{n}\frac{n(x_3)}{n}\frac{n(x_4)}{n}$</li><li>二元语法：$p(x_1,x_2,x_3,x_4)=p(x_1)p(x_2|x_1)p(x_3|x_2)p(x_4|x_3)=\frac{n(x_1)}{n}\frac{n(x_1,x_2)}{n(x_1)}\frac{n(x_2,x_3)}{n(x_2)}\frac{n(x_3,x_4)}{n(x_3)}$</li><li>三元语法：$p(x_1,x_2,x_3,x_4)=p(x_1)p(x_2|x_1)p(x_3|x_1,x_2)p(x_4|x_2,x_3)$</li></ul><p>根据此特点能够处理很长的序列</p><h2><span id="4-代码实现">4. 代码实现</span></h2><h3><span id="41-构建词频图">4.1 构建词频图</span></h3><p>将每个单词进行编码，构建词频图</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 语言模型和数据集</span></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line">tokens = d2l.tokenize(d2l.read_time_machine())</span><br><span class="line">corpus = [token <span class="keyword">for</span> line <span class="keyword">in</span> tokens <span class="keyword">for</span> token <span class="keyword">in</span> line]</span><br><span class="line">vocab = d2l.Vocab(corpus)</span><br><span class="line">vocab.token_freqs[:<span class="number">10</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">[(<span class="string">'the'</span>, <span class="number">2261</span>),</span><br><span class="line"> (<span class="string">'i'</span>, <span class="number">1267</span>),</span><br><span class="line"> (<span class="string">'and'</span>, <span class="number">1245</span>),</span><br><span class="line"> (<span class="string">'of'</span>, <span class="number">1155</span>),</span><br><span class="line"> (<span class="string">'a'</span>, <span class="number">816</span>),</span><br><span class="line"> (<span class="string">'to'</span>, <span class="number">695</span>),</span><br><span class="line"> (<span class="string">'was'</span>, <span class="number">552</span>),</span><br><span class="line"> (<span class="string">'in'</span>, <span class="number">541</span>),</span><br><span class="line"> (<span class="string">'that'</span>, <span class="number">443</span>),</span><br><span class="line"> (<span class="string">'my'</span>, <span class="number">440</span>)]</span><br></pre></td></tr></tbody></table></figure><p>绘制词频图</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 最流行的词被称为停用词，画出的词频图</span></span><br><span class="line">freqs = [freq <span class="keyword">for</span> token, freq <span class="keyword">in</span> vocab.token_freqs]</span><br><span class="line">d2l.plot(freqs, xlabel=<span class="string">'token: x'</span>, ylabel=<span class="string">'frequency: n(x)'</span>, xscale=<span class="string">'log'</span>,</span><br><span class="line">         yscale=<span class="string">'log'</span>)</span><br></pre></td></tr></tbody></table></figure><p><img src="http://xiaomanzhan.com.cn/content/image-20220503223429507.png" alt="image-20220503223429507"></p><p>其他的词元组合，比如二元语法、三元语法等等，查看词频</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 二元语法</span></span><br><span class="line">bigram_tokens = [pair <span class="keyword">for</span> pair <span class="keyword">in</span> <span class="built_in">zip</span>(corpus[:-<span class="number">1</span>], corpus[<span class="number">1</span>:])]</span><br><span class="line">bigram_vocab = d2l.Vocab(bigram_tokens)</span><br><span class="line">bigram_vocab.token_freqs[:<span class="number">10</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">[((<span class="string">'of'</span>, <span class="string">'the'</span>), <span class="number">309</span>),</span><br><span class="line"> ((<span class="string">'in'</span>, <span class="string">'the'</span>), <span class="number">169</span>),</span><br><span class="line"> ((<span class="string">'i'</span>, <span class="string">'had'</span>), <span class="number">130</span>),</span><br><span class="line"> ((<span class="string">'i'</span>, <span class="string">'was'</span>), <span class="number">112</span>),</span><br><span class="line"> ((<span class="string">'and'</span>, <span class="string">'the'</span>), <span class="number">109</span>),</span><br><span class="line"> ((<span class="string">'the'</span>, <span class="string">'time'</span>), <span class="number">102</span>),</span><br><span class="line"> ((<span class="string">'it'</span>, <span class="string">'was'</span>), <span class="number">99</span>),</span><br><span class="line"> ((<span class="string">'to'</span>, <span class="string">'the'</span>), <span class="number">85</span>),</span><br><span class="line"> ((<span class="string">'as'</span>, <span class="string">'i'</span>), <span class="number">78</span>),</span><br><span class="line"> ((<span class="string">'of'</span>, <span class="string">'a'</span>), <span class="number">73</span>)]</span><br></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">trigram_tokens = [</span><br><span class="line">    triple <span class="keyword">for</span> triple <span class="keyword">in</span> <span class="built_in">zip</span>(corpus[:-<span class="number">2</span>], corpus[<span class="number">1</span>:-<span class="number">1</span>], corpus[<span class="number">2</span>:])]</span><br><span class="line">trigram_vocab = d2l.Vocab(trigram_tokens)</span><br><span class="line">trigram_vocab.token_freqs[:<span class="number">10</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">[((<span class="string">'the'</span>, <span class="string">'time'</span>, <span class="string">'traveller'</span>), <span class="number">59</span>),</span><br><span class="line"> ((<span class="string">'the'</span>, <span class="string">'time'</span>, <span class="string">'machine'</span>), <span class="number">30</span>),</span><br><span class="line"> ((<span class="string">'the'</span>, <span class="string">'medical'</span>, <span class="string">'man'</span>), <span class="number">24</span>),</span><br><span class="line"> ((<span class="string">'it'</span>, <span class="string">'seemed'</span>, <span class="string">'to'</span>), <span class="number">16</span>),</span><br><span class="line"> ((<span class="string">'it'</span>, <span class="string">'was'</span>, <span class="string">'a'</span>), <span class="number">15</span>),</span><br><span class="line"> ((<span class="string">'here'</span>, <span class="string">'and'</span>, <span class="string">'there'</span>), <span class="number">15</span>),</span><br><span class="line"> ((<span class="string">'seemed'</span>, <span class="string">'to'</span>, <span class="string">'me'</span>), <span class="number">14</span>),</span><br><span class="line"> ((<span class="string">'i'</span>, <span class="string">'did'</span>, <span class="string">'not'</span>), <span class="number">14</span>),</span><br><span class="line"> ((<span class="string">'i'</span>, <span class="string">'saw'</span>, <span class="string">'the'</span>), <span class="number">13</span>),</span><br><span class="line"> ((<span class="string">'i'</span>, <span class="string">'began'</span>, <span class="string">'to'</span>), <span class="number">13</span>)]</span><br></pre></td></tr></tbody></table></figure><p>直观地对比三种模型中的标记频率</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 直观地对比三种模型中的标记频率</span></span><br><span class="line">bigram_freqs = [freq <span class="keyword">for</span> token, freq <span class="keyword">in</span> bigram_vocab.token_freqs]</span><br><span class="line">trigram_freqs = [freq <span class="keyword">for</span> token, freq <span class="keyword">in</span> trigram_vocab.token_freqs]</span><br><span class="line">d2l.plot([freqs, bigram_freqs, trigram_freqs], xlabel=<span class="string">'token: x'</span>,</span><br><span class="line">         ylabel=<span class="string">'frequency: n(x)'</span>, xscale=<span class="string">'log'</span>, yscale=<span class="string">'log'</span>,</span><br><span class="line">         legend=[<span class="string">'unigram'</span>, <span class="string">'bigram'</span>, <span class="string">'trigram'</span>])</span><br></pre></td></tr></tbody></table></figure><p><img src="http://xiaomanzhan.com.cn/content/image-20220503224114471.png" alt="image-20220503224114471"></p><h3><span id="42-生成小批量子序列">4.2 生成小批量子序列</span></h3><ol><li>随机地生成一个小批量数据的特征和标签以供读取。在随机采样中，每个样本都是在原始的长序列上任意捕获的子序列。</li></ol><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">seq_data_iter_random</span>(<span class="params">corpus, batch_size, num_steps</span>):  </span><br><span class="line">    <span class="string">"""使用随机抽样生成一个小批量子序列。"""</span></span><br><span class="line">    corpus = corpus[random.randint(<span class="number">0</span>, num_steps - <span class="number">1</span>):]</span><br><span class="line">    num_subseqs = (<span class="built_in">len</span>(corpus) - <span class="number">1</span>) // num_steps</span><br><span class="line">    initial_indices = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">0</span>, num_subseqs * num_steps, num_steps))</span><br><span class="line">    random.shuffle(initial_indices)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">data</span>(<span class="params">pos</span>):</span><br><span class="line">        <span class="keyword">return</span> corpus[pos:pos + num_steps]</span><br><span class="line"></span><br><span class="line">    num_batches = num_subseqs // batch_size</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, batch_size * num_batches, batch_size):</span><br><span class="line">        initial_indices_per_batch = initial_indices[i:i + batch_size]</span><br><span class="line">        X = [data(j) <span class="keyword">for</span> j <span class="keyword">in</span> initial_indices_per_batch]</span><br><span class="line">        Y = [data(j + <span class="number">1</span>) <span class="keyword">for</span> j <span class="keyword">in</span> initial_indices_per_batch]</span><br><span class="line">        <span class="keyword">yield</span> torch.tensor(X), torch.tensor(Y)</span><br></pre></td></tr></tbody></table></figure><p>生成一个从 0 到 34 的序列</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">my_seq = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">35</span>))</span><br><span class="line"><span class="keyword">for</span> X, Y <span class="keyword">in</span> seq_data_iter_random(my_seq, batch_size=<span class="number">2</span>, num_steps=<span class="number">5</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">'X: '</span>, X, <span class="string">'\nY:'</span>, Y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">X:  tensor([[ <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>],</span><br><span class="line">        [<span class="number">19</span>, <span class="number">20</span>, <span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>]]) </span><br><span class="line">Y: tensor([[<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>],</span><br><span class="line">        [<span class="number">20</span>, <span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>, <span class="number">24</span>]])</span><br><span class="line">X:  tensor([[<span class="number">29</span>, <span class="number">30</span>, <span class="number">31</span>, <span class="number">32</span>, <span class="number">33</span>],</span><br><span class="line">        [ <span class="number">4</span>,  <span class="number">5</span>,  <span class="number">6</span>,  <span class="number">7</span>,  <span class="number">8</span>]]) </span><br><span class="line">Y: tensor([[<span class="number">30</span>, <span class="number">31</span>, <span class="number">32</span>, <span class="number">33</span>, <span class="number">34</span>],</span><br><span class="line">        [ <span class="number">5</span>,  <span class="number">6</span>,  <span class="number">7</span>,  <span class="number">8</span>,  <span class="number">9</span>]])</span><br><span class="line">X:  tensor([[<span class="number">14</span>, <span class="number">15</span>, <span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>],</span><br><span class="line">        [<span class="number">24</span>, <span class="number">25</span>, <span class="number">26</span>, <span class="number">27</span>, <span class="number">28</span>]]) </span><br><span class="line">Y: tensor([[<span class="number">15</span>, <span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>, <span class="number">19</span>],</span><br><span class="line">        [<span class="number">25</span>, <span class="number">26</span>, <span class="number">27</span>, <span class="number">28</span>, <span class="number">29</span>]])</span><br></pre></td></tr></tbody></table></figure><ol><li>顺序分区生成一个小批量子序列。</li></ol><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保证两个相邻的小批量中的子序列在原始序列上也是相邻的</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">seq_data_iter_sequential</span>(<span class="params">corpus, batch_size, num_steps</span>):  </span><br><span class="line">    <span class="string">"""使用顺序分区生成一个小批量子序列。"""</span></span><br><span class="line">    offset = random.randint(<span class="number">0</span>, num_steps)</span><br><span class="line">    num_tokens = ((<span class="built_in">len</span>(corpus) - offset - <span class="number">1</span>) // batch_size) * batch_size</span><br><span class="line">    Xs = torch.tensor(corpus[offset:offset + num_tokens])</span><br><span class="line">    Ys = torch.tensor(corpus[offset + <span class="number">1</span>:offset + <span class="number">1</span> + num_tokens])</span><br><span class="line">    Xs, Ys = Xs.reshape(batch_size, -<span class="number">1</span>), Ys.reshape(batch_size, -<span class="number">1</span>)</span><br><span class="line">    num_batches = Xs.shape[<span class="number">1</span>] // num_steps</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, num_steps * num_batches, num_steps):</span><br><span class="line">        X = Xs[:, i:i + num_steps]</span><br><span class="line">        Y = Ys[:, i:i + num_steps]</span><br><span class="line">        <span class="keyword">yield</span> X, Y</span><br></pre></td></tr></tbody></table></figure><p>读取每个小批量的子序列的特征 X 和标签 Y</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取每个小批量的子序列的特征 X 和标签 Y</span></span><br><span class="line"><span class="keyword">for</span> X, Y <span class="keyword">in</span> seq_data_iter_sequential(my_seq, batch_size=<span class="number">2</span>, num_steps=<span class="number">5</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">'X: '</span>, X, <span class="string">'\nY:'</span>, Y)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">X:  tensor([[ <span class="number">2</span>,  <span class="number">3</span>,  <span class="number">4</span>,  <span class="number">5</span>,  <span class="number">6</span>],</span><br><span class="line">        [<span class="number">18</span>, <span class="number">19</span>, <span class="number">20</span>, <span class="number">21</span>, <span class="number">22</span>]]) </span><br><span class="line">Y: tensor([[ <span class="number">3</span>,  <span class="number">4</span>,  <span class="number">5</span>,  <span class="number">6</span>,  <span class="number">7</span>],</span><br><span class="line">        [<span class="number">19</span>, <span class="number">20</span>, <span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>]])</span><br><span class="line">X:  tensor([[ <span class="number">7</span>,  <span class="number">8</span>,  <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>],</span><br><span class="line">        [<span class="number">23</span>, <span class="number">24</span>, <span class="number">25</span>, <span class="number">26</span>, <span class="number">27</span>]]) </span><br><span class="line">Y: tensor([[ <span class="number">8</span>,  <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>],</span><br><span class="line">        [<span class="number">24</span>, <span class="number">25</span>, <span class="number">26</span>, <span class="number">27</span>, <span class="number">28</span>]])</span><br><span class="line">X:  tensor([[<span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>, <span class="number">16</span>],</span><br><span class="line">        [<span class="number">28</span>, <span class="number">29</span>, <span class="number">30</span>, <span class="number">31</span>, <span class="number">32</span>]]) </span><br><span class="line">Y: tensor([[<span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>, <span class="number">16</span>, <span class="number">17</span>],</span><br><span class="line">        [<span class="number">29</span>, <span class="number">30</span>, <span class="number">31</span>, <span class="number">32</span>, <span class="number">33</span>]])</span><br></pre></td></tr></tbody></table></figure><h3><span id="43-加载序列数据的迭代器">4.3 加载序列数据的迭代器</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SeqDataLoader</span>:  </span><br><span class="line">    <span class="string">"""加载序列数据的迭代器。"""</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, batch_size, num_steps, use_random_iter, max_tokens</span>):</span><br><span class="line">        <span class="keyword">if</span> use_random_iter:</span><br><span class="line">            self.data_iter_fn = d2l.seq_data_iter_random</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.data_iter_fn = d2l.seq_data_iter_sequential</span><br><span class="line">        self.corpus, self.vocab = d2l.load_corpus_time_machine(max_tokens)</span><br><span class="line">        self.batch_size, self.num_steps = batch_size, num_steps</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.data_iter_fn(self.corpus, self.batch_size, self.num_steps)</span><br></pre></td></tr></tbody></table></figure><h3><span id="44-返回数据迭代和词汇表">4.4 返回数据迭代和词汇表</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 最后，我们定义了一个函数 load_data_time_machine ，它同时返回数据迭代器和词汇表</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_data_time_machine</span>(<span class="params">batch_size, num_steps,  </span></span><br><span class="line"><span class="params">                           use_random_iter=<span class="literal">False</span>, max_tokens=<span class="number">10000</span></span>):</span><br><span class="line">    <span class="string">"""返回时光机器数据集的迭代器和词汇表。"""</span></span><br><span class="line">    data_iter = SeqDataLoader(batch_size, num_steps, use_random_iter,</span><br><span class="line">                              max_tokens)</span><br><span class="line">    <span class="keyword">return</span> data_iter, data_iter.vocab</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 循环神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 循环神经网络 </tag>
            
            <tag> 文本预处理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>序列模型</title>
      <link href="/2022/04/14/machine-learning/xun-huan-shen-jing-wang-luo/1.xu-lie-mo-xing/"/>
      <url>/2022/04/14/machine-learning/xun-huan-shen-jing-wang-luo/1.xu-lie-mo-xing/</url>
      
        <content type="html"><![CDATA[<h1><span id="序列模型">序列模型</span></h1><h2><span id="1-统计工具">1. 统计工具</span></h2><p>以股票价格为例</p><p><img src="http://xiaomanzhan.com.cn/content/ftse100.png" alt="../_images/ftse100.png" style="zoom:67%;"></p><p>在时间 $t$ 观察到 $x_t$，那么得到 $T$ 个不独立的随机变量 $(x_1,…,x_T)$，我们如果想要知道时间 $t$ 观察到 $x_t$ 的变化，可以通过以下途径。</p><p>使用条件概率展开：</p><script type="math/tex; mode=display">p(a,b)=p(a)p(b|a)=p(b)p(a|b)</script><script type="math/tex; mode=display">p(x)=p(x_1)\cdot p(x_2|x_1)\cdot p(x_3|x_1,x_2)\cdot ...p(x_T|x_1,...x_{T-1})</script><p><img src="http://xiaomanzhan.com.cn/content/image-20220414162851865.png" alt="image-20220414162851865"></p><p>反向如下：</p><script type="math/tex; mode=display">p(x)=p(x_T)\cdot p(x_{T-1}|x_T)\cdot p(x_{T-2}|x_{T-1},x_T)\cdot ...p(x_1|x_2,...x_{T})</script><p><img src="http://xiaomanzhan.com.cn/content/image-20220414162922331.png" alt="image-20220414162922331"></p><h2><span id="2-自回归模型">2. 自回归模型</span></h2><h3><span id="21-方案a-马尔科夫假设">2.1 方案A-马尔科夫假设</span></h3><script type="math/tex; mode=display">p(x)=p(x_1)\cdot p(x_2|x_1)\cdot p(x_3|x_1,x_2)\cdot ...p(x_T|x_1,...x_{T-1})</script><p>假设当前数据只跟 $\tau$ 个过去数据点相关，使用过去的数据进行训练一个MLP模型</p><script type="math/tex; mode=display">p(x_t|x_1,...x_{t-1})=p(x_t|x_{t-\tau},...x_{t-1})=p(x_t|f(x_{t-\tau},...x_{t-1}))</script><h3><span id="22-方案b-潜变量模型">2.2 方案B - 潜变量模型</span></h3><script type="math/tex; mode=display">p(x)=p(x_1)\cdot p(x_2|x_1)\cdot p(x_3|x_1,x_2)\cdot ...p(x_T|x_1,...x_{T-1})</script><p>引入潜变量 $h_t$ 来表示过去的信息 $ht=f(x_1, …x_{t-1})$，这样 $x_t=p(x_t|h_t)$</p><p><img src="http://xiaomanzhan.com.cn/content/image-20220414164047072.png" alt="image-20220414164047072"></p><h2><span id="4-总结">4. 总结：</span></h2><ol><li>时序模型中，当前数据跟之前观察的数据相关</li><li>自回归模型使用自身过去数据来预测未来</li><li>马尔科夫模型假设当前只跟最近少数数据相关，从而简化模型；</li><li>潜变量模型使用潜变量来概括历史信息</li></ol><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 循环神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 循环神经网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ResNet</title>
      <link href="/2022/04/14/machine-learning/juan-ji-shen-jing-wang-luo/resnet/"/>
      <url>/2022/04/14/machine-learning/juan-ji-shen-jing-wang-luo/resnet/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="resnet">ResNet</span></h1><h2><span id="1-resnet优势">1. ResNet优势</span></h2><p>因为随着神经网络层数的增加，模型复杂度变大，准确度不一定上升。如果把每层的神经网络看做一个函数，如下图所示，星星代表最优（即最深颜色中心点）。</p><ul><li>标有Fi的闭合区域表示函数，闭合区域的面积代表函数的复杂程度，在这个区域中能够找到一个最优的模型（可以用区域中的一个点来表示，该点到最优值的距离可以用来衡量模型的好坏）</li><li>从左图中可以看出，随着函数的复杂度的不断增加，虽然函数的区域面积增大了，但是在该区域中所能找到的最优模型（该区域内的某一点）离最优值的距离可能会越来越远（也就是模型所在的区域随着函数复杂度的增加，逐渐偏离了原来的区域，离最优值越来越远）（非嵌套函数（non-nested function））</li><li>解决上述问题（模型走偏）的方法：每一次增加函数复杂度之后函数所覆盖的区域会包含原来函数所在的区域（嵌套函数（nested function）），只有当较复杂的函数类包含复杂度较小的函数类时，才能确保提高它的性能，如右图所示</li></ul><p><img src="http://xiaomanzhan.com.cn/content/image-20220424224834077.png" alt="image-20220424224834077"></p><h3><span id="11-解决的主要问题">1.1 解决的主要问题</span></h3><ol><li>梯度爆炸和梯度消失在引入<code>bn</code>层之后基本解决，残差是为了解决网络退化；</li><li>也能够解决梯度消失和梯度爆炸。</li></ol><h2><span id="2-网络架构">2. 网络架构</span></h2><h3><span id="21-残差块">2.1 残差块</span></h3><ul><li>串联一个层改变函数类，我们希望能扩大函数类；</li><li>残差快加入快速通道（右边）来得到 $f(x)=x+g(x)$</li></ul><p><img src="http://xiaomanzhan.com.cn/content/image-20220424225926642.png" alt="image-20220424225926642" style="zoom: 80%;"></p><h3><span id="22-resnet-块细节">2.2 ResNet 块细节</span></h3><p>当通道数一致的情况下直接使用 $H(x)=F(x)+x$ ，当通道数不一致的情况下使用一个 $1\times 1$的卷积调整通道数，计算方式为 $H(x)=F(x)+Wx$。</p><p><img src="http://xiaomanzhan.com.cn/content/image-20220424230005016.png" alt="image-20220424230005016" style="zoom:67%;"></p><h3><span id="23-不同的残差快">2.3 不同的残差快</span></h3><p><img src="http://xiaomanzhan.com.cn/content/image-20220424230047170.png" alt="image-20220424230047170"></p><h3><span id="24-resnet-块">2.4 Resnet 块</span></h3><ul><li>高宽减半ResNet块（步幅2）</li><li>后接多个高宽不变的ResNet块</li></ul><p><img src="http://xiaomanzhan.com.cn/content/image-20220424230132394.png" alt="image-20220424230132394"></p><h3><span id="25-resnet结构">2.5 ResNet结构</span></h3><p>与VGG和GoogleNet的架构类似都是由块构成，但是替换为了ResNet块</p><p><img src="http://xiaomanzhan.com.cn/content/resnet18.svg" alt="resnet18"></p><h3><span id="26-resnet为何能解决梯度消失">2.6 ResNet为何能解决梯度消失</span></h3><p>残差网络是由许多具有相似结构的部分组成的，每一部分通常被称为“残差块”，如下图，其中F(x)表示残差函数。残差网络的精妙之处在于它把对于完整的输出的学习问题归结于对于残差的学习（Residual Learning）问题。</p><p>如果只把浅层的输出做恒等映射（即F(X)=0）输入到深层，这样网络加深也并不会出现网络退化。所以，他在网络中加入了“短路”机制，并且这样不但解决了梯度消失问题，同时也提高了计算效率。</p><p><img src="http://xiaomanzhan.com.cn/content/v2-b0b4a08cb66360ccd4098de158a92e14_720w.jpg" alt="img"></p><h3><span id="27-总结">2.7 总结</span></h3><ul><li>残差快使得很深的网络更加容易训练<ul><li>甚至可以训练一千层的网络</li></ul></li><li>残差网络对随后的深层神经网络设计产生了深远影响，无论是卷积类网络还是全连接类网络</li></ul><h2><span id="3-代码实现">3. 代码实现</span></h2><p>数据加载与LeNet一样，参看LeNet</p><h3><span id="31-残差块实现">3.1 残差块实现</span></h3><p>因为残差块分两种（包不包含 $1\times 1$ 的卷积），参数信息包含输入通道数、输出通道数、是否使用 $1\times 1$ 卷积、步长。因残差块的输入维度和输出维度相等，所以没有pool层。</p><ol><li>两个卷积层，第二个卷积层的输入/输出通道数相同。</li><li>每次做完卷积后跟一个batchnorm操作（防止梯度爆炸），再使用激活函数。需要注意 $1\times 1$ 的卷积后面不必跟batchnorm操作。</li></ol><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 残差块设计</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Residual</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_channels, num_channels, </span></span><br><span class="line"><span class="params">                 use_1x1conv=<span class="literal">False</span>, strides=<span class="number">1</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(</span><br><span class="line">            input_channels, num_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, stride=strides)</span><br><span class="line">        self.conv2 = nn.Conv2d(</span><br><span class="line">            num_channels, num_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> use_1x1conv:</span><br><span class="line">            self.conv3 = nn.Conv2d(</span><br><span class="line">                input_channels, num_channels, kernel_size=<span class="number">1</span>, stride=strides)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.conv3 = <span class="literal">None</span></span><br><span class="line">        self.bn1 = nn.BatchNorm2d(num_channels)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(num_channels)</span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        y = F.relu(self.bn1(self.conv1(x)))</span><br><span class="line">        y = self.bn2(self.conv2(y))</span><br><span class="line">        <span class="keyword">if</span> self.conv3:</span><br><span class="line">            x = self.conv3(x)</span><br><span class="line">        y += x</span><br><span class="line">        <span class="keyword">return</span> F.relu(y)</span><br></pre></td></tr></tbody></table></figure><p>查看残差块层</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">blk = Residual(<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">blk</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">Residual(</span><br><span class="line">  (conv1): Conv2d(<span class="number">3</span>, <span class="number">3</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (conv2): Conv2d(<span class="number">3</span>, <span class="number">3</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (bn1): BatchNorm2d(<span class="number">3</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">  (bn2): BatchNorm2d(<span class="number">3</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">  (relu): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">)</span><br></pre></td></tr></tbody></table></figure><p>输入输出前后不变</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(<span class="number">4</span>, <span class="number">3</span>, <span class="number">6</span>, <span class="number">6</span>)</span><br><span class="line">y = blk(x)</span><br><span class="line">y.shape</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">torch.Size([<span class="number">4</span>, <span class="number">3</span>, <span class="number">6</span>, <span class="number">6</span>])</span><br></pre></td></tr></tbody></table></figure><p>残差块操作，增加通道数，减半输出的高宽</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 增加通道数，减半输出的高宽</span></span><br><span class="line">blk = Residual(<span class="number">3</span>, <span class="number">6</span>, use_1x1conv=<span class="literal">True</span>, strides=<span class="number">2</span>)</span><br><span class="line">blk</span><br></pre></td></tr></tbody></table></figure><h3><span id="32-resnet模型实现">3.2 ResNet模型实现</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">b1 = nn.Sequential(nn.Conv2d(<span class="number">1</span>, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>),</span><br><span class="line">                   nn.BatchNorm2d(<span class="number">64</span>), nn.ReLU(),</span><br><span class="line">                   nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnet_block</span>(<span class="params">input_channels, num_channels, num_residuals,</span></span><br><span class="line"><span class="params">                 first_block=<span class="literal">False</span></span>):</span><br><span class="line">    blk = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_residuals):</span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">0</span> <span class="keyword">and</span> <span class="keyword">not</span> first_block:</span><br><span class="line">            blk.append(</span><br><span class="line">                Residual(input_channels, num_channels, use_1x1conv=<span class="literal">True</span>,</span><br><span class="line">                         strides=<span class="number">2</span>))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            blk.append(Residual(num_channels, num_channels))</span><br><span class="line">    <span class="keyword">return</span> blk</span><br><span class="line"></span><br><span class="line">b2 = nn.Sequential(*resnet_block(<span class="number">64</span>, <span class="number">64</span>, <span class="number">2</span>, first_block=<span class="literal">True</span>))</span><br><span class="line">b3 = nn.Sequential(*resnet_block(<span class="number">64</span>, <span class="number">128</span>, <span class="number">2</span>))</span><br><span class="line">b4 = nn.Sequential(*resnet_block(<span class="number">128</span>, <span class="number">256</span>, <span class="number">2</span>))</span><br><span class="line">b5 = nn.Sequential(*resnet_block(<span class="number">256</span>, <span class="number">512</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">net = nn.Sequential(b1, b2, b3, b4, b5, </span><br><span class="line">                    nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="number">1</span>)),</span><br><span class="line">                    nn.Flatten(), nn.Linear(<span class="number">512</span>, <span class="number">10</span>))</span><br><span class="line">net</span><br></pre></td></tr></tbody></table></figure><p>查看每层对输入数据做出的维度变化</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">X = torch.rand(size=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> net:</span><br><span class="line">    X = layer(X)</span><br><span class="line">    <span class="built_in">print</span>(layer.__class__.__name__, <span class="string">'output shape:\t'</span>, X.shape)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">Sequential output shape: torch.Size([<span class="number">1</span>, <span class="number">64</span>, <span class="number">56</span>, <span class="number">56</span>])</span><br><span class="line">Sequential output shape: torch.Size([<span class="number">1</span>, <span class="number">64</span>, <span class="number">56</span>, <span class="number">56</span>])</span><br><span class="line">Sequential output shape: torch.Size([<span class="number">1</span>, <span class="number">128</span>, <span class="number">28</span>, <span class="number">28</span>])</span><br><span class="line">Sequential output shape: torch.Size([<span class="number">1</span>, <span class="number">256</span>, <span class="number">14</span>, <span class="number">14</span>])</span><br><span class="line">Sequential output shape: torch.Size([<span class="number">1</span>, <span class="number">512</span>, <span class="number">7</span>, <span class="number">7</span>])</span><br><span class="line">AdaptiveAvgPool2d output shape: torch.Size([<span class="number">1</span>, <span class="number">512</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">Flatten output shape: torch.Size([<span class="number">1</span>, <span class="number">512</span>])</span><br><span class="line">Linear output shape: torch.Size([<span class="number">1</span>, <span class="number">10</span>])</span><br></pre></td></tr></tbody></table></figure><p>训练模型与LeNet一样，参看LeNet</p><blockquote><p>参考：</p><ol><li><a href="https://www.bilibili.com/read/cv15415155?from=note">29 残差网络 ResNet【动手学深度学习v2】</a></li><li><a href="https://www.bilibili.com/video/BV1bV41177ap/">残差网络 ResNet</a></li></ol></blockquote><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
          <category> 卷积神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 卷积神经网络 </tag>
            
            <tag> ResNet </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode380</title>
      <link href="/2022/04/13/leetcode/mei-ri-yi-ti/leetcode380/"/>
      <url>/2022/04/13/leetcode/mei-ri-yi-ti/leetcode380/</url>
      
        <content type="html"><![CDATA[<h1><span id="380-o1-时间插入-删除和获取随机元素">380. O(1) 时间插入、删除和获取随机元素</span></h1><blockquote><p><a href="https://leetcode-cn.com/problems/insert-delete-getrandom-o1/">380. O(1) 时间插入、删除和获取随机元素</a></p></blockquote><h2><span id="题目">题目</span></h2><p>实现<code>RandomizedSet</code> 类：</p><ul><li><code>RandomizedSet()</code> 初始化 <code>RandomizedSet</code> 对象</li><li><code>bool insert(int val)</code> 当元素 <code>val</code> 不存在时，向集合中插入该项，并返回 <code>true</code> ；否则，返回 <code>false</code> 。</li><li><code>bool remove(int val)</code> 当元素 <code>val</code> 存在时，从集合中移除该项，并返回 <code>true</code> ；否则，返回 <code>false</code> 。</li><li><code>int getRandom()</code> 随机返回现有集合中的一项（测试用例保证调用此方法时集合中至少存在一个元素）。每个元素应该有 相同的概率 被返回。</li></ul><p>你必须实现类的所有函数，并满足每个函数的 平均 时间复杂度为 <code>O(1)</code> 。</p><h2><span id="示例">示例</span></h2><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">输入</span><br><span class="line">["RandomizedSet", "insert", "remove", "insert", "getRandom", "remove", "insert", "getRandom"]</span><br><span class="line">[[], [1], [2], [2], [], [1], [2], []]</span><br><span class="line">输出</span><br><span class="line">[null, true, false, true, 2, true, false, 2]</span><br><span class="line"></span><br><span class="line">解释</span><br><span class="line">RandomizedSet randomizedSet = new RandomizedSet();</span><br><span class="line">randomizedSet.insert(1); // 向集合中插入 1 。返回 true 表示 1 被成功地插入。</span><br><span class="line">randomizedSet.remove(2); // 返回 false ，表示集合中不存在 2 。</span><br><span class="line">randomizedSet.insert(2); // 向集合中插入 2 。返回 true 。集合现在包含 [1,2] 。</span><br><span class="line">randomizedSet.getRandom(); // getRandom 应随机返回 1 或 2 。</span><br><span class="line">randomizedSet.remove(1); // 从集合中移除 1 ，返回 true 。集合现在包含 [2] 。</span><br><span class="line">randomizedSet.insert(2); // 2 已在集合中，所以返回 false 。</span><br><span class="line">randomizedSet.getRandom(); // 由于 2 是集合中唯一的数字，getRandom 总是返回 2 。</span><br></pre></td></tr></tbody></table></figure><h2><span id="解题思路">解题思路</span></h2><p>变长数组 + 哈希表的思路，边长数组存储元素，哈希表维护元素所在的<code>index</code>。</p><p>每次插入时，插入到数组末尾，哈希表对应的新插入的元素<code>index</code>为<code>len(nums)</code>；当删除元素时分三步完成：</p><ol><li>根据哈希表找到删除元素<code>key</code>对应的<code>index</code>；</li><li>将数组<code>nums</code>中<code>index</code>位置元素替换为数组<code>nums</code>的最后一个元素；</li><li>更新哈希表中替换元素对应的index；</li><li>删除<code>nums</code>最后一个元素，删除哈希表中<code>key</code>为删除元素<code>val</code>的信息</li></ol><h3><span id="题解">题解</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RandomizedSet</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.nums = []</span><br><span class="line">        self.indices = {}</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">insert</span>(<span class="params">self, val: <span class="built_in">int</span></span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        <span class="keyword">if</span> val <span class="keyword">in</span> self.indices:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        self.indices[val] = <span class="built_in">len</span>(self.nums)</span><br><span class="line">        self.nums.append(val)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">remove</span>(<span class="params">self, val: <span class="built_in">int</span></span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        <span class="keyword">if</span> val <span class="keyword">not</span> <span class="keyword">in</span> self.indices:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        ind = self.indices[val]</span><br><span class="line">        self.nums[ind] = self.nums[-<span class="number">1</span>]</span><br><span class="line">        self.indices[self.nums[ind]] = ind</span><br><span class="line">        self.nums.pop()</span><br><span class="line">        <span class="keyword">del</span> self.indices[val]</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">getRandom</span>(<span class="params">self</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="keyword">return</span> choice(self.nums)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Your RandomizedSet object will be instantiated and called as such:</span></span><br><span class="line"><span class="comment"># obj = RandomizedSet()</span></span><br><span class="line"><span class="comment"># param_1 = obj.insert(val)</span></span><br><span class="line"><span class="comment"># param_2 = obj.remove(val)</span></span><br><span class="line"><span class="comment"># param_3 = obj.getRandom()</span></span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> 难度-中等 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeetCode </tag>
            
            <tag> 哈希表 </tag>
            
            <tag> 变长数组 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>批量归一化</title>
      <link href="/2022/04/13/machine-learning/juan-ji-shen-jing-wang-luo/pi-liang-gui-yi-hua/"/>
      <url>/2022/04/13/machine-learning/juan-ji-shen-jing-wang-luo/pi-liang-gui-yi-hua/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="批量归一化">批量归一化</span></h1><h2><span id="1-缘由">1. 缘由</span></h2><ul><li>因为损失出现在最后，后面的层训练较快 (参数信息更新块)，上面层梯度大，权重更新快</li><li>数据在最底部，所以会导致以下问题：<ul><li>底部的层训练较慢；</li><li>底部层一变化，所有都得跟着变化；</li><li>最后的那些层需要重新学习的次数非常多；</li><li>导致收敛变慢</li><li>底部梯度小，权重更新慢</li></ul></li></ul><p><strong>底部和顶部如下图所示：</strong></p><p><img src="http://xiaomanzhan.com.cn/content/image-20220424222715976.png" alt="image-20220424222715976"></p><p>如何在学习底部层的时候避免变化顶部层？使用批量归一化。</p><h2><span id="2-批量归一化">2. 批量归一化</span></h2><p>固定小批量里面的均值和方差，$B$表示小批量样本， $\epsilon$ 是一个非常小的数据，能够防止方差变成0</p><script type="math/tex; mode=display">\mu_B=\frac{1}{|B|}\sum_{i\in B}x_i\\ \sigma_B^2=\frac{1}{|B|}\sum_{i\in B}(x_i-\mu_B)^2+\epsilon</script><p>然后在做额外的调整（可学习的参数）, $\gamma$ 表示方差， $\beta$ 表示均值， $\gamma$ 和 $\beta$ 是可以学习的参数。当小批量数据里的均值和方差不好的时候， $\gamma$ 和 $\beta$ 的存在会使得神经网络中的数值会好一点</p><script type="math/tex; mode=display">x_{i+1}=\gamma\frac{x_i-\mu_B}{\sigma_B}+\beta</script><p>注意：$\mu$ 和 $\sigma$ 是根据数据来的， $\gamma$ 和 $\beta$ 是可以学习的参数</p><h3><span id="21-批量归一化的使用">2.1 批量归一化的使用</span></h3><p>所以批量归一化层是一个线性变换，能够让后续的变换不是那么剧烈</p><ul><li>可学习的参数为 $\gamma$ 和 $\beta$</li><li>作用在<ul><li>全连接层和卷积层输出上，激活函数前</li><li>全连接层和卷积层输入上</li></ul></li><li>对全连接层，作用在特征维</li><li>对于卷积层，作用在通道层</li></ul><h3><span id="22-批量归一化的优势">2.2 批量归一化的优势</span></h3><ol><li><p>能够减少内部协变量的转移；</p></li><li><p>能够通过在每个小批量里面加入噪音来控制模型的复杂度，其中$\hat\mu_B$ 可以看做是随机偏移，$\hat\sigma_B$ 可以看做是随机缩放；</p><script type="math/tex; mode=display">x_{i+1}=\gamma\frac{x_i-\hat\mu_B}{\hat\sigma_B}+\beta</script></li><li><p>没必要跟Dropout混合使用</p></li></ol><h3><span id="23-总结">2.3 总结</span></h3><ul><li>批量归一化会固定小批量中的均值和方差，然后学习出适合的偏移和缩放</li><li>能够加速收敛速度，但是一般不改变模型的精度。</li></ul><h2><span id="3-代码实现">3. 代码实现</span></h2><h3><span id="31-批量归一化">3.1 批量归一化</span></h3><p>我们从头开始实现一个具有张量的批量规范化层。先实现批量归一化函数<code>batch_norm</code></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">batch_norm</span>(<span class="params">X, gamma, beta, moving_mean, moving_var, eps, momentum</span>):</span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    moving_mean, moving_var: 表示全局的均值和方差，</span></span><br><span class="line"><span class="string">    eps: 是为了避免结果为0，</span></span><br><span class="line"><span class="string">    momentum: 用来更新moving_mean和moving_var的东西</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> torch.is_grad_enabled(): <span class="comment"># 不做梯度的情况，测试集</span></span><br><span class="line">        X_hat = (X - moving_mean) / torch.sqrt(moving_var + eps)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># X只能是全连接层2或者卷积层4</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(X.shape) <span class="keyword">in</span> (<span class="number">2</span>, <span class="number">4</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(X.shape) == <span class="number">2</span>:</span><br><span class="line">            mean = X.mean(dim=<span class="number">0</span>)</span><br><span class="line">            var = ((X - mean) ** <span class="number">2</span>).mean(dim=<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            mean = X.mean(dim=(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>), keepdim=<span class="literal">True</span>)</span><br><span class="line">            var = ((X - mean) ** <span class="number">2</span>).mean(dim=(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>), keepdim=<span class="literal">True</span>)</span><br><span class="line">        X_hat = (X - mean) / torch.sqrt(var + eps)</span><br><span class="line">        moving_mean = momentum * moving_mean + (<span class="number">1</span> - momentum) * mean</span><br><span class="line">        moving_var = momentum * moving_var + (<span class="number">1</span> - momentum) * var</span><br><span class="line">    Y = gamma * X_hat + beta</span><br><span class="line">    <span class="keyword">return</span> Y, moving_mean.data, moving_var.data</span><br></pre></td></tr></tbody></table></figure><p>实现批量归一化层</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BatchNorm</span>(nn.Module):</span><br><span class="line">    <span class="comment"># num_features：完全连接层的输出数量或卷积层的输出通道数。</span></span><br><span class="line">    <span class="comment"># num_dims：2表示完全连接层，4表示卷积层</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_features, num_dims</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="keyword">if</span> num_dims == <span class="number">2</span>:</span><br><span class="line">            shape = (<span class="number">1</span>, num_features)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            shape = (<span class="number">1</span>, num_features, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 参与求梯度和迭代的拉伸和偏移参数，分别初始化成1和0</span></span><br><span class="line">        self.gamma = nn.Parameter(torch.ones(shape))</span><br><span class="line">        self.beta = nn.Parameter(torch.zeros(shape))</span><br><span class="line">        <span class="comment"># 非模型参数的变量初始化为0和1</span></span><br><span class="line">        self.moving_mean = torch.zeros(shape)</span><br><span class="line">        self.moving_var = torch.ones(shape)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="comment"># 如果X不在内存上，将moving_mean和moving_var</span></span><br><span class="line">        <span class="comment"># 复制到X所在显存上</span></span><br><span class="line">        <span class="keyword">if</span> self.moving_mean.device != X.device:</span><br><span class="line">            self.moving_mean = self.moving_mean.to(X.device)</span><br><span class="line">            self.moving_var = self.moving_var.to(X.device)</span><br><span class="line">        <span class="comment"># 保存更新过的moving_mean和moving_var</span></span><br><span class="line">        Y, self.moving_mean, self.moving_var = batch_norm(</span><br><span class="line">            X, self.gamma, self.beta, self.moving_mean,</span><br><span class="line">            self.moving_var, eps=<span class="number">1e-5</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line">        <span class="keyword">return</span> Y</span><br></pre></td></tr></tbody></table></figure><h3><span id="32-lenetbatchnorm">3.2 LeNet+BatchNorm</span></h3><p>使用批量规范化层的 LeNet，在原神经网络的基础上，每个卷积层和激活函数层之间添加一个batchNorm层</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对LeNet网络进行修改</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Reshape</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> x.view(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line"></span><br><span class="line">net = torch.nn.Sequential(</span><br><span class="line">    Reshape(), </span><br><span class="line">    nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>), BatchNorm(<span class="number">6</span>, num_dims=<span class="number">4</span>), </span><br><span class="line">    nn.Sigmoid(), nn.AvgPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, kernel_size=<span class="number">5</span>), BatchNorm(<span class="number">16</span>, num_dims=<span class="number">4</span>), </span><br><span class="line">    nn.Sigmoid(), nn.AvgPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>), </span><br><span class="line">    nn.Flatten(),</span><br><span class="line">    nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>), BatchNorm(<span class="number">120</span>, num_dims=<span class="number">2</span>), nn.Sigmoid(),</span><br><span class="line">    nn.Linear(<span class="number">120</span>, <span class="number">84</span>), BatchNorm(<span class="number">84</span>, num_dims=<span class="number">2</span>), nn.Sigmoid(), </span><br><span class="line">    nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line">)</span><br><span class="line">net</span><br></pre></td></tr></tbody></table></figure><p>调用包实现</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 调用包实现情况</span></span><br><span class="line"><span class="comment"># 对LeNet网络进行修改</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Reshape</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> x.view(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line"></span><br><span class="line">net = torch.nn.Sequential(</span><br><span class="line">    Reshape(), </span><br><span class="line">    nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>), nn.BatchNorm2d(<span class="number">6</span>), </span><br><span class="line">    nn.Sigmoid(), nn.AvgPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, kernel_size=<span class="number">5</span>), nn.BatchNorm2d(<span class="number">16</span>), </span><br><span class="line">    nn.Sigmoid(), nn.AvgPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>), </span><br><span class="line">    nn.Flatten(),</span><br><span class="line">    nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>), nn.BatchNorm1d(<span class="number">120</span>), nn.Sigmoid(),</span><br><span class="line">    nn.Linear(<span class="number">120</span>, <span class="number">84</span>), nn.BatchNorm1d(<span class="number">84</span>), nn.Sigmoid(), </span><br><span class="line">    nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line">)</span><br><span class="line">net</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
          <category> 卷积神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 卷积神经网络 </tag>
            
            <tag> 批量归一化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GoogleAlexNet</title>
      <link href="/2022/04/12/machine-learning/juan-ji-shen-jing-wang-luo/googlealexnet/"/>
      <url>/2022/04/12/machine-learning/juan-ji-shen-jing-wang-luo/googlealexnet/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="googlealexnet">GoogleAlexNet</span></h1><h2><span id="1-googlealexnet-优势">1. GoogleAlexNet 优势</span></h2><ol><li>第一个卷积的个数超过100个的CNN</li><li><p>使用了Inception块，有四条超参数的卷积层和池化层的路来抽取不同的信息；</p><ol><li>它的模型参数小，计算复杂度低；</li></ol></li><li><p>GoogleNet使用了9块Inception块，网络结构深度多达百层。</p></li></ol><h2><span id="2-网络结构">2. 网络结构</span></h2><h3><span id="21-inception块">2.1 Inception块</span></h3><p>在GoogLeNet中，基本的卷积块被称为 <em>Inception块</em>（Inception block）。详细结构如下图所示：</p><p><img src="http://xiaomanzhan.com.cn/content/inception.svg" alt="inception"></p><p>Inception块由四条并行路径组成。 </p><ol><li>前三条路径使用窗口大小为 $1×1$、$3×3$ 和 $5×5$ 的卷积层，从不同空间大小中提取信息。 </li><li>中间的两条路径在输入上执行1×1卷积，以减少通道数，从而降低模型的复杂性。 </li><li>第四条路径使用3×3最大汇聚层，然后使用1×1卷积层来改变通道数。 </li></ol><p>这四条路径都使用合适的填充来使输入与输出的高和宽一致，最后我们将每条线路的输出在通道维度上连结，并构成Inception块的输出。在Inception块中，通常调整的超参数是每层输出通道数。</p><p>跟单<code>3*3</code>或<code>5*5</code>的卷积层相比，Inception块有更少的参数个数和计算复杂度</p><div class="table-container"><table><thead><tr><th></th><th>#parameters</th><th>Flops(计算)</th></tr></thead><tbody><tr><td>Inception</td><td>0.16M</td><td>128M</td></tr><tr><td>3*3 Conv</td><td>0.44M</td><td>346M</td></tr><tr><td>5*5 Conv</td><td>1.22M</td><td>963M</td></tr></tbody></table></div><h3><span id="22-googlenet模型">2.2 GoogleNet模型</span></h3><p><img src="http://xiaomanzhan.com.cn/content/inception-full.svg" alt="inception-full"></p><p>GoogLeNet在网络模型方面与AlexNet、VGG还是有一些相通之处的，它们的主要相通之处就体现在卷积部分，</p><ul><li>AlexNet采用5个卷积层</li><li>VGG把5个卷积层替换成5个卷积块</li><li>GoogLeNet采用5个不同的模块组成主体卷积部分</li></ul><p>用表格的形式表示GoogLeNet的网络结构如下所示：</p><p><img src="http://xiaomanzhan.com.cn/content/Googlenet_table.jpg" alt="Googlenet_table"></p><h3><span id="23-inception-后续变种">2.3 Inception 后续变种</span></h3><ul><li>Inception-BN (v2) - 使用batch nromalization</li><li>Inception- V3 - 修改了Inception块<ul><li>替换 $5\times5$ 为多个 $3\times3$ 卷积层</li><li>替换 $5\times5$ 为 $1\times7$ 和 $7\times1$ 卷积层</li><li>替换 $3\times3$ 为 $1\times3$ 和 $3\times1$ 卷积层</li><li>更深</li></ul></li><li>Inception-V4- 使用残差连接</li></ul><h2><span id="3-代码实现">3. 代码实现</span></h2><p>数据集的加载方式和 LeNet的加载方式一致</p><h3><span id="31-inception-块">3.1 Inception 块</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Inception</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, c1, c2, c3, c4, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>(Inception, self).__init__(**kwargs)</span><br><span class="line">        self.p1_1 = nn.Conv2d(in_channels, c1, kernel_size=<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        self.p2_1 = nn.Conv2d(in_channels, c2[<span class="number">0</span>], kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.p2_2 = nn.Conv2d(c2[<span class="number">0</span>], c2[<span class="number">1</span>], kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        self.p3_1 = nn.Conv2d(in_channels, c3[<span class="number">0</span>], kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.p3_2 = nn.Conv2d(c3[<span class="number">0</span>], c3[<span class="number">1</span>], kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>)</span><br><span class="line">        </span><br><span class="line">        self.p4_1 = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.p4_2 = nn.Conv2d(in_channels, c4, kernel_size=<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        p1 = F.relu(self.p1_1(x))</span><br><span class="line">        p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))</span><br><span class="line">        p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))</span><br><span class="line">        p4 = F.relu(self.p4_2(self.p4_1(x)))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 在输出维度上将其铺开，使用cat的方式</span></span><br><span class="line">        <span class="keyword">return</span> torch.cat((p1, p2, p3, p4), dim=<span class="number">1</span>)</span><br></pre></td></tr></tbody></table></figure><h3><span id="32-googlenet模型实现">3.2 GoogleNet模型实现</span></h3><p>对每个stage阶段实现：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实现每个stage</span></span><br><span class="line">b1 = nn.Sequential(nn.Conv2d(<span class="number">1</span>, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>),</span><br><span class="line">                   nn.ReLU(), nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">b2 = nn.Sequential(nn.Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=<span class="number">1</span>), nn.ReLU(),</span><br><span class="line">                   nn.Conv2d(<span class="number">64</span>, <span class="number">192</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">                   nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">b3 = nn.Sequential(Inception(<span class="number">192</span>, <span class="number">64</span>, (<span class="number">96</span>, <span class="number">128</span>), (<span class="number">16</span>, <span class="number">32</span>), <span class="number">32</span>),</span><br><span class="line">                   Inception(<span class="number">256</span>, <span class="number">128</span>, (<span class="number">128</span>, <span class="number">192</span>), (<span class="number">32</span>, <span class="number">96</span>), <span class="number">64</span>),</span><br><span class="line">                   nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">b4 = nn.Sequential(Inception(<span class="number">480</span>, <span class="number">192</span>, (<span class="number">96</span>, <span class="number">208</span>), (<span class="number">16</span>, <span class="number">48</span>), <span class="number">64</span>),</span><br><span class="line">                   Inception(<span class="number">512</span>, <span class="number">160</span>, (<span class="number">112</span>, <span class="number">224</span>), (<span class="number">24</span>, <span class="number">64</span>), <span class="number">64</span>),</span><br><span class="line">                   Inception(<span class="number">512</span>, <span class="number">128</span>, (<span class="number">128</span>, <span class="number">256</span>), (<span class="number">24</span>, <span class="number">64</span>), <span class="number">64</span>),</span><br><span class="line">                   Inception(<span class="number">512</span>, <span class="number">112</span>, (<span class="number">144</span>, <span class="number">288</span>), (<span class="number">32</span>, <span class="number">64</span>), <span class="number">64</span>),</span><br><span class="line">                   Inception(<span class="number">528</span>, <span class="number">256</span>, (<span class="number">160</span>, <span class="number">320</span>), (<span class="number">32</span>, <span class="number">128</span>), <span class="number">128</span>),</span><br><span class="line">                   nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">b5 = nn.Sequential(Inception(<span class="number">832</span>, <span class="number">256</span>, (<span class="number">160</span>, <span class="number">320</span>), (<span class="number">32</span>, <span class="number">128</span>), <span class="number">128</span>),</span><br><span class="line">                   Inception(<span class="number">832</span>, <span class="number">384</span>, (<span class="number">192</span>, <span class="number">384</span>), (<span class="number">48</span>, <span class="number">128</span>), <span class="number">128</span>),</span><br><span class="line">                   nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="number">1</span>)), nn.Flatten())</span><br><span class="line"></span><br><span class="line">net = nn.Sequential(b1, b2, b3, b4, b5, nn.Linear(<span class="number">1024</span>, <span class="number">10</span>))</span><br><span class="line">net</span><br></pre></td></tr></tbody></table></figure><p>输出：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line">Sequential(</span><br><span class="line">  (0): Sequential(</span><br><span class="line">    (0): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))</span><br><span class="line">    (1): ReLU()</span><br><span class="line">    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)</span><br><span class="line">  )</span><br><span class="line">  (1): Sequential(</span><br><span class="line">    (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))</span><br><span class="line">    (1): ReLU()</span><br><span class="line">    (2): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)</span><br><span class="line">  )</span><br><span class="line">  (2): Sequential(</span><br><span class="line">    (0): Inception(</span><br><span class="line">      (p1_1): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))</span><br><span class="line">      (p2_1): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))</span><br><span class="line">      (p2_2): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">      (p3_1): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1))</span><br><span class="line">      (p3_2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))</span><br><span class="line">      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)</span><br><span class="line">      (p4_2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))</span><br><span class="line">    )</span><br><span class="line">    (1): Inception(</span><br><span class="line">      (p1_1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))</span><br><span class="line">      (p2_1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))</span><br><span class="line">      (p2_2): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">      (p3_1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))</span><br><span class="line">      (p3_2): Conv2d(32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))</span><br><span class="line">      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)</span><br><span class="line">      (p4_2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))</span><br><span class="line">    )</span><br><span class="line">    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)</span><br><span class="line">  )</span><br><span class="line">  (3): Sequential(</span><br><span class="line">    (0): Inception(</span><br><span class="line">      (p1_1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1))</span><br><span class="line">      (p2_1): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1))</span><br><span class="line">      (p2_2): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">      (p3_1): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1))</span><br><span class="line">      (p3_2): Conv2d(16, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))</span><br><span class="line">      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)</span><br><span class="line">      (p4_2): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1))</span><br><span class="line">    )</span><br><span class="line">    (1): Inception(</span><br><span class="line">      (p1_1): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1))</span><br><span class="line">      (p2_1): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))</span><br><span class="line">      (p2_2): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">      (p3_1): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))</span><br><span class="line">      (p3_2): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))</span><br><span class="line">      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)</span><br><span class="line">      (p4_2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))</span><br><span class="line">    )</span><br><span class="line">    (2): Inception(</span><br><span class="line">      (p1_1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))</span><br><span class="line">      (p2_1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))</span><br><span class="line">      (p2_2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">      (p3_1): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))</span><br><span class="line">      (p3_2): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))</span><br><span class="line">      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)</span><br><span class="line">      (p4_2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))</span><br><span class="line">    )</span><br><span class="line">    (3): Inception(</span><br><span class="line">      (p1_1): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))</span><br><span class="line">      (p2_1): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))</span><br><span class="line">      (p2_2): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">      (p3_1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))</span><br><span class="line">      (p3_2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))</span><br><span class="line">      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)</span><br><span class="line">      (p4_2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))</span><br><span class="line">    )</span><br><span class="line">    (4): Inception(</span><br><span class="line">      (p1_1): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1))</span><br><span class="line">      (p2_1): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1))</span><br><span class="line">      (p2_2): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">      (p3_1): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1))</span><br><span class="line">      (p3_2): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))</span><br><span class="line">      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)</span><br><span class="line">      (p4_2): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1))</span><br><span class="line">    )</span><br><span class="line">    (5): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)</span><br><span class="line">  )</span><br><span class="line">  (4): Sequential(</span><br><span class="line">    (0): Inception(</span><br><span class="line">      (p1_1): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1))</span><br><span class="line">      (p2_1): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1))</span><br><span class="line">      (p2_2): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">      (p3_1): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1))</span><br><span class="line">      (p3_2): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))</span><br><span class="line">      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)</span><br><span class="line">      (p4_2): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))</span><br><span class="line">    )</span><br><span class="line">    (1): Inception(</span><br><span class="line">      (p1_1): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1))</span><br><span class="line">      (p2_1): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1))</span><br><span class="line">      (p2_2): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">      (p3_1): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1))</span><br><span class="line">      (p3_2): Conv2d(48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))</span><br><span class="line">      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)</span><br><span class="line">      (p4_2): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))</span><br><span class="line">    )</span><br><span class="line">    (2): AdaptiveAvgPool2d(output_size=(1, 1))</span><br><span class="line">    (3): Flatten(start_dim=1, end_dim=-1)</span><br><span class="line">  )</span><br><span class="line">  (5): Linear(in_features=1024, out_features=10, bias=True)</span><br><span class="line">)</span><br></pre></td></tr></tbody></table></figure><p>查看模型在每一层处对数据特征的调整。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 为了使Fashion-MNIST上的训练短小精悍，我们将输入的高和宽从224降到96</span></span><br><span class="line">X = torch.randn(size=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">96</span>, <span class="number">96</span>))</span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> net:</span><br><span class="line">    X = layer(X)</span><br><span class="line">    <span class="built_in">print</span>(layer.__class__.__name__, <span class="string">'Output shape:\t'</span>, X.shape)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">Sequential Output shape: torch.Size([<span class="number">1</span>, <span class="number">64</span>, <span class="number">24</span>, <span class="number">24</span>])</span><br><span class="line">Sequential Output shape: torch.Size([<span class="number">1</span>, <span class="number">192</span>, <span class="number">12</span>, <span class="number">12</span>])</span><br><span class="line">Sequential Output shape: torch.Size([<span class="number">1</span>, <span class="number">480</span>, <span class="number">6</span>, <span class="number">6</span>])</span><br><span class="line">Sequential Output shape: torch.Size([<span class="number">1</span>, <span class="number">832</span>, <span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line">Sequential Output shape: torch.Size([<span class="number">1</span>, <span class="number">1024</span>])</span><br><span class="line">Linear Output shape: torch.Size([<span class="number">1</span>, <span class="number">10</span>])</span><br></pre></td></tr></tbody></table></figure><p>训练模型与LeNet一样，参看LeNet</p><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
          <category> 卷积神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 卷积神经网络 </tag>
            
            <tag> GoogleAlexNet </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NiN</title>
      <link href="/2022/04/12/machine-learning/juan-ji-shen-jing-wang-luo/nin/"/>
      <url>/2022/04/12/machine-learning/juan-ji-shen-jing-wang-luo/nin/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="nin">NiN</span></h1><h2><span id="1-nin优势">1. NiN优势</span></h2><p>NIN有两个特性</p><ul><li>MLP代替GLM<ul><li>实现跨通道的交互和信息整合；</li><li>进行卷积核通道数的降维和升维。</li><li>在一定程度上减少参数信息，可以看做是将$N\times N$卷积操作转化为两个$1\times 1$ 的卷积操作。</li></ul></li><li>Global Average Pooling<ul><li>解决全连接层参数过多的问题。</li></ul></li></ul><h3><span id="11-mlp代替glm">1.1 MLP代替GLM</span></h3><p>GLM就是广义线性模型。那么MLP是指，在做卷积操作的时候，把线性操作变为多层感知机。<br>左图为普通的卷积，右图为mlpconv，Mlpconv相当于在正常的卷积层后面，再添加一个1×1的卷积层。</p><p><img src="http://xiaomanzhan.com.cn/content/20190521100054634.png" alt="在这里插入图片描述"></p><h3><span id="2-global-average-pooling">2. Global Average Pooling</span></h3><p>问题：卷积层虽然需要较少的参数，$c_i <em> c_o </em> k^2 $，但是卷积层的最后一个全连接层的参数量是非常大的：</p><ul><li>$LeNet\ \ \  16\times5\times5\times120=48k$</li><li>$AlexNet\ \ \ 256\times5\times5\times4096=26M$</li><li>$VGG\ \ \ 512\times7\times7\times4096=102M$</li></ul><p>所以提出了<code>Global Average Pooling</code>， 主要为了解决全连接层参数过多的问题，早期对于分类问题，最后一个卷积层的 <code>Feature Map</code> 通常与全连接层连接，最后通过 <code>softmax</code> 逻辑回归分类。全连接层带来的问题就是参数空间过大，容易过拟合。早期 <code>Alex</code> 采用了<code>Dropout</code> 的方法，来减轻过拟合，提高网络的泛化能力，但依旧无法解决参数过多问题。</p><h2><span id="2-网络架构">2. 网络架构</span></h2><h3><span id="21-nin块">2.1 NiN块</span></h3><ul><li>一个卷积层后跟两个全连接层；<ul><li>步幅1，无填充，输出形状跟卷积层输出一样；</li><li>起到全连接层的作用（此处全连接指的是在 <strong>通道/空间</strong> 维度上进行全连接）</li></ul></li></ul><p><img src="http://xiaomanzhan.com.cn/content/image-20220424213128276.png" alt></p><h3><span id="22-nin架构">2.2 NiN架构</span></h3><p>下图是NIN的网络结构，它包括三个mlpconv层和一个全局平均池化层。</p><p><img src="http://xiaomanzhan.com.cn/content/image-20220424211644985.png" alt="image-20220424211644985"></p><p>NiN架构的特点</p><ul><li>无全连接层</li><li>交替使用NiN块和步幅为2的最大池化层<ul><li>逐步减小高宽和增大通道数</li></ul></li><li>最后使用全局平均池化层得到输出<ul><li>其输入通道数是类别数;</li><li>使其不容易过拟合，使用更少的参数个数</li></ul></li></ul><p><img src="http://xiaomanzhan.com.cn/content/nin.svg" alt="nin"></p><p>NiN使用一个全局池化层来代替VGG和AlexNet中的全连接层。这就使其不容易过拟合，使用更少的参数个数</p><h2><span id="3-代码实现">3. 代码实现</span></h2><p>数据集的加载方式和 LeNet的加载方式一致</p><h3><span id="31-nin块实现">3.1 NiN块实现</span></h3><p>块的输入包含 输入通道数、输出通道数、卷积核大小（用于最初的卷积）、strides、padding</p><ol><li>构建二维卷积；</li><li>跟两个 $1\times 1$ 的二维卷积；</li><li>每个卷积层后面需要跟一个激活函数。</li></ol><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">nin_block</span>(<span class="params">in_channels, out_channels, kernel_size, strides, padding</span>):</span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">        nn.Conv2d(in_channels, out_channels, kernel_size, strides, padding),</span><br><span class="line">        nn.ReLU(), nn.Conv2d(out_channels, out_channels, kernel_size=<span class="number">1</span>),</span><br><span class="line">        nn.ReLU(), nn.Conv2d(out_channels, out_channels, kernel_size=<span class="number">1</span>),</span><br><span class="line">        nn.ReLU()</span><br><span class="line">    )</span><br></pre></td></tr></tbody></table></figure><h3><span id="32-nin模型实现">3.2 NiN模型实现</span></h3><p>在每个NiN 块后面跟一个maxpool操作，将输出图像大小减半，最后一个NiN块不跟 maxpool 操作，而是跟一个全局池化层操作。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">net = nn.Sequential(</span><br><span class="line">    nin_block(<span class="number">1</span>, <span class="number">96</span>, kernel_size=<span class="number">11</span>, strides=<span class="number">4</span>, padding=<span class="number">0</span>),</span><br><span class="line">    nn.MaxPool2d(<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nin_block(<span class="number">96</span>, <span class="number">256</span>, kernel_size=<span class="number">5</span>, strides=<span class="number">1</span>, padding=<span class="number">2</span>),</span><br><span class="line">    nn.MaxPool2d(<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nin_block(<span class="number">256</span>, <span class="number">384</span>, kernel_size=<span class="number">3</span>, strides=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">    nn.MaxPool2d(<span class="number">3</span>, stride=<span class="number">2</span>), nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">    nin_block(<span class="number">384</span>, <span class="number">10</span>, kernel_size=<span class="number">3</span>, strides=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">    nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="number">1</span>)), <span class="comment"># 使用全局池化层，指定每个通道的输出size（H,W）</span></span><br><span class="line">    nn.Flatten()</span><br><span class="line">)</span><br></pre></td></tr></tbody></table></figure><p>查看每层对输入数据做出的维度变化</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">X = torch.randn(size=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> net:</span><br><span class="line">    X = layer(X)</span><br><span class="line">    <span class="built_in">print</span>(layer.__class__.__name__, <span class="string">"Output shape:\t"</span>, X.shape)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">Sequential Output shape: torch.Size([<span class="number">1</span>, <span class="number">96</span>, <span class="number">54</span>, <span class="number">54</span>])</span><br><span class="line">MaxPool2d Output shape: torch.Size([<span class="number">1</span>, <span class="number">96</span>, <span class="number">26</span>, <span class="number">26</span>])</span><br><span class="line">Sequential Output shape: torch.Size([<span class="number">1</span>, <span class="number">256</span>, <span class="number">26</span>, <span class="number">26</span>])</span><br><span class="line">MaxPool2d Output shape: torch.Size([<span class="number">1</span>, <span class="number">256</span>, <span class="number">12</span>, <span class="number">12</span>])</span><br><span class="line">Sequential Output shape: torch.Size([<span class="number">1</span>, <span class="number">384</span>, <span class="number">12</span>, <span class="number">12</span>])</span><br><span class="line">MaxPool2d Output shape: torch.Size([<span class="number">1</span>, <span class="number">384</span>, <span class="number">5</span>, <span class="number">5</span>])</span><br><span class="line">Dropout Output shape: torch.Size([<span class="number">1</span>, <span class="number">384</span>, <span class="number">5</span>, <span class="number">5</span>])</span><br><span class="line">Sequential Output shape: torch.Size([<span class="number">1</span>, <span class="number">10</span>, <span class="number">5</span>, <span class="number">5</span>])</span><br><span class="line">AdaptiveAvgPool2d Output shape: torch.Size([<span class="number">1</span>, <span class="number">10</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">Flatten Output shape: torch.Size([<span class="number">1</span>, <span class="number">10</span>])</span><br></pre></td></tr></tbody></table></figure><p>训练模型与LeNet一样，参看LeNet</p><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
          <category> 卷积神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 卷积神经网络 </tag>
            
            <tag> NiN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VGG</title>
      <link href="/2022/04/12/machine-learning/juan-ji-shen-jing-wang-luo/vgg/"/>
      <url>/2022/04/12/machine-learning/juan-ji-shen-jing-wang-luo/vgg/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="vgg">VGG</span></h1><h2><span id="1-vgg优点">1. VGG优点</span></h2><p>如何做到网络层比AlexNet更深更大：</p><ul><li>更多的全连接层（太贵、太耗时间）</li><li>更多的卷积层</li><li><strong>将卷积层组合成块</strong></li></ul><h2><span id="2-vgg网络架构">2. VGG网络架构</span></h2><p><img src="http://xiaomanzhan.com.cn/content/27175ac326484325b1cdaa4b4b89dec9.png" alt="VGG16"></p><h3><span id="21-vgg块">2.1 VGG块</span></h3><p>VGG更加有优势的地方在于，提出了VGG块，VGG块包含</p><ul><li>3*3卷积（填充1）（n层，m通道）</li><li>2*2最大池化层（步幅2）</li></ul><p><img src="http://xiaomanzhan.com.cn/content/image-20220424203243432.png" alt="image-20220424203243432"></p><h3><span id="22-vgg架构">2.2 VGG架构</span></h3><ul><li>多个VGG块后接全连接层；</li><li>不同次数的重复块得到不同的结构VGG-16，VGG-19，…</li></ul><p><img src="C:/Users/Gxl/Desktop/vgg.svg" alt="../_images/vgg.svg"></p><h3><span id="23-vgg-各种网络结构">2.3 VGG 各种网络结构</span></h3><p>VGGNet以下6种不同结构，我们以通常所说的VGG-16(即<strong>下图D列</strong>)为例，展示其结构示意图</p><p><img src="http://xiaomanzhan.com.cn/content/6c484661cf1f4c108d75f36b771a24e8.png" alt="VGG" style="zoom:67%;"></p><h2><span id="3-cnn发展史">3. CNN发展史：</span></h2><ul><li>LeNet(1995)<ul><li>2卷积+池化层</li><li>2全连接层</li></ul></li><li>AlexNet<ul><li>更大更深</li><li>ReLU，Dropout，数据增强</li></ul></li><li>VGG<ul><li>更大更深的AlexNet (重复的VGG块)</li></ul></li></ul><h2><span id="4-代码实现">4. 代码实现</span></h2><p>数据加载与LeNet一样，参看LeNet</p><h3><span id="41-vgg-block实现">4.1 VGG Block实现</span></h3><p>需要指明输入的卷积层数、输入通道数、输出通道数。</p><ol><li>每个卷积层使用核大小为3，padding为1的卷积进行处理，在卷积操作的时候特征的输入维度不发生变化；</li><li>再经过一个pool块，将输入特征维度减少一半。</li></ol><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">vgg_block</span>(<span class="params">num_convs, in_channels, out_channels</span>):</span><br><span class="line">    layers = []</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_convs):</span><br><span class="line">        layers.append(</span><br><span class="line">            nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line">        layers.append(nn.ReLU())</span><br><span class="line">        in_channels = out_channels</span><br><span class="line">    layers.append(nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>))</span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(*layers)</span><br></pre></td></tr></tbody></table></figure><h3><span id="42-构建vgg网络结构">4.2 构建VGG网络结构</span></h3><p>使用一个变量 <code>conv_arch</code> 记录每个 <code>vgg</code> 块的详细信息。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># conv_arch记录VGG的一个经典结构，根据此结构构造模型</span></span><br><span class="line">conv_arch = ((<span class="number">1</span>, <span class="number">64</span>), (<span class="number">1</span>, <span class="number">128</span>), (<span class="number">2</span>, <span class="number">256</span>), (<span class="number">2</span>, <span class="number">512</span>), (<span class="number">2</span>, <span class="number">512</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vgg</span>(<span class="params">conv_arch</span>):</span><br><span class="line">    conv_blks = []</span><br><span class="line">    in_channels = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> (num_convs, out_channels) <span class="keyword">in</span> conv_arch:</span><br><span class="line">        conv_blks.append(</span><br><span class="line">            vgg_block(num_convs, in_channels, out_channels)</span><br><span class="line">        )</span><br><span class="line">        in_channels = out_channels</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">        *conv_blks, nn.Flatten(),</span><br><span class="line">        nn.Linear(out_channels * <span class="number">7</span> * <span class="number">7</span>, <span class="number">4096</span>), nn.ReLU(), nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">        nn.Linear(<span class="number">4096</span>, <span class="number">4096</span>), nn.ReLU(), nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">        nn.Linear(<span class="number">4096</span>, <span class="number">10</span>)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">net=vgg(conv_arch)</span><br><span class="line">net</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">Sequential(</span><br><span class="line">  (<span class="number">0</span>): Sequential(</span><br><span class="line">    (<span class="number">0</span>): Conv2d(<span class="number">1</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">1</span>): ReLU()</span><br><span class="line">    (<span class="number">2</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">  )</span><br><span class="line">  (<span class="number">1</span>): Sequential(</span><br><span class="line">    (<span class="number">0</span>): Conv2d(<span class="number">64</span>, <span class="number">128</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">1</span>): ReLU()</span><br><span class="line">    (<span class="number">2</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">  )</span><br><span class="line">  (<span class="number">2</span>): Sequential(</span><br><span class="line">    (<span class="number">0</span>): Conv2d(<span class="number">128</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">1</span>): ReLU()</span><br><span class="line">    (<span class="number">2</span>): Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">3</span>): ReLU()</span><br><span class="line">    (<span class="number">4</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">  )</span><br><span class="line">  (<span class="number">3</span>): Sequential(</span><br><span class="line">    (<span class="number">0</span>): Conv2d(<span class="number">256</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">1</span>): ReLU()</span><br><span class="line">    (<span class="number">2</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">3</span>): ReLU()</span><br><span class="line">    (<span class="number">4</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">  )</span><br><span class="line">  (<span class="number">4</span>): Sequential(</span><br><span class="line">    (<span class="number">0</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">1</span>): ReLU()</span><br><span class="line">    (<span class="number">2</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">3</span>): ReLU()</span><br><span class="line">    (<span class="number">4</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">  )</span><br><span class="line">  (<span class="number">5</span>): Flatten(start_dim=<span class="number">1</span>, end_dim=-<span class="number">1</span>)</span><br><span class="line">  (<span class="number">6</span>): Linear(in_features=<span class="number">25088</span>, out_features=<span class="number">4096</span>, bias=<span class="literal">True</span>)</span><br><span class="line">  (<span class="number">7</span>): ReLU()</span><br><span class="line">  (<span class="number">8</span>): Dropout(p=<span class="number">0.5</span>, inplace=<span class="literal">False</span>)</span><br><span class="line">  (<span class="number">9</span>): Linear(in_features=<span class="number">4096</span>, out_features=<span class="number">4096</span>, bias=<span class="literal">True</span>)</span><br><span class="line">  (<span class="number">10</span>): ReLU()</span><br><span class="line">  (<span class="number">11</span>): Dropout(p=<span class="number">0.5</span>, inplace=<span class="literal">False</span>)</span><br><span class="line">  (<span class="number">12</span>): Linear(in_features=<span class="number">4096</span>, out_features=<span class="number">10</span>, bias=<span class="literal">True</span>)</span><br><span class="line">)</span><br></pre></td></tr></tbody></table></figure><p>查看每层对输入数据做出的维度变化</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X = torch.randn(size=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line"><span class="keyword">for</span> blk <span class="keyword">in</span> net:</span><br><span class="line">    X = blk(X)</span><br><span class="line">    <span class="built_in">print</span>(blk.__class__.__name__, <span class="string">'Output shape:\t'</span>, X.shape)</span><br></pre></td></tr></tbody></table></figure><p>训练模型与LeNet一样，参看LeNet</p><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
          <category> 卷积神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 卷积神经网络 </tag>
            
            <tag> VGG </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AlexNet</title>
      <link href="/2022/04/12/machine-learning/juan-ji-shen-jing-wang-luo/alexnet/"/>
      <url>/2022/04/12/machine-learning/juan-ji-shen-jing-wang-luo/alexnet/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="alexnet">AlexNet</span></h1><h2><span id="1-alexnet-优势">1. AlexNet 优势</span></h2><p>AlexNet可以看做是对LeNet的优化，可以看作更深更大的LeNet，主要改进有：</p><ul><li>丢弃法</li><li>ReLU</li><li>MaxPooling</li></ul><h2><span id="2-网络结构">2. 网络结构</span></h2><p>网络结构层数做的更深，全连接层仍然有三层。</p><p><img src="C:/Users/Gxl/Desktop/alexnet.svg" alt="../_images/alexnet.svg"></p><h3><span id="21-第一层的变化">2.1 第一层的变化</span></h3><p>使用了更大的核窗口和步长（因为图片更大了），使用了更大的池化窗口并且使用了最大池化层。</p><p><img src="http://xiaomanzhan.com.cn/content/image-20220424201531056.png" alt="image-20220424201531056"></p><h3><span id="22-后面接的卷积层">2.2 后面接的卷积层</span></h3><p>新增了三层卷积层，同时输出通道更多。</p><p><img src="http://xiaomanzhan.com.cn/content/image-20220424201748254.png" alt="image-20220424201748254"></p><h3><span id="23-输出层">2.3 输出层</span></h3><p>均是使用了三层全连接结构进行输出，从最开始的 120 增加到 4096 层。</p><p><img src="http://xiaomanzhan.com.cn/content/image-20220424202016446.png" alt="image-20220424202016446"></p><p>更多细节的不同：</p><ol><li>激活函数，从sigmoid变成了ReLU（减缓梯度消失）</li><li>隐藏全连接层后加入丢弃层</li><li>数据增强</li></ol><h2><span id="3-代码实现">3. 代码实现</span></h2><h3><span id="31-构建神经网络">3.1 构建神经网络</span></h3><p>数据集加载方式和 LeNet 类似，此处略。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">net = nn.Sequential(</span><br><span class="line">    nn.Conv2d(<span class="number">1</span>, <span class="number">96</span>, kernel_size=<span class="number">11</span>, stride=<span class="number">4</span>, padding=<span class="number">1</span>), nn.ReLU(),</span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nn.Conv2d(<span class="number">96</span>, <span class="number">256</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>), nn.ReLU(),</span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nn.Conv2d(<span class="number">256</span>, <span class="number">384</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>), nn.ReLU(),</span><br><span class="line">    nn.Conv2d(<span class="number">384</span>, <span class="number">384</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>), nn.ReLU(),</span><br><span class="line">    nn.Conv2d(<span class="number">384</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>), nn.ReLU(),</span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nn.Flatten(),</span><br><span class="line">    nn.Linear(<span class="number">6400</span>, <span class="number">4096</span>), nn.ReLU(), nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">    nn.Linear(<span class="number">4096</span>, <span class="number">4096</span>), nn.ReLU(), nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">    nn.Linear(<span class="number">4096</span>, <span class="number">10</span>)</span><br><span class="line">)</span><br><span class="line">net</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">Sequential(</span><br><span class="line">  (<span class="number">0</span>): Conv2d(<span class="number">1</span>, <span class="number">96</span>, kernel_size=(<span class="number">11</span>, <span class="number">11</span>), stride=(<span class="number">4</span>, <span class="number">4</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">1</span>): ReLU()</span><br><span class="line">  (<span class="number">2</span>): MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">  (<span class="number">3</span>): Conv2d(<span class="number">96</span>, <span class="number">256</span>, kernel_size=(<span class="number">5</span>, <span class="number">5</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">  (<span class="number">4</span>): ReLU()</span><br><span class="line">  (<span class="number">5</span>): MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">  (<span class="number">6</span>): Conv2d(<span class="number">256</span>, <span class="number">384</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">7</span>): ReLU()</span><br><span class="line">  (<span class="number">8</span>): Conv2d(<span class="number">384</span>, <span class="number">384</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">9</span>): ReLU()</span><br><span class="line">  (<span class="number">10</span>): Conv2d(<span class="number">384</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">11</span>): ReLU()</span><br><span class="line">  (<span class="number">12</span>): MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">  (<span class="number">13</span>): Flatten(start_dim=<span class="number">1</span>, end_dim=-<span class="number">1</span>)</span><br><span class="line">  (<span class="number">14</span>): Linear(in_features=<span class="number">6400</span>, out_features=<span class="number">4096</span>, bias=<span class="literal">True</span>)</span><br><span class="line">  (<span class="number">15</span>): ReLU()</span><br><span class="line">  (<span class="number">16</span>): Dropout(p=<span class="number">0.5</span>, inplace=<span class="literal">False</span>)</span><br><span class="line">  (<span class="number">17</span>): Linear(in_features=<span class="number">4096</span>, out_features=<span class="number">4096</span>, bias=<span class="literal">True</span>)</span><br><span class="line">  (<span class="number">18</span>): ReLU()</span><br><span class="line">  (<span class="number">19</span>): Dropout(p=<span class="number">0.5</span>, inplace=<span class="literal">False</span>)</span><br><span class="line">  (<span class="number">20</span>): Linear(in_features=<span class="number">4096</span>, out_features=<span class="number">10</span>, bias=<span class="literal">True</span>)</span><br><span class="line">)</span><br></pre></td></tr></tbody></table></figure><p>查看模型在每一层对数据的调整。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">X = torch.randn(<span class="number">1</span>, <span class="number">1</span>, <span class="number">224</span>, <span class="number">224</span>)</span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> net:</span><br><span class="line">    X = layer(X)</span><br><span class="line">    <span class="built_in">print</span>(layer.__class__.__name__, <span class="string">'Output shape:\t'</span>, X.shape)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">Conv2d Output shape: torch.Size([<span class="number">1</span>, <span class="number">96</span>, <span class="number">54</span>, <span class="number">54</span>])</span><br><span class="line">ReLU Output shape: torch.Size([<span class="number">1</span>, <span class="number">96</span>, <span class="number">54</span>, <span class="number">54</span>])</span><br><span class="line">MaxPool2d Output shape: torch.Size([<span class="number">1</span>, <span class="number">96</span>, <span class="number">26</span>, <span class="number">26</span>])</span><br><span class="line">Conv2d Output shape: torch.Size([<span class="number">1</span>, <span class="number">256</span>, <span class="number">26</span>, <span class="number">26</span>])</span><br><span class="line">ReLU Output shape: torch.Size([<span class="number">1</span>, <span class="number">256</span>, <span class="number">26</span>, <span class="number">26</span>])</span><br><span class="line">MaxPool2d Output shape: torch.Size([<span class="number">1</span>, <span class="number">256</span>, <span class="number">12</span>, <span class="number">12</span>])</span><br><span class="line">Conv2d Output shape: torch.Size([<span class="number">1</span>, <span class="number">384</span>, <span class="number">12</span>, <span class="number">12</span>])</span><br><span class="line">ReLU Output shape: torch.Size([<span class="number">1</span>, <span class="number">384</span>, <span class="number">12</span>, <span class="number">12</span>])</span><br><span class="line">Conv2d Output shape: torch.Size([<span class="number">1</span>, <span class="number">384</span>, <span class="number">12</span>, <span class="number">12</span>])</span><br><span class="line">ReLU Output shape: torch.Size([<span class="number">1</span>, <span class="number">384</span>, <span class="number">12</span>, <span class="number">12</span>])</span><br><span class="line">Conv2d Output shape: torch.Size([<span class="number">1</span>, <span class="number">256</span>, <span class="number">12</span>, <span class="number">12</span>])</span><br><span class="line">ReLU Output shape: torch.Size([<span class="number">1</span>, <span class="number">256</span>, <span class="number">12</span>, <span class="number">12</span>])</span><br><span class="line">MaxPool2d Output shape: torch.Size([<span class="number">1</span>, <span class="number">256</span>, <span class="number">5</span>, <span class="number">5</span>])</span><br><span class="line">Flatten Output shape: torch.Size([<span class="number">1</span>, <span class="number">6400</span>])</span><br><span class="line">Linear Output shape: torch.Size([<span class="number">1</span>, <span class="number">4096</span>])</span><br><span class="line">ReLU Output shape: torch.Size([<span class="number">1</span>, <span class="number">4096</span>])</span><br><span class="line">Dropout Output shape: torch.Size([<span class="number">1</span>, <span class="number">4096</span>])</span><br><span class="line">Linear Output shape: torch.Size([<span class="number">1</span>, <span class="number">4096</span>])</span><br><span class="line">ReLU Output shape: torch.Size([<span class="number">1</span>, <span class="number">4096</span>])</span><br><span class="line">Dropout Output shape: torch.Size([<span class="number">1</span>, <span class="number">4096</span>])</span><br><span class="line">Linear Output shape: torch.Size([<span class="number">1</span>, <span class="number">10</span>])</span><br></pre></td></tr></tbody></table></figure><p>构建<code>DataLoader</code> 和训练过程与<code>LeNet</code> 类似，不再书写。</p><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
          <category> 卷积神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 卷积神经网络 </tag>
            
            <tag> AlexNet </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeNet</title>
      <link href="/2022/04/12/machine-learning/juan-ji-shen-jing-wang-luo/lenet/"/>
      <url>/2022/04/12/machine-learning/juan-ji-shen-jing-wang-luo/lenet/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="lenet">LeNet</span></h1><h2><span id="1-lenet优势">1. LeNet优势</span></h2><ol><li>先通过卷积层来学习图片的空间信息；</li><li>使用池化层降低图片的敏感度；</li><li>使用全连接层来转换到类别空间</li></ol><p>先将信息变多，再降维，这种方式能够有效提取空间特征，同时参数信息也不会大量激增。</p><h2><span id="2-网络结构">2. 网络结构</span></h2><p>LeNet（LeNet-5）由两个部分组成：</p><ul><li>卷积编码器：由两个卷积层组成;</li><li>全连接层密集块：由三个全连接层组成。</li></ul><p><img src="http://xiaomanzhan.com.cn/content/lenet.svg" alt="../_images/lenet.svg"></p><p>一般情况下，当卷积之后长宽减半之后，通道数增加两倍，增加通道数，能够使得模型匹配的通道数和能够匹配的模式变多了，变大了。</p><h2><span id="3-代码实现">3. 代码实现</span></h2><h3><span id="31-加载mnist数据集">3.1 加载MNIST数据集</span></h3><p>加载python包</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> multiprocessing</span><br><span class="line"><span class="keyword">from</span> torch.utils <span class="keyword">import</span> data</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line">d2l.use_svg_display() <span class="comment"># 使用svg显示图片，图像清晰度高</span></span><br><span class="line">multiprocessing.freeze_support() <span class="comment"># 终止进程</span></span><br></pre></td></tr></tbody></table></figure><p>数据在预处理时是需要进行归一化处理的，好处有两点：</p><ol><li><p>一定程度提高模型精度</p><p>在机器学习或者深度学习中，大多模型的loss计算，需要假定数据的所有特征都是零均值并且具有同一阶方差的。这样在计算loss时，才能将所有特征属性统一处理。</p><p>比如，在KNN中，我们需要计算样本之间的欧式距离，如果样本两个属性的量纲差距过大，则大量纲的属性在距离计算中就占据了主导地位。而现实中，可能恰恰相反。所以，加入归一化，将数据的特征属性scale到统一量纲，可以一定程度解决这个问题。</p></li><li><p>提升收敛速度</p><p>对于使用梯度下降优化的模型，每次迭代会找到梯度最大的方向迭代更新模型参数。但是，如果模型的特征属性量纲不一，那么我们寻求最优解的特征空间，就可以看做是一个椭圆形的，其中大量冈的属性对应的参数有较长的轴。在更新过程中，可能会出现更新过程不是一直朝向极小点更新的，而是呈现‘Z’字型。使用了归一化对齐量纲之后，更新过程就变成了在近似圆形空间，不断向圆心（极值点）迭代的过程：</p><p><img src="http://xiaomanzhan.com.cn/content/20200805221327218.png" alt="未使用归一化"></p><p><img src="http://xiaomanzhan.com.cn/content/20200805221357566.png" alt="使用归一化"></p></li></ol><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 能够通过ToTensor实例将图像数据从PIL类型转换为32位浮点数格式</span></span><br><span class="line"><span class="comment"># 并除以255使得所有的数值均在0到1之间</span></span><br><span class="line">trans = transforms.ToTensor()</span><br><span class="line">mnist_train = torchvision.datasets.FashionMNIST(</span><br><span class="line">    root=<span class="string">"./data"</span>, train=<span class="literal">True</span>, transform=trans, download=<span class="literal">True</span>)</span><br><span class="line">mnist_test = torchvision.datasets.FashionMNIST(</span><br><span class="line">    root=<span class="string">"./data"</span>, train=<span class="literal">False</span>, transform=trans, download=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">len</span>(mnist_train), <span class="built_in">len</span>(mnist_test)</span><br></pre></td></tr></tbody></table></figure><h3><span id="32-构建模型">3.2 构建模型</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Reshape</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> x.view(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line"></span><br><span class="line">net = torch.nn.Sequential(Reshape(), </span><br><span class="line">                          nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>), nn.Sigmoid(),</span><br><span class="line">                          nn.AvgPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>),</span><br><span class="line">                          nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, kernel_size=<span class="number">5</span>), nn.Sigmoid(),</span><br><span class="line">                          nn.AvgPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>), </span><br><span class="line">                          nn.Flatten(),</span><br><span class="line">                          nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>), nn.Sigmoid(),</span><br><span class="line">                          nn.Linear(<span class="number">120</span>, <span class="number">84</span>), nn.Sigmoid(), </span><br><span class="line">                          nn.Linear(<span class="number">84</span>, <span class="number">10</span>))</span><br><span class="line">net</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">Sequential(</span><br><span class="line">  (<span class="number">0</span>): Reshape()</span><br><span class="line">  (<span class="number">1</span>): Conv2d(<span class="number">1</span>, <span class="number">6</span>, kernel_size=(<span class="number">5</span>, <span class="number">5</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">  (<span class="number">2</span>): Sigmoid()</span><br><span class="line">  (<span class="number">3</span>): AvgPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>)</span><br><span class="line">  (<span class="number">4</span>): Conv2d(<span class="number">6</span>, <span class="number">16</span>, kernel_size=(<span class="number">5</span>, <span class="number">5</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">5</span>): Sigmoid()</span><br><span class="line">  (<span class="number">6</span>): AvgPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>)</span><br><span class="line">  (<span class="number">7</span>): Flatten(start_dim=<span class="number">1</span>, end_dim=-<span class="number">1</span>)</span><br><span class="line">  (<span class="number">8</span>): Linear(in_features=<span class="number">400</span>, out_features=<span class="number">120</span>, bias=<span class="literal">True</span>)</span><br><span class="line">  (<span class="number">9</span>): Sigmoid()</span><br><span class="line">  (<span class="number">10</span>): Linear(in_features=<span class="number">120</span>, out_features=<span class="number">84</span>, bias=<span class="literal">True</span>)</span><br><span class="line">  (<span class="number">11</span>): Sigmoid()</span><br><span class="line">  (<span class="number">12</span>): Linear(in_features=<span class="number">84</span>, out_features=<span class="number">10</span>, bias=<span class="literal">True</span>)</span><br><span class="line">)</span><br></pre></td></tr></tbody></table></figure><blockquote><p>注意：在<code>LeNet</code>中使用<code>sigmoid</code> 激活函数是因为当时还没有 <code>relu</code> 激活函数</p></blockquote><p>查看模型在每一层处对数据特征的调整。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">X = torch.rand(size=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>), dtype=torch.float32)</span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> net:</span><br><span class="line">    X = layer(X)</span><br><span class="line">    <span class="built_in">print</span>(layer.__class__.__name__, <span class="string">'output shape: \t'</span>, X.shape)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">Reshape output shape:  torch.Size([<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>])</span><br><span class="line">Conv2d output shape:  torch.Size([<span class="number">1</span>, <span class="number">6</span>, <span class="number">28</span>, <span class="number">28</span>])</span><br><span class="line">Sigmoid output shape:  torch.Size([<span class="number">1</span>, <span class="number">6</span>, <span class="number">28</span>, <span class="number">28</span>])</span><br><span class="line">AvgPool2d output shape:  torch.Size([<span class="number">1</span>, <span class="number">6</span>, <span class="number">14</span>, <span class="number">14</span>])</span><br><span class="line">Conv2d output shape:  torch.Size([<span class="number">1</span>, <span class="number">16</span>, <span class="number">10</span>, <span class="number">10</span>])</span><br><span class="line">Sigmoid output shape:  torch.Size([<span class="number">1</span>, <span class="number">16</span>, <span class="number">10</span>, <span class="number">10</span>])</span><br><span class="line">AvgPool2d output shape:  torch.Size([<span class="number">1</span>, <span class="number">16</span>, <span class="number">5</span>, <span class="number">5</span>])</span><br><span class="line">Flatten output shape:  torch.Size([<span class="number">1</span>, <span class="number">400</span>])</span><br><span class="line">Linear output shape:  torch.Size([<span class="number">1</span>, <span class="number">120</span>])</span><br><span class="line">Sigmoid output shape:  torch.Size([<span class="number">1</span>, <span class="number">120</span>])</span><br><span class="line">Linear output shape:  torch.Size([<span class="number">1</span>, <span class="number">84</span>])</span><br><span class="line">Sigmoid output shape:  torch.Size([<span class="number">1</span>, <span class="number">84</span>])</span><br><span class="line">Linear output shape:  torch.Size([<span class="number">1</span>, <span class="number">10</span>])</span><br></pre></td></tr></tbody></table></figure><h3><span id="33-构建dataloader">3.3 构建DataLoader</span></h3><p>通过 <code>get_dataloader_worker</code> 函数调整加载数据集时用的进程数</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">batch_size = <span class="number">256</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># num_workers，使用4个进程来读取数据，根据CPU来进行选择；</span></span><br><span class="line"><span class="comment"># shuffle是否进行随机，一般情况下训练集进行随机，测试集不用</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_dataloader_worker</span>():</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line">train_iter = data.DataLoader(mnist_train, batch_size=batch_size, shuffle=<span class="literal">True</span>, </span><br><span class="line">                             num_workers=get_dataloader_worker())</span><br><span class="line">test_iter = data.DataLoader(mnist_test, batch_size=batch_size, shuffle=<span class="literal">False</span>, </span><br><span class="line">                            num_workers=get_dataloader_worker())</span><br><span class="line"></span><br><span class="line"><span class="comment"># train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)</span></span><br></pre></td></tr></tbody></table></figure><h3><span id="34-训练模型">3.4 训练模型</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate_accuracy_gpu</span>(<span class="params">net, data_iter, device=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">"""使用GPU计算模型在数据集上的精度"""</span></span><br><span class="line">    <span class="comment"># 获取模型的设备信息</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(net, nn.Module):</span><br><span class="line">        net.<span class="built_in">eval</span>()</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> device:</span><br><span class="line">            device = <span class="built_in">next</span>(<span class="built_in">iter</span>(net.parameters())).device</span><br><span class="line">    metric = d2l.Accumulator(<span class="number">2</span>) <span class="comment"># 累加器，方便计算所有batch的准确率</span></span><br><span class="line">    <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter:</span><br><span class="line">        <span class="comment"># 将数据信息加载到 模型所在设备上进行运算</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(X, <span class="built_in">list</span>):</span><br><span class="line">            X = [x.to(device) <span class="keyword">for</span> x <span class="keyword">in</span> X]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            X = X.to(device)</span><br><span class="line">        y = y.to(device)</span><br><span class="line">        metric.add(d2l.accuracy(net(X), y), y.numel())</span><br><span class="line">    <span class="comment"># 计算平均准确率</span></span><br><span class="line">    <span class="keyword">return</span> metric[<span class="number">0</span>] / metric[<span class="number">1</span>]</span><br></pre></td></tr></tbody></table></figure><p><code>numel</code>函数获取<code>tensor</code> 中一共包含多少个元素。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_ch6</span>(<span class="params">net, train_iter, test_iter, num_epochs, lr, device</span>):</span><br><span class="line">    <span class="string">"""用GPU训练模型"""</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_weights</span>(<span class="params">m</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">type</span>(m) == nn.Linear <span class="keyword">or</span> <span class="built_in">type</span>(m) == nn.Conv2d:</span><br><span class="line">            nn.init.xavier_uniform_(m.weight)</span><br><span class="line"></span><br><span class="line">    net.apply(init_weights)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">'training on'</span>, device)</span><br><span class="line">    net.to(device)</span><br><span class="line">    optimizer = torch.optim.SGD(net.parameters(), lr=lr)</span><br><span class="line">    loss = nn.CrossEntropyLoss()</span><br><span class="line">    animator = d2l.Animator(xlabel=<span class="string">'epoch'</span>, xlim=[<span class="number">1</span>, num_epochs],</span><br><span class="line">                            legend=[<span class="string">'train loss'</span>, <span class="string">'train acc'</span>, <span class="string">'test acc'</span>])</span><br><span class="line">    timer, num_batches = d2l.Timer(), <span class="built_in">len</span>(train_iter)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        metric = d2l.Accumulator(<span class="number">3</span>)</span><br><span class="line">        net.train()</span><br><span class="line">        <span class="keyword">for</span> i, (X, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_iter):</span><br><span class="line">            timer.start()</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            X, y = X.to(device), y.to(device)</span><br><span class="line">            y_hat = net(X)</span><br><span class="line">            l = loss(y_hat, y)</span><br><span class="line">            l.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                metric.add(l * X.shape[<span class="number">0</span>], d2l.accuracy(y_hat, y), X.shape[<span class="number">0</span>])</span><br><span class="line">            timer.stop()</span><br><span class="line">            train_l = metric[<span class="number">0</span>] / metric[<span class="number">2</span>]</span><br><span class="line">            train_acc = metric[<span class="number">1</span>] / metric[<span class="number">2</span>]</span><br><span class="line">            <span class="keyword">if</span> (i + <span class="number">1</span>) % (num_batches // <span class="number">5</span>) == <span class="number">0</span> <span class="keyword">or</span> i == num_batches - <span class="number">1</span>:</span><br><span class="line">                animator.add(epoch + (i + <span class="number">1</span>) / num_batches,</span><br><span class="line">                             (train_l, train_acc, <span class="literal">None</span>))</span><br><span class="line">        test_acc = evaluate_accuracy_gpu(net, test_iter)</span><br><span class="line">        animator.add(epoch + <span class="number">1</span>, (<span class="literal">None</span>, <span class="literal">None</span>, test_acc))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f'loss <span class="subst">{train_l:<span class="number">.3</span>f}</span>, train acc <span class="subst">{train_acc:<span class="number">.3</span>f}</span>, '</span></span><br><span class="line">          <span class="string">f'test acc <span class="subst">{test_acc:<span class="number">.3</span>f}</span>'</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f'<span class="subst">{metric[<span class="number">2</span>] * num_epochs / timer.<span class="built_in">sum</span>():<span class="number">.1</span>f}</span> examples/sec '</span></span><br><span class="line">          <span class="string">f'on <span class="subst">{<span class="built_in">str</span>(device)}</span>'</span>)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 训练和评估LeNet-5模型</span></span><br><span class="line">lr, num_epochs = <span class="number">0.9</span>, <span class="number">10</span></span><br><span class="line">train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">loss <span class="number">0.387</span>, train acc <span class="number">0.856</span>, test acc <span class="number">0.844</span></span><br><span class="line"><span class="number">16652.5</span> examples/sec on cuda:<span class="number">0</span></span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
          <category> 卷积神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 卷积神经网络 </tag>
            
            <tag> LeNet </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>markmap</title>
      <link href="/2022/04/12/markmap/"/>
      <url>/2022/04/12/markmap/</url>
      
        <content type="html"><![CDATA[<h1><span id="神经网络">神经网络</span></h1><h2><span id="卷积神经网络">卷积神经网络</span></h2><ul><li>卷积神经网络（LeNet）</li><li>深度卷积神经网络（AlexNet）</li><li>使用块的网络（VGG）</li><li>网络中的网络（NiN）</li><li>含并行连结的网络（GoogLeNet）</li><li>批量归一化（Batch Norm）</li><li>残差网络（ResNet）</li></ul><h2><span id="计算机视觉">计算机视觉</span></h2><h2><span id="循环神经网络">循环神经网络</span></h2><ul><li>循环神经网络（RNN）</li><li>门控循环单元（GRU）</li><li>长短期记忆网络（LSTM）</li><li>深层循环神经网络（Deep RNN）</li><li>双向循环神经网络</li><li>编码器-解码器结构（Encoder-Decoder）</li><li>序列到序列学习（seq2seq）</li><li>束搜索</li></ul><h2><span id="注意力机制">注意力机制</span></h2><ul><li>使用注意力机制的seq2seq</li><li>Transformer</li><li>BERT</li></ul><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode806</title>
      <link href="/2022/04/12/leetcode/mei-ri-yi-ti/leetcode806/"/>
      <url>/2022/04/12/leetcode/mei-ri-yi-ti/leetcode806/</url>
      
        <content type="html"><![CDATA[<h1><span id="806-写字符串需要的行数">806. 写字符串需要的行数</span></h1><blockquote><p><a href="https://leetcode-cn.com/problems/number-of-lines-to-write-string/">806. 写字符串需要的行数</a></p></blockquote><h2><span id="题目">题目</span></h2><p>我们要把给定的字符串 <code>S</code> 从左到右写到每一行上，每一行的最大宽度为 <code>100</code> 个单位，如果我们在写某个字母的时候会使这行超过了<code>100</code> 个单位，那么我们应该把这个字母写到下一行。我们给定了一个数组 <code>widths</code> ，这个数组 <code>widths[0]</code> 代表 ‘a’ 需要的单位， <code>widths[1]</code> 代表 ‘b’ 需要的单位，…， <code>widths[25]</code> 代表 ‘z’ 需要的单位。</p><p>现在回答两个问题：至少多少行能放下S，以及最后一行使用的宽度是多少个单位？将你的答案作为长度为2的整数列表返回。</p><p>示例 1:</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">输入: </span><br><span class="line">widths = [10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10]</span><br><span class="line">S = "abcdefghijklmnopqrstuvwxyz"</span><br><span class="line">输出: [3, 60]</span><br><span class="line">解释: </span><br><span class="line">所有的字符拥有相同的占用单位10。所以书写所有的26个字母，</span><br><span class="line">我们需要2个整行和占用60个单位的一行。</span><br></pre></td></tr></tbody></table></figure><p>示例 2:</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">输入: </span><br><span class="line">widths = [4,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10]</span><br><span class="line">S = "bbbcccdddaaa"</span><br><span class="line">输出: [2, 4]</span><br><span class="line">解释: </span><br><span class="line">除去字母'a'所有的字符都是相同的单位10，并且字符串 "bbbcccdddaa" 将会覆盖 9 * 10 + 2 * 4 = 98 个单位.</span><br><span class="line">最后一个字母 'a' 将会被写到第二行，因为第一行只剩下2个单位了。</span><br><span class="line">所以，这个答案是2行，第二行有4个单位宽度。</span><br></pre></td></tr></tbody></table></figure><h2><span id="解题思路">解题思路</span></h2><p>直接暴力方法</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">numberOfLines</span>(<span class="params">self, widths: <span class="type">List</span>[<span class="built_in">int</span>], s: <span class="built_in">str</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        MAX_WIDTH = <span class="number">100</span></span><br><span class="line">        lines, width = <span class="number">1</span>, <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> s:</span><br><span class="line">            need = widths[<span class="built_in">ord</span>(c) - <span class="built_in">ord</span>(<span class="string">'a'</span>)]</span><br><span class="line">            width += need</span><br><span class="line">            <span class="keyword">if</span> width &gt; MAX_WIDTH:</span><br><span class="line">                lines += <span class="number">1</span></span><br><span class="line">                width = need</span><br><span class="line">        <span class="keyword">return</span> [lines, width]</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> 难度-简单 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeetCode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode357</title>
      <link href="/2022/04/11/leetcode/mei-ri-yi-ti/leetcode357/"/>
      <url>/2022/04/11/leetcode/mei-ri-yi-ti/leetcode357/</url>
      
        <content type="html"><![CDATA[<h1><span id="357-统计各位数字都不同的数字个数">357. 统计各位数字都不同的数字个数</span></h1><blockquote><p><a href="https://leetcode-cn.com/problems/count-numbers-with-unique-digits/">357. 统计各位数字都不同的数字个数</a></p></blockquote><h2><span id="题目">题目</span></h2><p>给你一个整数 $n$ ，统计并返回各位数字都不同的数字 $x $ 的个数，其中 $0 &lt;= x &lt; 10^n$ 。</p><p>示例 1：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输入：n = 2</span><br><span class="line">输出：91</span><br><span class="line">解释：答案应为除去 11、22、33、44、55、66、77、88、99 外，在 0 ≤ x &lt; 100 范围内的所有数字。 </span><br></pre></td></tr></tbody></table></figure><p>示例 2：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入：n = 0</span><br><span class="line">输出：1</span><br></pre></td></tr></tbody></table></figure><h2><span id="解题思路">解题思路</span></h2><p>使用排列组合的方式解题，考虑三种情况，两种情况属于边界情况</p><ul><li><p><code>n = 0</code>时，只有一种情况符合，即<code>0</code>；</p></li><li><p><code>n=1</code>时，有<code>10</code>种选择，即<code>0~9</code>；</p></li><li><p>当<code>n&gt;=2</code>时，进行排列组合，有限考虑最高位的数，最高位只能是<code>1~9</code>，次高位为<code>0~9</code>去除与最高位相同的数字即可，有9种可能。所以n位全满的情况下</p><script type="math/tex; mode=display">f(n)=9*(9 - 2 + 2)*...*(9-n + 2)</script></li></ul><h3><span id="题解">题解</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">countNumbersWithUniqueDigits</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="keyword">if</span> n == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> n == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">10</span></span><br><span class="line">        res, cur = <span class="number">10</span>, <span class="number">9</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n - <span class="number">1</span>):</span><br><span class="line">            cur *= <span class="number">9</span> - i</span><br><span class="line">            res += cur</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> 难度-中等 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeetCode </tag>
            
            <tag> 分情况讨论 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode804</title>
      <link href="/2022/04/10/leetcode/mei-ri-yi-ti/leetcode804/"/>
      <url>/2022/04/10/leetcode/mei-ri-yi-ti/leetcode804/</url>
      
        <content type="html"><![CDATA[<h1><span id="804-唯一摩尔斯密码词">804. 唯一摩尔斯密码词</span></h1><blockquote><p><a href="https://leetcode-cn.com/problems/unique-morse-code-words/">804. 唯一摩尔斯密码词</a></p></blockquote><h2><span id="题目">题目</span></h2><p>国际摩尔斯密码定义一种标准编码方式，将每个字母对应于一个由一系列点和短线组成的字符串， 比如:</p><p><code>'a'</code> 对应<code>".-"</code> ，<br><code>'b'</code> 对应 <code>"-..."</code> ，<br><code>'c'</code> 对应 <code>"-.-."</code> ，以此类推。<br>为了方便，所有 <code>26</code> 个英文字母的摩尔斯密码表如下：</p><p><code>[".-","-...","-.-.","-..",".","..-.","--.","....","..",".---","-.-",".-..","--","-.","---",".--.","--.-",".-.","...","-","..-","...-",".--","-..-","-.--","--.."]</code><br>给你一个字符串数组 <code>words</code> ，每个单词可以写成每个字母对应摩尔斯密码的组合。</p><p>例如，<code>"cab"</code>可以写成 <code>"-.-..--..."</code> ，(即 <code>"-.-."</code> + <code>".-"</code> + <code>"-..."</code> 字符串的结合)。我们将这样一个连接过程称作 单词翻译 。<br>对 <code>words</code> 中所有单词进行单词翻译，返回不同 单词翻译 的数量。</p><p>例如：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">输入: words = ["gin", "zen", "gig", "msg"]</span><br><span class="line">输出: 2</span><br><span class="line">解释: </span><br><span class="line">各单词翻译如下:</span><br><span class="line">"gin" -&gt; "--...-."</span><br><span class="line">"zen" -&gt; "--...-."</span><br><span class="line">"gig" -&gt; "--...--."</span><br><span class="line">"msg" -&gt; "--...--."</span><br><span class="line"></span><br><span class="line">共有 2 种不同翻译, "--...-." 和 "--...--.".</span><br></pre></td></tr></tbody></table></figure><h2><span id="题解">题解</span></h2><p>使用hashset的方式求解，灵活运用<code>"".join(...)</code></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">uniqueMorseRepresentations</span>(<span class="params">self, words: <span class="type">List</span>[<span class="built_in">str</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        MORSE = [<span class="string">".-"</span>, <span class="string">"-..."</span>, <span class="string">"-.-."</span>, <span class="string">"-.."</span>, <span class="string">"."</span>, <span class="string">"..-."</span>, <span class="string">"--."</span>,</span><br><span class="line">                 <span class="string">"...."</span>, <span class="string">".."</span>, <span class="string">".---"</span>, <span class="string">"-.-"</span>, <span class="string">".-.."</span>, <span class="string">"--"</span>, <span class="string">"-."</span>,</span><br><span class="line">                 <span class="string">"---"</span>, <span class="string">".--."</span>, <span class="string">"--.-"</span>, <span class="string">".-."</span>, <span class="string">"..."</span>, <span class="string">"-"</span>, <span class="string">"..-"</span>,</span><br><span class="line">                 <span class="string">"...-"</span>, <span class="string">".--"</span>, <span class="string">"-..-"</span>, <span class="string">"-.--"</span>, <span class="string">"--.."</span>]</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(<span class="built_in">set</span>(<span class="string">""</span>.join(MORSE[<span class="built_in">ord</span>(ch) - <span class="built_in">ord</span>(<span class="string">'a'</span>)] <span class="keyword">for</span> ch <span class="keyword">in</span> word) <span class="keyword">for</span> word <span class="keyword">in</span> words))</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure><h2><span id="注意">注意：</span></h2><p><code>ord()</code>函数主要用来返回对应字符的<code>ascii码</code>，字符不可以直接进行加减运算。</p><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> 难度-简单 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeetCode </tag>
            
            <tag> HashSet </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>模型选择</title>
      <link href="/2022/04/10/mo-xing-xuan-ze/"/>
      <url>/2022/04/10/mo-xing-xuan-ze/</url>
      
        <content type="html"><![CDATA[<h1><span id="模型选择">模型选择</span></h1><h2><span id="1-模型选择">1. 模型选择</span></h2><h3><span id="11-训练误差和泛化误差">1.1 训练误差和泛化误差</span></h3><ul><li>训练误差：模型在训练数据上的误差；</li><li>泛化误差：模型在新数据上的误差</li></ul><h3><span id="12-验证集和测试集">1.2 验证集和测试集</span></h3><ul><li>验证集：一个用来评估模型好坏的数据集</li><li>测试集：只用一次的数据集</li></ul><h3><span id="13-k-则交叉验证">1.3 K-则交叉验证</span></h3><ul><li><p>在<strong>没有足够多的数据</strong>时使用（这是常态）</p></li><li><p>算法：</p><hr><p>a. 将训练数据分割成K块</p><p>b. <code>For i=1,...,K</code></p><pre><code>    使用第`i`块作为验证数据集，其余的作为训练集；</code></pre><p>c. 报告<code>K</code>个验证集误差的平均</p><hr></li></ul><ul><li>常用：K=5 or K=10</li></ul><h2><span id="2-过拟合和欠拟合">2. 过拟合和欠拟合</span></h2><p>下面表的表示模型的复杂度与数据之间的关系：</p><p>数据（简单、复杂）；模型容量（低、高）</p><div class="table-container"><table><thead><tr><th></th><th>简单</th><th>复杂</th></tr></thead><tbody><tr><td>低</td><td>正常</td><td>欠拟合</td></tr><tr><td>高</td><td>过拟合</td><td>正常</td></tr></tbody></table></div><p>一般根据数据的复杂程度来选择模型的容量。</p><h3><span id="21-模型容量">2.1 模型容量：</span></h3><ol><li>拟合各种函数的能力；</li><li>低容量的模型难以拟合训练数据；</li><li>高容量的模型可以记住所有的训练数据</li></ol><p>模型容量对误差的影响如下图所示：</p><p><img src="http://xiaomanzhan.com.cn/content/image-20220410232903776.png" alt="image-20220410232903776"></p><p>训练误差会一直下降，但是泛化误差会先下降后上升。</p><h3><span id="22-数据复杂度">2.2 数据复杂度</span></h3><ul><li>多个重要因素<ul><li>样本个数</li><li>每个样本的元素个数</li><li>时间、空间结构</li><li>多样性</li></ul></li></ul><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode780</title>
      <link href="/2022/04/09/leetcode/mei-ri-yi-ti/leetcode780/"/>
      <url>/2022/04/09/leetcode/mei-ri-yi-ti/leetcode780/</url>
      
        <content type="html"><![CDATA[<h1><span id="780-到达终点">780. 到达终点</span></h1><blockquote><p><a href="https://leetcode-cn.com/problems/reaching-points/">780. 到达终点</a></p></blockquote><h2><span id="题目">题目</span></h2><p>给定四个整数 <code>sx</code> , <code>sy</code> ，<code>tx</code> 和 <code>ty</code>，如果通过一系列的转换可以从起点 <code>(sx, sy)</code>到达终点 <code>(tx, ty)</code>，则返回 <code>true</code>，否则返回 <code>false</code>。从点 (x, y) 可以转换到<code>(x, x+y)</code> 或者 <code>(x+y, y)</code>。</p><p>示例 1:</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">输入: sx = 1, sy = 1, tx = 3, ty = 5</span><br><span class="line">输出: true</span><br><span class="line">解释:</span><br><span class="line">可以通过以下一系列转换从起点转换到终点：</span><br><span class="line">(1, 1) -&gt; (1, 2)</span><br><span class="line">(1, 2) -&gt; (3, 2)</span><br><span class="line">(3, 2) -&gt; (3, 5)</span><br></pre></td></tr></tbody></table></figure><p>示例 2:</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入: sx = 1, sy = 1, tx = 2, ty = 2 </span><br><span class="line">输出: false</span><br></pre></td></tr></tbody></table></figure><p>示例 3:</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入: sx = 1, sy = 1, tx = 1, ty = 1 </span><br><span class="line">输出: true</span><br></pre></td></tr></tbody></table></figure><h2><span id="解题思路一">解题思路一：</span></h2><p>使用动态规划的方式，进行深度优先搜索，以<code>p[][]</code>的方式对中间结果进行保存，判断<code>p[x][y]</code>是否能够变化为最终的终点坐标。</p><p>缺点：时间复杂度较高，当深度过大时，时间复杂度超标</p><h2><span id="解题思路二">解题思路二：</span></h2><p>使用反向计算的方式，看题找思路</p><p>如果从 <code>(sx,sy)</code> 开始正向计算，则可能的情况非常多，会超出时间限制。注意到 <code>sx</code>,<code>sy</code>,<code>tx</code>,<code>ty</code> 都是正整数，因此对于给定的状态 <code>(tx,ty)</code>，只有当 <code>tx!=ty</code> 时才存在上一个状态，且上一个状态唯一，可能的情况如下：</p><ul><li>如果 <code>tx=ty</code>，不存在上一个状态，状态 <code>(tx,ty)</code> 即为起点状态；</li><li>如果 <code>tx&gt;ty</code>，则上一个状态是 <code>(tx−ty,ty)</code>；</li><li>如果 <code>tx&lt;ty</code>，则上一个状态是 <code>(tx,ty−tx)</code>。</li></ul><p>同时注意，每次更新状态有可能只进行<code>x</code>上的更新，不对<code>y</code>更新，所以为了减少计算，需要将状态更新改为<code>tx=tx%ty</code></p><h3><span id="题解">题解</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reachingPoints</span>(<span class="params">self, sx: <span class="built_in">int</span>, sy: <span class="built_in">int</span>, tx: <span class="built_in">int</span>, ty: <span class="built_in">int</span></span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        <span class="keyword">while</span> sx &lt; tx != ty &gt; sy:</span><br><span class="line">            <span class="keyword">if</span> tx &gt; ty:</span><br><span class="line">                tx %= ty</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                ty %= tx</span><br><span class="line">        <span class="keyword">if</span> tx == sx <span class="keyword">and</span> ty == sy:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">elif</span> tx == sx:</span><br><span class="line">            <span class="keyword">return</span> ty &gt; sy <span class="keyword">and</span> (ty - sy) % tx == <span class="number">0</span> <span class="comment"># 注意如果直接使用 ty % tx == sy是不对的，因为ty % tx可能会出现余数为0的情况</span></span><br><span class="line">        <span class="keyword">elif</span> ty == sy:</span><br><span class="line">            <span class="keyword">return</span> tx &gt; sx <span class="keyword">and</span> (tx - sx) % ty == <span class="number">0</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> 难度-困难 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeetCode </tag>
            
            <tag> 找规律 </tag>
            
            <tag> 动态规划 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode429</title>
      <link href="/2022/04/08/leetcode/mei-ri-yi-ti/leetcode429/"/>
      <url>/2022/04/08/leetcode/mei-ri-yi-ti/leetcode429/</url>
      
        <content type="html"><![CDATA[<h1><span id="429-n-叉树的层序遍历">429. N 叉树的层序遍历</span></h1><blockquote><p><a href="https://leetcode-cn.com/problems/n-ary-tree-level-order-traversal/">429. N 叉树的层序遍历</a></p></blockquote><h2><span id="题目">题目</span></h2><p>给定一个 N 叉树，返回其节点值的<em>层序遍历</em>。（即从左到右，逐层遍历）。树的序列化输入是用层序遍历，每组子节点都由 null 值分隔（参见示例）。</p><p>示例1：</p><p><img src="http://xiaomanzhan.com.cn/content/narytreeexample.png" alt="img"></p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入：root = [1,null,3,2,4,null,5,6]</span><br><span class="line">输出：[[1],[3,2,4],[5,6]]</span><br></pre></td></tr></tbody></table></figure><p><img src="http://xiaomanzhan.com.cn/content/sample_4_964.png" alt="img"></p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入：root = [1,null,2,3,4,5,null,null,6,7,null,8,null,9,10,null,null,11,null,12,null,13,null,null,14]</span><br><span class="line">输出：[[1],[2,3,4,5],[6,7,8,9,10],[11,12,13],[14]]</span><br></pre></td></tr></tbody></table></figure><h2><span id="解题思路">解题思路</span></h2><p>使用广度优先搜索的方法，逐层访问记录</p><h3><span id="题解">题解</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string"># Definition for a Node.</span></span><br><span class="line"><span class="string">class Node:</span></span><br><span class="line"><span class="string">    def __init__(self, val=None, children=None):</span></span><br><span class="line"><span class="string">        self.val = val</span></span><br><span class="line"><span class="string">        self.children = children</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">levelOrder</span>(<span class="params">self, root: <span class="string">'Node'</span></span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span><br><span class="line">        <span class="keyword">if</span> root <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line">        res = [[root.val]]</span><br><span class="line">        q = deque([root])</span><br><span class="line">        <span class="keyword">while</span> q:</span><br><span class="line">            res_cur = []</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(q)):</span><br><span class="line">                node = q.popleft()</span><br><span class="line">                <span class="keyword">for</span> n <span class="keyword">in</span> node.children:</span><br><span class="line">                    q.append(n)</span><br><span class="line">                    res_cur.append(n.val)</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(res_cur) &gt; <span class="number">0</span>:</span><br><span class="line">                res.append(res_cur)</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> 难度-中等 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeetCode </tag>
            
            <tag> 广度优先搜索 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode796</title>
      <link href="/2022/04/07/leetcode/mei-ri-yi-ti/leetcode796/"/>
      <url>/2022/04/07/leetcode/mei-ri-yi-ti/leetcode796/</url>
      
        <content type="html"><![CDATA[<h1><span id="796-旋转字符串">796. 旋转字符串</span></h1><blockquote><p><a href="https://leetcode-cn.com/problems/rotate-string/">796. 旋转字符串</a></p></blockquote><h2><span id="题目">题目</span></h2><p>给定两个字符串, s 和 goal。如果在若干次旋转操作之后，s 能变成 goal ，那么返回 true 。s 的旋转操作就是将 s 最左边的字符移动到最右边。 </p><p>例如, 若 s = ‘abcde’，在旋转一次之后结果就是’bcdea’ 。</p><p>示例 1:</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入: s = "abcde", goal = "cdeab"</span><br><span class="line">输出: true</span><br></pre></td></tr></tbody></table></figure><p>示例 2:</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入: s = "abcde", goal = "abced"</span><br><span class="line">输出: false</span><br></pre></td></tr></tbody></table></figure><h2><span id="思路一">思路一</span></h2><p>直接使用遍历的方式，旋转一遍判断是否存在。</p><h3><span id="题解">题解</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">rotateString</span>(<span class="params">self, s: <span class="built_in">str</span>, goal: <span class="built_in">str</span></span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(s) != <span class="built_in">len</span>(goal):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="keyword">if</span> s == goal:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(s)):</span><br><span class="line">            <span class="keyword">if</span> goal == s[i:] + s[<span class="number">0</span>:i]:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></tbody></table></figure><h2><span id="思路二">思路二</span></h2><p>因为旋转可以相当于两个一模一样的字符串进行拼接的一个子串，所以只要确定<code>goal</code>字符串是否为<code>s+s</code>的一部分即可。</p><h3><span id="题解">题解</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">rotateString</span>(<span class="params">self, s: <span class="built_in">str</span>, goal: <span class="built_in">str</span></span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        <span class="keyword">return</span> (goal <span class="keyword">in</span> s + s) <span class="keyword">if</span> <span class="built_in">len</span>(s) == <span class="built_in">len</span>(goal) <span class="keyword">else</span> <span class="literal">False</span></span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> 难度-简单 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeetCode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode310</title>
      <link href="/2022/04/06/leetcode/mei-ri-yi-ti/leetcode310/"/>
      <url>/2022/04/06/leetcode/mei-ri-yi-ti/leetcode310/</url>
      
        <content type="html"><![CDATA[<h1><span id="310-最小高度树">310. 最小高度树</span></h1><blockquote><p><a href="https://leetcode-cn.com/problems/minimum-height-trees/">310. 最小高度树</a></p></blockquote><h2><span id="题目">题目</span></h2><p>树是一个无向图，其中任何两个顶点只通过一条路径连接。 换句话说，一个任何没有简单环路的连通图都是一棵树。</p><p>给你一棵包含 n 个节点的树，标记为 0 到 n - 1 。给定数字 n 和一个有 n - 1 条无向边的 edges 列表（每一个边都是一对标签），其中 edges[i] = [ai, bi] 表示树中节点 ai 和 bi 之间存在一条无向边。可选择树中任何一个节点作为根。当选择节点 x 作为根节点时，设结果树的高度为 h 。在所有可能的树中，具有最小高度的树（即，min(h)）被称为 最小高度树 。</p><p>请你找到所有的 最小高度树 并按 任意顺序 返回它们的根节点标签列表。树的高度是指根节点和叶子节点之间最长向下路径上边的数量。</p><p><img src="http://xiaomanzhan.com.cn/content/e1.jpg" alt="img"></p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输入：n = 4, edges = [[1,0],[1,2],[1,3]]</span><br><span class="line">输出：[1]</span><br><span class="line">解释：如图所示，当根是标签为 1 的节点时，树的高度是 1 ，这是唯一的最小高度树。</span><br></pre></td></tr></tbody></table></figure><p><img src="http://xiaomanzhan.com.cn/content/e2.jpg" alt="img"></p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入：n = 6, edges = [[3,0],[3,1],[3,2],[3,4],[5,4]]</span><br><span class="line">输出：[3,4]</span><br></pre></td></tr></tbody></table></figure><h2><span id="思路一">思路一</span></h2><p>使用广度优先搜索，解本题之前需要知道两个点：</p><ul><li>假设树中距离最长的两个节点为 $(x,y)$，它们之间的距离为 $dist[x][y]$，则可以推出以任意节点构成的树最小高度一定为 $\textit{minheight} = \Big \lceil \dfrac{\textit{maxdist}}{2} \Big \rceil$，且最小高度的树根节点一定在 节点 x 到节点 y 的路径上。根据路径长度 $m=maxdist$，可根据奇偶进行划分，寻找最终解，注意下标从 0 计算<ul><li>m 为偶数时，最小高度为 $\frac{m}{2}$，最小高度树的根节点为 $p_{\frac{m}{2}}$ 和 $p_{\frac{m}{2} - 1}$；</li><li>m 为奇数时，最小高度为 $\frac{m}{2}$，最小高度树的根节点为 $p_{\frac{m}{2}}$ ；</li></ul></li><li>寻找图中距离最远的两个节点与它们之间的路径算法<ol><li>以任意节点 <em>p</em> 出现，利用广度优先搜索或者深度优先搜索找到以 <em>p</em> 为起点的最长路径的终点 <em>x</em>；</li><li>以节点 <em>x</em> 出发，找到以 <em>x</em> 为起点的最长路径的终点 <em>y</em>；</li><li><em>x</em> 到 <em>y</em> 之间的路径即为图中的最长路径，找到路径的中间节点即为根节点。</li></ol></li></ul><h3><span id="题解">题解</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">findMinHeightTrees</span>(<span class="params">self, n: <span class="built_in">int</span>, edges: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        <span class="keyword">if</span> n == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> [<span class="number">0</span>]</span><br><span class="line">        g = [[] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">        <span class="keyword">for</span> x, y <span class="keyword">in</span> edges:</span><br><span class="line">            g[x].append(y)</span><br><span class="line">            g[y].append(x)</span><br><span class="line">        parents = [<span class="number">0</span>] * n</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">bfs</span>(<span class="params">s: <span class="built_in">int</span></span>):</span><br><span class="line">            q = deque([s])</span><br><span class="line">            flags = [<span class="literal">True</span>] * n</span><br><span class="line">            flags[s] = <span class="literal">False</span></span><br><span class="line">            <span class="keyword">while</span> q:</span><br><span class="line">                x = q.popleft()</span><br><span class="line">                <span class="keyword">for</span> y <span class="keyword">in</span> g[x]:</span><br><span class="line">                    <span class="keyword">if</span> flags[y]:</span><br><span class="line">                        q.append(y)</span><br><span class="line">                        parents[y] = x</span><br><span class="line">                        flags[y] = <span class="literal">False</span></span><br><span class="line">            <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">        x = bfs(<span class="number">0</span>)  <span class="comment"># 找到与节点 0 最远的节点 x</span></span><br><span class="line">        y = bfs(x)  <span class="comment"># 找到与节点 x 最远的节点 y</span></span><br><span class="line">        path = []</span><br><span class="line">        parents[x] = -<span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> y != -<span class="number">1</span>:</span><br><span class="line">            path.append(y)</span><br><span class="line">            y = parents[y]</span><br><span class="line">        max_len = <span class="built_in">len</span>(path)</span><br><span class="line">        <span class="keyword">return</span> [path[max_len // <span class="number">2</span>]] <span class="keyword">if</span> max_len % <span class="number">2</span> == <span class="number">1</span> <span class="keyword">else</span> [path[max_len // <span class="number">2</span> - <span class="number">1</span>], path[max_len // <span class="number">2</span>]]</span><br></pre></td></tr></tbody></table></figure><h2><span id="思路二">思路二</span></h2><p>使用深度优先搜索，解法和上述一致</p><h3><span id="题解">题解</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">findMinHeightTrees</span>(<span class="params">self, n: <span class="built_in">int</span>, edges: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        <span class="keyword">if</span> n == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> [<span class="number">0</span>]</span><br><span class="line">        g = [[] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">        <span class="keyword">for</span> x, y <span class="keyword">in</span> edges:</span><br><span class="line">            g[x].append(y)</span><br><span class="line">            g[y].append(x)</span><br><span class="line">        parents = [<span class="number">0</span>] * n</span><br><span class="line">        max_depth, node = <span class="number">0</span>, -<span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">dfs</span>(<span class="params">x: <span class="built_in">int</span>, pa: <span class="built_in">int</span>, depth: <span class="built_in">int</span></span>):</span><br><span class="line">            <span class="keyword">nonlocal</span> max_depth, node</span><br><span class="line">            <span class="keyword">if</span> depth &gt; max_depth:</span><br><span class="line">                max_depth, node = depth, x</span><br><span class="line">            parents[x] = pa</span><br><span class="line">            <span class="keyword">for</span> y <span class="keyword">in</span> g[x]:</span><br><span class="line">                <span class="keyword">if</span> y != pa:</span><br><span class="line">                    dfs(y, x, depth + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        dfs(<span class="number">0</span>, -<span class="number">1</span>, <span class="number">0</span>)   <span class="comment"># 找到与节点 0 最远的节点 x</span></span><br><span class="line">        max_depth = <span class="number">0</span></span><br><span class="line">        dfs(node, -<span class="number">1</span>, <span class="number">0</span>)   <span class="comment"># 找到与节点 x 最远的节点 y</span></span><br><span class="line">        path = []</span><br><span class="line">        <span class="keyword">while</span> node != -<span class="number">1</span>:</span><br><span class="line">            path.append(node)</span><br><span class="line">            node = parents[node]</span><br><span class="line">        max_len = <span class="built_in">len</span>(path)</span><br><span class="line">        <span class="keyword">return</span> [path[max_len // <span class="number">2</span>]] <span class="keyword">if</span> max_len % <span class="number">2</span> == <span class="number">1</span> <span class="keyword">else</span> [path[max_len // <span class="number">2</span> - <span class="number">1</span>], path[max_len // <span class="number">2</span>]]</span><br></pre></td></tr></tbody></table></figure><h2><span id="思路三">思路三</span></h2><p>使用拓扑排序的方式进行层层剥削，直到最后只剩余一个或者两个节点的时候停止。每次剥削掉最外层的节点，不断深入。</p><h3><span id="题解">题解</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">findMinHeightTrees</span>(<span class="params">self, n: <span class="built_in">int</span>, edges: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        <span class="keyword">if</span> n == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> [<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> n == <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">return</span> [<span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">        g = [[] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">        deg = [<span class="number">0</span>] * n</span><br><span class="line">        remain_node = n</span><br><span class="line">        <span class="keyword">for</span> x, y <span class="keyword">in</span> edges:</span><br><span class="line">            g[x].append(y)</span><br><span class="line">            g[y].append(x)</span><br><span class="line">            deg[x] += <span class="number">1</span></span><br><span class="line">            deg[y] += <span class="number">1</span></span><br><span class="line">        <span class="comment"># 取出第一次度为1的坐标</span></span><br><span class="line">        deg_1 = [i <span class="keyword">for</span> i, d <span class="keyword">in</span> <span class="built_in">enumerate</span>(deg) <span class="keyword">if</span> d == <span class="number">1</span>]</span><br><span class="line">        <span class="keyword">while</span> remain_node &gt; <span class="number">2</span>:</span><br><span class="line">            remain_node -= <span class="built_in">len</span>(deg_1)</span><br><span class="line">            t = deg_1</span><br><span class="line">            deg_1 = []</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> t:</span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> g[i]:</span><br><span class="line">                    deg[j] -= <span class="number">1</span></span><br><span class="line">                    <span class="keyword">if</span> deg[j] == <span class="number">1</span>:</span><br><span class="line">                        deg_1.append(j)</span><br><span class="line">        <span class="keyword">return</span> deg_1</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> 难度-中等 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeetCode </tag>
            
            <tag> 拓扑排序 </tag>
            
            <tag> 深度有限搜索 </tag>
            
            <tag> 广度优先搜索 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode762</title>
      <link href="/2022/04/05/leetcode/mei-ri-yi-ti/leetcode762/"/>
      <url>/2022/04/05/leetcode/mei-ri-yi-ti/leetcode762/</url>
      
        <content type="html"><![CDATA[<h1><span id="762-二进制表示中质数个计算置位">762. 二进制表示中质数个计算置位</span></h1><blockquote><p><a href="https://leetcode-cn.com/problems/prime-number-of-set-bits-in-binary-representation/">762. 二进制表示中质数个计算置位</a></p></blockquote><h2><span id="题目">题目</span></h2><p>给你两个整数 left 和 right ，在闭区间 [left, right] 范围内，统计并返回 计算置位位数为质数 的整数个数。计算<strong>置位位数</strong> 就是二进制表示中 1 的个数。</p><ul><li>例如， 21 的二进制表示 10101 有 3 个计算置位。</li></ul><p>示例 1：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">输入：left = 6, right = 10</span><br><span class="line">输出：4</span><br><span class="line">解释：</span><br><span class="line">6 -&gt; 110 (2 个计算置位，2 是质数)</span><br><span class="line">7 -&gt; 111 (3 个计算置位，3 是质数)</span><br><span class="line">9 -&gt; 1001 (2 个计算置位，2 是质数)</span><br><span class="line">10-&gt; 1010 (2 个计算置位，2 是质数)</span><br><span class="line">共计 4 个计算置位为质数的数字。</span><br></pre></td></tr></tbody></table></figure><p>示例 2：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">输入：left = 10, right = 15</span><br><span class="line">输出：5</span><br><span class="line">解释：</span><br><span class="line">10 -&gt; 1010 (2 个计算置位, 2 是质数)</span><br><span class="line">11 -&gt; 1011 (3 个计算置位, 3 是质数)</span><br><span class="line">12 -&gt; 1100 (2 个计算置位, 2 是质数)</span><br><span class="line">13 -&gt; 1101 (3 个计算置位, 3 是质数)</span><br><span class="line">14 -&gt; 1110 (3 个计算置位, 3 是质数)</span><br><span class="line">15 -&gt; 1111 (4 个计算置位, 4 不是质数)</span><br><span class="line">共计 5 个计算置位为质数的数字。</span><br></pre></td></tr></tbody></table></figure><h2><span id="思路一">思路一</span></h2><ol><li>求区间每个数的二进制中1的个数 t；</li><li>判断个数 t 是否为质数</li></ol><h3><span id="题解">题解</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">countPrimeSetBits</span>(<span class="params">self, left: <span class="built_in">int</span>, right: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">isPrime</span>(<span class="params">x: <span class="built_in">int</span></span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">            <span class="keyword">if</span> x &lt; <span class="number">2</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">            i = <span class="number">2</span></span><br><span class="line">            <span class="keyword">while</span> i * i &lt;= x:</span><br><span class="line">                <span class="keyword">if</span> x % i == <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">bitcount_</span>(<span class="params">x: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">            c = <span class="number">0</span></span><br><span class="line">            <span class="keyword">while</span> x:</span><br><span class="line">                <span class="keyword">if</span> x % <span class="number">2</span> != <span class="number">0</span>:</span><br><span class="line">                    c += <span class="number">1</span></span><br><span class="line">                x //= <span class="number">2</span></span><br><span class="line">            <span class="keyword">return</span> c</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">sum</span>([isPrime(bitcount_(x)) <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(left, right + <span class="number">1</span>)])</span><br></pre></td></tr></tbody></table></figure><h2><span id="思路二">思路二</span></h2><p>利用一个<code>mask</code>来判断质数</p><p>注意到 $right \le 10^6 &lt; 2^20$，因此二进制中 1 的个数不会超过 19，而不超过 19 的质数只有</p><p>2, 3, 5, 7, 11, 13, 17, 19</p><p>我们可以用一个二进制数 $mask=665772=(10100010100010101100)_2$ 来存储这些质数，其中 $mask$ 二进制的从低到高的第 i 位为 1 表示 i 是质数，为 0 表示 i 不是质数。</p><p>设整数 x 的二进制中 1 的个数为 c，若  $mask$ 按位与 $ 2^c $ 不为 0，则说明 c 是一个质数。</p><h3><span id="题解">题解</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">countPrimeSetBits</span>(<span class="params">self, left: <span class="built_in">int</span>, right: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">sum</span>(((<span class="number">1</span> &lt;&lt; x.bit_count()) &amp; <span class="number">665772</span>) != <span class="number">0</span> <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(left, right + <span class="number">1</span>))</span><br></pre></td></tr></tbody></table></figure><p>参考资料：<a href="https://leetcode-cn.com/problems/prime-number-of-set-bits-in-binary-representation/solution/er-jin-zhi-biao-shi-zhong-zhi-shu-ge-ji-jy35g/">LeetCode题解</a></p><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> 难度-简单 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeetCode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>树状数组模板</title>
      <link href="/2022/04/05/basic-algorithm/shu-zhuang-shu-zu/"/>
      <url>/2022/04/05/basic-algorithm/shu-zhuang-shu-zu/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="树状数组模板">树状数组模板</span></h1><h2><span id="1-问题引入">1. 问题引入</span></h2><p>给出一个数组$nums$，完成以下操作</p><ul><li>将$index$上的数加上$val$</li><li>输出区间 $[l, r]$内每个数的和</li></ul><h2><span id="2-前置知识">2. 前置知识</span></h2><p>$lowbit(x)$ 运算，表示非负整数 $n$ 在二进制表示下最低位$1$及其后面的$0$构成的数值。</p><p>例如：$lowbit(44)=lowbit((101100)_2)=(100)_2=4$</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">  1 0 1 1 0 0 (1)</span><br><span class="line">取反   0 1 0 0 1 1(2)</span><br><span class="line">加一   0 1 0 1 0 0(3)</span><br><span class="line">与操作 0 0 0 1 0 0   (4) 将(1)(3)进行与操作</span><br></pre></td></tr></tbody></table></figure><p>即 $lowbit(x) = x \&amp; (-x + 1)$</p><p>因为在计算机中是进行补码操作，所以 $lowbit(x) = x \&amp; -x$</p><h2><span id="3-树状数组">3. 树状数组</span></h2><p>区间查询 =&gt; 前缀和 =&gt; 树结构维护，时间复杂度为 $O(log_2n)$</p><p>对于一个序列需要建立一个这样的结构：</p><ol><li>节点 $t[x]$ 保存以 $x$ 为根的子树中叶节点值的和，并将 $x$ 转化为二进制。</li></ol><p><img src="http://xiaomanzhan.com.cn/content/image-20220405163931678.png" alt="image-20220405163931678"></p><ol><li>计算 $lowbit(x)$ ，$t[x]$ 节点的长度就是 $lowbit(x)$</li></ol><p><img src="http://xiaomanzhan.com.cn/content/image-20220405164145452.png" alt="image-20220405164145452"></p><ol><li>观察上面存在的规律<ol><li>$t[x]$ 节点的父节点为 $ t[x+lowbit(x)]$</li><li>$t[x]=\sum^x_{i=x-lowbit(x)+1}nums[i]$</li><li>整棵树的深度为 $log_2n + 1$</li></ol></li><li>$add$ 操作</li></ol><p>以$add(index=3,\ val=5)$ 为例</p><p><img src="http://xiaomanzhan.com.cn/content/image-20220405164631676.png" alt="image-20220405164631676"></p><p>代码如下：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">index: <span class="built_in">int</span>, val: <span class="built_in">int</span></span>):</span><br><span class="line">    <span class="keyword">while</span> index &lt;= n:</span><br><span class="line">        t[index] += val</span><br><span class="line">        <span class="comment"># index += lowbit(x)</span></span><br><span class="line">        index += index &amp; -index</span><br></pre></td></tr></tbody></table></figure><ol><li>$ask(x)$操作-前缀和操作</li></ol><p>以$ask(index=7)$ 为例</p><p><img src="http://xiaomanzhan.com.cn/content/image-20220405165103162.png" alt="image-20220405165103162"></p><p>代码如下：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">ask</span>(<span class="params">index: <span class="built_in">int</span></span>):</span><br><span class="line">    ans = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> index:</span><br><span class="line">        ans += t[index]</span><br><span class="line">        <span class="comment"># index -= lowbit(x)</span></span><br><span class="line">        index -= index &amp; -index</span><br><span class="line">    <span class="keyword">return</span> ans</span><br></pre></td></tr></tbody></table></figure><h2><span id="4-代码总结">4. 代码总结</span></h2><ol><li><p>单点修改，查询前缀和</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">index: <span class="built_in">int</span>, val: <span class="built_in">int</span></span>):</span><br><span class="line">    <span class="keyword">while</span> index &lt;= n:</span><br><span class="line">        t[index] += val</span><br><span class="line">        <span class="comment"># index += lowbit(x)</span></span><br><span class="line">        index += index &amp; -index</span><br><span class="line">        </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ask</span>(<span class="params">index: <span class="built_in">int</span></span>):</span><br><span class="line">    ans = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> index:</span><br><span class="line">        ans += t[index]</span><br><span class="line">        <span class="comment"># index -= lowbit(x)</span></span><br><span class="line">        index -= index &amp; -index</span><br><span class="line">    <span class="keyword">return</span> ans</span><br><span class="line"></span><br><span class="line"><span class="comment"># add(x, k)</span></span><br><span class="line"><span class="comment"># ask(x)</span></span><br></pre></td></tr></tbody></table></figure></li><li><p>单点修改，单点查询</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># add(x, k)</span></span><br><span class="line"><span class="comment"># ask(x) - ask(x - 1)</span></span><br></pre></td></tr></tbody></table></figure></li><li><p>单点修改，区间查询</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># add(x, k)</span></span><br><span class="line"><span class="comment"># ask(r) - ask(l - 1)</span></span><br></pre></td></tr></tbody></table></figure><p>参考地址: <a href="https://www.bilibili.com/video/BV1pE41197Qj?spm_id_from=333.337.search-card.all.click">https://www.bilibili.com/video/BV1pE41197Qj?spm_id_from=333.337.search-card.all.click</a></p></li></ol><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> 数论问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode307</title>
      <link href="/2022/04/04/leetcode/mei-ri-yi-ti/leetcode307/"/>
      <url>/2022/04/04/leetcode/mei-ri-yi-ti/leetcode307/</url>
      
        <content type="html"><![CDATA[<h1><span id="307-区域和检索-数组可修改">307. 区域和检索 - 数组可修改</span></h1><h2><span id="题目">题目</span></h2><p>给你一个数组 nums ，请你完成两类查询。</p><ol><li>其中一类查询要求 更新 数组 nums 下标对应的值</li><li>另一类查询要求返回数组 nums 中索引 left 和索引 right 之间（ 包含 ）的nums元素的 和 ，其中 left &lt;= right</li></ol><p>实现 NumArray 类：</p><ul><li>NumArray(int[] nums) 用整数数组 nums 初始化对象</li><li>void update(int index, int val) 将 nums[index] 的值 更新 为 val</li><li>int sumRange(int left, int right) 返回数组 nums 中索引 left 和索引 right 之间（ 包含 ）的nums元素的 和 （即，nums[left] + nums[left + 1], …, nums[right]）</li></ul><p>示例 1：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">输入：</span><br><span class="line">["NumArray", "sumRange", "update", "sumRange"]</span><br><span class="line">[[[1, 3, 5]], [0, 2], [1, 2], [0, 2]]</span><br><span class="line">输出：</span><br><span class="line">[null, 9, null, 8]</span><br><span class="line"></span><br><span class="line">解释：</span><br><span class="line">NumArray numArray = new NumArray([1, 3, 5]);</span><br><span class="line">numArray.sumRange(0, 2); // 返回 1 + 3 + 5 = 9</span><br><span class="line">numArray.update(1, 2);   // nums = [1,2,5]</span><br><span class="line">numArray.sumRange(0, 2); // 返回 1 + 2 + 5 = 8</span><br></pre></td></tr></tbody></table></figure><h2><span id="思路一">思路一</span></h2><p>==<strong>分块处理</strong>==，将数组分为大小为size的块，即块的总数为 $\lceil x \rceil$，用一个数组sums保存每个块的元素和，size取$\sqrt{len(nums)}$即可。更新块的时候只需要更新对应的块即可。下标index对应的块的下标为 $\lfloor \frac{index}{size} \rfloor$。</p><h3><span id="题解">题解</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">NumArray</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>):</span><br><span class="line">        n = <span class="built_in">len</span>(nums)</span><br><span class="line">        size = <span class="built_in">int</span>(n ** <span class="number">0.5</span>)</span><br><span class="line">        sums = [<span class="number">0</span>] * ((n + size - <span class="number">1</span>) // size)  <span class="comment"># 需要记住向上取整的操作</span></span><br><span class="line">        <span class="keyword">for</span> i, num <span class="keyword">in</span> <span class="built_in">enumerate</span>(nums):</span><br><span class="line">            sums[i // size] += num</span><br><span class="line">        self.sums = sums</span><br><span class="line">        self.nums = nums</span><br><span class="line">        self.size = size</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, index: <span class="built_in">int</span>, val: <span class="built_in">int</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        self.sums[index // self.size] += val - self.nums[index]</span><br><span class="line">        self.nums[index] = val</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sumRange</span>(<span class="params">self, left: <span class="built_in">int</span>, right: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        b1 = left // self.size</span><br><span class="line">        b2 = right // self.size</span><br><span class="line">        <span class="keyword">if</span> b1 == b2:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">sum</span>(self.nums[left: right + <span class="number">1</span>])</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">sum</span>(self.nums[left: (b1 + <span class="number">1</span>) * self.size]) + \</span><br><span class="line">               <span class="built_in">sum</span>(self.sums[b1 + <span class="number">1</span>: b2]) + \</span><br><span class="line">               <span class="built_in">sum</span>(self.nums[b2 * self.size: right + <span class="number">1</span>])</span><br></pre></td></tr></tbody></table></figure><h2><span id="思路二">思路二</span></h2><p>==<strong>构建线段树</strong>==，每个节点保存三个数据（起始节点位置，起始节点之间的数据信息和）。本题中出现了修改和求和操作，构建update递归函数对线段树进行修改操作，构建range递归函数对线段树进行范围求和操作。</p><p><strong>时间复杂度：</strong></p><ul><li>构造函数：$O(n)$</li><li>修改函数：$O(logn)$</li><li>范围求和函数：$O(logn)$</li></ul><p>空间复杂度：$O(n)$，只需要计算保存线段树的空间即可。</p><h3><span id="题解">题解</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">NumArray</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>):</span><br><span class="line">        n = <span class="built_in">len</span>(nums)</span><br><span class="line">        self.n = n</span><br><span class="line">        self.seg = [<span class="number">0</span>] * (n * <span class="number">4</span>)</span><br><span class="line">        self.build(nums, <span class="number">0</span>, <span class="number">0</span>, self.n - <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">build</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], node: <span class="built_in">int</span>, s: <span class="built_in">int</span>, e: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="keyword">if</span> s == e:</span><br><span class="line">            self.seg[node] = nums[s]</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        m = (s + e) // <span class="number">2</span></span><br><span class="line">        self.build(nums, node * <span class="number">2</span> + <span class="number">1</span>, s, m)</span><br><span class="line">        self.build(nums, node * <span class="number">2</span> + <span class="number">2</span>, m + <span class="number">1</span>, e)</span><br><span class="line">        self.seg[node] = self.seg[node * <span class="number">2</span> + <span class="number">1</span>] + self.seg[node * <span class="number">2</span> + <span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">change</span>(<span class="params">self, index: <span class="built_in">int</span>, val: <span class="built_in">int</span>, node: <span class="built_in">int</span>, s: <span class="built_in">int</span>, e: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="keyword">if</span> s == e:</span><br><span class="line">            self.seg[node] = val</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        m = (s + e) // <span class="number">2</span></span><br><span class="line">        <span class="keyword">if</span> index &lt;= m:</span><br><span class="line">            self.change(index, val, node * <span class="number">2</span> + <span class="number">1</span>, s, m)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.change(index, val, node * <span class="number">2</span> + <span class="number">2</span>, m + <span class="number">1</span>, e)</span><br><span class="line">        self.seg[node] = self.seg[node * <span class="number">2</span> + <span class="number">1</span>] + self.seg[node * <span class="number">2</span> + <span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">range</span>(<span class="params">self, left: <span class="built_in">int</span>, right: <span class="built_in">int</span>, node: <span class="built_in">int</span>, s: <span class="built_in">int</span>, e: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="keyword">if</span> left == s <span class="keyword">and</span> right == e:</span><br><span class="line">            <span class="keyword">return</span> self.seg[node]</span><br><span class="line">        m = (s + e) // <span class="number">2</span></span><br><span class="line">        <span class="keyword">if</span> right &lt;= m:</span><br><span class="line">            <span class="keyword">return</span> self.<span class="built_in">range</span>(left, right, node * <span class="number">2</span> + <span class="number">1</span>, s, m)</span><br><span class="line">        <span class="keyword">if</span> left &gt; m:</span><br><span class="line">            <span class="keyword">return</span> self.<span class="built_in">range</span>(left, right, node * <span class="number">2</span> + <span class="number">2</span>, m + <span class="number">1</span>, e)</span><br><span class="line">        <span class="keyword">return</span> self.<span class="built_in">range</span>(left, m, node * <span class="number">2</span> + <span class="number">1</span>, s, m) + self.<span class="built_in">range</span>(m + <span class="number">1</span>, right, node * <span class="number">2</span> + <span class="number">2</span>, m + <span class="number">1</span>, e)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, index: <span class="built_in">int</span>, val: <span class="built_in">int</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        self.change(index, val, <span class="number">0</span>, <span class="number">0</span>, self.n - <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sumRange</span>(<span class="params">self, left: <span class="built_in">int</span>, right: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="keyword">return</span> self.<span class="built_in">range</span>(left, right, <span class="number">0</span>, <span class="number">0</span>, self.n - <span class="number">1</span>)</span><br></pre></td></tr></tbody></table></figure><h2><span id="思路三">思路三</span></h2><p>使用树状数组进行解题。参考：<a href="http://xiaomanzhan.club/2022/04/05/basic-algorithm-template/shu-zhuang-shu-zu-mo-ban/">树状数组模板</a></p><h3><span id="题解">题解</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">NumArray</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>):</span><br><span class="line">        self.nums = nums</span><br><span class="line">        self.tree = [<span class="number">0</span>] * (<span class="built_in">len</span>(nums) + <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">for</span> i, num <span class="keyword">in</span> <span class="built_in">enumerate</span>(nums, <span class="number">1</span>):</span><br><span class="line">            self.add(i, num)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">self, index: <span class="built_in">int</span>, val: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="keyword">while</span> index &lt;= <span class="built_in">len</span>(self.nums):</span><br><span class="line">            self.tree[index] += val</span><br><span class="line">            index += index &amp; -index</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">ask</span>(<span class="params">self, index</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        ans = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> index:</span><br><span class="line">            ans += self.tree[index]</span><br><span class="line">            index -= index &amp; -index</span><br><span class="line">        <span class="keyword">return</span> ans</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, index: <span class="built_in">int</span>, val: <span class="built_in">int</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        self.add(index + <span class="number">1</span>, val - self.nums[index])</span><br><span class="line">        self.nums[index] = val</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sumRange</span>(<span class="params">self, left: <span class="built_in">int</span>, right: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="keyword">return</span> self.ask(right + <span class="number">1</span>) - self.ask(left)</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> 难度-中等 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeetCode </tag>
            
            <tag> 区域检索 </tag>
            
            <tag> 分块处理 </tag>
            
            <tag> 线段树 </tag>
            
            <tag> 树状数组 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>面试题</title>
      <link href="/2022/04/03/leetcode/mian-shi-ti/"/>
      <url>/2022/04/03/leetcode/mian-shi-ti/</url>
      
        <content type="html"><![CDATA[<h1><span id="面试题">面试题</span></h1><h2><span id="面试题-0812">面试题 08.12</span></h2><blockquote><p><a href="https://leetcode-cn.com/problems/eight-queens-lcci/">面试题 08.12. 八皇后</a></p></blockquote><p>设计一种算法，打印 N 皇后在 N × N 棋盘上的各种摆法，其中每个皇后都不同行、不同列，也不在对角线上。这里的“对角线”指的是所有的对角线，不只是平分整个棋盘的那两条对角线。</p><p>注意：本题相对原题做了扩展</p><p>示例:</p> <figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">输入：4</span><br><span class="line"> 输出：[[".Q..","...Q","Q...","..Q."],["..Q.","Q...","...Q",".Q.."]]</span><br><span class="line"> 解释: 4 皇后问题存在如下两个不同的解法。</span><br><span class="line">[</span><br><span class="line"> [".Q..",  // 解法 1</span><br><span class="line">  "...Q",</span><br><span class="line">  "Q...",</span><br><span class="line">  "..Q."],</span><br><span class="line"></span><br><span class="line"> ["..Q.",  // 解法 2</span><br><span class="line">  "Q...",</span><br><span class="line">  "...Q",</span><br><span class="line">  ".Q.."]</span><br><span class="line">]</span><br></pre></td></tr></tbody></table></figure><p>题解：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> LeetCode-面试题 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeetCode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode744</title>
      <link href="/2022/04/03/leetcode/mei-ri-yi-ti/leetcode744/"/>
      <url>/2022/04/03/leetcode/mei-ri-yi-ti/leetcode744/</url>
      
        <content type="html"><![CDATA[<h1><span id="744-寻找比目标字母大的最小字母">744. 寻找比目标字母大的最小字母</span></h1><h2><span id="题目">题目</span></h2><p>给你一个排序后的字符列表 letters ，列表中只包含小写英文字母。另给出一个目标字母 target，请你寻找在这一有序列表里比目标字母大的最小字母。</p><p>在比较时，字母是依序循环出现的。举个例子：</p><p>如果目标字母 target = ‘z’ 并且字符列表为 letters = [‘a’, ‘b’]，则答案返回 ‘a’</p><p>示例 1：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入: letters = ["c", "f", "j"]，target = "a"</span><br><span class="line">输出: "c"</span><br></pre></td></tr></tbody></table></figure><p>示例 2:</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入: letters = ["c","f","j"], target = "c"</span><br><span class="line">输出: "f"</span><br></pre></td></tr></tbody></table></figure><p>示例 3:</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入: letters = ["c","f","j"], target = "d"</span><br><span class="line">输出: "f"</span><br></pre></td></tr></tbody></table></figure><h2><span id="题解">题解</span></h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">nextGreatestLetter</span>(<span class="params">self, letters: <span class="type">List</span>[<span class="built_in">str</span>], target: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="keyword">return</span> letters[bisect_right(letters, target)] <span class="keyword">if</span> target &lt; letters[-<span class="number">1</span>] <span class="keyword">else</span> letters[<span class="number">0</span>]</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> 难度-简单 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeetCode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode420</title>
      <link href="/2022/04/02/leetcode/mei-ri-yi-ti/leetcode420/"/>
      <url>/2022/04/02/leetcode/mei-ri-yi-ti/leetcode420/</url>
      
        <content type="html"><![CDATA[<h1><span id="420-强密码检验器">420. 强密码检验器</span></h1><h2><span id="题目">题目</span></h2><p>如果一个密码满足下述所有条件，则认为这个密码是强密码：<br>由至少 6 个，至多 20 个字符组成。<br>至少包含 一个小写 字母，一个大写 字母，和 一个数字 。<br>同一字符 不能 连续出现三次 (比如 “…aaa…” 是不允许的, 但是 “…aa…a…” 如果满足其他条件也可以算是强密码)。<br>给你一个字符串 password ，返回 将 password 修改到满足强密码条件需要的最少修改步数。如果 password 已经是强密码，则返回 0 。</p><p>在一步修改操作中，你可以：</p><p>插入一个字符到 password ，<br>从 password 中删除一个字符，或<br>用另一个字符来替换 password 中的某个字符。</p><p>示例 1：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入：password = "a"</span><br><span class="line">输出：5</span><br></pre></td></tr></tbody></table></figure><p>示例 2：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入：password = "aA1"</span><br><span class="line">输出：3</span><br></pre></td></tr></tbody></table></figure><p>示例 3：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入：password = "1337C0d3"</span><br><span class="line">输出：0</span><br></pre></td></tr></tbody></table></figure><h2><span id="思路">思路</span></h2><p>分类讨论：</p><ol><li>当密码长度位于<code>[0, 6)</code>；<ol><li><strong>“删除”</strong>操作没有任何意义，<strong>“添加”</strong>或<strong>“修改”</strong>才有意义，<strong>“修改”</strong>只需要判断字符串是否包含了小写字母、大写字母、数字即可，所以操作只需要判断 <code>max(不足6的位数，需要修改的位数)</code></li></ol></li><li>当密码长度位于<code>[6,20]</code>;<ol><li><strong>“删除”</strong>或者<strong>“添加”</strong>操作没有任何意义，所以只需要考虑<strong>“修改”</strong>即可，当连续出现的位数k大于3的时候，只需要考虑 <strong>修改</strong> k//3次即可，同时也需要考虑字符串中是否包含了大小写字母、数字，取上述两种情况的最大值即可。 </li></ol></li><li>当密码长度位于<code>(20, )</code>;<ol><li><strong>“添加”</strong>操作没有任何意义，所以只需要进行<strong>“修改”</strong>或<strong>“删除”</strong>即可，以删除为主，修改为辅。</li><li>考虑密码不限制位数的时候，只考虑替换，只需要修改 k//3(k&gt;=3)次，即可。</li><li>因为位数大于20的时候，有限考虑删除。<ol><li>当 <code>k%3==0(k&gt;3)</code>时，删除一位，可减少修改的次数，修改的次数k//3减少1，剩余连续位数，只有删除3个时，修改的次数才会减1；</li><li>当 <code>k%3==1(k&gt;3)</code>时，删除两位，可减少修改的次数，修改的次数k//3减少1，剩余连续位数，只有删除3个时，修改的次数才会减1；</li><li>当<code>k%3==2(k&gt;3)</code>时，每删除三位，可减少修改的次数一次。</li></ol></li><li>因此在删除操作时，有限考虑 <code>k%3==0</code>的时候，删除一位的操作，其次考虑所有<code>k%3==1</code>时，删除两位的操作，最后考虑删除三位的操作。</li><li>最后的操作数为删除次数的操作<code>n - 20</code> 加上<code>max(替换操作次数, 3 - 字符种类)</code>。</li></ol></li></ol><h2><span id="题解">题解</span></h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">strongPasswordChecker</span>(<span class="params">self, password: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        n = <span class="built_in">len</span>(password)</span><br><span class="line">        lower = upper = digit = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">for</span> ch <span class="keyword">in</span> password:</span><br><span class="line">            <span class="keyword">if</span> ch.islower():</span><br><span class="line">                lower = <span class="literal">True</span></span><br><span class="line">            <span class="keyword">elif</span> ch.isupper():</span><br><span class="line">                upper = <span class="literal">True</span></span><br><span class="line">            <span class="keyword">elif</span> ch.isdigit():</span><br><span class="line">                digit = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">        categories = lower + upper + digit</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> n &lt; <span class="number">6</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">max</span>(<span class="number">6</span> - n, <span class="number">3</span> - categories)</span><br><span class="line">        <span class="keyword">elif</span> n &lt;= <span class="number">20</span>:</span><br><span class="line">            replace = cnt = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">            cur = <span class="string">'#'</span></span><br><span class="line">            <span class="keyword">for</span> ch <span class="keyword">in</span> password:</span><br><span class="line">                <span class="keyword">if</span> ch == cur:</span><br><span class="line">                    cnt += <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    replace += cnt // <span class="number">3</span></span><br><span class="line">                    cnt = <span class="number">1</span></span><br><span class="line">                    cur = ch</span><br><span class="line">            replace += cnt // <span class="number">3</span></span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">max</span>(replace, <span class="number">3</span> - categories)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 记录替换次数和删除次数</span></span><br><span class="line">            replace, remove, rm2, cnt = <span class="number">0</span>, n - <span class="number">20</span>, <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">            cur = <span class="string">'#'</span></span><br><span class="line">            <span class="keyword">for</span> ch <span class="keyword">in</span> password:</span><br><span class="line">                <span class="keyword">if</span> ch == cur:</span><br><span class="line">                    cnt += <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">if</span> cnt &gt;= <span class="number">3</span>:</span><br><span class="line">                        <span class="keyword">if</span> cnt % <span class="number">3</span> == <span class="number">0</span>:</span><br><span class="line">                            remove -= <span class="number">1</span></span><br><span class="line">                            replace -= <span class="number">1</span></span><br><span class="line">                        <span class="keyword">elif</span> cnt % <span class="number">3</span> == <span class="number">1</span>:</span><br><span class="line">                            rm2 += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">                    replace += cnt // <span class="number">3</span></span><br><span class="line">                    cnt = <span class="number">1</span></span><br><span class="line">                    cur = ch</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> cnt &gt;= <span class="number">3</span>:</span><br><span class="line">                <span class="keyword">if</span> cnt % <span class="number">3</span> == <span class="number">0</span>:</span><br><span class="line">                    remove -= <span class="number">1</span></span><br><span class="line">                    replace -= <span class="number">1</span></span><br><span class="line">                <span class="keyword">elif</span> cnt % <span class="number">3</span> == <span class="number">1</span>:</span><br><span class="line">                    rm2 += <span class="number">1</span></span><br><span class="line">            replace += cnt // <span class="number">3</span></span><br><span class="line"></span><br><span class="line">            use2 = <span class="built_in">min</span>(replace, rm2, remove // <span class="number">2</span>)</span><br><span class="line">            replace -= use2</span><br><span class="line">            remove -= use2 * <span class="number">2</span></span><br><span class="line">            use3 = <span class="built_in">min</span>(replace, remove // <span class="number">3</span>)</span><br><span class="line">            replace -= use3</span><br><span class="line">            remove -= use3 * <span class="number">3</span></span><br><span class="line">            <span class="keyword">return</span> n - <span class="number">20</span> + <span class="built_in">max</span>(replace, <span class="number">3</span> - categories)</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> 难度-困难 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeetCode </tag>
            
            <tag> 分情况讨论 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode954</title>
      <link href="/2022/04/01/leetcode/mei-ri-yi-ti/leetcode954/"/>
      <url>/2022/04/01/leetcode/mei-ri-yi-ti/leetcode954/</url>
      
        <content type="html"><![CDATA[<h1><span id="954-二倍数对数组">954. 二倍数对数组</span></h1><h2><span id="题目">题目</span></h2><p>给定一个长度为偶数的整数数组 <code>arr</code>，只有对 <code>arr</code> 进行重组后可以满足 “对于每个 <code>0 &lt;= i &lt; len(arr) / 2</code>，都有 <code>arr[2 * i + 1] = 2 * arr[2 * i]</code>” 时，返回 <code>true</code>；否则，返回 <code>false</code>。</p><p>示例 1：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入：arr = [3,1,3,6]</span><br><span class="line">输出：false</span><br></pre></td></tr></tbody></table></figure><p>示例 2：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入：arr = [2,1,2,6]</span><br><span class="line">输出：false</span><br></pre></td></tr></tbody></table></figure><p>示例 3：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输入：arr = [4,-2,2,-4]</span><br><span class="line">输出：true</span><br><span class="line">解释：可以用 [-2,-4] 和 [2,4] 这两组组成 [-2,-4,2,4] 或是 [2,4,-2,-4]</span><br></pre></td></tr></tbody></table></figure><h2><span id="思路">思路</span></h2><p>使用<strong>哈希表 + 排序</strong>的思路，题目明显表示，元素<code>x</code>对应的元素<code>2*x</code>数量上至少要多余元素<code>x</code>的数量，使用哈希表（字典）进行判断，当计算完毕<code>x</code>之后，更新元素<code>2*x</code>的数量，直到最后。</p><ol><li>首先计算出arr中每个元素的数量；</li><li>对于元素0，只能与0进行匹配，首先判断元素0的数量是否为偶数；</li><li>将哈希表中的元素进行绝对值排序，因为负数*2等于更小的负数，所以需要进行绝对值排序。</li><li>循环遍历哈希表，直到结束。</li></ol><h2><span id="题解">题解</span></h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">canReorderDoubled</span>(<span class="params">self, arr: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        cnt = Counter(arr)</span><br><span class="line">        <span class="keyword">if</span> cnt[<span class="number">0</span>] % <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="comment"># 下面排序方法一样</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="built_in">sorted</span>(cnt, key=<span class="keyword">lambda</span> k: <span class="built_in">abs</span>(k)))</span><br><span class="line">        <span class="built_in">print</span>(<span class="built_in">sorted</span>(cnt, key=<span class="built_in">abs</span>)</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">sorted</span>(cnt, key=<span class="keyword">lambda</span> k: <span class="built_in">abs</span>(k)):</span><br><span class="line">            <span class="keyword">if</span> cnt[<span class="number">2</span> * x] &lt; cnt[x]:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">            cnt[<span class="number">2</span> * x] -= cnt[x]</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> 难度-中等 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeetCode </tag>
            
            <tag> 哈希表 </tag>
            
            <tag> 排序 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>剑指_Offer</title>
      <link href="/2022/03/31/leetcode/jian-zhi-offer/"/>
      <url>/2022/03/31/leetcode/jian-zhi-offer/</url>
      
        <content type="html"><![CDATA[<h1><span id="剑指-offer">剑指 Offer</span></h1><h2><span id="剑指-offer-03">剑指 Offer 03</span></h2><blockquote><p>寻找重复数字</p></blockquote><p>找出数组中重复的数字。在一个长度为 n 的数组 nums 里的所有数字都在 0～n-1 的范围内。数组中某些数字是重复的，但不知道有几个数字重复了，也不知道每个数字重复了几次。请找出数组中任意一个重复的数字。</p><p><strong>示例 1：</strong></p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输入：</span><br><span class="line">[2, 3, 1, 0, 2, 5, 3]</span><br><span class="line">输出：2 或 3 </span><br></pre></td></tr></tbody></table></figure><p><strong>解题：</strong></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">findRepeatNumber</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        dic = <span class="built_in">set</span>()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> nums:</span><br><span class="line">            <span class="keyword">if</span> i <span class="keyword">in</span> dic:</span><br><span class="line">                <span class="keyword">return</span> i</span><br><span class="line">            dic.add(i)</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span></span><br></pre></td></tr></tbody></table></figure><h2><span id="剑指-offer-04">剑指 Offer 04</span></h2><blockquote><p>二维数组中的查找</p></blockquote><p>在一个 n * m 的二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个高效的函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。</p><p><strong>示例:</strong></p><p>现有矩阵 matrix 如下：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">  [1,   4,  7, 11, 15],</span><br><span class="line">  [2,   5,  8, 12, 19],</span><br><span class="line">  [3,   6,  9, 16, 22],</span><br><span class="line">  [10, 13, 14, 17, 24],</span><br><span class="line">  [18, 21, 23, 26, 30]</span><br><span class="line">]</span><br><span class="line">给定 target = 5，返回 true。</span><br><span class="line"></span><br><span class="line">给定 target = 20，返回 false。</span><br></pre></td></tr></tbody></table></figure><p><strong>解题思路：</strong></p><p>方案一：使用暴力的方法，逐元素便利，寻找是否存在；</p><p>方案二：线性查找的方式，因为数组中元素每行从左到右递增以及每列从上到下递增的特点，所以考虑从左上角开始遍历，并不能很方便的进行遍历。但是从左下角开始便利，当当前元素 &gt; target 时，向上移动，当当前元素 &lt; target时，向右移动。</p><p><img src="http://r9b9hav76.hn-bkt.clouddn.com/1.png" alt="1"></p><p><img src="http://r9b9hav76.hn-bkt.clouddn.com//2.png" alt="2"></p><p><strong>题解：</strong></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">findNumberIn2DArray</span>(<span class="params">self, matrix: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]], target: <span class="built_in">int</span></span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        <span class="keyword">if</span> matrix <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> <span class="built_in">len</span>(matrix) == <span class="number">0</span> <span class="keyword">or</span> <span class="built_in">len</span>(matrix[<span class="number">0</span>]) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        i, j = <span class="built_in">len</span>(matrix) - <span class="number">1</span>, <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> i &gt;= <span class="number">0</span> <span class="keyword">and</span> j &lt; <span class="built_in">len</span>(matrix[<span class="number">0</span>]):</span><br><span class="line">            <span class="keyword">if</span> matrix[i][j] &gt; target:</span><br><span class="line">                i -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> matrix[i][j] &lt; target:</span><br><span class="line">                j += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></tbody></table></figure><h2><span id="剑指-offer-05">剑指 Offer 05</span></h2><blockquote><p>剑指 Offer 05. 替换空格: <a href="https://leetcode-cn.com/problems/ti-huan-kong-ge-lcof/">https://leetcode-cn.com/problems/ti-huan-kong-ge-lcof/</a></p></blockquote><p><strong>题目：</strong></p><p>请实现一个函数，把字符串 s 中的每个空格替换成”%20”。</p><p> <strong>示例 1：</strong></p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入：s = "We are happy."</span><br><span class="line">输出："We%20are%20happy."</span><br></pre></td></tr></tbody></table></figure><p><strong>题解</strong></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">replaceSpace</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        res = []</span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> s:</span><br><span class="line">            <span class="keyword">if</span> c == <span class="string">' '</span>:</span><br><span class="line">                res.append(<span class="string">"%20"</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                res.append(c)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">''</span>.join(res)</span><br></pre></td></tr></tbody></table></figure><h2><span id="剑指-offer-06">剑指 Offer 06</span></h2><blockquote><p>剑指 Offer 06. 从尾到头打印链表：<a href="https://leetcode-cn.com/problems/cong-wei-dao-tou-da-yin-lian-biao-lcof/">https://leetcode-cn.com/problems/cong-wei-dao-tou-da-yin-lian-biao-lcof/</a></p></blockquote><p><strong>题目</strong></p><p>输入一个链表的头节点，从尾到头反过来返回每个节点的值（用数组返回）。</p><p> <strong>示例 1：</strong></p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入：head = [1,3,2]</span><br><span class="line">输出：[2,3,1]</span><br></pre></td></tr></tbody></table></figure><p>解题思路：</p><p>方法一：递归方法</p><p>注意：list相加是进行末尾增加元素，而非元素相加</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"># class ListNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.next = None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reversePrint</span>(<span class="params">self, head: ListNode</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        <span class="keyword">return</span> self.reversePrint(head.<span class="built_in">next</span>) + [head.val] <span class="keyword">if</span> head <span class="keyword">else</span> []</span><br></pre></td></tr></tbody></table></figure><p>方法二：辅助栈的方法</p><p>注意：python中的栈是使用list直接进行操作，拥有append和pop功能。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reversePrint</span>(<span class="params">self, head: ListNode</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        res = []</span><br><span class="line">        <span class="keyword">while</span> head:</span><br><span class="line">            res.append(head.val)</span><br><span class="line">            head = head.<span class="built_in">next</span></span><br><span class="line">        <span class="keyword">return</span> res[::-<span class="number">1</span>]</span><br></pre></td></tr></tbody></table></figure><h2><span id="剑指-offer-07">剑指 Offer 07</span></h2><blockquote><p>剑指 Offer 07. 重建二叉树: <a href="https://leetcode-cn.com/problems/zhong-jian-er-cha-shu-lcof/">https://leetcode-cn.com/problems/zhong-jian-er-cha-shu-lcof/</a>)</p></blockquote><p><strong>题目</strong></p><p>输入某二叉树的前序遍历和中序遍历的结果，请构建该二叉树并返回其根节点。</p><p>假设输入的前序遍历和中序遍历的结果中都不含重复的数字。</p><p> <img src="http://r9b9hav76.hn-bkt.clouddn.com//tree.jpg" alt="img"></p><p>示例 1:</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Input: preorder = [3,9,20,15,7], inorder = [9,3,15,20,7]</span><br><span class="line">Output: [3,9,20,null,null,15,7]</span><br></pre></td></tr></tbody></table></figure><p>示例 2:</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Input: preorder = [-1], inorder = [-1]</span><br><span class="line">Output: [-1]</span><br></pre></td></tr></tbody></table></figure><p><strong>解题思路</strong></p><p>对于任意一颗树而言，前序遍历的形式总是 <code>[ 根节点, [左子树的前序遍历结果], [右子树的前序遍历结果] ]</code><br>而中序遍历的形式总是<code>[ [左子树的中序遍历结果], 根节点, [右子树的中序遍历结果] ]</code></p><p>所以根据规律可以使用递归操作来进行，在细节上需要做一个 map 能够存储中序遍历的位置信息方便定位根节点。</p><p><strong>题解</strong></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.left = None</span></span><br><span class="line"><span class="comment">#         self.right = None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">buildTree</span>(<span class="params">self, preorder: <span class="type">List</span>[<span class="built_in">int</span>], inorder: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; TreeNode:</span><br><span class="line">        n = <span class="built_in">len</span>(preorder)</span><br><span class="line">        inorder_index = {ele: i <span class="keyword">for</span> i, ele <span class="keyword">in</span> <span class="built_in">enumerate</span>(inorder)}</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">myBulid</span>(<span class="params">preorder_l: <span class="built_in">int</span>, preorder_r: <span class="built_in">int</span>, inorder_l: <span class="built_in">int</span>, inorder_r: <span class="built_in">int</span></span>) -&gt; TreeNode:</span><br><span class="line">            <span class="keyword">if</span> preorder_l &gt; preorder_r:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">            preorder_root = preorder_l</span><br><span class="line">            inorder_index_root = inorder_index[preorder[preorder_root]]</span><br><span class="line">            root = TreeNode(preorder[preorder_root])</span><br><span class="line">            root_left_len = inorder_index_root - inorder_l</span><br><span class="line">            root_right_len = inorder_r - inorder_index_root</span><br><span class="line">            root.left = myBulid(preorder_l + <span class="number">1</span>, preorder_l + root_left_len, inorder_l, inorder_index_root - <span class="number">1</span>)</span><br><span class="line">            root.right = myBulid(preorder_r - root_right_len + <span class="number">1</span>, preorder_r, inorder_index_root + <span class="number">1</span>, inorder_r)</span><br><span class="line">            <span class="keyword">return</span> root</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> myBulid(<span class="number">0</span>, n - <span class="number">1</span>, <span class="number">0</span>, n - <span class="number">1</span>)</span><br></pre></td></tr></tbody></table></figure><h2><span id="剑指-offer-09">剑指 Offer 09</span></h2><blockquote><p>剑指 Offer 09. 用两个栈实现队列：<a href="https://leetcode-cn.com/problems/yong-liang-ge-zhan-shi-xian-dui-lie-lcof/">https://leetcode-cn.com/problems/yong-liang-ge-zhan-shi-xian-dui-lie-lcof/</a></p></blockquote><p><strong>题目</strong></p><p>用两个栈实现一个队列。队列的声明如下，请实现它的两个函数 <code>appendTail</code> 和 <code>deleteHead</code> ，分别完成在队列尾部插入整数和在队列头部删除整数的功能。(若队列中没有元素，deleteHead 操作返回 -1 )</p><p><strong>示例</strong></p><p><strong>解题思路</strong></p><p>因为栈只能在队尾进行操作，所以可以利用栈A实现入队操作，栈B实现出队操作。</p><ol><li>入队时，将栈B中所有数据通过出栈的方式逐步加入栈A中，再进行入队操作；</li><li>出队时，将栈A中所有数据通过出栈的方式逐步加入栈B中，此时栈B中末尾就是需要进行出栈的数，再进行出队操作；</li></ol><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CQueue</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.queueA = deque()</span><br><span class="line">        self.queueB = deque()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">appendTail</span>(<span class="params">self, value: <span class="built_in">int</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(self.queueB) != <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">while</span> self.queueB:</span><br><span class="line">                self.queueA.append(self.queueB.pop())</span><br><span class="line">        self.queueA.append(value)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">deleteHead</span>(<span class="params">self</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(self.queueA) == <span class="number">0</span> <span class="keyword">and</span> <span class="built_in">len</span>(self.queueB) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> -<span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(self.queueB) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">while</span> self.queueA:</span><br><span class="line">                self.queueB.append(self.queueA.pop())</span><br><span class="line">        <span class="keyword">return</span> self.queueB.pop()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Your CQueue object will be instantiated and called as such:</span></span><br><span class="line"><span class="comment"># obj = CQueue()</span></span><br><span class="line"><span class="comment"># obj.appendTail(value)</span></span><br><span class="line"><span class="comment"># param_2 = obj.deleteHead()</span></span><br></pre></td></tr></tbody></table></figure><h2><span id="剑指-offer-10-i">剑指 Offer 10- I</span></h2><blockquote><p>剑指 Offer 10- I. 斐波那契数列：<a href="https://leetcode-cn.com/problems/fei-bo-na-qi-shu-lie-lcof/">https://leetcode-cn.com/problems/fei-bo-na-qi-shu-lie-lcof/</a></p></blockquote><p>参考题模板</p><h2><span id="剑指-offer-10-ii">剑指 Offer 10- II</span></h2><blockquote><p>剑指 Offer 10- II. 青蛙跳台阶问题：<a href="https://leetcode-cn.com/problems/qing-wa-tiao-tai-jie-wen-ti-lcof/">https://leetcode-cn.com/problems/qing-wa-tiao-tai-jie-wen-ti-lcof/</a></p></blockquote><p><strong>题目</strong></p><p>一只青蛙一次可以跳上<code>1</code>级台阶，也可以跳上<code>2</code>级台阶。求该青蛙跳上一个 <code>n</code> 级的台阶总共有多少种跳法。答案需要取模 <code>1e9+7（1000000007）</code>，如计算初始结果为：<code>1000000008</code>，请返回 <code>1</code>。</p><p><strong>解题思路</strong></p><blockquote><p>寻找递推关联关系，即 <em>f</em>(<em>n</em>) 和 f<em>(</em>n−1)…f(1) 之间是有联系的</p></blockquote><p>设跳上 n 级台阶有 f(n) 种跳法。在所有跳法中，青蛙的最后一步只有两种情况： 跳上 1 级或 2 级台阶。</p><ul><li>当为 1 级台阶： 剩 n-1 个台阶，此情况共有 f(n−1) 种跳法；<br>当为 2 级台阶： 剩 n−2 个台阶，此情况共有 f(n−2) 种跳法。</li></ul><p>f(n) 为以上两种情况之和，即 f(n)=f(n-1)+f(n-2) ，以上递推性质为斐波那契数列。本题可转化为 求斐波那契数列第 n 项的值 ，与 面试题10- I. 斐波那契数列等价，唯一的不同在于起始数字不同。</p><ul><li>青蛙跳台阶问题： f(0)=1 , f(1)=1 , f(2)=2；</li><li>斐波那契数列问题： f(0)=0 , f(1)=1 , f(2)=1 。</li></ul><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">numWays</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        nums = [<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n + <span class="number">1</span>)]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">dp</span>(<span class="params">n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">            <span class="keyword">nonlocal</span> nums</span><br><span class="line">            <span class="keyword">if</span> nums[n] != <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">return</span> nums[n]</span><br><span class="line">            <span class="keyword">if</span> n == <span class="number">0</span> <span class="keyword">or</span> n == <span class="number">1</span>:</span><br><span class="line">                nums[n] = <span class="number">1</span></span><br><span class="line">                <span class="keyword">return</span> nums[n]</span><br><span class="line">            nums[n] = (dp(n - <span class="number">1</span>) + dp(n - <span class="number">2</span>)) % <span class="number">1000000007</span></span><br><span class="line">            <span class="keyword">return</span> nums[n]</span><br><span class="line">        <span class="keyword">return</span> dp(n)</span><br></pre></td></tr></tbody></table></figure><h2><span id="剑指-offer-11">剑指 Offer 11</span></h2><blockquote><p>剑指 Offer 11. 旋转数组的最小数字：<a href="https://leetcode-cn.com/problems/xuan-zhuan-shu-zu-de-zui-xiao-shu-zi-lcof/">https://leetcode-cn.com/problems/xuan-zhuan-shu-zu-de-zui-xiao-shu-zi-lcof/</a></p></blockquote><p><strong>题目</strong></p><p>把一个数组最开始的若干个元素搬到数组的末尾，我们称之为数组的旋转。给你一个可能存在 <strong>重复</strong> 元素值的数组 <code>numbers</code> ，它原来是一个升序排列的数组，并按上述情形进行了一次旋转。请返回旋转数组的最小元素。例如，数组 <code>[3,4,5,1,2]</code> 为 <code>[1,2,3,4,5]</code> 的一次旋转，该数组的最小值为 <code>1</code>。  </p><p>注意，数组 <code>[a[0], a[1], a[2], ..., a[n-1]]</code> 旋转一次 的结果为数组 <code>[a[n-1], a[0], a[1], a[2], ..., a[n-2]]</code> 。</p><p><strong>示例 1：</strong></p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入：numbers = [3,4,5,1,2]</span><br><span class="line">输出：1</span><br></pre></td></tr></tbody></table></figure><p><strong>示例 2：</strong></p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入：numbers = [2,2,2,0,1]</span><br><span class="line">输出：0</span><br></pre></td></tr></tbody></table></figure><p><strong>解题思路一：暴力</strong></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">minArray</span>(<span class="params">self, numbers: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        ans = numbers[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(numbers)):</span><br><span class="line">            <span class="keyword">if</span> numbers[i] &lt; ans:</span><br><span class="line">                <span class="keyword">return</span> numbers[i]</span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></tbody></table></figure><p><strong>解题思路一：二分法</strong></p><p>因为在二分法比较的数据是片段的尾部数据，又由于数组中存在大量的连续相同的数据，所以当 <code>numbers[mid] == numbers[right]</code> 时，将 <code>right</code> 变化为 <code>right=right-1</code>，使得即使<code>mid</code>最小时仍然控制在片段内，而不丢失。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">minArray</span>(<span class="params">self, numbers: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        l, r = <span class="number">0</span>, <span class="built_in">len</span>(numbers) - <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> l &lt; r:</span><br><span class="line">            mid = (l + r) &gt;&gt; <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> numbers[mid] &lt; numbers[r]:</span><br><span class="line">                r = mid</span><br><span class="line">            <span class="keyword">elif</span> numbers[mid] &gt; numbers[r]:</span><br><span class="line">                l = mid + <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                r -= <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> numbers[l]</span><br></pre></td></tr></tbody></table></figure><h2><span id="剑指-offer-12">剑指 Offer 12</span></h2><blockquote><p>剑指 Offer 12. 矩阵中的路径：<a href="https://leetcode-cn.com/problems/ju-zhen-zhong-de-lu-jing-lcof/">https://leetcode-cn.com/problems/ju-zhen-zhong-de-lu-jing-lcof/</a></p></blockquote><p><strong>题目</strong></p><p>给定一个 <code>m x n</code> 二维字符网格 <code>board</code> 和一个字符串单词 <code>word</code> 。如果 <code>word</code> 存在于网格中，返回 <code>true</code> ；否则，返回 <code>false</code> 。</p><p>单词必须按照字母顺序，通过相邻的单元格内的字母构成，其中“相邻”单元格是那些水平相邻或垂直相邻的单元格。同一个单元格内的字母不允许被重复使用。</p><p><strong>示例</strong></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">示例 <span class="number">1</span>：</span><br><span class="line">输入：board = </span><br><span class="line">[[<span class="string">"A"</span>,<span class="string">"B"</span>,<span class="string">"C"</span>,<span class="string">"E"</span>],</span><br><span class="line"> [<span class="string">"S"</span>,<span class="string">"F"</span>,<span class="string">"C"</span>,<span class="string">"S"</span>],</span><br><span class="line"> [<span class="string">"A"</span>,<span class="string">"D"</span>,<span class="string">"E"</span>,<span class="string">"E"</span>]], word = <span class="string">"ABCCED"</span></span><br><span class="line">输出：true</span><br><span class="line"></span><br><span class="line">示例 <span class="number">2</span>：</span><br><span class="line">输入：board = </span><br><span class="line">[[<span class="string">"a"</span>,<span class="string">"b"</span>],</span><br><span class="line"> [<span class="string">"c"</span>,<span class="string">"d"</span>]], word = <span class="string">"abcd"</span></span><br><span class="line">输出：false</span><br></pre></td></tr></tbody></table></figure><p><strong>解题思路</strong></p><p>使用深度优先搜索的方式，没必要用dp，因为存在限制，不能重复使用元素，路径不同对其有影响。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">exist</span>(<span class="params">self, board: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">str</span>]], word: <span class="built_in">str</span></span>) -&gt; <span class="built_in">bool</span>: </span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">dfs</span>(<span class="params">i, j, k</span>):</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> (<span class="number">0</span> &lt;= i &lt; <span class="built_in">len</span>(board)) <span class="keyword">or</span> <span class="keyword">not</span> (<span class="number">0</span> &lt;= j &lt; <span class="built_in">len</span>(board[<span class="number">0</span>])) <span class="keyword">or</span> board[i][j] != word[k]:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">            <span class="keyword">if</span> k == <span class="built_in">len</span>(word) - <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">            board[i][j] = <span class="string">''</span></span><br><span class="line">            res = dfs(i + <span class="number">1</span>, j, k + <span class="number">1</span>) <span class="keyword">or</span> dfs(i, j + <span class="number">1</span>, k + <span class="number">1</span>) <span class="keyword">or</span> \</span><br><span class="line">                  dfs(i - <span class="number">1</span>, j, k + <span class="number">1</span>) <span class="keyword">or</span> dfs(i, j - <span class="number">1</span>, k + <span class="number">1</span>)</span><br><span class="line">            board[i][j] = word[k]</span><br><span class="line">            <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(board)):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(board[<span class="number">0</span>])):</span><br><span class="line">                <span class="keyword">if</span> dfs(i, j, <span class="number">0</span>):</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></tbody></table></figure><h2><span id="剑指-offer-13">剑指 Offer 13</span></h2><blockquote><p>剑指 Offer 13. 机器人的运动范围：<a href="https://leetcode-cn.com/problems/ji-qi-ren-de-yun-dong-fan-wei-lcof/">https://leetcode-cn.com/problems/ji-qi-ren-de-yun-dong-fan-wei-lcof/</a></p></blockquote><p><strong>题目</strong></p><p>地上有一个<code>m</code>行<code>n</code>列的方格，从坐标 <code>[0,0]</code> 到坐标 <code>[m-1,n-1]</code> 。一个机器人从坐标 <code>[0, 0]</code> 的格子开始移动，它每次可以向左、右、上、下移动一格（不能移动到方格外），也不能进入行坐标和列坐标的数位之和大于<code>k</code>的格子。例如，当<code>k</code>为<code>18</code>时，机器人能够进入方格 <code>[35, 37]</code> ，因为<code>3+5+3+7=18</code>。但它不能进入方格 <code>[35, 38]</code>，因为<code>3+5+3+8=19</code>。请问该机器人能够到达多少个格子？</p><p><strong>示例</strong></p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">示例 1：</span><br><span class="line">输入：m = 2, n = 3, k = 1</span><br><span class="line">输出：3</span><br><span class="line"></span><br><span class="line">示例 2：</span><br><span class="line">输入：m = 3, n = 1, k = 0</span><br><span class="line">输出：1</span><br></pre></td></tr></tbody></table></figure><p><strong>解题思路</strong></p><p>使用深度优先搜索或者广度有限搜索的方法进行遍历，找机器人能够走过的位置，因为从 <code>(0,0)</code>开始移动，所以范围控制在向右或者向上。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">movingCount</span>(<span class="params">self, m: <span class="built_in">int</span>, n: <span class="built_in">int</span>, k: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        stats = [[<span class="literal">True</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(m)]</span><br><span class="line">        res = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">dfs</span>(<span class="params">x, y</span>):</span><br><span class="line">            <span class="keyword">nonlocal</span> stats, res</span><br><span class="line"></span><br><span class="line">            <span class="keyword">def</span> <span class="title function_">digitsum</span>(<span class="params">n</span>):</span><br><span class="line">                <span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line">                <span class="keyword">while</span> n:</span><br><span class="line">                    <span class="built_in">sum</span> += n % <span class="number">10</span></span><br><span class="line">                    n //= <span class="number">10</span></span><br><span class="line">                <span class="keyword">return</span> <span class="built_in">sum</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="number">0</span> &lt;= x &lt; m <span class="keyword">and</span> <span class="number">0</span> &lt;= y &lt; n <span class="keyword">and</span> digitsum(x) + digitsum(y) &lt;= k:</span><br><span class="line">                <span class="keyword">if</span> stats[x][y]:</span><br><span class="line">                    stats[x][y] = <span class="literal">False</span></span><br><span class="line">                    res += <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">return</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">            <span class="keyword">for</span> direct <span class="keyword">in</span> [[<span class="number">1</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">1</span>]]:</span><br><span class="line">                nx, ny = x + direct[<span class="number">0</span>], y + direct[<span class="number">1</span>]</span><br><span class="line">                dfs(nx, ny)</span><br><span class="line">        dfs(<span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></tbody></table></figure><h2><span id="剑指-offer-14-i">剑指 Offer 14- I</span></h2><blockquote><p>剑指 Offer 14- I. 剪绳子：<a href="https://leetcode-cn.com/problems/jian-sheng-zi-lcof/">https://leetcode-cn.com/problems/jian-sheng-zi-lcof/</a></p></blockquote><p><strong>题目</strong></p><p>给你一根长度为 <code>n</code> 的绳子，请把绳子剪成整数长度的 <code>m</code> 段（<code>m</code>、<code>n</code>都是整数，<code>n&gt;1</code>并且<code>m&gt;1</code>），每段绳子的长度记为 <code>k[0],k[1]...k[m-1]</code> 。请问 <code>k[0]*k[1]*...*k[m-1]</code> 可能的最大乘积是多少？例如，当绳子的长度是<code>8</code>时，我们把它剪成长度分别为<code>2、3、3</code>的三段，此时得到的最大乘积是<code>18</code>。</p><p><strong>示例</strong></p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">示例 1：</span><br><span class="line">输入: 2</span><br><span class="line">输出: 1</span><br><span class="line">解释: 2 = 1 + 1, 1 × 1 = 1</span><br><span class="line"></span><br><span class="line">示例 2:</span><br><span class="line">输入: 10</span><br><span class="line">输出: 36</span><br><span class="line">解释: 10 = 3 + 3 + 4, 3 × 3 × 4 = 36</span><br></pre></td></tr></tbody></table></figure><p><strong>题解</strong></p><p>使用深度优先搜索或者广度优先搜索的方法进行遍历。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">cuttingRope</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="keyword">if</span> n == <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> n == <span class="number">3</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">2</span></span><br><span class="line"></span><br><span class="line">        dp = [<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n + <span class="number">1</span>)]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">dfs</span>(<span class="params">k</span>):</span><br><span class="line">            <span class="keyword">nonlocal</span> dp</span><br><span class="line">            <span class="keyword">if</span> dp[k] != <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">return</span> dp[k]</span><br><span class="line">            <span class="keyword">if</span> k <span class="keyword">in</span> [<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]:</span><br><span class="line">                dp[k] = k</span><br><span class="line">                <span class="keyword">return</span> k</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, k // <span class="number">2</span> + <span class="number">1</span>):</span><br><span class="line">                dp[k] = <span class="built_in">max</span>(dp[k], dfs(i) * dfs(k - i))</span><br><span class="line">            <span class="keyword">return</span> dp[k]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> dfs(n)</span><br></pre></td></tr></tbody></table></figure><p><strong>解题思路二</strong></p><p>使用贪心的思路进行求解</p><p>最好的结果肯定3越多越好，但是需要控制尾数不足4的时候。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">cuttingRope</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="keyword">if</span> n &lt;= <span class="number">3</span>: <span class="keyword">return</span> n - <span class="number">1</span></span><br><span class="line">        a, b = n // <span class="number">3</span>, n % <span class="number">3</span></span><br><span class="line">        <span class="keyword">if</span> b == <span class="number">0</span>: <span class="keyword">return</span> <span class="built_in">int</span>(math.<span class="built_in">pow</span>(<span class="number">3</span>, a))</span><br><span class="line">        <span class="keyword">if</span> b == <span class="number">1</span>: <span class="keyword">return</span> <span class="built_in">int</span>(math.<span class="built_in">pow</span>(<span class="number">3</span>, a - <span class="number">1</span>) * <span class="number">4</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">int</span>(math.<span class="built_in">pow</span>(<span class="number">3</span>, a) * <span class="number">2</span>)</span><br></pre></td></tr></tbody></table></figure><h2><span id="剑指-offer-14-ii">剑指 Offer 14- II</span></h2><blockquote><p>剑指 Offer 14- II. 剪绳子 II：<a href="https://leetcode-cn.com/problems/jian-sheng-zi-ii-lcof/">https://leetcode-cn.com/problems/jian-sheng-zi-ii-lcof/</a></p></blockquote><p>题目与上题一样，但是结果需要取模，答案需要取模 1e9+7（1000000007），如计算初始结果为：1000000008，请返回 1。</p><p><strong>解题思路</strong></p><p>方案一：使用深度优先搜索/广度优先搜索的方案；</p><p>方案二：贪心算法+快速幂求余</p><p>方案三：贪心算法</p><p>因为python方法不需要考虑过界问题，所以可以在答案最后进行取模。下面利用方案二求解。</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def cuttingRope(self, n: int) -&gt; int:</span><br><span class="line">        if n &lt;= 3: return n - 1</span><br><span class="line">        a, b, p, res = n // 3, n % 3, 1000000007, 1</span><br><span class="line">        def pow2(x, y):</span><br><span class="line">            ans = 1</span><br><span class="line">            while y:</span><br><span class="line">                if y &amp; 1 == 1:</span><br><span class="line">                    ans = ans * x % p</span><br><span class="line">                y &gt;&gt;= 1</span><br><span class="line">                x = x * x % p</span><br><span class="line">            return ans</span><br><span class="line">        if b == 0: return pow2(3, a)</span><br><span class="line">        if b == 1: return pow2(3, a - 1) * 4 % p</span><br><span class="line">        if b == 2: return pow2(3, a) * 2 % p</span><br></pre></td></tr></tbody></table></figure><h2><span id="剑指-offer-15">剑指 Offer 15</span></h2><blockquote><p>剑指 Offer 15. 二进制中1的个数：<a href="https://leetcode-cn.com/problems/er-jin-zhi-zhong-1de-ge-shu-lcof/">https://leetcode-cn.com/problems/er-jin-zhi-zhong-1de-ge-shu-lcof/</a></p></blockquote><p>编写一个函数，输入是一个无符号整数（以二进制串的形式），返回其二进制表达式中数字位数为 ‘1’ 的个数（也被称为 <a href="http://en.wikipedia.org/wiki/Hamming_weight">汉明重量</a>).）。</p><p>解题思路：</p><ol><li>使用除法+取余操作计算1的个数；</li><li>使用位运算计算1的个数</li></ol><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">hammingWeight</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        res = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> n:</span><br><span class="line">            <span class="keyword">if</span> n &amp; <span class="number">1</span>:</span><br><span class="line">                res += <span class="number">1</span></span><br><span class="line">            n &gt;&gt;= <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> 剑指Offer </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeetCode </tag>
            
            <tag> 剑指Offer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode728</title>
      <link href="/2022/03/31/leetcode/mei-ri-yi-ti/leetcode728/"/>
      <url>/2022/03/31/leetcode/mei-ri-yi-ti/leetcode728/</url>
      
        <content type="html"><![CDATA[<h1><span id="728-自除数">728. 自除数</span></h1><h2><span id="题目">题目</span></h2><p>自除数 是指可以被它包含的每一位数整除的数。</p><p>例如，128 是一个 自除数 ，因为 128 % 1 == 0，128 % 2 == 0，128 % 8 == 0。<br>自除数 不允许包含 0 。</p><p>给定两个整数 left 和 right ，返回一个列表，列表的元素是范围 [left, right] 内所有的 自除数 。</p><p>示例 1：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入：left = 1, right = 22</span><br><span class="line">输出：[1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 15, 22]</span><br></pre></td></tr></tbody></table></figure><p>示例 2:</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入：left = 47, right = 85</span><br><span class="line">输出：[48,55,66,77]</span><br></pre></td></tr></tbody></table></figure><h2><span id="题解">题解</span></h2><h3><span id="python">Python</span></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">selfDividingNumbers</span>(<span class="params">self, left: <span class="built_in">int</span>, right: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">isSelfDividing</span>(<span class="params">num: <span class="built_in">int</span></span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">            x = num</span><br><span class="line">            <span class="keyword">while</span> x:</span><br><span class="line">                x, d = <span class="built_in">divmod</span>(x, <span class="number">10</span>)</span><br><span class="line">                <span class="keyword">if</span> d == <span class="number">0</span> <span class="keyword">or</span> num % d:</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(left, right + <span class="number">1</span>) <span class="keyword">if</span> isSelfDividing(i)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    sol = Solution()</span><br><span class="line">    res = sol.selfDividingNumbers(<span class="number">47</span>, <span class="number">85</span>)</span><br><span class="line">    <span class="built_in">print</span>(res)</span><br></pre></td></tr></tbody></table></figure><h3><span id="java">Java</span></h3><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> {</span><br><span class="line">    <span class="keyword">public</span> List&lt;Integer&gt; <span class="title function_">selfDividingNumbers</span><span class="params">(<span class="type">int</span> left, <span class="type">int</span> right)</span> {</span><br><span class="line">        List&lt;Integer&gt; ans = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> left; i &lt;= right; i++){</span><br><span class="line">            <span class="keyword">if</span>(isSelfDividing(i))</span><br><span class="line">                ans.add(i);</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> ans;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> Boolean <span class="title function_">isSelfDividing</span><span class="params">(<span class="type">int</span> num)</span> {</span><br><span class="line">        <span class="type">int</span> <span class="variable">x</span> <span class="operator">=</span> num;</span><br><span class="line">        <span class="keyword">while</span>(x != <span class="number">0</span>){</span><br><span class="line">            <span class="type">int</span> <span class="variable">d</span> <span class="operator">=</span> x % <span class="number">10</span>;</span><br><span class="line">            x = x / <span class="number">10</span>;</span><br><span class="line">            <span class="keyword">if</span>(d == <span class="number">0</span> || num % d !=<span class="number">0</span>)</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> 难度-简单 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeetCode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关联规则算法</title>
      <link href="/2022/03/30/machine-learning/guan-lian-gui-ze-suan-fa/"/>
      <url>/2022/03/30/machine-learning/guan-lian-gui-ze-suan-fa/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="关联规则算法与apriori算法原理">关联规则算法与Apriori算法原理</span></h1><h2><span id="1-举例说明">1. 举例说明</span></h2><p>例如：购物车的数据进行关联规则挖掘，寻找关联规则；</p><p>尿布 -&gt; 啤酒[支持度=10%，置信度=70%]</p><p>支持度表示规则的有用性：表示有10%顾客的同时购买啤酒和尿布</p><p>置信度表示规则的可靠性：表示有购买尿布的顾客有70%购买啤酒</p><h2><span id="2-基本概念的理解">2. 基本概念的理解</span></h2><div class="table-container"><table><thead><tr><th>TID</th><th>Items</th></tr></thead><tbody><tr><td>T1</td><td>{牛奶，面包}</td></tr><tr><td>T2</td><td>{面包，尿布，啤酒，鸡蛋}</td></tr><tr><td>T3</td><td>{面包，尿布，啤酒，可乐}</td></tr><tr><td>T4</td><td>{面包，牛奶，尿布，啤酒}</td></tr><tr><td>T5</td><td>{面包，牛奶，尿布，可乐}</td></tr></tbody></table></div><p>基本概念的理解:</p><ol><li>事务：所有情况的集合。例如：如上图所示购物篮数量的集合。</li><li>项：可以理解为研究的单个商品或者物品。例如：牛奶、面包等。</li><li>项的集合：所有项的集合。例如：{面包，啤酒，鸡蛋，牛奶，尿布，可乐}</li><li>项集：包含多个项的集合。例如：{面包，牛奶}</li><li>K-项集：包含k个项的集合。例如：2项集{面包，牛奶}，3项集等等</li><li>频繁项集：项集在事务中出现的比例大于一定的阈值。</li><li>规则：形如A=&gt;B的蕴含关系，A和B为非空不相交项集。</li><li>支持度：两个非空不相交项集在事务中同时出现的概率，support(A=&gt;B)=P(AUB)<br> 例如：A={牛奶}，B={面包}，support(A=&gt;B)=3/5=60%</li><li>置信度：两个非空不相交项集，在事务中A的情况下出现B的概率，confidience(A=&gt;B)=P(B|A)<br> 例如：A={牛奶}，B={面包}，confidience(A=&gt;B)=3/3=100%</li><li>最小支持度：专家定义的衡量支持度的阈值，表示统计意义上的最低重要性。</li><li>最小置信度：专家定义的衡量置信度的阈值，表示关联规则的最低可靠性。</li><li>强规则：同时满足最小支持度和最小置信度的规则。</li></ol><h2><span id="3-关联规则挖掘步骤">3. 关联规则挖掘步骤</span></h2><ol><li>生成满足最小支持度的频繁项集；</li><li>从频繁集中，找到满足最低置信度的规则；</li><li>生成强关联规则。</li></ol><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
          <category> 推荐算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> 机器学习 </tag>
            
            <tag> 推荐算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Apriori算法</title>
      <link href="/2022/03/30/machine-learning/apriori-suan-fa/"/>
      <url>/2022/03/30/machine-learning/apriori-suan-fa/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="apriori算法实现超市商品搭配出售方案"><strong>Apriori算法实现超市商品搭配出售方案</strong></span></h1><h2><span id="1-算法概述">1. 算法概述</span></h2><p>Apriori算法是一种挖掘关联规则的频繁项集算法，其核心思想是通过频繁项集==找出物品之间的关联规则==。 它的主要任务就是设法发现事物之间的内在联系。比如在常见的超市购物数据集，或者电商的网购数据集中，如果我们找到了频繁出现的数据集，那么对于超市，我们可以优化产品的位置摆放，对于电商，我们可以优化商品所在的仓库位置，达到节约成本，增加经济效益的目的。</p><p>关于这个算法有一个非常有名的故事：”尿布和啤酒”。故事是这样的：美国的妇女们经常会嘱咐她们的丈夫下班后为孩子买尿布，而丈夫在买完尿布后又要顺手买回自己爱喝的啤酒，因此啤酒和尿布在一起被购买的机会很多。这个举措使尿布和啤酒的销量双双增加，并一直为众商家所津津乐道。</p><h2><span id="2-应用领域">2. 应用领域</span></h2><p>该算法已经被广泛的应用到商业、网络安全，移动通信等各个领域。</p><ol><li>Apriori算法应用广泛，可用于消费市场价格分析，猜测顾客的消费习惯，比如较有名的“尿布和啤酒”的故事；</li><li>网络安全领域中的入侵检测技术；</li><li>可用在用于高校管理中，根据挖掘规则可以有效地辅助学校管理部门有针对性的开展贫困助学工作；</li><li>也可用在移动通信领域中，指导运营商的业务运营和辅助业务提供商的决策制定。</li></ol><p>关联规则算法的主要应用是购物篮分析，是为了从大量的订单中发现商品潜在的关联。其中常用的一个算法叫Apriori先验算法。</p><h2><span id="3-实验介绍">3. 实验介绍</span></h2><p>某大型连锁超市，在各个地区都有分店，在特定的时期需要做促销活动，由于每个地区消费者的行为有所差异，因此需要对每个地区的购物车数据单独分析，找出适合每个地区的商品促销套餐。购物车数据包含如下所示三个字段：用户标识，地区编号，购物车商品代码</p><p>使用<code>pyfpgrowth</code>包中的<code>find_frequent_patterns</code>来确定最低频数的组合，使用<code>generate_association_rules</code>来确定最低置信度的组合，以此来确定强相关规则，再选取最佳的前N个组合作为最终结果。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加需要的模块</span></span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line"><span class="keyword">import</span> pyfpgrowth <span class="keyword">as</span> fp</span><br><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">destIddict = {<span class="number">571</span>: <span class="string">'杭州'</span>, <span class="number">574</span>: <span class="string">'宁波'</span>, <span class="number">577</span>: <span class="string">'温州'</span>, <span class="number">573</span>: <span class="string">'嘉兴'</span>,</span><br><span class="line">              <span class="number">572</span>: <span class="string">'湖州'</span>, <span class="number">575</span>: <span class="string">'绍兴'</span>, <span class="number">579</span>: <span class="string">'金华'</span>, <span class="number">570</span>: <span class="string">'衢州'</span>,</span><br><span class="line">              <span class="number">580</span>: <span class="string">'舟山'</span>, <span class="number">576</span>: <span class="string">'台州'</span>, <span class="number">578</span>: <span class="string">'丽水'</span>}</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"*"</span> * <span class="number">10</span> + <span class="string">"以下输出了其中三个地区的商品套餐列表"</span> + <span class="string">"*"</span> * <span class="number">10</span>)</span><br><span class="line"><span class="keyword">for</span> i, destid <span class="keyword">in</span> <span class="built_in">enumerate</span>(destIddict.items()):</span><br><span class="line">    <span class="keyword">if</span> i &gt;= <span class="number">3</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">'%s地区的商品套餐列表'</span> % destid[<span class="number">1</span>])</span><br><span class="line">    dest_data = initData(destid[<span class="number">0</span>])</span><br><span class="line">    result1 = fp.find_frequent_patterns(dest_data, support_threshold=<span class="number">100</span>)  <span class="comment"># 最低频数为100</span></span><br><span class="line">    rules = fp.generate_association_rules(result1, confidence_threshold=<span class="number">0.35</span>)  <span class="comment"># 最低置信度为0.35</span></span><br><span class="line">    sortRules = <span class="built_in">sorted</span>(rules.items(), key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>][<span class="number">1</span>], reverse=<span class="literal">True</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"包含%d类套餐方案"</span> % <span class="built_in">len</span>(getlenRuleKinds(sortRules)))</span><br><span class="line">    kindkeys = getlenRuleKinds(sortRules).keys()</span><br><span class="line">    <span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> kindkey <span class="keyword">in</span> kindkeys:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">"************第%d类套餐,包含%d个套餐组合的频繁套餐规则：*****************"</span> % (kindkey - <span class="number">1</span>, kindkey))</span><br><span class="line">        rulesval = getlenRules(sortRules, kindkey)</span><br><span class="line">        cardNameDict = Id2CardName(rulesval)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">"规则总数%d个,其中排名前10的规则是："</span> % <span class="built_in">len</span>(cardNameDict))</span><br><span class="line">        <span class="keyword">for</span> j, items <span class="keyword">in</span> <span class="built_in">enumerate</span>(cardNameDict.items()):</span><br><span class="line">            <span class="keyword">if</span> j &lt;= <span class="number">9</span>:</span><br><span class="line">                <span class="built_in">print</span>(items)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">"***************************************"</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">'\n'</span>)</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
          <category> 推荐算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> 机器学习 </tag>
            
            <tag> 推荐算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker学习</title>
      <link href="/2022/03/30/others/docker/"/>
      <url>/2022/03/30/others/docker/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="docker学习">Docker学习</span></h1><h2><span id="docker安装">Docker安装</span></h2><h3><span id="环境准备">环境准备</span></h3><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">192.168.137.21</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看当前系统版本号</span></span><br><span class="line">uname</span><br><span class="line"><span class="meta prompt_"> </span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看当前系统版本的详细信息</span></span><br><span class="line">cat /etc/os-release</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure><h3><span id="安装docker">安装Docker</span></h3><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">1. 卸载旧的版本</span></span><br><span class="line">yum remove docker \</span><br><span class="line">    docker-client \</span><br><span class="line">    docker-client-latest \</span><br><span class="line">    docker-common \</span><br><span class="line">    docker-latest \</span><br><span class="line">    docker-latest-logrotate \</span><br><span class="line">    docker-logrotate \</span><br><span class="line">    docker-engine</span><br><span class="line">    </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">2. 需要的安装包</span></span><br><span class="line">yum install -y yum-utils</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">3. 设置镜像仓库</span></span><br><span class="line">yum-config-manager \</span><br><span class="line">--add-repo \</span><br><span class="line">https://download.docker.com/linux/centos/docker-ce.repo # 国外地址</span><br><span class="line"></span><br><span class="line">yum-config-manager \</span><br><span class="line">--add-repo \</span><br><span class="line">http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo # 国内源</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">更新 yum 软件包索引</span></span><br><span class="line">yum makecache fast</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">4. 安装Docker镜像相关的引擎  docker-ce是社区版 ee是企业版</span></span><br><span class="line">yum install docker-ce docker-ce-cli containerd.io</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">5. 启动 Docker</span></span><br><span class="line">systemctl start docker</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">6. 查看当前docker的安装情况</span></span><br><span class="line">docker version</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">7. hello-world</span></span><br><span class="line">docker run hello-world</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">8. 查看Docker镜像</span></span><br><span class="line">docker images</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">9. 了解卸载</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">卸载 Docker Engine, CLI, and Containerd packages:（卸载依赖）</span></span><br><span class="line">yum remove docker-ce docker-ce-cli containerd.io</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">删除所有的images, containers, and volumes（删除资源）</span></span><br><span class="line">rm -rf /var/lib/docker # docker的默认工作路径</span><br><span class="line">rm -rf /var/lib/containerd</span><br></pre></td></tr></tbody></table></figure><h3><span id="阿里云镜像加速">阿里云镜像加速</span></h3><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">针对Docker客户端版本大于 1.10.0 的用户</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">通过修改daemon配置文件/etc/docker/daemon.json来使用加速器</span></span><br><span class="line">mkdir -p /etc/docker</span><br><span class="line"></span><br><span class="line">tee /etc/docker/daemon.json &lt;&lt;-'EOF'</span><br><span class="line">{</span><br><span class="line">  "registry-mirrors": ["https://xrqxoe3h.mirror.aliyuncs.com"]</span><br><span class="line">}</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">重启服务</span></span><br><span class="line">systemctl daemon-reload</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">重启Docker</span></span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></tbody></table></figure><h3><span id="底层原理">底层原理</span></h3><p><strong>1. Docker是怎么工作的</strong></p><p>Docker是一个Client-Service结构的系统，Docker的守护进程运行在主机上，通过Socket从客户端访问！</p><p>Docker-Service接收到Docker-Client的指令，就会执行这个命令。</p><p><strong>2. Docker为什么比VM快</strong></p><ul><li>Docker有着比虚拟机更少的抽象层；</li><li>Docker利用的是宿主机的内核，vm需要的是Guest OS；</li></ul><h2><span id="docker的常用命令">Docker的常用命令</span></h2><h3><span id="帮助命令">帮助命令</span></h3><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker version # 显示docker的显示信息</span><br><span class="line">docker info# 显示docker的系统信息，包括镜像和容器的数量</span><br><span class="line">docker &lt;comment&gt; --help# 帮助命令</span><br></pre></td></tr></tbody></table></figure><p>官方文档 <a href="https://docs.docker.com/reference/">https://docs.docker.com/reference/</a></p><h3><span id="镜像命令">镜像命令</span></h3><p><strong>docker images</strong> 查看所有本地的主机镜像</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# docker images</span><br><span class="line">REPOSITORY    TAG       IMAGE ID       CREATED        SIZE</span><br><span class="line">hello-world   latest    d1165f221234   4 months ago   13.3kB</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">解释</span></span><br><span class="line">REPOSITORY镜像的仓库源</span><br><span class="line">TAG镜像的标签</span><br><span class="line">IMAGE ID镜像的ID</span><br><span class="line">CREATED镜像的创建时间</span><br><span class="line">SIZE镜像的大小</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">可选项</span></span><br><span class="line">Options:</span><br><span class="line">  -a, --all             # 列出所有的镜像</span><br><span class="line">  -q, --quiet           # 只显示镜像ID</span><br></pre></td></tr></tbody></table></figure><p><strong>docker search</strong> 搜索镜像</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# docker search mysql</span><br><span class="line">NAME                              DESCRIPTION                                     STARS     OFFICIAL   AUTOMATED</span><br><span class="line">mysql                             MySQL is a widely used, open-source relation…   11158     [OK]       </span><br><span class="line">mariadb                           MariaDB Server is a high performing open sou…   4235      [OK]       </span><br><span class="line">mysql/mysql-server                Optimized MySQL Server Docker images. Create…   830                  [OK]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">可选项，通过搜索来过滤</span></span><br><span class="line">--filter=STARS=3000# 搜索出来的是STARS &gt; 3000 的</span><br></pre></td></tr></tbody></table></figure><p><strong>docker pull</strong> 下载镜像</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">下载镜像 docker pull 镜像名[:tag]</span></span><br><span class="line">[root@localhost ~]# docker pull mysql</span><br><span class="line">Using default tag: latest# 如果不写tag， 默认就是最新版</span><br><span class="line">latest: Pulling from library/mysql</span><br><span class="line">33847f680f63: Pull complete # 分层下载，docker image的核心，联和文件系统</span><br><span class="line">5cb67864e624: Pull complete </span><br><span class="line">1a2b594783f5: Pull complete </span><br><span class="line">b30e406dd925: Pull complete </span><br><span class="line">48901e306e4c: Pull complete </span><br><span class="line">603d2b7147fd: Pull complete </span><br><span class="line">802aa684c1c4: Pull complete </span><br><span class="line">715d3c143a06: Pull complete </span><br><span class="line">6978e1b7a511: Pull complete </span><br><span class="line">f0d78b0ac1be: Pull complete </span><br><span class="line">35a94d251ed1: Pull complete </span><br><span class="line">36f75719b1a9: Pull complete </span><br><span class="line">Digest: sha256:8b928a5117cf5c2238c7a09cd28c2e801ac98f91c3f8203a8938ae51f14700fd# 签名</span><br><span class="line">Status: Downloaded newer image for mysql:latest</span><br><span class="line">docker.io/library/mysql:latest# 真实地址</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">等价于它</span></span><br><span class="line">docker pull mysql</span><br><span class="line">docker pull docker.io/library/mysql:latest</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">指定版本下载</span></span><br><span class="line">[root@localhost ~]# docker pull mysql:5.7</span><br><span class="line">5.7: Pulling from library/mysql</span><br><span class="line">33847f680f63: Already exists </span><br><span class="line">5cb67864e624: Already exists </span><br><span class="line">1a2b594783f5: Already exists </span><br><span class="line">b30e406dd925: Already exists </span><br><span class="line">48901e306e4c: Already exists </span><br><span class="line">603d2b7147fd: Already exists </span><br><span class="line">802aa684c1c4: Already exists </span><br><span class="line">5b5a19178915: Pull complete </span><br><span class="line">f9ce7411c6e4: Pull complete </span><br><span class="line">f51f6977d9b2: Pull complete </span><br><span class="line">aeb6b16ce012: Pull complete </span><br><span class="line">Digest: sha256:be70d18aedc37927293e7947c8de41ae6490ecd4c79df1db40d1b5b5af7d9596</span><br><span class="line">Status: Downloaded newer image for mysql:5.7</span><br><span class="line">docker.io/library/mysql:5.7</span><br></pre></td></tr></tbody></table></figure><p><strong>docker rmi</strong> 删除镜像</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker rmi -f &lt;IMAGE ID&gt;# 删除单个镜像</span><br><span class="line">docker rmi -f &lt;IMAGE ID&gt; &lt;IMAGE ID&gt; &lt;IMAGE ID&gt; # 删除多个镜像</span><br><span class="line">docker rmi -f $(docker images -aq)# 递归迭代删除所有镜像</span><br></pre></td></tr></tbody></table></figure><h3><span id="容器命令">容器命令</span></h3><p><strong>说明：有了镜像才可以创建容器，使用linux下载一个centos镜像来测试学习</strong></p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull centos</span><br></pre></td></tr></tbody></table></figure><p><strong>新建容器并启动</strong></p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">docker run [可选参数] image</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">参数说明</span></span><br><span class="line">--name="Name"容器名字Tomcat01 Tomcat02，用来区分容器</span><br><span class="line">-d后台方式运行</span><br><span class="line">-it使用交互方式运行，进入容器查看内容</span><br><span class="line">-p指定容器的端口-p8080:8080</span><br><span class="line">-p ip:主机端口：容器端口</span><br><span class="line">-p 主机端口：容器端口（常用）</span><br><span class="line">-p 容器端口</span><br><span class="line">容器端口</span><br><span class="line">-P随机指定端口</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">测试 （使用bash启动并进入容器）</span></span><br><span class="line">[root@localhost ~]# docker run -it centos /bin/bash </span><br><span class="line">[root@ffd1542c82f2 /]# ls# 查看容器内的centos，其中很多命令不完善</span><br><span class="line">bin  dev  etc  home  lib  lib64  lost+found  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var</span><br><span class="line">[root@ffd1542c82f2 /]# exit# 退出容器</span><br></pre></td></tr></tbody></table></figure><p><strong>列出所有运行的容器</strong></p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">docker ps 命令</span></span><br><span class="line"># 没有后续可选项，则表示列出当前正在运行的容器</span><br><span class="line">  -a            # 列出当前正在运行的容器+带出历史运行过得容器</span><br><span class="line">  -n=?# 显示最近创建的n个容器</span><br><span class="line">  -q# 只显示容器的编号</span><br><span class="line"></span><br><span class="line">[root@localhost /]# docker ps</span><br><span class="line">CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES</span><br><span class="line">[root@localhost /]# docker ps -a</span><br><span class="line">CONTAINER ID   IMAGE          COMMAND       CREATED         STATUS                     PORTS     NAMES</span><br><span class="line">ffd1542c82f2   centos         "/bin/bash"   4 minutes ago   Exited (0) 2 minutes ago             nice_fermat</span><br><span class="line">664379ddd5bf   d1165f221234   "/hello"      2 hours ago     Exited (0) 2 hours ago               elastic_bartik</span><br></pre></td></tr></tbody></table></figure><p><strong>退出容器</strong></p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">exit# 直接容器停止并退出</span><br><span class="line">Ctrl + P + Q # 容器不停止退出</span><br></pre></td></tr></tbody></table></figure><p><strong>删除容器</strong></p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker rm 容器id# 删除指定容器(-f 表示强制删除，正在运行中的只能通过强制删除来执行)</span><br><span class="line">docker rm -f $(docker ps -aq)  # 删除所有容器</span><br><span class="line">docker ps -a -q|xargs docker rm# 删除所有容器</span><br></pre></td></tr></tbody></table></figure><p><strong>启动和停止容器的操作</strong></p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker start 容器id</span><br><span class="line">docker restart 容器id</span><br><span class="line">docker stop 容器id# 停止</span><br><span class="line">docker kill 容器id# 强制停止</span><br></pre></td></tr></tbody></table></figure><h3><span id="其他常用命令">其他常用命令</span></h3><p>后台启动容器</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">命令 docker run -d 镜像名</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">问题 docker ps, 发现centos停止了</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">常见的坑，docker容器使用后台运行，必须要有一个前台进程，docker发现没有应用，就会自动停止</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">nginx，容器启动后，发现自己没有提供容器，就会立刻停止，就是没有程序了</span></span><br></pre></td></tr></tbody></table></figure><p><strong>查看日志</strong></p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">docker logs -f -t --tail &lt;number&gt; 容器id</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">自己编写一段shell脚本</span></span><br><span class="line">[root@localhost /]# docker run -d centos /bin/sh -c "while true;do echo Hello word;sleep 1;done"</span><br><span class="line">[root@localhost /]# docker ps</span><br><span class="line">CONTAINER ID   IMAGE</span><br><span class="line">dbac5d3e0b02   centos</span><br><span class="line">8c7f10bda482   centos</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">显示日志</span></span><br><span class="line">-tf# 显示日志</span><br><span class="line">--tail number #显示日志条数</span><br></pre></td></tr></tbody></table></figure><p><strong>查看容器中的进程信息 ps</strong></p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">命令</span></span><br><span class="line">docker top 容器id</span><br><span class="line">[root@localhost /]# docker top dbac5d3e0b02</span><br><span class="line">UID(当前的用户ID)    PID(父ID)           PPID(进程ID)        C                   STIME               TTY  </span><br><span class="line">root                12525               12507               0                   15:46               ?   </span><br><span class="line">root                12781               12525               0                   15:50               ?    </span><br></pre></td></tr></tbody></table></figure><p><strong>查看镜像的源数据</strong></p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">命令</span></span><br><span class="line">docker inspect 容器id</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">测试</span></span><br><span class="line">[</span><br><span class="line">    {</span><br><span class="line">        "Id": "dbac5d3e0b020deb2b0c10bc8c4dc43a75ed28be69e8fef7f80baf2555433ae2",</span><br><span class="line">        "Created": "2021-07-24T07:46:41.190366997Z",</span><br><span class="line">        "Path": "/bin/sh",</span><br><span class="line">        "Args": [</span><br><span class="line">            "-c",</span><br><span class="line">            "while true;do echo Hello word;sleep 1;done"</span><br><span class="line">        ],</span><br><span class="line">        "State": {</span><br><span class="line">            "Status": "running",</span><br><span class="line">            "Running": true,</span><br><span class="line">            "Paused": false,</span><br><span class="line">            "Restarting": false,</span><br><span class="line">            "OOMKilled": false,</span><br><span class="line">            "Dead": false,</span><br><span class="line">            "Pid": 12525,</span><br><span class="line">            "ExitCode": 0,</span><br><span class="line">            "Error": "",</span><br><span class="line">            "StartedAt": "2021-07-24T07:46:41.437400782Z",</span><br><span class="line">            "FinishedAt": "0001-01-01T00:00:00Z"</span><br><span class="line">        },</span><br><span class="line">        "Image": "sha256:300e315adb2f96afe5f0b2780b87f28ae95231fe3bdd1e16b9ba606307728f55",</span><br><span class="line">        "ResolvConfPath": "/var/lib/docker/containers/dbac5d3e0b020deb2b0c10bc8c4dc43a75ed28be69e8fef7f80baf2555433ae2/resolv.conf",</span><br><span class="line">        "HostnamePath": "/var/lib/docker/containers/dbac5d3e0b020deb2b0c10bc8c4dc43a75ed28be69e8fef7f80baf2555433ae2/hostname",</span><br><span class="line">        "HostsPath": "/var/lib/docker/containers/dbac5d3e0b020deb2b0c10bc8c4dc43a75ed28be69e8fef7f80baf2555433ae2/hosts",</span><br><span class="line">        "LogPath": "/var/lib/docker/containers/dbac5d3e0b020deb2b0c10bc8c4dc43a75ed28be69e8fef7f80baf2555433ae2/dbac5d3e0b020deb2b0c10bc8c4dc43a75ed28be69e8fef7f80baf2555433ae2-json.log",</span><br><span class="line">        "Name": "/peaceful_bassi",</span><br><span class="line">        "RestartCount": 0,</span><br><span class="line">        "Driver": "overlay2",</span><br><span class="line">        "Platform": "linux",</span><br><span class="line">        "MountLabel": "",</span><br><span class="line">        "ProcessLabel": "",</span><br><span class="line">        "AppArmorProfile": "",</span><br><span class="line">        "ExecIDs": null,</span><br><span class="line">        "HostConfig": {</span><br><span class="line">            "Binds": null,</span><br><span class="line">            "ContainerIDFile": "",</span><br><span class="line">            "LogConfig": {</span><br><span class="line">                "Type": "json-file",</span><br><span class="line">                "Config": {}</span><br><span class="line">            },</span><br><span class="line">            "NetworkMode": "default",</span><br><span class="line">            "PortBindings": {},</span><br><span class="line">            "RestartPolicy": {</span><br><span class="line">                "Name": "no",</span><br><span class="line">                "MaximumRetryCount": 0</span><br><span class="line">            },</span><br><span class="line">            "AutoRemove": false,</span><br><span class="line">            "VolumeDriver": "",</span><br><span class="line">            "VolumesFrom": null,</span><br><span class="line">            "CapAdd": null,</span><br><span class="line">            "CapDrop": null,</span><br><span class="line">            "CgroupnsMode": "host",</span><br><span class="line">            "Dns": [],</span><br><span class="line">            "DnsOptions": [],</span><br><span class="line">            "DnsSearch": [],</span><br><span class="line">            "ExtraHosts": null,</span><br><span class="line">            "GroupAdd": null,</span><br><span class="line">            "IpcMode": "private",</span><br><span class="line">            "Cgroup": "",</span><br><span class="line">            "Links": null,</span><br><span class="line">            "OomScoreAdj": 0,</span><br><span class="line">            "PidMode": "",</span><br><span class="line">            "Privileged": false,</span><br><span class="line">            "PublishAllPorts": false,</span><br><span class="line">            "ReadonlyRootfs": false,</span><br><span class="line">            "SecurityOpt": null,</span><br><span class="line">            "UTSMode": "",</span><br><span class="line">            "UsernsMode": "",</span><br><span class="line">            "ShmSize": 67108864,</span><br><span class="line">            "Runtime": "runc",</span><br><span class="line">            "ConsoleSize": [</span><br><span class="line">                0,</span><br><span class="line">                0</span><br><span class="line">            ],</span><br><span class="line">            "Isolation": "",</span><br><span class="line">            "CpuShares": 0,</span><br><span class="line">            "Memory": 0,</span><br><span class="line">            "NanoCpus": 0,</span><br><span class="line">            "CgroupParent": "",</span><br><span class="line">            "BlkioWeight": 0,</span><br><span class="line">            "BlkioWeightDevice": [],</span><br><span class="line">            "BlkioDeviceReadBps": null,</span><br><span class="line">            "BlkioDeviceWriteBps": null,</span><br><span class="line">            "BlkioDeviceReadIOps": null,</span><br><span class="line">            "BlkioDeviceWriteIOps": null,</span><br><span class="line">            "CpuPeriod": 0,</span><br><span class="line">            "CpuQuota": 0,</span><br><span class="line">            "CpuRealtimePeriod": 0,</span><br><span class="line">            "CpuRealtimeRuntime": 0,</span><br><span class="line">            "CpusetCpus": "",</span><br><span class="line">            "CpusetMems": "",</span><br><span class="line">            "Devices": [],</span><br><span class="line">            "DeviceCgroupRules": null,</span><br><span class="line">            "DeviceRequests": null,</span><br><span class="line">            "KernelMemory": 0,</span><br><span class="line">            "KernelMemoryTCP": 0,</span><br><span class="line">            "MemoryReservation": 0,</span><br><span class="line">            "MemorySwap": 0,</span><br><span class="line">            "MemorySwappiness": null,</span><br><span class="line">            "OomKillDisable": false,</span><br><span class="line">            "PidsLimit": null,</span><br><span class="line">            "Ulimits": null,</span><br><span class="line">            "CpuCount": 0,</span><br><span class="line">            "CpuPercent": 0,</span><br><span class="line">            "IOMaximumIOps": 0,</span><br><span class="line">            "IOMaximumBandwidth": 0,</span><br><span class="line">            "MaskedPaths": [</span><br><span class="line">                "/proc/asound",</span><br><span class="line">                "/proc/acpi",</span><br><span class="line">                "/proc/kcore",</span><br><span class="line">                "/proc/keys",</span><br><span class="line">                "/proc/latency_stats",</span><br><span class="line">                "/proc/timer_list",</span><br><span class="line">                "/proc/timer_stats",</span><br><span class="line">                "/proc/sched_debug",</span><br><span class="line">                "/proc/scsi",</span><br><span class="line">                "/sys/firmware"</span><br><span class="line">            ],</span><br><span class="line">            "ReadonlyPaths": [</span><br><span class="line">                "/proc/bus",</span><br><span class="line">                "/proc/fs",</span><br><span class="line">                "/proc/irq",</span><br><span class="line">                "/proc/sys",</span><br><span class="line">                "/proc/sysrq-trigger"</span><br><span class="line">            ]</span><br><span class="line">        },</span><br><span class="line">        "GraphDriver": {</span><br><span class="line">            "Data": {</span><br><span class="line">                "LowerDir": "/var/lib/docker/overlay2/d3bd1b8d57396b90cff4c17e12bece3e34754ed9bb57c58c7313b76f497a7e32-init/diff:/var/lib/docker/overlay2/caf2bb1d0c18a4a795b952cdfb87a2782faef45e4666c0acf08e9bef985a3807/diff",</span><br><span class="line">                "MergedDir": "/var/lib/docker/overlay2/d3bd1b8d57396b90cff4c17e12bece3e34754ed9bb57c58c7313b76f497a7e32/merged",</span><br><span class="line">                "UpperDir": "/var/lib/docker/overlay2/d3bd1b8d57396b90cff4c17e12bece3e34754ed9bb57c58c7313b76f497a7e32/diff",</span><br><span class="line">                "WorkDir": "/var/lib/docker/overlay2/d3bd1b8d57396b90cff4c17e12bece3e34754ed9bb57c58c7313b76f497a7e32/work"</span><br><span class="line">            },</span><br><span class="line">            "Name": "overlay2"</span><br><span class="line">        },</span><br><span class="line">        "Mounts": [],</span><br><span class="line">        "Config": {</span><br><span class="line">            "Hostname": "dbac5d3e0b02",</span><br><span class="line">            "Domainname": "",</span><br><span class="line">            "User": "",</span><br><span class="line">            "AttachStdin": false,</span><br><span class="line">            "AttachStdout": false,</span><br><span class="line">            "AttachStderr": false,</span><br><span class="line">            "Tty": false,</span><br><span class="line">            "OpenStdin": false,</span><br><span class="line">            "StdinOnce": false,</span><br><span class="line">            "Env": [</span><br><span class="line">                "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"</span><br><span class="line">            ],</span><br><span class="line">            "Cmd": [</span><br><span class="line">                "/bin/sh",</span><br><span class="line">                "-c",</span><br><span class="line">                "while true;do echo Hello word;sleep 1;done"</span><br><span class="line">            ],</span><br><span class="line">            "Image": "centos",</span><br><span class="line">            "Volumes": null,</span><br><span class="line">            "WorkingDir": "",</span><br><span class="line">            "Entrypoint": null,</span><br><span class="line">            "OnBuild": null,</span><br><span class="line">            "Labels": {</span><br><span class="line">                "org.label-schema.build-date": "20201204",</span><br><span class="line">                "org.label-schema.license": "GPLv2",</span><br><span class="line">                "org.label-schema.name": "CentOS Base Image",</span><br><span class="line">                "org.label-schema.schema-version": "1.0",</span><br><span class="line">                "org.label-schema.vendor": "CentOS"</span><br><span class="line">            }</span><br><span class="line">        },</span><br><span class="line">        "NetworkSettings": {</span><br><span class="line">            "Bridge": "",</span><br><span class="line">            "SandboxID": "b7172ccad7ead2be7fbc21570310e75a704efca6e9ea96b4c8403e0f780dd953",</span><br><span class="line">            "HairpinMode": false,</span><br><span class="line">            "LinkLocalIPv6Address": "",</span><br><span class="line">            "LinkLocalIPv6PrefixLen": 0,</span><br><span class="line">            "Ports": {},</span><br><span class="line">            "SandboxKey": "/var/run/docker/netns/b7172ccad7ea",</span><br><span class="line">            "SecondaryIPAddresses": null,</span><br><span class="line">            "SecondaryIPv6Addresses": null,</span><br><span class="line">            "EndpointID": "cbdc0fbaf967498b9998bc00218256fbc5e2392884cf86e76ef26926821d1b00",</span><br><span class="line">            "Gateway": "172.17.0.1",</span><br><span class="line">            "GlobalIPv6Address": "",</span><br><span class="line">            "GlobalIPv6PrefixLen": 0,</span><br><span class="line">            "IPAddress": "172.17.0.3",</span><br><span class="line">            "IPPrefixLen": 16,</span><br><span class="line">            "IPv6Gateway": "",</span><br><span class="line">            "MacAddress": "02:42:ac:11:00:03",</span><br><span class="line">            "Networks": {</span><br><span class="line">                "bridge": {</span><br><span class="line">                    "IPAMConfig": null,</span><br><span class="line">                    "Links": null,</span><br><span class="line">                    "Aliases": null,</span><br><span class="line">                    "NetworkID": "d7f11f7ce17c96a9b447952eb7cb5738ea9065bc59b508086dc834980998cec5",</span><br><span class="line">                    "EndpointID": "cbdc0fbaf967498b9998bc00218256fbc5e2392884cf86e76ef26926821d1b00",</span><br><span class="line">                    "Gateway": "172.17.0.1",</span><br><span class="line">                    "IPAddress": "172.17.0.3",</span><br><span class="line">                    "IPPrefixLen": 16,</span><br><span class="line">                    "IPv6Gateway": "",</span><br><span class="line">                    "GlobalIPv6Address": "",</span><br><span class="line">                    "GlobalIPv6PrefixLen": 0,</span><br><span class="line">                    "MacAddress": "02:42:ac:11:00:03",</span><br><span class="line">                    "DriverOpts": null</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">]</span><br></pre></td></tr></tbody></table></figure><p><strong>进入当前正在运行的命令</strong></p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">方式一：命令</span></span><br><span class="line">docker exec -it 容器id bashShell</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">测试</span></span><br><span class="line">[root@localhost /]# docker exec -it dbac5d3e0b02 /bin/bash</span><br><span class="line">[root@dbac5d3e0b02 /]# ps -ef</span><br><span class="line">UID        PID  PPID  C STIME TTY          TIME CMD</span><br><span class="line">root         1     0  0 07:46 ?        00:00:00 /bin/sh -c while true;do echo Hello word;sleep 1;done</span><br><span class="line">root       774     0  0 07:59 pts/0    00:00:00 /bin/bash</span><br><span class="line">root       796   774  0 07:59 pts/0    00:00:00 ps -ef</span><br><span class="line">root       797     1  0 07:59 ?        00:00:00 /bin/sh -c while true;do echo Hello word;sleep 1;done</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">方式二：命令</span></span><br><span class="line">docker attach 容器id</span><br><span class="line">[root@localhost /]# docker attach dbac5d3e0b02</span><br><span class="line">正在执行当前的代码...</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">docker <span class="built_in">exec</span><span class="comment"># 进入容器后开启一个新的终端，可以在里面进行操作（常用）</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">docker attach<span class="comment"># 进入容器当前正在执行的终端，不会启动新的进程</span></span></span><br></pre></td></tr></tbody></table></figure><p><strong>从容器内拷贝文件到主机上</strong></p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">docker cp 容器id:容器内路径 目的的主机路径</span><br><span class="line">[root@localhost ~]# docker run -it centos /bin/bash</span><br><span class="line">[root@5ef4c579aec7 /]# cd /home</span><br><span class="line">[root@localhost home]# docker attach 5ef4c579aec7</span><br><span class="line">[root@5ef4c579aec7 /]# cd /home</span><br><span class="line">[root@5ef4c579aec7 home]# touch test.java</span><br><span class="line">[root@5ef4c579aec7 home]# eixt</span><br><span class="line">bash: eixt: command not found</span><br><span class="line">[root@5ef4c579aec7 home]# exit</span><br><span class="line">exit</span><br><span class="line">[root@localhost home]# docker ps</span><br><span class="line">CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES</span><br><span class="line">[root@localhost home]# docker ps -a</span><br><span class="line">CONTAINER ID   IMAGE     COMMAND       CREATED         STATUS                       PORTS     NAMES</span><br><span class="line">5ef4c579aec7   centos    "/bin/bash"   3 minutes ago   Exited (127) 7 seconds ago             elastic_margulis</span><br><span class="line">[root@localhost home]# docker cp 5ef4c579aec7:/home/test.java /home/</span><br><span class="line">[root@localhost home]# ls</span><br><span class="line">gxl01  test.java</span><br></pre></td></tr></tbody></table></figure><h3><span id="命令小结">命令小结</span></h3><p>自己总结一下，列出来，方便查询</p><h3><span id="作业练习">作业练习</span></h3><blockquote><p>作业一：Docker 安装 Nginx</p></blockquote><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">1. 搜索镜像 search建议去dockerHub搜索，可以看帮助文档</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">2. 下载镜像 pull</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">3. 运行测试</span></span><br><span class="line">[root@localhost home]# docker images</span><br><span class="line">REPOSITORY   TAG       IMAGE ID       CREATED        SIZE</span><br><span class="line">nginx        latest    08b152afcfae   46 hours ago   133MB</span><br><span class="line">centos       latest    300e315adb2f   7 months ago   209MB</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">3344是nginx01容器中80端口在本地服务器上的映射</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-d 后台运行</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">--name 给容器起名</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-p 暴露端口，宿主机端口:容器内端口(端口暴露指代宿主机的防火墙将3344暴露出来，映射到nginx01容器的80端口)</span></span><br><span class="line">[root@localhost home]# docker run -d --name nginx01 -p 3344:80 nginx</span><br><span class="line">00d23b93cb9b42c329ebb95f6e0b1d76bb056f84f7170ffc0e21ce24b455a66c</span><br><span class="line">[root@localhost home]# docker images</span><br><span class="line">REPOSITORY   TAG       IMAGE ID       CREATED        SIZE</span><br><span class="line">nginx        latest    08b152afcfae   46 hours ago   133MB</span><br><span class="line">centos       latest    300e315adb2f   7 months ago   209MB</span><br><span class="line">[root@localhost home]# docker ps</span><br><span class="line">CONTAINER ID   IMAGE     COMMAND                  CREATED          STATUS          PORTS                                   NAMES</span><br><span class="line">00d23b93cb9b   nginx     "/docker-entrypoint.…"   22 seconds ago   Up 21 seconds   0.0.0.0:3344-&gt;80/tcp, :::3344-&gt;80/tcp   nginx01</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">验证端口是否可以访问</span></span><br><span class="line">[root@localhost home]# curl localhost:3344</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">之后尝试在浏览器通过 ip:端口的方式访问</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">4. 进入容器</span></span><br><span class="line">[root@localhost home]# docker exec -it nginx01 /bin/bash</span><br><span class="line">root@00d23b93cb9b:/# cd /etc/nginx/</span><br><span class="line">root@00d23b93cb9b:/etc/nginx# ls</span><br><span class="line">conf.d          mime.types  nginx.conf   uwsgi_params</span><br><span class="line">fastcgi_params  modules     scgi_params</span><br><span class="line">root@00d23b93cb9b:/etc/nginx# whereis nginx</span><br><span class="line">nginx: /usr/sbin/nginx /usr/lib/nginx /etc/nginx /usr/share/nginx</span><br></pre></td></tr></tbody></table></figure><blockquote><p>作业二：Docker 部署 tomact</p></blockquote><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">官方的使用</span></span><br><span class="line">docker run -it --rm tomcat:9.0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">之前的使用都是后台运行，停止容器后仍然可以查到，run -it --<span class="built_in">rm</span>，一般用来测试，执行完上述命令即删</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">常规方法：下载后启动并运行</span></span><br><span class="line">docker pull tomcat</span><br><span class="line">docker run -d -p 3355:8080 --name tomcat01 tomcat</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">测试访问是否有问题</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">出现404错误</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">进入容器</span></span><br><span class="line">[root@localhost home]# docker exec -it tomcat01 /bin/bash</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">发现问题：1. linux命令少了，没有ll命令，可以使用<span class="built_in">ls</span> -al代替； 2. 没有webapps。原因在于阿里云镜像知识最小的镜像，所有不必要的全部剔除，保证最小可运行的环境。</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将webapps放到特定目录</span></span><br><span class="line">root@91bcb7139ea8:/usr/local/tomcat# cp webapps.dist/* webapps</span><br><span class="line">cp: -r not specified; omitting directory 'webapps.dist/ROOT'</span><br><span class="line">cp: -r not specified; omitting directory 'webapps.dist/docs'</span><br><span class="line">cp: -r not specified; omitting directory 'webapps.dist/examples'</span><br><span class="line">cp: -r not specified; omitting directory 'webapps.dist/host-manager'</span><br><span class="line">cp: -r not specified; omitting directory 'webapps.dist/manager'</span><br><span class="line">root@91bcb7139ea8:/usr/local/tomcat# cp -r webapps.dist/* webapps</span><br><span class="line">root@91bcb7139ea8:/usr/local/tomcat# cd webapps</span><br><span class="line">root@91bcb7139ea8:/usr/local/tomcat/webapps# ls</span><br><span class="line">ROOT  docs  examples  host-manager  manager</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">再次测试，发现无错误</span></span><br></pre></td></tr></tbody></table></figure><blockquote><p>作业三：部署ES + KIBANA</p></blockquote><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ES 暴露的端口较多</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ES 十分消耗内存</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ES 的数据一般需要放置在安全目录！进行挂载</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动 elasticsearch</span></span><br><span class="line">docker run -d --name elasticsearch -p 9200:9200 -p 9300:9300 -e "discovery.type=single-node" elasticsearch:7.6.2</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">由于这个是非常卡的，可以使用docker stats查看当前cpu状态</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">因为太占资源，终止，所以考虑增加内存限制，修改配置文件 -e 环境配置修改</span></span><br><span class="line">docker run -d --name elasticsearch02 -p 9200:9200 -p 9300:9300 -e "discovery.type=single-node" -e ES_JAVA_OPTS="-Xms64m -Xmx512m" elasticsearch:7.6.2</span><br></pre></td></tr></tbody></table></figure><h3><span id="可视化">可视化</span></h3><ul><li><p>portainer（先用这个学习理论）</p><p>什么是portainer，一个图形化管理工具。</p><p>下载启动运行</p></li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -p 8088:9000 \</span><br><span class="line">--restart=always -v /var/run/docker.sock:/var/run/docker.sock --privileged=true portainer/portainer</span><br></pre></td></tr></tbody></table></figure><p>​                使用外网进行测试：8088端口</p><ul><li>Rancher（CI/CD学习时使用）</li></ul><h2><span id="docker-镜像讲解">Docker 镜像讲解</span></h2><h3><span id="镜像是什么">镜像是什么</span></h3><p>镜像是一种轻量级、可执行的独立软件包，用来打包软件运行环境和基于运行环境开发的软件，它包含运行某个软件所需要的所有内容，包括代码、运行时、库、环境变量和配置文件。所有应用直接打包成docker镜像，可以直接运行！</p><p>如何得到镜像：</p><ul><li>从远程仓库下载</li><li>朋友拷贝</li><li>自己制作一个镜像</li></ul><h3><span id="docker-镜像加载原理">Docker 镜像加载原理</span></h3><blockquote><p>UnionFS （联和文件系统）</p></blockquote><p>类似 git，支持对文件系统的修改作为一次提交来一层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系统下。Union文件系统是Docker镜像的基础。镜像可以通过继承，制作各种具体的应用镜像。</p><p>特性：一次同时加载多个文件系统，但从外面看起来，只能看到一个文件系统，联和加载会把各层文件系统叠加起来，这样最终的文件系统会包含所有底层的文件和目录。</p><blockquote><p>Docker 镜像加载原理</p></blockquote><p>bootfs(boot file system) 主要包含bootloader和kernel, bootloader主要是引导加载kernel。Docker镜像的最底层是bootfs。当boot加载完成之后整个内核就在内存中了，此时内存的使用权已由bootfs转交给内核，此时系统也会卸载bootfs。</p><p>rootfs(root file system), 在bootfs之上。包含的就是典型Linux系统中的/dev, /proc, /bin, /etc等标准目录和文件。rootfs就是各种不同的操作系统发行版，比如Ubuntu，Centos等等。</p><p>为什么Docker容器很小？</p><p>因为对于一个精简的OS，rootfs可以很小，只需要包含最基本的命令、工具和程序库就可以，底层直接使用Host的kernel，自己只需要提供rootfs就可以了，对于不同的linux发行版，bootfs基本一致，rootfs会有差别，因此可以公用bootfs。</p><h3><span id="分层理解">分层理解</span></h3><blockquote><p>分层的镜像</p></blockquote><p>在下载镜像时，可以注意到下载的日志是一层一层的在下载。</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost home]# docker pull redis</span><br><span class="line">Using default tag: latest</span><br><span class="line">latest: Pulling from library/redis</span><br><span class="line">33847f680f63: Already exists </span><br><span class="line">26a746039521: Pull complete </span><br><span class="line">18d87da94363: Pull complete </span><br><span class="line">5e118a708802: Pull complete </span><br><span class="line">ecf0dbe7c357: Pull complete </span><br><span class="line">46f280ba52da: Pull complete </span><br><span class="line">Digest: sha256:cd0c68c5479f2db4b9e2c5fbfdb7a8acb77625322dd5b474578515422d3ddb59</span><br><span class="line">Status: Downloaded newer image for redis:latest</span><br><span class="line">docker.io/library/redis:latest</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看redis镜像的具体信息</span></span><br><span class="line">[root@localhost home]# docker image inspect redis:latest</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">layer表示当前镜像包含的层，类似git，按顺序下载，下一层下载完毕实现对上一层的一个更新，整体下载完毕后，会生成一个层，即一个镜像</span></span><br><span class="line">"RootFS": {</span><br><span class="line">    "Type": "layers",</span><br><span class="line">    "Layers": [</span><br><span class="line">        "sha256:814bff7343242acfd20a2c841e041dd57c50f0cf844d4abd2329f78b992197f4",</span><br><span class="line">        "sha256:dd1ebb1f5319785e34838c7332a71e5255bda9ccf61d2a0bf3bff3d2c3f4cdb4",</span><br><span class="line">        "sha256:11f99184504048b93dc2bdabf1999d6bc7d9d9ded54d15a5f09e36d8c571c32d",</span><br><span class="line">        "sha256:e461360755916af80821289b1cbc503692cf63e4e93f09b35784d9f7a819f7f2",</span><br><span class="line">        "sha256:45f6df6342536d948b07e9df6ad231bf17a73e5861a84fc3c9ee8a59f73d0f9f",</span><br><span class="line">        "sha256:262de04acb7e0165281132c876c0636c358963aa3e0b99e7fbeb8aba08c06935"</span><br><span class="line">    ]</span><br><span class="line">},</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure><blockquote><p>特点</p></blockquote><p>Docker 镜像都是只读的，当容器启动时，一个新的可写被加载到镜像的顶部！这一层就是我们所说的容器层，容器之下都叫镜像层！</p><h3><span id="commot-镜像">commot 镜像</span></h3><p>如何提交一个自己的镜像</p><figure class="highlight dockerfile"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker commit 提交容器成为一个新的副本</span><br><span class="line"></span><br><span class="line"><span class="comment"># 命令和git原理类似</span></span><br><span class="line">docker commit -m=<span class="string">"提交的描述信息"</span> -a=<span class="string">"作者"</span> 容器id 目标镜像名:[TAG]</span><br></pre></td></tr></tbody></table></figure><p>实践</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动一个tomcat</span></span><br><span class="line">[root@localhost home]# docker run -it -p 8080:8080 tomcat</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将加入webapps之后的tomcat版本提交</span></span><br><span class="line">[root@localhost ~]# docker commit -a="gxl" -m="add webapps app" 87fa7eb87411 tomcat2.0:1.0 </span><br><span class="line">sha256:ab87991fac1bfec5c13b202c35aff374943fd9df03309bb8c5ba79aa15224ab0</span><br><span class="line">[root@localhost ~]# docker images</span><br><span class="line">REPOSITORY            TAG       IMAGE ID       CREATED         SIZE</span><br><span class="line">tomcat2.0             1.0       ab87991fac1b   7 seconds ago   673MB</span><br></pre></td></tr></tbody></table></figure><h2><span id="容器数据卷">容器数据卷</span></h2><h3><span id="什么是容器数据卷">什么是容器数据卷</span></h3><p>容器之间可以有一个数据共享技术！Docker容器中产生的数据，同步到本地！这就是卷技术！目录的挂载，将我们容器内的目录，挂载到Linux上面！</p><p>总结：容器的持久化和同步操作！容器之间也是可以进行数据共享的！</p><h3><span id="使用数据卷">使用数据卷</span></h3><blockquote><p>方式一：直接使用命令来挂载</p></blockquote><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">docker run -it -v 主机目录:容器内目录</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">测试</span></span><br><span class="line">[root@localhost ~]# docker run -it -v /home/ceshi:/home centos /bin/bash</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">docker inspect 容器<span class="built_in">id</span>，查看容器信息</span></span><br><span class="line">[root@localhost ceshi]# docker inspect 891847f6e5f7</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">容器的挂载信息，挂载 -v 卷</span></span><br><span class="line">"Mounts": [</span><br><span class="line">    {</span><br><span class="line">        "Type": "bind",</span><br><span class="line">        "Source": "/home/ceshi", # 映射的主机目录</span><br><span class="line">        "Destination": "/home",# 容器中的目录</span><br><span class="line">        "Mode": "",</span><br><span class="line">        "RW": true,</span><br><span class="line">        "Propagation": "rprivate"</span><br><span class="line">    }</span><br><span class="line">],</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">双向绑定，一边发生变化，另一边也会发生变化</span></span><br></pre></td></tr></tbody></table></figure><p>常用方式：在修改某些服务器配置文件时，考虑使用挂载的方式进行，每次修改配置只需要在主机上进行修改即可。</p><h3><span id="实战安装mysql">实战：安装MySQL</span></h3><p>思考：MySQL的数据持久化问题</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# docker pull mysql:5.7</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动镜像</span></span><br><span class="line">[root@localhost ~]# docker run -d -p 3310:3306 -v /home/mysql/conf:/etc/mysql/conf.d -v /home/mysql/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 --name mysql01 mysql:5.7</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动成功之后，我们在本地使用mysql进行连接测试--可以成功</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">持久化可以理解为将mysql数据持久化保存在本地服务器，之后mysql服务器容器进行删除，也不会影响本地的数据卷</span></span><br></pre></td></tr></tbody></table></figure><h3><span id="具名和匿名挂载">具名和匿名挂载</span></h3><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">匿名挂载</span></span><br><span class="line">-v 容器内路径！</span><br><span class="line">docker run -d -P --name nginx02 -v /etc/nginx nginx</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看所有的 volume 的情况</span></span><br><span class="line">[root@localhost ~]# docker volume ls</span><br><span class="line">local     5e55284fa50435535c15afa40651def91db502fa99a16aefa5fc4f92d654b07d</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">这里发现，这种就是匿名挂载，我们在 -v 只写了容器内的路径，没有写容器外的路径</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">具名挂载</span></span><br><span class="line">docker run -d -P --name nginx03 -v juming-nginx:/etc/nginx nginx</span><br><span class="line">[root@localhost ~]# docker volume ls</span><br><span class="line">local     juming-nginx</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">通过 -v 卷名:容器内路径</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看一下这个卷</span></span><br><span class="line">[root@localhost ~]# docker volume inspect juming-nginx</span><br><span class="line">[</span><br><span class="line">    {</span><br><span class="line">        "CreatedAt": "2021-07-25T13:16:04+08:00",</span><br><span class="line">        "Driver": "local",</span><br><span class="line">        "Labels": null,</span><br><span class="line">        # 表示挂载地址</span><br><span class="line">        "Mountpoint": "/var/lib/docker/volumes/juming-nginx/_data",</span><br><span class="line">        "Name": "juming-nginx",</span><br><span class="line">        "Options": null,</span><br><span class="line">        "Scope": "local"</span><br><span class="line">    }</span><br><span class="line">]</span><br></pre></td></tr></tbody></table></figure><p>所有Docker容器内的卷，在没有指定目录的情况下都是在<code>/var/lib/docker/volumes/xxx/_data</code>中</p><p>我们通过具名挂载可以方便的找到我们的一个卷，大多数情况下使用的是<code>具名挂载</code></p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">具名挂载、匿名挂载、指定路径挂载</span></span><br><span class="line">-v 容器内路径 # 匿名挂载</span><br><span class="line">-v 卷名:容器内路径  # 具名挂载</span><br><span class="line">-v /宿主机路径:容器内路径# 指定路径挂载</span><br></pre></td></tr></tbody></table></figure><p>扩展：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">通过 -v 容器内路径, ro/rw 改变读写权限</span></span><br><span class="line">roreadonly# 只读</span><br><span class="line">rwreadwrite# 可读可写（不写，默认为rw）</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">一旦设置了容器权限，容器对我们挂载出来的内容就有了限定!</span></span><br><span class="line">docker run -d -P --name nginx04 -v juming-nginx:/etc/nginx:ro nginx</span><br><span class="line">docker run -d -P --name nginx04 -v juming-nginx:/etc/nginx:rw nginx</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ro 只要看到ro就说明这个路径只能通过宿主机来操作，容器内部是无法操作的!</span></span><br></pre></td></tr></tbody></table></figure><h3><span id="初识dockerfile">初识DockerFile</span></h3><p>DockerFile就是用来构建 docker镜像的构建文件!可以通过写dockerfile命令脚本来实现。</p><blockquote><p>方式二</p></blockquote><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建一个dockerfile文件，名字可以随机，建议使用dockerfile开头</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">文件中的内容指令（大写）参数</span></span><br><span class="line">FROM centos</span><br><span class="line"></span><br><span class="line">VOLUM ["volume01", "volume02"]</span><br><span class="line"></span><br><span class="line">CMD echo "---end---"</span><br><span class="line"></span><br><span class="line">CMD /bin/bash</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">这里每个命令就是镜像的一层</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">执行上述命令，打包成一个新的镜像并提交 -t生成的镜像名</span></span><br><span class="line">[root@localhost docker-test-volume]# docker build -f /home/docker-test-volume/dockerfile1 -t localhost/centos:1.0 .</span><br><span class="line">Sending build context to Docker daemon  2.048kB</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">这里每个命令就是镜像的一层</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">1. centos的重定向</span></span><br><span class="line">Step 1/4 : FROM centos</span><br><span class="line"><span class="meta prompt_"> ---&gt; </span><span class="language-bash">300e315adb2f</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">2. 对生成的镜像，在创建的时候进行挂载</span></span><br><span class="line">Step 2/4 : VOLUME ["volume01", "volume02"]</span><br><span class="line"><span class="meta prompt_"> ---&gt; </span><span class="language-bash">Running <span class="keyword">in</span> b393dbf42fac</span></span><br><span class="line">Removing intermediate container b393dbf42fac</span><br><span class="line"><span class="meta prompt_"> ---&gt; </span><span class="language-bash">2e2ad7cc9364</span></span><br><span class="line">Step 3/4 : CMD echo "---end---"</span><br><span class="line"><span class="meta prompt_"> ---&gt; </span><span class="language-bash">Running <span class="keyword">in</span> 4060d9812574</span></span><br><span class="line">Removing intermediate container 4060d9812574</span><br><span class="line"><span class="meta prompt_"> ---&gt; </span><span class="language-bash">62605877f237</span></span><br><span class="line">Step 4/4 : CMD /bin/bash</span><br><span class="line"><span class="meta prompt_"> ---&gt; </span><span class="language-bash">Running <span class="keyword">in</span> ac2df04559e3</span></span><br><span class="line">Removing intermediate container ac2df04559e3</span><br><span class="line"><span class="meta prompt_"> ---&gt; </span><span class="language-bash">5206574493a5</span></span><br><span class="line">Successfully built 5206574493a5</span><br><span class="line">Successfully tagged localhost/centos:1.0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动自己的镜像 5206574493a5-镜像<span class="built_in">id</span></span></span><br><span class="line">[root@localhost docker-test-volume]# docker run -it 5206574493a5 /bin/bash</span><br><span class="line">[root@9dee0e99a55e /]# ls -l</span><br><span class="line">total 0</span><br><span class="line">drwxr-xr-x.  20 root root 262 Dec  4  2020 var</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">下面两个就是在生成镜像的时候自动挂载的数据卷目录</span></span><br><span class="line">drwxr-xr-x.   2 root root   6 Jul 25 08:40 volume01</span><br><span class="line">drwxr-xr-x.   2 root root   6 Jul 25 08:40 volume02</span><br></pre></td></tr></tbody></table></figure><p>这个volume01、volume02在外部一定有一个同步的目录！</p><p><code>VOLUME ["volume01", "volume02"]</code></p><p>查一下卷挂载的路径</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost docker-test-volume]# docker inspect 9dee0e99a55e</span><br><span class="line">"Mounts": [</span><br><span class="line">    {</span><br><span class="line">        "Type": "volume",</span><br><span class="line">        "Name": "a44a3a2ab2cac02a9496a0d2ba95c642f8db6fb633e1a6e92085dcac97f9ddc9",</span><br><span class="line">        "Source": "/var/lib/docker/volumes/a44a3a2ab2cac02a9496a0d2ba95c642f8db6fb633e1a6e92085dcac97f9ddc9/_data",</span><br><span class="line">        "Destination": "volume01",</span><br><span class="line">        "Driver": "local",</span><br><span class="line">        "Mode": "",</span><br><span class="line">        "RW": true,</span><br><span class="line">        "Propagation": ""</span><br><span class="line">    },</span><br><span class="line">    {</span><br><span class="line">        "Type": "volume",</span><br><span class="line">        "Name": "ac746ec0b43315a475c7c1f5330ad5026db538fafba638a09c854ba5fc16c61b",</span><br><span class="line">        "Source": "/var/lib/docker/volumes/ac746ec0b43315a475c7c1f5330ad5026db538fafba638a09c854ba5fc16c61b/_data",</span><br><span class="line">        "Destination": "volume02",</span><br><span class="line">        "Driver": "local",</span><br><span class="line">        "Mode": "",</span><br><span class="line">        "RW": true,</span><br><span class="line">        "Propagation": ""</span><br><span class="line">    }</span><br><span class="line">],</span><br></pre></td></tr></tbody></table></figure><p>假设镜像没有挂载卷，要手动进行镜像挂载 -v 卷名:容器内路径！</p><h3><span id="数据卷容器">数据卷容器</span></h3><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">操作：将docker02挂载到docker01实现数据的同步，将docker03挂载到docker02，实现两者之间的数据同步，本地中也存在挂载卷，docker01、docker02、docker03在本地挂载的位置是一致的，可以使用docker inspect查看</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">docker run -it --name docker名 --volumes-from 挂载容器<span class="built_in">id</span> 镜像<span class="built_in">id</span>或者镜像名</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">建立docker01容器</span></span><br><span class="line">[root@localhost /]# docker run -it --name docker01 localhost/centos:1.0</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">docker02容器继承docker01，实现挂载同步</span></span><br><span class="line">[root@localhost /]# docker run -it --name docker02 --volumes-from docker01 localhost/centos:1.0</span><br><span class="line">[root@localhost /]# docker run -it --name docker03 --volumes-from docker02 localhost/centos:1.0</span><br></pre></td></tr></tbody></table></figure><p>多个mysql实现数据共享</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# docker run -d -p 3310:3306 -v /etc/mysql/conf.d -v /var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 --name mysql01 mysql:5.7</span><br><span class="line"></span><br><span class="line">[root@localhost ~]# docker run -d -p 3310:3306 -e MYSQL_ROOT_PASSWORD=123456 --name mysql02 --volumes-from mysql01 mysql:5.7</span><br></pre></td></tr></tbody></table></figure><p><strong>结论</strong></p><p>容器之间配置信息的传递，数据卷容器的生命周期一致持续到没有容器使用为止。但是一旦持续化到本地，这个时候，本地的数据是不会删除的！</p><h2><span id="dockerfile">DockerFile</span></h2><h3><span id="dockerfile介绍">DockerFile介绍</span></h3><p>dockerfile使用来构建docker镜像的文件！命令参数脚本！</p><p>构建步骤：</p><ol><li>编写一个dockerfile文件</li><li>docker build 构建成一个镜像</li><li>docker run 运行镜像</li><li>docker push 发布镜像（DockerHub、阿里云镜像仓库！）</li></ol><p>查看一下官方文档</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">点击具体版本进入github，可以看到dockerfile脚本</span></span><br><span class="line">FROM scratch # 一个最基本的镜像</span><br><span class="line">ADD centos-7-x86_64-docker.tar.xz /  # 添加一个centos7的功能</span><br><span class="line"></span><br><span class="line">LABEL \  # 添加一些centos7的一些基本标签label</span><br><span class="line">    org.label-schema.schema-version="1.0" \</span><br><span class="line">    org.label-schema.name="CentOS Base Image" \</span><br><span class="line">    org.label-schema.vendor="CentOS" \</span><br><span class="line">    org.label-schema.license="GPLv2" \</span><br><span class="line">    org.label-schema.build-date="20201113" \</span><br><span class="line">    org.opencontainers.image.title="CentOS Base Image" \</span><br><span class="line">    org.opencontainers.image.vendor="CentOS" \</span><br><span class="line">    org.opencontainers.image.licenses="GPL-2.0-only" \</span><br><span class="line">    org.opencontainers.image.created="2020-11-13 00:00:00+00:00"</span><br><span class="line"></span><br><span class="line">CMD ["/bin/bash"]</span><br></pre></td></tr></tbody></table></figure><p>很多官方镜像都是基础包，很多功能都没有，我们通常会搭建自己的镜像！</p><h3><span id="dockerfile构建过程">DockerFile构建过程</span></h3><p><strong>基础知识</strong></p><ol><li>每个保留关键字（指令）都是必须是大写字母</li><li>执行从上到下顺序执行</li><li><code>#</code>表示注释</li><li>每个指令都会创建提交一个新的镜像层，并提交</li></ol><p><img src="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fimg2020.cnblogs.com%2Fblog%2F1869289%2F202005%2F1869289-20200529090814461-1122968296.png&amp;refer=http%3A%2F%2Fimg2020.cnblogs.com&amp;app=2002&amp;size=f9999,10000&amp;q=a80&amp;n=0&amp;g=0n&amp;fmt=jpeg?sec=1629797850&amp;t=6933ac1fe6a1c4ddd055e9dcc30e0edf" alt="img"></p><p>DcokerFile镜像逐渐成为企业交付的标准，必须掌握！</p><p>DockerFile：构建文件，定义了一切的步骤，源代码</p><p>DockerImages：通过DockerFile构建生成的镜像，最终发布和运行产品</p><p>Docker容器：容器就是镜像运行起来提供的服务器</p><h3><span id="dockerfile的指令">DockerFile的指令</span></h3><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">FROM # 基础镜像，一切从这里开始</span><br><span class="line">MAINTAINER# 镜像是谁写的，姓名+邮箱</span><br><span class="line">RUN# 镜像构建的时候需要运行的命令</span><br><span class="line">ADD# 步骤，tomcat镜像，这个tomcat压缩包！添加内容</span><br><span class="line">WORKDIR# 镜像的工作目录</span><br><span class="line">VOLUME# 挂载的目录</span><br><span class="line">EXPOSE# 暴露端口配置</span><br><span class="line">CMD# 指定这个容器启动的时候要运行的命令，只有最后一个会生效，可以被替代</span><br><span class="line">ENTRYPOINT# 指定这个容器启动的时候要运行的命令，可以追加命令</span><br><span class="line">ONBUILD# 当构建一个被继承 DockerFile 这个时候就会运行 ONBUILD 的指令，触发指令</span><br><span class="line">COPY # 类似ADD，将我们文件拷贝到镜像中</span><br><span class="line">ENV# 构建的时候设置环境变量！</span><br></pre></td></tr></tbody></table></figure><h3><span id="实战测试-创建自己的centos镜像">实战测试-创建自己的Centos镜像</span></h3><p>Docker Hub 中 99% 镜像都是从这个基础镜像过来的 FROM <code>scratch</code>，然后配置需要的软件和配置来进行的构建</p><blockquote><p>创建自己的centos</p></blockquote><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">1. 编写Dockerfile的文件</span></span><br><span class="line">[root@localhost home]# cat mydockerfile-centos </span><br><span class="line">FROM centos</span><br><span class="line">MAINTAINER GUOXL&lt;xinleguo@outlook.com&gt;</span><br><span class="line"></span><br><span class="line">ENV MYPATH /usr/local# 设置工作路径</span><br><span class="line">WORKDIR $MYPATH</span><br><span class="line"></span><br><span class="line">RUN yum -y install vim</span><br><span class="line">RUN yum -y install net-tools</span><br><span class="line"></span><br><span class="line">EXPOSE 80</span><br><span class="line"></span><br><span class="line">CMD echo $MYPATH</span><br><span class="line">CMD echo "---end---"</span><br><span class="line">CMD /bin/bash</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">2. 通过这个文件构建镜像</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">命令 docker build -f dockerfile文件路径 -t 镜像名:[tag]</span></span><br><span class="line"></span><br><span class="line">Successfully built 88bb91d56aa2</span><br><span class="line">Successfully tagged mycentos:0.1</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">3. 测试运行</span></span><br></pre></td></tr></tbody></table></figure><p>增加之后的镜像</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost home]# docker run -it mycentos:0.1</span><br><span class="line">[root@6ce26b5f132e local]# pwd</span><br><span class="line">/usr/local</span><br><span class="line">[root@6ce26b5f132e local]# ifconfig</span><br><span class="line">eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class="line">        inet 172.17.0.6  netmask 255.255.0.0  broadcast 172.17.255.255</span><br><span class="line">        ether 02:42:ac:11:00:06  txqueuelen 0  (Ethernet)</span><br><span class="line">        RX packets 8  bytes 656 (656.0 B)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 0  bytes 0 (0.0 B)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536</span><br><span class="line">        inet 127.0.0.1  netmask 255.0.0.0</span><br><span class="line">        loop  txqueuelen 1000  (Local Loopback)</span><br><span class="line">        RX packets 0  bytes 0 (0.0 B)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 0  bytes 0 (0.0 B)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure><p>本地docker镜像的变更地址</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost home]# docker history 88bb91d56aa2 # 镜像id</span><br><span class="line">IMAGE          CREATED         CREATED BY                                      SIZE      COMMENT</span><br><span class="line">88bb91d56aa2   7 minutes ago   /bin/sh -c #(nop)  CMD ["/bin/sh" "-c" "/bin…   0B        </span><br><span class="line">d7ed51f66b99   7 minutes ago   /bin/sh -c #(nop)  CMD ["/bin/sh" "-c" "echo…   0B        </span><br><span class="line">14d64a6ce413   7 minutes ago   /bin/sh -c #(nop)  CMD ["/bin/sh" "-c" "echo…   0B        </span><br><span class="line">df620171bab5   7 minutes ago   /bin/sh -c #(nop)  EXPOSE 80                    0B        </span><br><span class="line">a51b3b997e53   7 minutes ago   /bin/sh -c yum -y install net-tools             27.7MB    </span><br><span class="line">bd64cf31f5a3   7 minutes ago   /bin/sh -c yum -y install vim                   65.2MB    </span><br><span class="line">dda1db55e5ed   8 minutes ago   /bin/sh -c #(nop) WORKDIR /usr/local            0B        </span><br><span class="line">b0c738f47d37   8 minutes ago   /bin/sh -c #(nop)  ENV MYPATH=/usr/local        0B        </span><br><span class="line">1389604442d6   8 minutes ago   /bin/sh -c #(nop)  MAINTAINER GUOXL&lt;xinleguo…   0B        </span><br><span class="line">300e315adb2f   7 months ago    /bin/sh -c #(nop)  CMD ["/bin/bash"]            0B        </span><br><span class="line">&lt;missing&gt;      7 months ago    /bin/sh -c #(nop)  LABEL org.label-schema.sc…   0B        </span><br><span class="line">&lt;missing&gt;      7 months ago    /bin/sh -c #(nop) ADD file:bd7a2aed6ede423b7…   209MB     </span><br><span class="line">[root@localhost home]# </span><br></pre></td></tr></tbody></table></figure><p>使用<code>history</code>可以查看一些官方镜像的变更历史，了解官方镜像是怎么做的</p><blockquote><p>CMD 和 ENTRYPOINT 的区别</p></blockquote><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CMD# 指定这个容器启动的时候要运行的命令，只有最后一个会生效，可以被替代</span><br><span class="line">ENTRYPOINT# 指定这个容器启动的时候要运行的命令，可以追加命令</span><br></pre></td></tr></tbody></table></figure><p>测试 <code>cmd</code> 命令</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">编写 dockerfile文件</span></span><br><span class="line">[root@localhost dockerfile]# cat dockerfile-cmd-test </span><br><span class="line">FROM centos</span><br><span class="line">CMD ["ls", "-a"]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">构建镜像</span></span><br><span class="line">[root@localhost dockerfile]# docker build -f dockerfile-cmd-test -t cmdtest .</span><br><span class="line">Successfully built 2462b18a2cd8</span><br><span class="line">Successfully tagged cmdtest:latest</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">run运行，发现我们的<span class="built_in">ls</span> -a命令生效</span></span><br><span class="line">[root@localhost dockerfile]# docker run 2462b18a2cd8</span><br><span class="line">.</span><br><span class="line">..</span><br><span class="line">.dockerenv</span><br><span class="line">bin</span><br><span class="line">dev</span><br><span class="line">etc</span><br><span class="line">home</span><br><span class="line">...</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">想追加一个命令 -l， <span class="built_in">ls</span> -al</span></span><br><span class="line">[root@localhost dockerfile]# docker run 2462b18a2cd8 -l</span><br><span class="line">docker: Error response from daemon: OCI runtime create failed: container_linux.go:380: starting container process caused: exec: "-l": executable file not found in $PATH: unknown.</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">失败原因在于 cmd 的清理下， <span class="string">'-l'</span> 替换了 <span class="string">'CMD ["ls", "-a"]'</span> 命令， -l不是命令所以报错</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">使用 <span class="built_in">ls</span> -al 可以执行</span></span><br><span class="line">[root@localhost dockerfile]#  docker run 2462b18a2cd8 ls -al</span><br><span class="line">total 0</span><br><span class="line">drwxr-xr-x.   1 root root   6 Jul 25 15:24 .</span><br><span class="line">drwxr-xr-x.   1 root root   6 Jul 25 15:24 ..</span><br><span class="line">-rwxr-xr-x.   1 root root   0 Jul 25 15:24 .dockerenv</span><br><span class="line">lrwxrwxrwx.   1 root root   7 Nov  3  2020 bin -&gt; usr/bin</span><br><span class="line">drwxr-xr-x.   5 root root 340 Jul 25 15:24 dev</span><br></pre></td></tr></tbody></table></figure><p>测试 <code>ENTRYPOINT</code> 命令</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost dockerfile]# vi dockerfile-cmd-entrypoint</span><br><span class="line">FROM centos</span><br><span class="line">ENTRYPOINT ["ls", "-a"]</span><br><span class="line"></span><br><span class="line">[root@localhost dockerfile]# docker build -f dockerfile-cmd-entrypoint -t entorypoint-test .</span><br><span class="line">Successfully built 94635b3392fc</span><br><span class="line">Successfully tagged entorypoint-test:latest</span><br><span class="line">[root@localhost dockerfile]# docker run 94635b3392fc</span><br><span class="line">.</span><br><span class="line">..</span><br><span class="line">usr</span><br><span class="line">var</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">我们的追加命令，是直接拼接在我们的 ENTRYPOINT 命令的后面</span></span><br><span class="line">[root@localhost dockerfile]# docker run 94635b3392fc -l</span><br><span class="line">total 0</span><br><span class="line">drwxr-xr-x.   1 root root   6 Jul 25 15:27 .</span><br><span class="line">drwxr-xr-x.   1 root root   6 Jul 25 15:27 ..</span><br><span class="line">drwxr-xr-x.   5 root root 340 Jul 25 15:27 dev</span><br><span class="line">drwxr-xr-x.   1 root root  66 Jul 25 15:27 etc</span><br></pre></td></tr></tbody></table></figure><p>Dockerfile中很多命令十分相似，我们需要了解他们的区别</p><h3><span id="实战-tomcat-镜像">实战 Tomcat 镜像</span></h3><ol><li>准备镜像文件 tomact 压缩包，jdk的压缩包</li></ol><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost mysql]# ls</span><br><span class="line">apache-tomcat-9.0.50.tar.gz  jdk-8u171-linux-x64.tar.gz</span><br></pre></td></tr></tbody></table></figure><ol><li>编写一个dockerfile文件，官方命名<code>Dockerfile</code>,<code>build</code>会自动寻找这个文件，不需要 <code>-f</code> 指定了。</li></ol><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">dockerfile 文件</span></span><br><span class="line">FROM centos</span><br><span class="line">MAINTAINET guoxl&lt;xinleguo@outlook.com&gt;</span><br><span class="line"></span><br><span class="line">COPY readme.txt /usr/local/readme.txt</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ADD 命令自动解压</span></span><br><span class="line">ADD jdk-8u171-linux-x64.tar.gz /usr/local/</span><br><span class="line">ADD apache-tomcat-9.0.50.tar.gz /usr/local/</span><br><span class="line"></span><br><span class="line">RUN yum -y install vim</span><br><span class="line"></span><br><span class="line">ENV MYPATH /usr/local</span><br><span class="line">WORKDIR $MYPATH</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">配置JAVA和TOMCAT的环境变量</span></span><br><span class="line">ENV JAVA_HOME /usr/local/jdk1.8.0_171</span><br><span class="line">ENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class="line">ENV CATALINA_HOME /usr/local/apache-tomcat-9.0.50</span><br><span class="line">ENV CATALINA_BASH /usr/local/apache-tomcat-9.0.50</span><br><span class="line">ENV PATH $PATH:$JAVA_HOME/bin:$CATALINA_HOME/lib:$CATALINA_BASH/bin</span><br><span class="line"></span><br><span class="line">EXPOSE 8080</span><br><span class="line"></span><br><span class="line">CMD /usr/local/apache-tomcat-9.0.50/bin/startup.sh &amp;&amp; tail -F /url/local/apache-tomcat-9.0.50/bin/logs/catalina.out</span><br></pre></td></tr></tbody></table></figure><ol><li>创建自己的镜像</li></ol><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">因为使用的是dockerfile，所以不需要在指定</span></span><br><span class="line">[root@localhost mysql]# docker build -t diytomcat .</span><br></pre></td></tr></tbody></table></figure><ol><li>创建容器并启动</li></ol><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost mysql]# docker run -d -p 9090:8080 --name gxltomcat -v /home/mysql/test:/url/local/apache-tomcat-9.0.50/webapps/test -v /home/mysql/tomcatlogs/:/url/local/apache-tomcat-9.0.50/logs diytomcat</span><br><span class="line">e9ffcb0abd0eba046ed9e7b74cc12269a52ed2f710c6f728921e10adfd5fb9cc</span><br><span class="line">[root@localhost mysql]# docker exec -it e9ffcb0abd0e /bin/bash</span><br></pre></td></tr></tbody></table></figure><ol><li>访问测试</li><li>部署web项目到Tomcat中，部署成功，可以直接访问（略）</li></ol><p>之后的开发步骤，需要掌握DockerFile的编写</p><h3><span id="发布自己的镜像">发布自己的镜像</span></h3><blockquote><p>DockerHub</p></blockquote><ol><li>注册自己的账号（确定可以登陆）</li><li>提交自己的镜像</li><li>登陆，登陆完毕之后就可以上传镜像了</li></ol><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost mysql]# docker login --help</span><br><span class="line"></span><br><span class="line">Usage:  docker login [OPTIONS] [SERVER]</span><br><span class="line"></span><br><span class="line">Log in to a Docker registry.</span><br><span class="line">If no server is specified, the default is defined by the daemon.</span><br><span class="line"></span><br><span class="line">Options:</span><br><span class="line">  -p, --password string   Password</span><br><span class="line">      --password-stdin    Take the password from stdin</span><br><span class="line">  -u, --username string   Username</span><br><span class="line">  </span><br><span class="line">[root@localhost mysql]# docker login -u 17610826032</span><br><span class="line">Password:</span><br><span class="line">Login Successed</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">提交镜像, 作者名/镜像名:[tag]，自己的镜像最好加上自己的版本号</span></span><br><span class="line">[root@localhost mysql]# docker push guoxl/diytomcat:1.0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">对镜像增加一个名字:[tag]</span></span><br><span class="line">[root@localhost mysql]# docker tag b38f9d66755c guoxl/tomcat:1.0</span><br><span class="line">[root@localhost mysql]# docker images</span><br><span class="line">REPOSITORY            TAG       IMAGE ID       CREATED          SIZE</span><br><span class="line">guoxl/tomcat          1.0       b38f9d66755c   19 minutes ago   678MB</span><br><span class="line">diytomcat             latest    b38f9d66755c   19 minutes ago   678MB</span><br><span class="line">[root@localhost mysql]# docker push guoxl/tomcat:1.0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">登出</span></span><br><span class="line">docker logout</span><br></pre></td></tr></tbody></table></figure><blockquote><p>阿里云镜像服务器</p></blockquote><ol><li>登陆阿里云并找到自己的镜像服务（镜像仓库）</li><li>创建自己的命名空间（阿里云里面创建）</li><li>创建容器镜像仓库（阿里云里面创建）</li><li>浏览基本信息，会有具体操作信息（具体操作参考官方文档）</li></ol><blockquote><p>网站开源、部署项目都是发布镜像/容器</p></blockquote><p><img src="C:\Users\Gxl\AppData\Roaming\Typora\typora-user-images\image-20210726235545157.png" alt="image-20210726235545157"></p><h2><span id="docker-网络">Docker 网络</span></h2><p>容器编排、容器部署</p><h3><span id="理解-docker0">理解 Docker0</span></h3><p>首先清空所有环境：<code>PS C:\Users\Gxl&gt; docker rmi -f $(docker images -aq)</code></p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">PS C:\Users\Gxl&gt; docker run -d -P --name tomcat01 tomcat</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看容器 IP地址，发现容器启动的时候会得到一个 eth0@if11 的 ip 地址，docker分配的</span></span><br><span class="line">PS C:\Users\Gxl&gt; docker exec -it tomcat01 ip addr</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: tunl0@NONE: &lt;NOARP&gt; mtu 1480 qdisc noop state DOWN group default qlen 1000</span><br><span class="line">    link/ipip 0.0.0.0 brd 0.0.0.0</span><br><span class="line">3: sit0@NONE: &lt;NOARP&gt; mtu 1480 qdisc noop state DOWN group default qlen 1000</span><br><span class="line">    link/sit 0.0.0.0 brd 0.0.0.0</span><br><span class="line">10: eth0@if11: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default</span><br><span class="line">    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0</span><br><span class="line">    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">       </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">思考本地服务器 是否可以 ping 通容器内部 ：172.17.0.2</span></span><br><span class="line">PS C:\Users\Gxl&gt; ping 172.17.0.2</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">linux 可以 ping 通 docker 容器内部</span></span><br></pre></td></tr></tbody></table></figure><blockquote><p>原理</p></blockquote><ol><li>我们每启动一个 Docker 容器， docker 就会给 docker 容器分配一个 ip，我们只要安装了 docker，就会有一个网卡 docker0桥接模式，使用的技术是 env-pair 技术！</li></ol><p>再启动一个容器</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">PS C:\Users\Gxl&gt; docker run -d -P --name tomcat02 tomcat</span><br><span class="line">546523fe7fb3eb70829108a710c65778f54be30cb8b123b29ea3e249ca243131</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看ip信息</span></span><br><span class="line">PS C:\Users\Gxl&gt; docker exec -it tomcat02 ip addr</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: tunl0@NONE: &lt;NOARP&gt; mtu 1480 qdisc noop state DOWN group default qlen 1000</span><br><span class="line">    link/ipip 0.0.0.0 brd 0.0.0.0</span><br><span class="line">3: sit0@NONE: &lt;NOARP&gt; mtu 1480 qdisc noop state DOWN group default qlen 1000</span><br><span class="line">    link/sit 0.0.0.0 brd 0.0.0.0</span><br><span class="line">12: eth0@if13: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default</span><br><span class="line">    link/ether 02:42:ac:11:00:03 brd ff:ff:ff:ff:ff:ff link-netnsid 0</span><br><span class="line">    inet 172.17.0.3/16 brd 172.17.255.255 scope global eth0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">       </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">我们发现这个容器带来的网卡都是一对对的</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">evth-pair 就是一对的虚拟设备接口，他们都是成对出现的，一端连接协议，一端批次相连</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">由于这个原因， evth-pair可以作为一个桥梁，连接各种虚拟网络设备的</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">OpenStac， Docker容器之间的连接，OVS的连接，都是使用env-pair 技术</span></span><br></pre></td></tr></tbody></table></figure><ol><li>我们来测试一下 tomcat01 和 tomcat02 是否可以 ping 通！</li></ol><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">PS C:\Users\Gxl&gt; docker exec -it tomcat02 ping 172.17.0.2</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">结论：容器和容器之间是可以互相 ping 通的！</span></span><br></pre></td></tr></tbody></table></figure><p>结论： tomcat01 和 tomcat02 是公用的一个路由器—-docker0，只要删除容器，对应的网桥一对就没了！</p><p>所有的容器不指定网络的情况下，都是docker0 路由的，docker会给我们的容器分配一个默认的可用的 IP： 0 ~ 255    </p><p>255.255.0.1/16(16代表两位，一位是八)，代表可以存放255*255-2（广播地址和mask）-局域网</p><p>255.255.0.1/24，代表只有后面255个可以存储网络的范围-域</p><h3><span id="link">—link</span></h3><blockquote><p>思考一个场景，我们编写了一个微服务，database url=ip，项目不重启，数据库ip换了，我们希望可以处理这个问题，可以用名字进行访问容器？</p></blockquote><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">PS C:\Users\Gxl&gt; docker exec -it tomcat02 ping tomcat01</span><br><span class="line">ping: tomcat01: Name or service not known</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如何解决？</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">通过--<span class="built_in">link</span>来解决</span></span><br><span class="line">PS C:\Users\Gxl&gt; docker run -d -P --name tomcat03 --link tomcat02 tomcat</span><br><span class="line">79f4cbc766c1845fcffbf5f634f80724444fbee8d93262a1495eb196f99f336b</span><br><span class="line">PS C:\Users\Gxl&gt; docker exec -it tomcat03 ping tomcat02</span><br><span class="line">PING tomcat02 (172.17.0.3) 56(84) bytes of data.</span><br><span class="line">64 bytes from tomcat02 (172.17.0.3): icmp_seq=1 ttl=64 time=0.147 ms</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在未配置的情况下，查看反向是否可以ping通</span></span><br><span class="line">PS C:\Users\Gxl&gt; docker exec -it tomcat02 ping tomcat03</span><br><span class="line">ping: tomcat03: Name or service not known</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">不可以</span></span><br></pre></td></tr></tbody></table></figure><p>探究：inspect</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">PS C:\Users\Gxl&gt; docker network --help</span><br><span class="line">Usage:  docker network COMMAND</span><br><span class="line">Manage networks</span><br><span class="line">Commands:</span><br><span class="line">  connect     Connect a container to a network</span><br><span class="line">  create      Create a network</span><br><span class="line">  disconnect  Disconnect a container from a network</span><br><span class="line">  inspect     Display detailed information on one or more networks</span><br><span class="line">  ls          List networks</span><br><span class="line">  prune       Remove all unused networks</span><br><span class="line">  rm          Remove one or more networks</span><br><span class="line"></span><br><span class="line">Run 'docker network COMMAND --help' for more information on a command.</span><br><span class="line"></span><br><span class="line">PS C:\Users\Gxl&gt; docker network ls</span><br><span class="line">NETWORK ID     NAME      DRIVER    SCOPE</span><br><span class="line">eda7d0c2c96a   bridge    bridge    local</span><br><span class="line">d3656a69fbaf   host      host      local</span><br><span class="line">48ecdc979956   none      null      local</span><br></pre></td></tr></tbody></table></figure><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">PS C:\Users\Gxl&gt; docker network inspect eda7d0c2c96a</span><br><span class="line">"Containers": {</span><br><span class="line">     "546523fe7fb3eb70829108a710c65778f54be30cb8b123b29ea3e249ca243131": {</span><br><span class="line">         "Name": "tomcat02",</span><br><span class="line">         "EndpointID": "79b597134e20063a2240381c5b71edaa2c4058951f6d125d10b1839d89d95356",</span><br><span class="line">         "MacAddress": "02:42:ac:11:00:03",</span><br><span class="line">         "IPv4Address": "172.17.0.3/16",</span><br><span class="line">         "IPv6Address": ""</span><br><span class="line">     },</span><br><span class="line">     "79f4cbc766c1845fcffbf5f634f80724444fbee8d93262a1495eb196f99f336b": {</span><br><span class="line">         "Name": "tomcat03",</span><br><span class="line">         "EndpointID": "1de12a280ecd92fa073cc417d86b693322988f0a5edb136bd2355ee3a6121918",</span><br><span class="line">         "MacAddress": "02:42:ac:11:00:04",</span><br><span class="line">         "IPv4Address": "172.17.0.4/16",</span><br><span class="line">         "IPv6Address": ""</span><br><span class="line">     },</span><br><span class="line">     "815db066728cda65001362d43dd7690ff3703640b27c5098510926f7c920e2ef": {</span><br><span class="line">         "Name": "tomcat01",</span><br><span class="line">         "EndpointID": "82f0a84448ddd1f36a89630a9baa5573f12e1ec77786e848767e968fafeba352",</span><br><span class="line">         "MacAddress": "02:42:ac:11:00:02",</span><br><span class="line">         "IPv4Address": "172.17.0.2/16",</span><br><span class="line">         "IPv6Address": ""</span><br><span class="line"> }</span><br></pre></td></tr></tbody></table></figure><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看网络配置</span></span><br><span class="line">PS C:\Users\Gxl&gt; docker exec -it tomcat03 cat /etc/hosts</span><br><span class="line">127.0.0.1       localhost</span><br><span class="line">::1     localhost ip6-localhost ip6-loopback</span><br><span class="line">fe00::0 ip6-localnet</span><br><span class="line">ff00::0 ip6-mcastprefix</span><br><span class="line">ff02::1 ip6-allnodes</span><br><span class="line">ff02::2 ip6-allrouters</span><br><span class="line">172.17.0.3      tomcat02 546523fe7fb3</span><br><span class="line">172.17.0.4      79f4cbc766c1</span><br><span class="line"></span><br><span class="line">PS C:\Users\Gxl&gt; docker exec -it tomcat02 cat /etc/hosts</span><br><span class="line">127.0.0.1       localhost</span><br><span class="line">::1     localhost ip6-localhost ip6-loopback</span><br><span class="line">fe00::0 ip6-localnet</span><br><span class="line">ff00::0 ip6-mcastprefix</span><br><span class="line">ff02::1 ip6-allnodes</span><br><span class="line">ff02::2 ip6-allrouters</span><br><span class="line">172.17.0.3      546523fe7fb3</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">发现tomcat03绑定了tomcat02，没有反向绑定</span></span><br></pre></td></tr></tbody></table></figure><p><strong>本质开发：已经不建议使用 —link</strong></p><p>docker0问题：不支持容器名访问</p><h3><span id="自定义网络">自定义网络</span></h3><p>容器互联 </p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">移除一个网络</span></span><br><span class="line">PS C:\Users\Gxl&gt; docker network rm host</span><br></pre></td></tr></tbody></table></figure><p><strong>网络模式</strong></p><ul><li>bridge：桥接 docker（默认）</li><li>none：不配置网络</li><li>host：和宿主机共享网络</li><li>container：容器网络连通！（用的少！不建议使用）</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动一个容器，默认配置的网络  --net bridge 可以省略</span></span><br><span class="line">PS C:\Users\Gxl&gt; docker run -d -P --name tomcat01 --net bridge tomcat</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">docker0特点：默认，域名不能访问，--<span class="built_in">link</span>可以打通</span></span><br></pre></td></tr></tbody></table></figure><p><strong>创建网络</strong></p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">常用参数 --driver --subnet</span></span><br><span class="line">PS C:\Users\Gxl&gt; docker network create --help</span><br><span class="line"></span><br><span class="line">Usage:  docker network create [OPTIONS] NETWORK</span><br><span class="line"></span><br><span class="line">Create a network</span><br><span class="line"></span><br><span class="line">Options:</span><br><span class="line">  -d, --driver string        Driver to manage the Network (default "bridge")</span><br><span class="line">      --gateway strings      IPv4 or IPv6 Gateway for the master subnet</span><br><span class="line">      --ingress              Create swarm routing-mesh network</span><br><span class="line">      --internal             Restrict external access to the network</span><br><span class="line">      --ip-range strings     Allocate container ip from a sub-range</span><br><span class="line">      --ipam-driver string   IP Address Management Driver (default "default")</span><br><span class="line">      --ipam-opt map         Set IPAM driver specific options (default map[])</span><br><span class="line">      --ipv6                 Enable IPv6 networking</span><br><span class="line">      --label list           Set metadata on a network</span><br><span class="line">  -o, --opt map              Set driver specific options (default map[])</span><br><span class="line">      --scope string         Control the network's scope</span><br><span class="line">      --subnet strings       Subnet in CIDR format that represents a</span><br><span class="line">                             network segment</span><br><span class="line">                             </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">--driver 连接模式（桥接）  --subnet 子网地址  --gateway 网关（wifi路由）</span></span><br><span class="line">PS C:\Users\Gxl&gt; docker network create --driver bridge --subnet 192.168.0.0/16 --gateway 192.168.0.1 mynet</span><br><span class="line">bf84863118e49b5f92be4359ef0ebe8f7c013951762a10b381a43de15005e4cd</span><br><span class="line">PS C:\Users\Gxl&gt; docker network ls</span><br><span class="line">NETWORK ID     NAME      DRIVER    SCOPE</span><br><span class="line">eda7d0c2c96a   bridge    bridge    local</span><br><span class="line">d3656a69fbaf   host      host      local</span><br><span class="line">bf84863118e4   mynet     bridge    local</span><br><span class="line">48ecdc979956   none      null      local</span><br><span class="line"></span><br><span class="line">PS C:\Users\Gxl&gt; docker network inspect mynet</span><br><span class="line">"Config": [</span><br><span class="line">    {</span><br><span class="line">        "Subnet": "192.168.0.0/16",</span><br><span class="line">        "Gateway": "192.168.0.1"</span><br><span class="line">    }</span><br><span class="line">]</span><br></pre></td></tr></tbody></table></figure><p>使用自己创建的网络模式创建容器</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">PS C:\Users\Gxl&gt; docker run -d -P --name tomcat-net-01 --net mynet tomcat</span><br><span class="line">961a633b06d2107c785e8128e5316df30fc37bbab1c77a94bb61041dcc7438ce</span><br><span class="line">PS C:\Users\Gxl&gt; docker run -d -P --name tomcat-net-02 --net mynet tomcat</span><br><span class="line">4a54a1a2c164ad1f2c95072322ec435e939dc9a61801d4074148011312860001</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">可以看到在自己配置的网络模式下，创建的两个容器，ip变化情况</span></span><br><span class="line">PS C:\Users\Gxl&gt; docker network inspect mynet</span><br><span class="line">"Containers": {</span><br><span class="line">    "4a54a1a2c164ad1f2c95072322ec435e939dc9a61801d4074148011312860001": {</span><br><span class="line">    "Name": "tomcat-net-02",</span><br><span class="line">    "EndpointID": "1ad5c900179171d7ca3b4a0d323222edbf89960bae8ea6840e5038747467636e",</span><br><span class="line">    "MacAddress": "02:42:c0:a8:00:03",</span><br><span class="line">    "IPv4Address": "192.168.0.3/16",</span><br><span class="line">    "IPv6Address": ""</span><br><span class="line">    },</span><br><span class="line">    "961a633b06d2107c785e8128e5316df30fc37bbab1c77a94bb61041dcc7438ce": {</span><br><span class="line">    "Name": "tomcat-net-01",</span><br><span class="line">    "EndpointID": "cd95f0afe15224e9cb25b411a311948cb3a1a6b4ce49832ba8e955f08eee3a75",</span><br><span class="line">    "MacAddress": "02:42:c0:a8:00:02",</span><br><span class="line">    "IPv4Address": "192.168.0.2/16",</span><br><span class="line">    "IPv6Address": ""</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>再次查看两个容器的连接情况，再次测试<br></p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">PS C:\Users\Gxl&gt; docker exec -it tomcat-net-01 ping 192.168.0.3</span><br><span class="line">PING 192.168.0.3 (192.168.0.3) 56(84) bytes of data.</span><br><span class="line">64 bytes from 192.168.0.3: icmp_seq=1 ttl=64 time=0.074 ms</span><br><span class="line">64 bytes from 192.168.0.3: icmp_seq=2 ttl=64 time=0.029 ms</span><br><span class="line"></span><br><span class="line">PS C:\Users\Gxl&gt; docker exec -it tomcat-net-01 ping tomcat-net-02</span><br><span class="line">PING tomcat-net-02 (192.168.0.3) 56(84) bytes of data.</span><br><span class="line">64 bytes from tomcat-net-02.mynet (192.168.0.3): icmp_seq=1 ttl=64 time=0.055 ms</span><br></pre></td></tr></tbody></table></figure><p></p><p>我们自定义的网络docker都已经帮我们维护好了对应的关系，推荐我们平时这样使用网络！</p><p><strong>好处：</strong></p><p>不同的集群使用不同的网络，保证集群是安全和健康的</p><p>redis集群、mysql集群</p><h3><span id="网络连通">网络连通</span></h3><p><strong>测试</strong></p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">使用docker默认的当时创建两个容器</span></span><br><span class="line">PS C:\Users\Gxl&gt; docker run -d -P --name tomcat01 tomcat</span><br><span class="line">714fa78b631fe51fd4dd2740f15da33692a9c7718acb1484dd9c8c95f8012739</span><br><span class="line">PS C:\Users\Gxl&gt; docker run -d -P --name tomcat02 tomcat</span><br><span class="line">a108027e95645b07a60a0681ad135fb2eddccb4d6cc2b4b9220c2a772753728f</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">测试使用自己的网络创建的容器和默认创建的容器是否可以网络连通</span></span><br><span class="line">PS C:\Users\Gxl&gt; docker exec -it tomcat01 ping tomcat-net-01</span><br><span class="line">ping: tomcat-net-01: Name or service not known</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">连通不能</span></span><br></pre></td></tr></tbody></table></figure><p>使用 network 实现两个不同网段的容器互联</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">PS C:\Users\Gxl&gt; docker network --help</span><br><span class="line">Commands:</span><br><span class="line">  connect     Connect a container to a network</span><br><span class="line">  create      Create a network</span><br><span class="line">  disconnect  Disconnect a container from a network</span><br><span class="line">  inspect     Display detailed information on one or more networks</span><br><span class="line">  ls          List networks</span><br><span class="line">  prune       Remove all unused networks</span><br><span class="line">  rm          Remove one or more networks</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">建立网络连接</span></span><br><span class="line">PS C:\Users\Gxl&gt; docker network connect mynet tomcat01</span><br></pre></td></tr></tbody></table></figure><p>测试，发现两个网段都有 tomcat01，可以ping 通tomcat-net-01</p><p>一个容器两个ip地址</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">PS C:\Users\Gxl&gt; docker network inspect mynet</span><br><span class="line">"Containers": {  "714fa78b631fe51fd4dd2740f15da33692a9c7718acb1484dd9c8c95f8012739": {</span><br><span class="line">    "Name": "tomcat01",</span><br><span class="line">    "EndpointID": "be42cfdab97659c40945d772bc34938af33fa73b5c524d2a5c069cbf46fc4b6a",</span><br><span class="line">    "MacAddress": "02:42:c0:a8:00:04",</span><br><span class="line">    "IPv4Address": "192.168.0.4/16",</span><br><span class="line">    "IPv6Address": ""</span><br><span class="line">    },</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">PS C:\Users\Gxl&gt; docker network inspect bridge</span><br><span class="line">"Containers": {  "714fa78b631fe51fd4dd2740f15da33692a9c7718acb1484dd9c8c95f8012739": {</span><br><span class="line">    "Name": "tomcat01",</span><br><span class="line">    "EndpointID": "07733abd6a531cfdfbf8ba92db6206b1b8242a566bd4d2f1133c75ef91b06eba",</span><br><span class="line">    "MacAddress": "02:42:ac:11:00:02",</span><br><span class="line">    "IPv4Address": "172.17.0.2/16",</span><br><span class="line">    "IPv6Address": ""</span><br><span class="line">},</span><br></pre></td></tr></tbody></table></figure><h3><span id="实战部署-redis-集群">实战：部署 Redis 集群</span></h3><p>分片+高可用+负载均衡</p><p>首先先建立一个redis网络</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">PS C:\Users\Gxl&gt; docker network create redis --subnet 172.38.0.0/16</span><br><span class="line">ae409f017df79fd219b3b8a6df4e73bd6bcdc14cd14923f2bcc62deb11ef57e0</span><br></pre></td></tr></tbody></table></figure><p>通过脚本创建六个redis配置</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">for port in $(seq 1 6); \</span><br><span class="line">do \</span><br><span class="line">mkdir -p /mydata/redis/node-${port}/conf</span><br><span class="line">touch /mydata/redis/node-${port}/conf/redis.conf</span><br><span class="line">cat &lt;&lt; EOF &gt;/m/mydata/redis/node-${port}/conf/redis.conf</span><br><span class="line">port 6379</span><br><span class="line">bind 0.0.0.0</span><br><span class="line">cluster-enabled yes</span><br><span class="line">cluster-config-file nodes.conf</span><br><span class="line">cluster-node-timout 5000</span><br><span class="line">cluster-announce-ip 172.38.0.1${port}</span><br><span class="line">cluster-announce-port 6379</span><br><span class="line">cluster-announce-bus-port 16379</span><br><span class="line">appendonly yes</span><br><span class="line">EOF</span><br><span class="line">done</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> Docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
            <tag> 集群 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>最小生成树算法模板</title>
      <link href="/2022/03/27/basic-algorithm/zui-xiao-sheng-cheng-shu-suan-fa/"/>
      <url>/2022/03/27/basic-algorithm/zui-xiao-sheng-cheng-shu-suan-fa/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="最小生成树算法模板">最小生成树算法模板</span></h1><p>假设 <code>n</code> 表示图中点数，<code>m</code> 表示图中边数。</p><h2><span id="prim算法">Prim算法</span></h2><p>适用于稠密图，时间复杂度 <code>O(n2)</code>。核心思想：每次挑一条与当前集合相连的最短边。</p><figure class="highlight c++"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// st[i] 表示点i是否在当前生成树集合中</span></span><br><span class="line"><span class="comment">// dist[i] 表示点i到当前集合的最短边的长度</span></span><br><span class="line"><span class="comment">// g[i][j] 表示点i和点j之间边的长度</span></span><br><span class="line"><span class="comment">// 返回值：最小生成树中所有边的总长度</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">Prim</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="type">int</span> res = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= n; i ++ )</span><br><span class="line">    {</span><br><span class="line">        dist[i] = INF;</span><br><span class="line">        st[i] = <span class="literal">false</span>;</span><br><span class="line">    }</span><br><span class="line">    dist[<span class="number">1</span>] = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= n; i ++ )</span><br><span class="line">    {</span><br><span class="line">        <span class="type">int</span> id = <span class="number">-1</span>, min_dist = INF;</span><br><span class="line">        <span class="comment">// 寻找最短边</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">1</span>; j &lt;= n; j ++ )</span><br><span class="line">            <span class="keyword">if</span> (!st[j] &amp;&amp; dist[j] &lt; min_dist)</span><br><span class="line">            {</span><br><span class="line">                id = j;</span><br><span class="line">                min_dist = dist[j];</span><br><span class="line">            }</span><br><span class="line">        st[id] = <span class="literal">true</span>;</span><br><span class="line">        res += dist[id];</span><br><span class="line">        <span class="comment">// 用新加入的点更新其余点到生成树的最短边</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">1</span>; j &lt;= n; j ++ )</span><br><span class="line">            <span class="keyword">if</span> (!st[j])</span><br><span class="line">                dist[j] = <span class="built_in">min</span>(dist[j], g[id][j]);</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h2><span id="kruskal算法-使用并查集来进行合并">Kruskal算法 （使用并查集来进行合并）</span></h2><p>适用于稀疏图，时间复杂度 <code>O(mlogm)</code>。核心思想：从小到大挑不多余的边。</p><figure class="highlight c++"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 边的信息</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Edge</span></span><br><span class="line">{</span><br><span class="line">    <span class="type">int</span> a, b, v;</span><br><span class="line">    <span class="type">bool</span> <span class="keyword">operator</span>&lt; (<span class="type">const</span> Edge &amp;W) <span class="type">const</span></span><br><span class="line">    {</span><br><span class="line">        <span class="keyword">return</span> v &lt; W.v;</span><br><span class="line">    }</span><br><span class="line">};</span><br><span class="line"><span class="comment">// 并查集——寻找当前集合的代表元素</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">find</span><span class="params">(<span class="type">int</span> x)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="keyword">if</span> (father[x] != x) father[x] = <span class="built_in">find</span>(father[x]);</span><br><span class="line">    <span class="keyword">return</span> father[x];</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// 所有边存储在 Edge edges[M]; </span></span><br><span class="line"><span class="comment">// 函数返回最小生成树中所有边的总长度</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">Kruskal</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="type">int</span> res = <span class="number">0</span>;</span><br><span class="line">    <span class="comment">// 初始化并查集代表元素</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= n; i ++ ) father[i] = i;</span><br><span class="line">    <span class="built_in">sort</span>(edge, edge + m);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; m; i ++ )</span><br><span class="line">    {</span><br><span class="line">        <span class="type">int</span> a = edge[i].a, b = edge[i].b;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">find</span>(a) != <span class="built_in">find</span>(b))</span><br><span class="line">        {</span><br><span class="line">            res += edge[i].v;</span><br><span class="line">            father[<span class="built_in">find</span>(a)] = <span class="built_in">find</span>(b);</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> 最小生成树 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>最短路径算法模板</title>
      <link href="/2022/03/27/basic-algorithm/zui-duan-lu-suan-fa/"/>
      <url>/2022/03/27/basic-algorithm/zui-duan-lu-suan-fa/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="最短路算法模板">最短路算法模板</span></h1><p>我们只需考虑有向图上的算法，因为无向图是特殊的有向图。我们可以将所有无向边 <code>u &lt;-&gt; v</code>，都拆分成两条有向边：<code>u &lt;- u</code> 和 <code>u -&gt; v</code>。为了方便叙述，我们做如下约定：<code>n</code> 表示图中点数，<code>m</code> 表示图中边数。</p><h2><span id="最短路算法分为两大类">最短路算法分为两大类：</span></h2><ul><li>单源最短路，常用算法有：<ul><li><code>dijkstra</code>，只有所有边的权值为正时才可以使用。在稠密图上的时间复杂度是 <code>O(n^2)</code>，稀疏图上的时间复杂度是 <code>O(mlogn)</code>。</li><li><code>spfa</code>，不论边权是正的还是负的，都可以做。算法平均时间复杂度是 <code>O(km)</code>，<code>k</code> 是常数。 强烈推荐该算法。</li></ul></li><li>多源最短路，一般用<code>floyd</code>算法。代码很短，三重循环，时间复杂度是 <code>O(n3)</code>。</li></ul><p>算法模板：我们以 <a href="http://poj.org/problem?spm=a2c4e.11153940.blogcont9125.12.73ce6c6aEoRUod&amp;id=2387">poj2387 Til the Cows Come Home</a> 题目为例，给出上述所有算法的模板。</p><p>题目大意：给一张无向图，<code>n</code> 个点 <code>m</code> 条边，求从<code>1</code>号点到 <code>n</code> 号点的最短路径。输入中可能包含重边。</p><h3><span id="1-dijkstra算法on2">1、<code>dijkstra</code>算法<code>O(n^2)</code></span></h3><p>最裸的<code>dijkstra</code>算法，不用堆优化。每次暴力循环找距离最近的点。图用<strong>邻接矩阵</strong>存储。</p><figure class="highlight c++"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstring&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">1010</span>, M = <span class="number">2000010</span>, INF = <span class="number">1000000000</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> n, m;</span><br><span class="line"><span class="type">int</span> g[N][N], dist[N];   <span class="comment">// g[][]存储图的邻接矩阵, dist[]表示每个点到起点的距离</span></span><br><span class="line"><span class="type">bool</span> st[N];     <span class="comment">// 存储每个点的最短距离是否已确定</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">dijkstra</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= n; i++) dist[i] = INF;</span><br><span class="line">    dist[<span class="number">1</span>] = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++)</span><br><span class="line">    {</span><br><span class="line">        <span class="type">int</span> id, mind = INF;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">1</span>; j &lt;= n; j++)</span><br><span class="line">            <span class="keyword">if</span> (!st[j] &amp;&amp; dist[j] &lt; mind)</span><br><span class="line">            {</span><br><span class="line">                mind = dist[j];</span><br><span class="line">                id = j;</span><br><span class="line">            }</span><br><span class="line">        st[id] = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">1</span>; j &lt;= n; j++) dist[j] = <span class="built_in">min</span>(dist[j], dist[id] + g[id][j]);</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    cin &gt;&gt; m &gt;&gt; n;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= n; i++)</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">1</span>; j &lt;= n; j++)</span><br><span class="line">            g[i][j] = INF;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; m; i++)</span><br><span class="line">    {</span><br><span class="line">        <span class="type">int</span> a, b, c;</span><br><span class="line">        cin &gt;&gt; a &gt;&gt; b &gt;&gt; c;</span><br><span class="line">        g[a][b] = g[b][a] = <span class="built_in">min</span>(g[a][b], c);</span><br><span class="line">    }</span><br><span class="line">    <span class="built_in">dijkstra</span>();</span><br><span class="line">    cout &lt;&lt; dist[n] &lt;&lt; endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h3><span id="2-dijkstraheap优化-omlogn">2、<code>dijkstra+heap</code>优化 <code>O(mlogn)</code></span></h3><p>用堆维护所有点到起点的距离。时间复杂度是 <code>O(mlogn)</code>。这里我们可以手写堆，可以支持对堆中元素的修改操作，堆中元素个数不会超过 <code>n</code>。也可以直接使用<code>STL</code>中的<code>priority_queue</code>，但不能支持对堆中元素的修改，不过我们可以将所有修改过的点直接插入堆中，堆中会有重复元素，但堆中元素总数不会大于 <code>m</code>。只能处理边权为正数的问题。图用<strong>邻接表</strong>存储。</p><figure class="highlight c++"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> pair&lt;<span class="type">int</span>, <span class="type">int</span>&gt; PII;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> n;      <span class="comment">// 点的数量</span></span><br><span class="line"><span class="type">int</span> h[N], w[N], e[N], ne[N], idx;       <span class="comment">// 邻接表存储所有边</span></span><br><span class="line"><span class="type">int</span> dist[N];        <span class="comment">// 存储所有点到1号点的距离</span></span><br><span class="line"><span class="type">bool</span> st[N];     <span class="comment">// 存储每个点的最短距离是否已确定</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 求1号点到n号点的最短距离，如果不存在，则返回-1</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">dijkstra</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="built_in">memset</span>(dist, <span class="number">0x3f</span>, <span class="keyword">sizeof</span> dist);</span><br><span class="line">    dist[<span class="number">1</span>] = <span class="number">0</span>;</span><br><span class="line">    priority_queue&lt;PII, vector&lt;PII&gt;, greater&lt;PII&gt;&gt; heap;</span><br><span class="line">    heap.<span class="built_in">push</span>({<span class="number">0</span>, <span class="number">1</span>});      <span class="comment">// first存储距离，second存储节点编号</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (heap.<span class="built_in">size</span>())</span><br><span class="line">    {</span><br><span class="line">        <span class="keyword">auto</span> t = heap.<span class="built_in">top</span>();</span><br><span class="line">        heap.<span class="built_in">pop</span>();</span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> ver = t.second, distance = t.first;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (st[ver]) <span class="keyword">continue</span>;</span><br><span class="line">        st[ver] = <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = h[ver]; i != <span class="number">-1</span>; i = ne[i])</span><br><span class="line">        {</span><br><span class="line">            <span class="type">int</span> j = e[i];</span><br><span class="line">            <span class="keyword">if</span> (dist[j] &gt; distance + w[i])</span><br><span class="line">            {</span><br><span class="line">                dist[j] = distance + w[i];</span><br><span class="line">                heap.<span class="built_in">push</span>({dist[j], j});</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (dist[n] == <span class="number">0x3f3f3f3f</span>) <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">return</span> dist[n];</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h3><span id="3-spfa算法-okm">3、<code>spfa</code>算法 <code>O(km)</code></span></h3><p><code>bellman-ford</code>算法的优化版本，可以处理存在负边权的最短路问题。最坏情况下的时间复杂度是 <code>O(nm)</code>，但实践证明<code>spfa算法</code>的运行效率非常高，期望运行时间是 <code>O(km)</code>，其中 <code>k</code> 是常数。但需要注意的是，在网格图中，<code>spfa算法</code>的效率比较低，如果边权为正，则尽量使用 <code>dijkstra</code> 算法。</p><p>图采用邻接表存储。队列为手写的循环队列。</p><figure class="highlight c++"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstring&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;queue&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">1010</span>, M = <span class="number">2000010</span>, INF = <span class="number">1000000000</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> n, m;</span><br><span class="line"><span class="type">int</span> dist[N], q[N];      <span class="comment">// dist表示每个点到起点的距离, q 是队列</span></span><br><span class="line"><span class="type">int</span> h[N], e[M], v[M], ne[M], idx;       <span class="comment">// 邻接表</span></span><br><span class="line"><span class="type">bool</span> st[N];     <span class="comment">// 存储每个点是否在队列中</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">add</span><span class="params">(<span class="type">int</span> a, <span class="type">int</span> b, <span class="type">int</span> c)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    e[idx] = b, v[idx] = c, ne[idx] = h[a], h[a] = idx++;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">spfa</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="type">int</span> hh = <span class="number">0</span>, tt = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= n; i++) dist[i] = INF;</span><br><span class="line">    dist[<span class="number">1</span>] = <span class="number">0</span>;</span><br><span class="line">    q[tt++] = <span class="number">1</span>, st[<span class="number">1</span>] = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span> (hh != tt)</span><br><span class="line">    {</span><br><span class="line">        <span class="type">int</span> t = q[hh++];</span><br><span class="line">        st[t] = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">if</span> (hh == n) hh = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = h[t]; i != <span class="number">-1</span>; i = ne[i])</span><br><span class="line">            <span class="keyword">if</span> (dist[e[i]] &gt; dist[t] + v[i])</span><br><span class="line">            {</span><br><span class="line">                dist[e[i]] = dist[t] + v[i];</span><br><span class="line">                <span class="keyword">if</span> (!st[e[i]])</span><br><span class="line">                {</span><br><span class="line">                    st[e[i]] = <span class="number">1</span>;</span><br><span class="line">                    q[tt++] = e[i];</span><br><span class="line">                    <span class="keyword">if</span> (tt == n) tt = <span class="number">0</span>;</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="built_in">memset</span>(h, <span class="number">-1</span>, <span class="keyword">sizeof</span> h);</span><br><span class="line">    cin &gt;&gt; m &gt;&gt; n;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; m; i++)</span><br><span class="line">    {</span><br><span class="line">        <span class="type">int</span> a, b, c;</span><br><span class="line">        cin &gt;&gt; a &gt;&gt; b &gt;&gt; c;</span><br><span class="line">        <span class="built_in">add</span>(a, b, c);</span><br><span class="line">        <span class="built_in">add</span>(b, a, c);</span><br><span class="line">    }</span><br><span class="line">    <span class="built_in">spfa</span>();</span><br><span class="line">    cout &lt;&lt; dist[n] &lt;&lt; endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h3><span id="4-floyd算法-on3">4、<code>floyd</code>算法 <code>O(n^3)</code></span></h3><p>标准弗洛伊德算法，三重循环。循环结束之后 <code>d[i][j]</code>存储的就是点 <code>i</code> 到点 <code>j</code> 的最短距离。<br>需要注意循环顺序不能变：第一层枚举中间点，第二层和第三层枚举起点和终点。</p><p>由于这道题目的数据范围较大，点数最多有1000个，因此<code>floyd</code>算法会超时。但我们的目的是给出算法模板哦~</p><figure class="highlight c++"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstring&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;queue&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">1010</span>, M = <span class="number">2000010</span>, INF = <span class="number">1000000000</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> n, m;</span><br><span class="line"><span class="type">int</span> d[N][N];    <span class="comment">// 存储两点之间的最短距离</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    cin &gt;&gt; m &gt;&gt; n;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= n; i++)</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">1</span>; j &lt;= n; j++)</span><br><span class="line">            d[i][j] = i == j ? <span class="number">0</span> : INF;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; m; i++)</span><br><span class="line">    {</span><br><span class="line">        <span class="type">int</span> a, b, c;</span><br><span class="line">        cin &gt;&gt; a &gt;&gt; b &gt;&gt; c;</span><br><span class="line">        d[a][b] = d[b][a] = <span class="built_in">min</span>(c, d[a][b]);</span><br><span class="line">    }</span><br><span class="line">    <span class="comment">// floyd 算法核心</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> k = <span class="number">1</span>; k &lt;= n; k++)</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= n; i++)</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">1</span>; j &lt;= n; j++)</span><br><span class="line">                d[i][j] = <span class="built_in">min</span>(d[i][j], d[i][k] + d[k][j]);</span><br><span class="line">    cout &lt;&lt; d[<span class="number">1</span>][n] &lt;&lt; endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> 最短路径 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>快速乘法</title>
      <link href="/2022/03/26/basic-algorithm/kuai-su-cheng-fa/"/>
      <url>/2022/03/26/basic-algorithm/kuai-su-cheng-fa/</url>
      
        <content type="html"><![CDATA[<h1><span id="快速乘法">快速乘法</span></h1><p><strong>快速乘法</strong>使用二进制将乘法转化为加法，既加快可以加快运算速度，又可以防止直接相乘之后溢出</p><h2><span id="方法一简单写法">方法一：简单写法</span></h2><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">ll <span class="title function_">quickMul</span><span class="params">(ll a,ll b,ll mod)</span></span><br><span class="line">{</span><br><span class="line">    ll res=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span>(b){</span><br><span class="line">        <span class="keyword">if</span>(b&amp;<span class="number">1</span>) res=(res+a)%mod;</span><br><span class="line">        a=(a+a)%mod;</span><br><span class="line">        b&gt;&gt;=<span class="number">1</span>;</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h2><span id="方法二更快更高效的写法">方法二：更快更高效的写法</span></h2><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">ll <span class="title function_">mul</span><span class="params">(ll a,ll b,ll mod)</span></span><br><span class="line">{</span><br><span class="line">    a%=mod;</span><br><span class="line">    b%=mod;</span><br><span class="line">    ll res=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span>(b){</span><br><span class="line">        <span class="keyword">if</span>(b&amp;<span class="number">1</span>){</span><br><span class="line">            res+=a;</span><br><span class="line">            <span class="keyword">if</span>(res&gt;=mod)</span><br><span class="line">                res-=mod;</span><br><span class="line">        }</span><br><span class="line">        b&gt;&gt;=<span class="number">1</span>;</span><br><span class="line">        a&lt;&lt;=<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span>(a&gt;=mod)  a-=mod;</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><hr><p><strong>利用快速乘法优化的快速幂</strong></p><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">ll <span class="title function_">mul</span><span class="params">(ll a,ll b,ll mod)</span></span><br><span class="line">{</span><br><span class="line">    a%=mod;</span><br><span class="line">    b%=mod;</span><br><span class="line">    ll res=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span>(b){</span><br><span class="line">        <span class="keyword">if</span>(b&amp;<span class="number">1</span>){</span><br><span class="line">        <span class="comment">//printf("%lld %lld %lld\n",a,b,res);</span></span><br><span class="line">            res+=a;</span><br><span class="line">            <span class="keyword">if</span>(res&gt;=mod)</span><br><span class="line">                res-=mod;</span><br><span class="line">        }</span><br><span class="line">        b&gt;&gt;=<span class="number">1</span>;</span><br><span class="line">        a&lt;&lt;=<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span>(a&gt;=mod)  a-=mod;</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">}</span><br><span class="line">ll <span class="title function_">quickPow</span><span class="params">(ll a,ll b,ll m)</span></span><br><span class="line">{</span><br><span class="line">    ll res=<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span>(b){</span><br><span class="line">        <span class="keyword">if</span>(b&amp;<span class="number">1</span>)</span><br><span class="line">        res=mul(res,a,m);</span><br><span class="line">        a=mul(a,a,m);</span><br><span class="line">        b&gt;&gt;=<span class="number">1</span>;</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> 快速乘法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>快速幂算法</title>
      <link href="/2022/03/26/basic-algorithm/kuai-su-mi-suan-fa/"/>
      <url>/2022/03/26/basic-algorithm/kuai-su-mi-suan-fa/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="快速幂算法模板">快速幂算法模板</span></h1><p>求 <code>m^k%p</code>，时间复杂度 <code>O(logk)</code>。</p><figure class="highlight c++"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">qmi</span><span class="params">(<span class="type">int</span> m, <span class="type">int</span> k, <span class="type">int</span> p)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="type">int</span> res = <span class="number">1</span> % p, t = m;</span><br><span class="line">    <span class="keyword">while</span> (k)</span><br><span class="line">    {</span><br><span class="line">        <span class="keyword">if</span> (k&amp;<span class="number">1</span>) res = res * t % p;</span><br><span class="line">        t = t * t % p;</span><br><span class="line">        k &gt;&gt;= <span class="number">1</span>;</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> 快速幂 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>马拉车算法</title>
      <link href="/2022/03/26/basic-algorithm/ma-la-che-suan-fa/"/>
      <url>/2022/03/26/basic-algorithm/ma-la-che-suan-fa/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="马拉车算法">马拉车算法</span></h1><p>解决求最长回文串，时间复杂度为<code>O(n)</code></p><h2><span id="1-预处理长度奇偶均处理成如此">1、预处理（长度奇偶均处理成如此）</span></h2><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">i       <span class="number">0</span> <span class="number">1</span> <span class="number">2</span> <span class="number">3</span> <span class="number">4</span> <span class="number">5</span> <span class="number">6</span> <span class="number">7</span> <span class="number">8</span> <span class="number">9</span> <span class="number">10</span> <span class="number">11</span> <span class="number">12</span> <span class="number">13</span></span><br><span class="line">arr[i]  $ # c # a # b # b # a  #  f  #</span><br><span class="line">p[i]      <span class="number">1</span> <span class="number">2</span> <span class="number">1</span> <span class="number">2</span> <span class="number">1</span> <span class="number">2</span> <span class="number">5</span> <span class="number">2</span> <span class="number">1</span> <span class="number">2</span>  <span class="number">1</span>  <span class="number">2</span>  <span class="number">1</span></span><br></pre></td></tr></tbody></table></figure><h2><span id="2-计算原始索引">2、计算原始索引</span></h2><p><code>int index = (i - p[i])/2</code></p><h2><span id="3-计算p数组">3、计算<code>p</code>数组</span></h2><p>设置两个变量<code>id</code>和<code>mx</code>，<code>id</code>是所有回文子串中，能延伸到最右端位置的那个回文子串的中心点位置，<code>mx</code>是该回文串能延伸到的最右端的位置。</p><p>当<code>i</code>等于<code>7</code>时，<code>id</code>等于<code>7</code>，<code>p[id] = 5</code>，在以位置<code>7</code>为中心的回文子串中，该回文子串的右边界是位置<code>12</code>。</p><p>当<code>i</code>等于<code>12</code>时，<code>id</code>等于<code>12</code>，<code>p[id] = 2</code>，在以位置<code>12</code>为中心的回文子串中，该回文子串的右边界是位置<code>14</code>。</p><p>由此我们可以得出回文子串右边界和其半径之间的关系：<code>mx = p[id]+id</code>。</p><hr><p>因为回文字符串是中心对称的，知道中心点位置<code>id</code>，如果一个位置的回文子串以<code>i</code>为中心，并且包含在以<code>id</code>为中心的回文子串中，即<code>mx &gt; i</code>，那么肯定会存在另外一个以<code>j</code>为中心回文子串，和以<code>i</code>为中心的回文子串相等且对称，即<code>p[j] = p[i]</code>，而<code>i</code>和<code>j</code>是以<code>id</code>为中心对称，即<code>i+j=2*id</code>，如果知道了i的值，那么<code>j = 2*id - i</code>。</p><p>但是我们需要考虑另外一种情况，如果存在一个以<code>i</code>为中心的回文子串，依旧有<code>mx &gt; i</code>，但是以<code>i</code> 为中心的回文子串右边界超过了<code>mx</code>，在<code>i</code>到<code>mx</code>的这段回文子串中，与另一端对称的以<code>j</code>为中心的回文子串还是相等的，此时<code>p[i] = mx - i</code>，<code>p[j] = [pi]</code>，至于右边界<code>mx</code>之外的子串，即以<code>i</code>为中心的回文子串超出的部分是否还是满足上述条件就需要遍历比较字符了。</p><p>因此，在<code>mx &gt; i</code>的情况下，<code>p[i] = Math.min(p[2*id - i], mx - i)</code>。<br> 另外如果<code>i</code>大于<code>mx</code>了，也即是边界<code>mx</code>后面的子串，依旧需要去比较字符计算。</p><h2><span id="4-代码">4、代码</span></h2><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title function_">Manacher</span><span class="params">(String s)</span> {</span><br><span class="line">    <span class="keyword">if</span> (s.length() &lt; <span class="number">2</span>) {</span><br><span class="line">        <span class="keyword">return</span> s;</span><br><span class="line">    }</span><br><span class="line">    <span class="comment">// 第一步：预处理，将原字符串转换为新字符串</span></span><br><span class="line">    <span class="type">String</span> <span class="variable">t</span> <span class="operator">=</span> <span class="string">"$"</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i=<span class="number">0</span>; i&lt;s.length(); i++) {</span><br><span class="line">        t += <span class="string">"#"</span> + s.charAt(i);</span><br><span class="line">    }</span><br><span class="line">    <span class="comment">// 尾部再加上字符@，变为奇数长度字符串</span></span><br><span class="line">    t += <span class="string">"#@"</span>;</span><br><span class="line">    <span class="comment">// 第二步：计算数组p、起始索引、最长回文半径</span></span><br><span class="line">    <span class="type">int</span> <span class="variable">n</span> <span class="operator">=</span> t.length();</span><br><span class="line">    <span class="comment">// p数组</span></span><br><span class="line">    <span class="type">int</span>[] p = <span class="keyword">new</span> <span class="title class_">int</span>[n];</span><br><span class="line">    <span class="type">int</span> <span class="variable">id</span> <span class="operator">=</span> <span class="number">0</span>, mx = <span class="number">0</span>;</span><br><span class="line">    <span class="comment">// 最长回文子串的长度</span></span><br><span class="line">    <span class="type">int</span> <span class="variable">maxLength</span> <span class="operator">=</span> -<span class="number">1</span>;</span><br><span class="line">    <span class="comment">// 最长回文子串的中心位置索引</span></span><br><span class="line">    <span class="type">int</span> <span class="variable">index</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> j=<span class="number">1</span>; j&lt;n-<span class="number">1</span>; j++) {</span><br><span class="line">        <span class="comment">// 参看前文第五部分</span></span><br><span class="line">        p[j] = mx &gt; j ? Math.min(p[<span class="number">2</span>*id-j], mx-j) : <span class="number">1</span>;</span><br><span class="line">        <span class="comment">// 向左右两边延伸，扩展右边界</span></span><br><span class="line">        <span class="keyword">while</span> (t.charAt(j+p[j]) == t.charAt(j-p[j])) {</span><br><span class="line">            p[j]++;</span><br><span class="line">        }</span><br><span class="line">        <span class="comment">// 如果回文子串的右边界超过了mx，则需要更新mx和id的值</span></span><br><span class="line">        <span class="keyword">if</span> (mx &lt; p[j] + j) {</span><br><span class="line">            mx = p[j] + j;</span><br><span class="line">            id = j;</span><br><span class="line">        }</span><br><span class="line">        <span class="comment">// 如果回文子串的长度大于maxLength，则更新maxLength和index的值</span></span><br><span class="line">        <span class="keyword">if</span> (maxLength &lt; p[j] - <span class="number">1</span>) {</span><br><span class="line">            <span class="comment">// 参看前文第三部分</span></span><br><span class="line">            maxLength = p[j] - <span class="number">1</span>;</span><br><span class="line">            index = j;</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">    <span class="comment">// 第三步：截取字符串，输出结果</span></span><br><span class="line">    <span class="comment">// 起始索引的计算参看前文第四部分</span></span><br><span class="line">    <span class="type">int</span> <span class="variable">start</span> <span class="operator">=</span> (index-maxLength)/<span class="number">2</span>;</span><br><span class="line">    <span class="keyword">return</span> s.substring(start, start + maxLength);</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> 马拉车 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基础算法模板集合</title>
      <link href="/2022/03/26/basic-algorithm/pai-xu-suan-fa/"/>
      <url>/2022/03/26/basic-algorithm/pai-xu-suan-fa/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="算法基础相关代码模板">算法基础相关代码模板</span></h1><h2><span id="1-快速排序算法模板-模板题">1、快速排序算法模板 —— 模板题</span></h2><figure class="highlight c++"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">quick_sort</span><span class="params">(<span class="type">int</span> q[], <span class="type">int</span> l, <span class="type">int</span> r)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="keyword">if</span> (l &gt;= r) <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> i = l - <span class="number">1</span>, j = r + <span class="number">1</span>, x = q[l + r &gt;&gt; <span class="number">1</span>];</span><br><span class="line">    <span class="keyword">while</span> (i &lt; j)</span><br><span class="line">    {</span><br><span class="line">        <span class="keyword">do</span> i ++ ; <span class="keyword">while</span> (q[i] &lt; x);</span><br><span class="line">        <span class="keyword">do</span> j -- ; <span class="keyword">while</span> (q[j] &gt; x);</span><br><span class="line">        <span class="keyword">if</span> (i &lt; j) <span class="built_in">swap</span>(q[i], q[j]);</span><br><span class="line">    }</span><br><span class="line">    <span class="built_in">quick_sort</span>(q, l, j), <span class="built_in">quick_sort</span>(q, j + <span class="number">1</span>, r);</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h2><span id="2-归并排序算法模板-模板题">2、归并排序算法模板 —— 模板题</span></h2><figure class="highlight c++"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">merge_sort</span><span class="params">(<span class="type">int</span> q[], <span class="type">int</span> l, <span class="type">int</span> r)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="keyword">if</span> (l &gt;= r) <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> mid = l + r &gt;&gt; <span class="number">1</span>;</span><br><span class="line">    <span class="built_in">merge_sort</span>(q, l, mid);</span><br><span class="line">    <span class="built_in">merge_sort</span>(q, mid + <span class="number">1</span>, r);</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> k = <span class="number">0</span>, i = l, j = mid + <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span> (i &lt;= mid &amp;&amp; j &lt;= r)</span><br><span class="line">        <span class="keyword">if</span> (q[i] &lt;= q[j]) tmp[k ++ ] = q[i ++ ];</span><br><span class="line">        <span class="keyword">else</span> tmp[k ++ ] = q[j ++ ];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (i &lt;= mid) tmp[k ++ ] = q[i ++ ];</span><br><span class="line">    <span class="keyword">while</span> (j &lt;= r) tmp[k ++ ] = q[j ++ ];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (i = l, j = <span class="number">0</span>; i &lt;= r; i ++, j ++ ) q[i] = tmp[j];</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h2><span id="3-整数二分算法模板-模板题">3、整数二分算法模板 —— 模板题</span></h2><figure class="highlight c++"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">check</span><span class="params">(<span class="type">int</span> x)</span> </span>{<span class="comment">/* ... */</span>} <span class="comment">// 检查x是否满足某种性质</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 区间[l, r]被划分成[l, mid]和[mid + 1, r]时使用：</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">bsearch_1</span><span class="params">(<span class="type">int</span> l, <span class="type">int</span> r)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="keyword">while</span> (l &lt; r)</span><br><span class="line">    {</span><br><span class="line">        <span class="type">int</span> mid = l + r &gt;&gt; <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">check</span>(mid)) r = mid;    <span class="comment">// check()判断mid是否满足性质</span></span><br><span class="line">        <span class="keyword">else</span> l = mid + <span class="number">1</span>;</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> l;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// 区间[l, r]被划分成[l, mid - 1]和[mid, r]时使用：</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">bsearch_2</span><span class="params">(<span class="type">int</span> l, <span class="type">int</span> r)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="keyword">while</span> (l &lt; r)</span><br><span class="line">    {</span><br><span class="line">        <span class="type">int</span> mid = l + r + <span class="number">1</span> &gt;&gt; <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">check</span>(mid)) l = mid;</span><br><span class="line">        <span class="keyword">else</span> r = mid - <span class="number">1</span>;</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> l;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h2><span id="4-浮点数二分算法模板-模板题">4、浮点数二分算法模板 —— 模板题</span></h2><figure class="highlight c++"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">check</span><span class="params">(<span class="type">double</span> x)</span> </span>{<span class="comment">/* ... */</span>} <span class="comment">// 检查x是否满足某种性质</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">double</span> <span class="title">bsearch_3</span><span class="params">(<span class="type">double</span> l, <span class="type">double</span> r)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="type">const</span> <span class="type">double</span> eps = <span class="number">1e-6</span>;   <span class="comment">// eps 表示精度，取决于题目对精度的要求</span></span><br><span class="line">    <span class="keyword">while</span> (r - l &gt; eps)</span><br><span class="line">    {</span><br><span class="line">        <span class="type">double</span> mid = (l + r) / <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">check</span>(mid)) r = mid;</span><br><span class="line">        <span class="keyword">else</span> l = mid;</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> l;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h2><span id="5-高精度计算方法-模板题">5、高精度计算方法 —— 模板题</span></h2><figure class="highlight c++"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 高精度加法</span></span><br><span class="line"><span class="comment">// C = A + B, A &gt;= 0, B &gt;= 0</span></span><br><span class="line"><span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">add</span><span class="params">(vector&lt;<span class="type">int</span>&gt; &amp;A, vector&lt;<span class="type">int</span>&gt; &amp;B)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="keyword">if</span> (A.<span class="built_in">size</span>() &lt; B.<span class="built_in">size</span>()) <span class="keyword">return</span> <span class="built_in">add</span>(B, A);</span><br><span class="line"></span><br><span class="line">    vector&lt;<span class="type">int</span>&gt; C;</span><br><span class="line">    <span class="type">int</span> t = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; A.<span class="built_in">size</span>(); i ++ )</span><br><span class="line">    {</span><br><span class="line">        t += A[i];</span><br><span class="line">        <span class="keyword">if</span> (i &lt; B.<span class="built_in">size</span>()) t += B[i];</span><br><span class="line">        C.<span class="built_in">push_back</span>(t % <span class="number">10</span>);</span><br><span class="line">        t /= <span class="number">10</span>;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (t) C.<span class="built_in">push_back</span>(t);</span><br><span class="line">    <span class="keyword">return</span> C;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><figure class="highlight c++"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 高精度减法</span></span><br><span class="line"><span class="comment">// C = A - B, 满足A &gt;= B, A &gt;= 0, B &gt;= 0</span></span><br><span class="line"><span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">sub</span><span class="params">(vector&lt;<span class="type">int</span>&gt; &amp;A, vector&lt;<span class="type">int</span>&gt; &amp;B)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    vector&lt;<span class="type">int</span>&gt; C;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>, t = <span class="number">0</span>; i &lt; A.<span class="built_in">size</span>(); i ++ )</span><br><span class="line">    {</span><br><span class="line">        t = A[i] - t;</span><br><span class="line">        <span class="keyword">if</span> (i &lt; B.<span class="built_in">size</span>()) t -= B[i];</span><br><span class="line">        C.<span class="built_in">push_back</span>((t + <span class="number">10</span>) % <span class="number">10</span>);</span><br><span class="line">        <span class="keyword">if</span> (t &lt; <span class="number">0</span>) t = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">else</span> t = <span class="number">0</span>;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (C.<span class="built_in">size</span>() &gt; <span class="number">1</span> &amp;&amp; C.<span class="built_in">back</span>() == <span class="number">0</span>) C.<span class="built_in">pop_back</span>();</span><br><span class="line">    <span class="keyword">return</span> C;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><figure class="highlight c++"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 高精度乘法</span></span><br><span class="line"><span class="comment">// C = A * b, A &gt;= 0, b &gt; 0</span></span><br><span class="line"><span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">mul</span><span class="params">(vector&lt;<span class="type">int</span>&gt; &amp;A, <span class="type">int</span> b)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    vector&lt;<span class="type">int</span>&gt; C;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> t = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; A.<span class="built_in">size</span>() || t; i ++ )</span><br><span class="line">    {</span><br><span class="line">        <span class="keyword">if</span> (i &lt; A.<span class="built_in">size</span>()) t += A[i] * b;</span><br><span class="line">        C.<span class="built_in">push_back</span>(t % <span class="number">10</span>);</span><br><span class="line">        t /= <span class="number">10</span>;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (C.<span class="built_in">size</span>() &gt; <span class="number">1</span> &amp;&amp; C.<span class="built_in">back</span>() == <span class="number">0</span>) C.<span class="built_in">pop_back</span>();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> C;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><figure class="highlight c++"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 高精度除法</span></span><br><span class="line"><span class="comment">// A / b = C ... r, A &gt;= 0, b &gt; 0</span></span><br><span class="line"><span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">div</span><span class="params">(vector&lt;<span class="type">int</span>&gt; &amp;A, <span class="type">int</span> b, <span class="type">int</span> &amp;r)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    vector&lt;<span class="type">int</span>&gt; C;</span><br><span class="line">    r = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = A.<span class="built_in">size</span>() - <span class="number">1</span>; i &gt;= <span class="number">0</span>; i -- )</span><br><span class="line">    {</span><br><span class="line">        r = r * <span class="number">10</span> + A[i];</span><br><span class="line">        C.<span class="built_in">push_back</span>(r / b);</span><br><span class="line">        r %= b;</span><br><span class="line">    }</span><br><span class="line">    <span class="built_in">reverse</span>(C.<span class="built_in">begin</span>(), C.<span class="built_in">end</span>());</span><br><span class="line">    <span class="keyword">while</span> (C.<span class="built_in">size</span>() &gt; <span class="number">1</span> &amp;&amp; C.<span class="built_in">back</span>() == <span class="number">0</span>) C.<span class="built_in">pop_back</span>();</span><br><span class="line">    <span class="keyword">return</span> C;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h2><span id="6-前缀和">6、前缀和</span></h2><p><strong>一维前缀和 —— 模板题</strong></p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">S[i] = a[1] + a[2] + ... a[i]</span><br><span class="line">a[l] + ... + a[r] = S[r] - S[l - 1]</span><br></pre></td></tr></tbody></table></figure><p><strong>二维前缀和 —— 模板题</strong></p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">S[i, j] = 第i行j列格子左上部分所有元素的和</span><br><span class="line">以(x1, y1)为左上角，(x2, y2)为右下角的子矩阵的和为：</span><br><span class="line">S[x2, y2] - S[x1 - 1, y2] - S[x2, y1 - 1] + S[x1 - 1, y1 - 1]</span><br></pre></td></tr></tbody></table></figure><h2><span id="7-差分">7、差分</span></h2><p>差分是求前缀和的逆操作，对于原数组<code>a[n]</code>构造出一个数组<code>b[n]</code>,使<code>a[n]</code>为<code>b[n]</code>的前缀和。一般用于快速对整个数组进行操作，比如对将 <code>a</code> 数组中<code>[l,r]</code> 部分的数据全部加上<code>c</code> 。使用暴力方法的话，时间复杂至少为<code>O(n)</code>，而使用差分算法可以将时间复杂度降低到<code>O(1)</code>。</p><p><strong><u>算法思路</u></strong>：<br>拥有数组<code>b[n]</code>后，想要对<code>a</code>数组中所有的数据加上<code>c</code>，只需要将<code>b[1]+c</code>即可，因为<code>a[i]</code>是<code>b[i]</code>的前缀和，<code>a[i]=b[1]+b[1]+b[3]+……+b[n]</code>。<code>b[1]</code>是所有的<code>a[i]</code>都拥有的子元素,将<code>b[0]+c</code>，那么<code>a[n]</code>中所有的数据都会加上<code>c</code>。如果想将<code>a</code>数组中<code>[l,r]</code>部分的数据全部加上<code>c</code>，只需要将<code>b[l]+c</code>，然后<code>b[r+1]-c</code>即可。</p><p><strong>一维差分 —— 模板题</strong></p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">给区间[l, r]中的每个数加上c：B[l] += c, B[r + 1] -= c</span><br></pre></td></tr></tbody></table></figure><p><strong>二维差分 —— 模板题</strong><br></p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">给以(x1, y1)为左上角，(x2, y2)为右下角的子矩阵中的所有元素加上c：</span><br><span class="line">S[x1, y1] += c, S[x2 + 1, y1] -= c, S[x1, y2 + 1] -= c, S[x2 + 1, y2 + 1] += c</span><br></pre></td></tr></tbody></table></figure><p></p><h2><span id="8-位运算-模板题">8、位运算 —— 模板题</span></h2><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">// 二进制中</span><br><span class="line">求n的第k位数字: n &gt;&gt; k &amp; 1</span><br><span class="line">返回n的最后一位1：lowbit(n) = n &amp; -n</span><br></pre></td></tr></tbody></table></figure><h2><span id="9-双指针算法-模板题">9、双指针算法 —— 模板题</span></h2><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">for (int i = 0, j = 0; i &lt; n; i ++ )</span><br><span class="line">{</span><br><span class="line">    while (j &lt; i &amp;&amp; check(i, j)) j ++ ;</span><br><span class="line"></span><br><span class="line">    // 具体问题的逻辑</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>常见问题分类：</p><ol><li>对于一个序列，用两个指针维护一段区间；</li><li>对于两个序列，维护某种次序，比如归并排序中合并两个有序序列的操作</li></ol><h2><span id="10-区间合并-模板题">10、区间合并 —— 模板题</span></h2><pre><code>// 将所有存在交集的区间合并void merge(vector&lt;PII&gt; &amp;segs){    vector&lt;PII&gt; res;    sort(segs.begin(), segs.end());    int st = -2e9, ed = -2e9;    for (auto seg : segs)        if (ed &lt; seg.first)        {            if (st != -2e9) res.push_back({st, ed});            st = seg.first, ed = seg.second;        }        else ed = max(ed, seg.second);    if (st != -2e9) res.push_back({st, ed});    segs = res;}</code></pre><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> 基础算法 </tag>
            
            <tag> 排序算法 </tag>
            
            <tag> 二分算法 </tag>
            
            <tag> 位运算 </tag>
            
            <tag> 区间合并 </tag>
            
            <tag> 双指针算法 </tag>
            
            <tag> 前缀和 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>偏移量技巧</title>
      <link href="/2022/03/26/basic-algorithm/pian-yi-liang-ji-qiao/"/>
      <url>/2022/03/26/basic-algorithm/pian-yi-liang-ji-qiao/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="偏移量技巧">偏移量技巧</span></h1><p>矩阵中位置关系（注意代码中坐标系与平时所见不一样）：</p><script type="math/tex; mode=display">\begin{matrix}x-1,y-1& x-1,y(0) &x-1,y+1\\x,y-1(3) & x,y & x,y+1(1) \\x+1,y-1& x+1,y(2) &x+1,y+1\end{matrix}</script><p>可以使用这个向量来进行循环操作，简单方便</p><script type="math/tex; mode=display">\begin{matrix}& -1,0&\\0,-1&0,0&0,1\\&1,0&\\\end{matrix}</script><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span>[] dx = <span class="keyword">new</span> <span class="title class_">int</span>[]{-<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>}, dy = <span class="keyword">new</span> <span class="title class_">int</span>[]{<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,-<span class="number">1</span>}</span><br></pre></td></tr></tbody></table></figure><h2><span id="题目蛇形矩阵">题目：蛇形矩阵</span></h2><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Main</span> {</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> {</span><br><span class="line">        <span class="type">Scanner</span> <span class="variable">scanner</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scanner</span>(System.in);</span><br><span class="line">        <span class="type">int</span> <span class="variable">n</span> <span class="operator">=</span> scanner.nextInt(), m = scanner.nextInt();</span><br><span class="line">        <span class="type">int</span>[][] ans = <span class="keyword">new</span> <span class="title class_">int</span>[n][m];</span><br><span class="line">        <span class="type">int</span>[] dx = <span class="keyword">new</span> <span class="title class_">int</span>[]{-<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>}, dy = <span class="keyword">new</span> <span class="title class_">int</span>[]{<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,-<span class="number">1</span>};</span><br><span class="line">        <span class="type">int</span> <span class="variable">x</span> <span class="operator">=</span> <span class="number">0</span>, y = <span class="number">0</span>, d = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">1</span>; i &lt;= n * m; i++) {</span><br><span class="line">            ans[x][y] = i;</span><br><span class="line">            <span class="type">int</span> <span class="variable">a</span> <span class="operator">=</span> x + dx[d], b = y + dy[d];</span><br><span class="line">            <span class="comment">// 判断下一步是否出界 或者 已经走过</span></span><br><span class="line">            <span class="keyword">if</span> (a &lt; <span class="number">0</span> || a &gt;= n || b &lt; <span class="number">0</span> || b &gt;= m || ans[a][b] != <span class="number">0</span>) {</span><br><span class="line">                <span class="comment">// 更新方向</span></span><br><span class="line">                d = (d + <span class="number">1</span>) % <span class="number">4</span>;</span><br><span class="line">                a = x + dx[d];</span><br><span class="line">                b = y + dy[d];</span><br><span class="line">            }</span><br><span class="line">            x = a;</span><br><span class="line">            y = b;</span><br><span class="line">        }</span><br><span class="line">        System.out.print(Arrays.deepToString(ans));</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> 偏移量 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>全排列实现</title>
      <link href="/2022/03/26/basic-algorithm/quan-pai-lie/"/>
      <url>/2022/03/26/basic-algorithm/quan-pai-lie/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="交换元素的方式进行全排列">交换元素的方式进行全排列</span></h1><h2><span id="46-全排列"></span></h2><p>给定一个 <strong>没有重复</strong> 数字的序列，返回其所有可能的全排列。</p><p>主要思想，交换位置，确定数组前面部分的排列，对后面的进行操作（交换位置）。</p><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> {</span><br><span class="line">    List&lt;List&lt;Integer&gt;&gt; ans = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">dfs</span><span class="params">(<span class="type">int</span>[] nums, <span class="type">int</span> m)</span> {</span><br><span class="line">        <span class="keyword">if</span> (m == nums.length) {</span><br><span class="line">            List&lt;Integer&gt; list = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> num : nums) {</span><br><span class="line">                list.add(num);</span><br><span class="line">            }</span><br><span class="line">            ans.add(list);</span><br><span class="line">        } <span class="keyword">else</span> {</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> m; i &lt; nums.length; i++) {</span><br><span class="line">                swap(nums, i, m);</span><br><span class="line">                <span class="comment">// 前面的位置已经确定，对后面的位置进行操作</span></span><br><span class="line">                dfs(nums, m + <span class="number">1</span>);</span><br><span class="line">                swap(nums, i, m);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">swap</span><span class="params">(<span class="type">int</span>[] nums, <span class="type">int</span> i, <span class="type">int</span> j)</span> {</span><br><span class="line">        <span class="type">int</span> <span class="variable">tmp</span> <span class="operator">=</span> nums[i];</span><br><span class="line">        nums[i] = nums[j];</span><br><span class="line">        nums[j] = tmp;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> List&lt;List&lt;Integer&gt;&gt; <span class="title function_">permute</span><span class="params">(<span class="type">int</span>[] nums)</span> {</span><br><span class="line">        <span class="type">int</span> <span class="variable">n</span> <span class="operator">=</span> nums.length;</span><br><span class="line">        dfs(nums, <span class="number">0</span>);</span><br><span class="line">        <span class="keyword">return</span> ans;</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> 全排列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>求解斐波那契数列的若干方法</title>
      <link href="/2022/03/26/basic-algorithm/qiu-jie-fei-bo-na-qi-shu-lie-de-ruo-gan-fang-fa/"/>
      <url>/2022/03/26/basic-algorithm/qiu-jie-fei-bo-na-qi-shu-lie-de-ruo-gan-fang-fa/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="求解斐波那契数列的若干方法">求解斐波那契数列的若干方法</span></h1><p>首先定义斐波那契数列问题：</p><blockquote><p>定义 <code>a0=1, a1=1, an=a_(n−1)+a_(n−2)</code>，求 <code>an</code> 是多少。<br>为了避免考虑整数溢出问题，我们求 <code>an%p</code>的值，<code>p=10^9+7</code>。</p></blockquote><h2><span id="算法1递归">算法1：递归</span></h2><p>递归计算的节点个数是 <code>O(2n)</code> 的级别的，存在大量重复计算。时间复杂度是 <code>O(2n)</code>，一秒内大约能算到第三四十项。</p><figure class="highlight c++"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">const</span> <span class="type">int</span> MOD = <span class="number">1000000007</span>;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">f</span><span class="params">(<span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="keyword">if</span> (n &lt;= <span class="number">1</span>) <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> (<span class="built_in">f</span>(n - <span class="number">1</span>) + <span class="built_in">f</span>(n - <span class="number">2</span>)) % MOD;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h2><span id="算法2记忆化搜索">算法2：记忆化搜索</span></h2><p>开一个大数组记录中间结果，如果一个状态被计算过，则直接查表，否则再递归计算。总共有 <code>n</code> 个状态，计算每个状态的复杂度是 <code>O(1)</code>，所以时间复杂度是 <code>O(n)</code>。一秒内算 <code>n=10^7</code> 毫无压力，但由于是递归计算，递归层数太多会爆栈，大约只能算到 <code>n=10^5</code> 级别。</p><figure class="highlight c++"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">100000</span>, MOD = <span class="number">1000000007</span>;</span><br><span class="line"><span class="type">int</span> a[N];</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">f2</span><span class="params">(<span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="keyword">if</span> (a[n]) <span class="keyword">return</span> a[n];</span><br><span class="line">    <span class="keyword">if</span> (n &lt;= <span class="number">1</span>) <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    a[n] = <span class="built_in">f2</span>(n - <span class="number">1</span>) + <span class="built_in">f2</span>(n - <span class="number">2</span>);</span><br><span class="line">    a[n] %= MOD;</span><br><span class="line">    <span class="keyword">return</span> a[n];</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h2><span id="算法3递推">算法3：递推</span></h2><p>开一个大数组，记录每个数的值。用循环递推计算。总共计算 <code>n</code> 个状态，所以时间复杂度是 <code>O(n)</code>。<br>但需要开一个长度是 <code>n</code> 的数组，内存将成为瓶颈，当 <code>n=10^8</code> 时，需要的内存是 </p><script type="math/tex; mode=display">\frac{4*10^8}{1024 * 1024}\cong381MB</script><p>分子中乘<code>4</code>是因为<code>C++</code>中 <code>int</code> 类型占4字节。</p><figure class="highlight c++"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">100000000</span>, MOD = <span class="number">1000000007</span>;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">f3</span><span class="params">(<span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    a[<span class="number">0</span>] = a[<span class="number">1</span>] = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">2</span>; i &lt;= n; i ++ )</span><br><span class="line">    {</span><br><span class="line">        a[i] = a[i - <span class="number">1</span>] + a[i - <span class="number">2</span>];</span><br><span class="line">        a[i] %= MOD;</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> a[n];</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h2><span id="算法4递归滚动变量">算法4：递归+滚动变量。</span></h2><p>仔细观察我们会发现，递推时我们只需要记录前两项的值即可，没有必要记录所有值，所以我们可以用滚动变量递推。时间复杂度还是 <code>O(n)</code>，但空间复杂度变成了 <code>O(1)</code>。</p><figure class="highlight c++"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">const</span> <span class="type">int</span> MOD = <span class="number">1000000007</span>;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">f4</span><span class="params">(<span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="type">int</span> x, y, z;</span><br><span class="line">    x = y = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">2</span>; i &lt;= n; i ++ )</span><br><span class="line">    {</span><br><span class="line">        z = (x + y) % MOD;</span><br><span class="line">        x = y;</span><br><span class="line">        y = z;</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> z;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h2><span id="算法5矩阵运算-快速幂">算法5：矩阵运算 + 快速幂。</span></h2><p>用算法<code>4</code>我们<code>1</code>秒内最多可以算到 <code>10^8</code> 级别，那当 <code>n</code> 更大时该怎么办呢？可以先利用矩阵运算的性质将通项公式变成幂次形式，然后用平方倍增（快速幂）的方法求解第 <code>n</code> 项。</p><p>首先我们定义向量：</p><script type="math/tex; mode=display">X_n=[a_n, a_{n-1}]，边界：x_1=[a_1, a_0]</script><p>然后我们可以找出矩阵：</p><script type="math/tex; mode=display">A=\begin{bmatrix} 1 & 1 \\ 1 & 0 \\ \end{bmatrix}</script><p>则有：</p><script type="math/tex; mode=display">X_n=X_{n−1}×A</script><p>所以：</p><script type="math/tex; mode=display">X_n=X_1×A^{n−1}</script><p>由于矩阵具有结合律，所以我们可以先求出 <code>A^{n−1}%P</code>，然后再用 <code>X_1</code> 左乘，即可求出 <code>X_n</code>，向量 <code>X_n</code> 的第一个元素就是 <code>a_n</code>。时间复杂度分析：快速幂的时间复杂度是 <code>O(logn)</code>，所以算法<code>5</code>的时间复杂度也是 <code>O(logn)</code>。</p><figure class="highlight c++"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstring&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;ctime&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> MOD = <span class="number">1000000007</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">mul</span><span class="params">(<span class="type">int</span> a[][<span class="number">2</span>], <span class="type">int</span> b[][<span class="number">2</span>], <span class="type">int</span> c[][<span class="number">2</span>])</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="type">int</span> temp[][<span class="number">2</span>] = {{<span class="number">0</span>, <span class="number">0</span>}, {<span class="number">0</span>, <span class="number">0</span>}};</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">2</span>; i ++ )</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; <span class="number">2</span>; j ++ )</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> k = <span class="number">0</span>; k &lt; <span class="number">2</span>; k ++ )</span><br><span class="line">            {</span><br><span class="line">                <span class="type">long</span> <span class="type">long</span> x = temp[i][j] + (<span class="type">long</span> <span class="type">long</span>)a[i][k] * b[k][j];</span><br><span class="line">                temp[i][j] = x % MOD;</span><br><span class="line">            }</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">2</span>; i ++ )</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; <span class="number">2</span>; j ++ )</span><br><span class="line">            c[i][j] = temp[i][j];</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">f_final</span><span class="params">(<span class="type">long</span> <span class="type">long</span> n)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="type">int</span> x[<span class="number">2</span>] = {<span class="number">1</span>, <span class="number">1</span>};</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> res[][<span class="number">2</span>] = {{<span class="number">1</span>, <span class="number">0</span>}, {<span class="number">0</span>, <span class="number">1</span>}};</span><br><span class="line">    <span class="type">int</span> t[][<span class="number">2</span>] = {{<span class="number">1</span>, <span class="number">1</span>}, {<span class="number">1</span>, <span class="number">0</span>}};</span><br><span class="line">    <span class="type">long</span> <span class="type">long</span> k = n - <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span> (k)</span><br><span class="line">    {</span><br><span class="line">        <span class="keyword">if</span> (k&amp;<span class="number">1</span>) <span class="built_in">mul</span>(res, t, res);</span><br><span class="line">        <span class="built_in">mul</span>(t, t, t);</span><br><span class="line">        k &gt;&gt;= <span class="number">1</span>;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> c[<span class="number">2</span>] = {<span class="number">0</span>, <span class="number">0</span>};</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">2</span>; i ++ )</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; <span class="number">2</span>; j ++ )</span><br><span class="line">        {</span><br><span class="line">            <span class="type">long</span> <span class="type">long</span> r = c[i] + (<span class="type">long</span> <span class="type">long</span>)x[j] * res[j][i];</span><br><span class="line">            c[i] = r % MOD;</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> c[<span class="number">0</span>];</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="type">long</span> <span class="type">long</span> n ;</span><br><span class="line"></span><br><span class="line">    cin &gt;&gt; n;</span><br><span class="line">    cout &lt;&lt; <span class="built_in">f_final</span>(n) &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> 斐波那契数列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数论问题模板</title>
      <link href="/2022/03/26/basic-algorithm/shu-lun-wen-ti-suan-fa/"/>
      <url>/2022/03/26/basic-algorithm/shu-lun-wen-ti-suan-fa/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="数论问题算法模板">数论问题算法模板</span></h1><h2><span id="1-欧几里得算法">1. 欧几里得算法</span></h2><p>求两个正整数的最大公约数，时间复杂度 <code>O(logn)</code>。计算<code>(a, b)</code>， 若<code>b</code>是0，则最大公约数为<code>a</code>；否则。将<code>a</code>除以<code>b</code>得到余数<code>r</code>，<code>a</code>和<code>b</code>的最大公约数就是<code>b</code>和<code>r</code>的最大公约数，即：<code>(a, b) = (b, r)</code></p><figure class="highlight c++"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">gcd</span><span class="params">(<span class="type">int</span> a, <span class="type">int</span> b)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="keyword">return</span> b ? <span class="built_in">gcd</span>(b, a % b) : a;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>最小公倍数求法</p><figure class="highlight c++"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">lcm</span><span class="params">(<span class="type">int</span> a ,<span class="type">int</span> b)</span></span>{</span><br><span class="line">      <span class="keyword">return</span> a*b / <span class="built_in">gcd</span>(b, a % b);</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h2><span id="2-扩展欧几里得算法">2. 扩展欧几里得算法</span></h2><p>裴蜀定理：若 <code>a,b</code> 是整数,且 <code>(a,b) = d</code>，那么对于任意的整数 <code>x,y,ax + by</code> 都一定是 <code>d</code> 的倍数，特别地，一定存在整数 <code>x,y</code>，使<code>ax + by = d</code> 成立。扩展欧几里得算法可以在 <code>O(logn)</code>的时间复杂度内求出系数 <code>x,y</code>。</p><figure class="highlight c++"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">exgcd</span><span class="params">(<span class="type">int</span> a, <span class="type">int</span> b, <span class="type">int</span> &amp;x, <span class="type">int</span> &amp;y)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="keyword">if</span> (!b)</span><br><span class="line">    {</span><br><span class="line">        x = <span class="number">1</span>; y = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">return</span> a;</span><br><span class="line">    }</span><br><span class="line">    <span class="type">int</span> d = <span class="built_in">exgcd</span>(b, a % b, y, x);</span><br><span class="line">    y -= (a/b) * x;</span><br><span class="line">    <span class="keyword">return</span> d;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h2><span id="3-线性筛素数">3. 线性筛素数</span></h2><p>可以在 <code>O(n)</code>的时间复杂度内求出 <code>1∼n</code>之间的所有质数。</p><figure class="highlight c++"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> primes[N], cnt;</span><br><span class="line"><span class="type">bool</span> st[N];</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">get_primes</span><span class="params">(<span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">2</span>; i &lt;= n; i ++ )</span><br><span class="line">    {</span><br><span class="line">        <span class="keyword">if</span> (!st[i]) primes[cnt ++ ] = i;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; primes[j] &lt;= n / i; j ++ )</span><br><span class="line">        {</span><br><span class="line">            st[primes[j] * i] = <span class="literal">true</span>;</span><br><span class="line">            <span class="keyword">if</span> (i % primes[j] == <span class="number">0</span>) <span class="keyword">break</span>;</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h2><span id="4-欧拉函数">4. 欧拉函数</span></h2><p>欧拉函数，一般记为 <code>ϕ(n)</code>，表示小于等于 <code>n</code> 的数中与 <code>n</code> 互质的数的个数。如果 <code>n=p1^a1 × p2^a2 × … × pm^am</code>,<br>则 <code>ϕ(n)=n(1 − 1/p1) … (1 − 1/pm)</code>.</p><p><strong>欧拉函数的常用性质：</strong></p><ul><li>如果 <code>n,m</code> 互质，则 <code>ϕ(nm)=ϕ(n)ϕ(m)</code>;</li><li>小于等于 <code>n</code>，且与 <code>n</code> 互质的数的和是 <code>ϕ(n) × n/2</code>;</li><li>欧拉定理：如果 <code>n,a</code> 互质，且均为正整数，则 <code>a^ϕ(n)≡1(mod n)</code>;</li></ul><hr><p><strong>下面的代码可以在 <code>O(n)</code> 的时间复杂度内求出 <code>1∼n</code> 中所有数的欧拉函数：</strong></p><figure class="highlight c++"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> primes[N], euler[N], cnt;</span><br><span class="line"><span class="type">bool</span> st[N];</span><br><span class="line"></span><br><span class="line"><span class="comment">// 质数存在primes[]中，euler[i] 表示i的欧拉函数</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">get_eulers</span><span class="params">(<span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    euler[<span class="number">1</span>] = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">2</span>; i &lt;= n; i ++ )</span><br><span class="line">    {</span><br><span class="line">        <span class="keyword">if</span> (!st[i])</span><br><span class="line">        {</span><br><span class="line">            primes[cnt ++ ] = i;</span><br><span class="line">            euler[i] = i - <span class="number">1</span>;</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; primes[j] &lt;= n / i; j ++ )</span><br><span class="line">        {</span><br><span class="line">            st[primes[j] * i] = <span class="literal">true</span>;</span><br><span class="line">            <span class="keyword">if</span> (i % primes[j] == <span class="number">0</span>)</span><br><span class="line">            {</span><br><span class="line">                euler[i * primes[j]] = euler[i] * primes[j];</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            }</span><br><span class="line">            euler[i * primes[j]] = euler[i] * (primes[j] - <span class="number">1</span>);</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> 数论问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>双指针法解题模板</title>
      <link href="/2022/03/26/basic-algorithm/shuang-zhi-zhen-fa/"/>
      <url>/2022/03/26/basic-algorithm/shuang-zhi-zhen-fa/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="双指针法解题模板">双指针法解题模板</span></h1><p>存在两种情况：</p><ul><li>双指针从同一边根据某种规律进行移动；</li><li>双指针从两边开始向内移动根据某种规律。</li></ul><h2><span id="27-移除元素-情况二"> <strong>情况二</strong></span></h2><p>给你一个数组 <code>nums</code> 和一个值 <code>val</code>，你需要<strong>原地</strong>移除所有数值等于 <code>val</code> 的元素，并返回移除后数组的新长度。不要使用额外的数组空间，你必须仅使用 <code>O(1)</code> 额外空间并<strong>原地</strong>修改输入数组。元素的顺序可以改变。你不需要考虑数组中超出新长度后面的元素。</p><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="type">int</span> <span class="title function_">removeElement</span><span class="params">(<span class="type">int</span>[] nums, <span class="type">int</span> val)</span> {</span><br><span class="line">    <span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> <span class="number">0</span>; j &lt; nums.length; j++) {</span><br><span class="line">        <span class="keyword">if</span> (nums[j] != val) {</span><br><span class="line">            nums[i] = nums[j];</span><br><span class="line">            i++;</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> i;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h2><span id="11-盛最多水的容器-情况二"> <strong>情况二</strong></span></h2><p>给你 <code>n</code> 个非负整数 <code>a1，a2，...，an</code>，每个数代表坐标中的一个点 <code>(i, ai)</code>。在坐标内画 <code>n</code> 条垂直线，垂直线 <code>i</code> 的两个端点分别为 <code>(i, ai)</code>和<code>(i, 0)</code>。找出其中的两条线，使得它们与 <code>x</code> 轴共同构成的容器可以容纳最多的水。</p><p>解题思路：双指针，从两端触发，找规律，对短的一边进行移动。</p><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Solution</span> {</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">maxArea</span><span class="params">(<span class="type">int</span>[] height)</span> {</span><br><span class="line">        <span class="type">int</span> <span class="variable">l</span> <span class="operator">=</span> <span class="number">0</span>, r = height.length - <span class="number">1</span>;</span><br><span class="line">        <span class="type">int</span> <span class="variable">ans</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span> (l &lt; r) {</span><br><span class="line">            <span class="type">int</span> <span class="variable">area</span> <span class="operator">=</span> Math.min(height[l], height[r]) * (r - l);</span><br><span class="line">            ans = Math.max(ans, area);</span><br><span class="line">            <span class="keyword">if</span> (height[l] &lt;= height[r]) {</span><br><span class="line">                ++l;</span><br><span class="line">            }</span><br><span class="line">            <span class="keyword">else</span> {</span><br><span class="line">                --r;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> ans;</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> 双指针法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>翻转关联</title>
      <link href="/2022/03/25/basic-algorithm/fan-zhuan-guan-lian/"/>
      <url>/2022/03/25/basic-algorithm/fan-zhuan-guan-lian/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="翻转关联问题">翻转关联问题</span></h1><p>翻转某一个节点，其相邻节点发生翻转，由初始状态翻转为目标状态需要几步。</p><ul><li>关于翻转问题其每个节点最多翻转一次。</li><li>针对简单翻转问题，考虑使用针对当前节点和最终状态节点情况判断，是否需要进行翻转。（适用于个别情况）</li></ul><h2><span id="例题1208-翻硬币">例题：<strong><a href="https://www.acwing.com/problem/content/1210/">1208. 翻硬币</a></strong></span></h2><blockquote><ol><li>翻硬币：<a href="https://www.acwing.com/problem/content/1210/">https://www.acwing.com/problem/content/1210/</a></li></ol></blockquote><p>小明正在玩一个“翻硬币”的游戏。桌上放着排成一排的若干硬币。我们用 * 表示正面，用 o 表示反面（是小写字母，不是零）。</p><p>比如，可能情形是：<code>**oo***oooo</code>，如果同时翻转左边的两个硬币，则变为：<code>oooo***oooo</code>。现在小明的问题是：如果已知了初始状态和要达到的目标状态，每次只能同时翻转相邻的两个硬币,那么对特定的局面，最少要翻动多少次呢？</p><p>我们约定：把翻动相邻的两个硬币叫做一步操作。</p><h3><span id="输入格式">输入格式</span></h3><p>两行等长的字符串，分别表示初始状态和要达到的目标状态。</p><h3><span id="输出格式">输出格式</span></h3><p>一个整数，表示最小操作步数</p><h3><span id="数据范围">数据范围</span></h3><p>输入字符串的长度均不超过100。数据保证答案一定有解。</p><p>解题：由于字符串长度不超过100，所以使用 <code>DFS</code> 会出现递归栈越界问题。所以考虑使用针对当前节点和最终状态节点情况判断，是否需要进行翻转。</p><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> {</span><br><span class="line">    <span class="type">Scanner</span> <span class="variable">scanner</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scanner</span>(System.in);</span><br><span class="line">    <span class="type">char</span>[] a = scanner.next().toCharArray();</span><br><span class="line">    <span class="type">char</span>[] b = scanner.next().toCharArray();</span><br><span class="line">    <span class="type">int</span> <span class="variable">res</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; a.length - <span class="number">1</span>; i++) {</span><br><span class="line">        <span class="keyword">if</span> (a[i] != b[i]) {</span><br><span class="line">            res++;</span><br><span class="line">            a[i] = a[i] == <span class="string">'*'</span>? <span class="string">'o'</span>: <span class="string">'*'</span>;</span><br><span class="line">            a[i + <span class="number">1</span>] = a[i + <span class="number">1</span>] == <span class="string">'*'</span>? <span class="string">'o'</span>: <span class="string">'*'</span>;</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">    System.out.println(res);</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> 翻转 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>二分查找模板</title>
      <link href="/2022/03/25/basic-algorithm/er-fen-cha-zhao/"/>
      <url>/2022/03/25/basic-algorithm/er-fen-cha-zhao/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="二分查找">二分查找</span></h1><p>二分模板一共有两个，分别适用于不同情况。<br>算法思路：假设目标值在闭区间[l, r]中， 每次将区间长度缩小一半，当l = r时，我们就找到了目标值。</p><p><strong>使用方法</strong>：一维数组，基于<code>index</code>的二分查找，基于<code>(nums[0], nums[n - 1])</code>的二分查找。</p><p>二维数组，使用方法一样，但是思路上是每次进行必要的函数<code>check(mid)</code>——需要自己编写。<a href="https://leetcode-cn.com/problems/kth-smallest-element-in-a-sorted-matrix/">378. 有序矩阵中第 K 小的元素</a></p><h2><span id="版本1">版本1</span></h2><p>当我们将区间<code>[l, r]</code>划分成<code>[l, mid]</code>和<code>[mid + 1, r]</code>时，其更新操作是<code>r = mid</code>或者<code>l = mid + 1</code>;，计算<code>mid</code>时不需要加1。</p><figure class="highlight c++"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">bsearch_1</span><span class="params">(<span class="type">int</span> l, <span class="type">int</span> r)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="keyword">while</span> (l &lt; r)</span><br><span class="line">    {</span><br><span class="line">        <span class="type">int</span> mid = l + r &gt;&gt; <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">check</span>(mid)) r = mid;</span><br><span class="line">        <span class="keyword">else</span> l = mid + <span class="number">1</span>;</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> l;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h2><span id="版本2">版本2</span></h2><p>当我们将区间<code>[l, r]</code>划分成<code>[l, mid - 1]</code>和<code>[mid, r]</code>时，其更新操作是<code>r = mid - 1</code>或者<code>l = mid</code>;，此时为了防止死循环，计算<code>mid</code>时需要加1。</p><figure class="highlight c++"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">bsearch_2</span><span class="params">(<span class="type">int</span> l, <span class="type">int</span> r)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="keyword">while</span> (l &lt; r)</span><br><span class="line">    {</span><br><span class="line">        <span class="type">int</span> mid = l + r + <span class="number">1</span> &gt;&gt; <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">check</span>(mid)) l = mid;</span><br><span class="line">        <span class="keyword">else</span> r = mid - <span class="number">1</span>;</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> l;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h3><span id="1-搜索插入位置">1. 搜索插入位置</span></h3><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="type">int</span> <span class="title function_">searchInsert</span><span class="params">(<span class="type">int</span>[] nums, <span class="type">int</span> target)</span> {</span><br><span class="line">    <span class="type">int</span> <span class="variable">n</span> <span class="operator">=</span> nums.length;</span><br><span class="line">    <span class="type">int</span> <span class="variable">left</span> <span class="operator">=</span> <span class="number">0</span>, right = n - <span class="number">1</span>, ans = n;</span><br><span class="line">    <span class="keyword">while</span> (left &lt;= right) {</span><br><span class="line">        <span class="type">int</span> <span class="variable">mid</span> <span class="operator">=</span> ((right - left) &gt;&gt; <span class="number">1</span>) + left;</span><br><span class="line">        <span class="keyword">if</span> (target &lt;= nums[mid]) {</span><br><span class="line">            ans = mid;</span><br><span class="line">            right = mid - <span class="number">1</span>;</span><br><span class="line">        } <span class="keyword">else</span> {</span><br><span class="line">            left = mid + <span class="number">1</span>;</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> ans;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><blockquote><p>注意：对连续的两个排列数组进行二分搜索</p></blockquote><h4><span id="题目搜索旋转排序数组">题目：搜索旋转排序数组</span></h4><p><a href="https://leetcode-cn.com/problems/search-in-rotated-sorted-array/">33. 搜索旋转排序数组</a>：<a href="https://leetcode-cn.com/problems/search-in-rotated-sorted-array/">https://leetcode-cn.com/problems/search-in-rotated-sorted-array/</a></p><p>升序排列的整数数组 <code>nums</code> 在预先未知的某个点上进行了旋转（例如，<code>[0,1,2,4,5,6,7]</code>经旋转后可能变为<code>[4,5,6,7,0,1,2]</code>）。</p><p>请你在数组中搜索<code>target</code>，如果数组中存在这个目标值，则返回它的索引，否则返回 <code>-1</code> 。</p><p>因为本题中每次循环判断条件以及更新l,r 与模板不同，所以循环终止条件不同。</p><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    def <span class="title function_">search</span><span class="params">(self, nums: List[<span class="type">int</span>], target: <span class="type">int</span>)</span> -&gt; <span class="type">int</span>:</span><br><span class="line">        n = len(nums)</span><br><span class="line">        <span class="type">if</span> <span class="variable">n</span> <span class="operator">=</span>= <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> -<span class="number">1</span></span><br><span class="line">        <span class="type">if</span> <span class="variable">n</span> <span class="operator">=</span>= <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span> <span class="keyword">if</span> nums[<span class="number">0</span>] == target <span class="keyword">else</span> -<span class="number">1</span></span><br><span class="line">        l, r = <span class="number">0</span>, n - <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> l &lt; r:</span><br><span class="line">            mid = (l + r) &gt;&gt; <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> nums[mid] == target:</span><br><span class="line">                <span class="keyword">return</span> mid</span><br><span class="line">            <span class="keyword">if</span> nums[<span class="number">0</span>] &lt;= nums[mid]:</span><br><span class="line">                <span class="keyword">if</span> nums[<span class="number">0</span>] &lt;= target &lt; nums[mid]:</span><br><span class="line">                    r = mid - <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    l = mid + <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">if</span> nums[mid] &lt; target &lt;= nums[n - <span class="number">1</span>]:</span><br><span class="line">                    l = mid + <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    r = mid - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span></span><br></pre></td></tr></tbody></table></figure><h3><span id="2-两数相除">2. 两数相除</span></h3><h4><span id="题目两数相除">题目：两数相除</span></h4><p> <a href="https://leetcode-cn.com/problems/divide-two-integers/">29. 两数相除</a>：<a href="https://leetcode-cn.com/problems/divide-two-integers/">https://leetcode-cn.com/problems/divide-two-integers/</a></p><p>给定两个整数，被除数 <code>dividend</code> 和除数 <code>divisor</code>。将两数相除，要求不使用乘法、除法和 <code>mod</code> 运算符。返回被除数 <code>dividend</code> 除以除数 <code>divisor</code> 得到的商。整数除法的结果应当截去（<code>truncate</code>）其小数部分，例如：<code>truncate(8.345) = 8 以及 truncate(-2.7335) = -2</code>。</p><p><strong>解题思路</strong>：二分 + 倍增乘法解法，首先判断是否存在负数，先进行取符号，然后正数进行运算。二分法取值范围为<code>[0, dividend]</code>。需要考虑三种特殊情况：</p><ol><li>被除数最小值的情况；</li><li>除数最小值的情况；</li><li>被除数为0的情况</li></ol><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    def <span class="title function_">divide</span><span class="params">(self, dividend: <span class="type">int</span>, divisor: <span class="type">int</span>)</span> -&gt; <span class="type">int</span>:</span><br><span class="line">        def <span class="title function_">mul</span><span class="params">(a, b)</span>:</span><br><span class="line">            ans = <span class="number">0</span></span><br><span class="line">            <span class="keyword">while</span> b:</span><br><span class="line">                <span class="keyword">if</span> b &amp; <span class="number">1</span> == <span class="number">1</span>:</span><br><span class="line">                    ans += a</span><br><span class="line">                b &gt;&gt;= <span class="number">1</span></span><br><span class="line">                a += a</span><br><span class="line">            <span class="keyword">return</span> ans</span><br><span class="line"></span><br><span class="line">        INT_MIN, INT_MAX = -<span class="number">2</span>**<span class="number">31</span>, <span class="number">2</span>**<span class="number">31</span> - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        # 考虑被除数为最小值的情况</span><br><span class="line">        <span class="type">if</span> <span class="variable">dividend</span> <span class="operator">=</span>= INT_MIN:</span><br><span class="line">            <span class="type">if</span> <span class="variable">divisor</span> <span class="operator">=</span>= <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">return</span> INT_MIN</span><br><span class="line">            <span class="type">if</span> <span class="variable">divisor</span> <span class="operator">=</span>= -<span class="number">1</span>:</span><br><span class="line"># 溢出返回最大值</span><br><span class="line">                <span class="keyword">return</span> INT_MAX</span><br><span class="line">        </span><br><span class="line">        # 考虑除数为最小值的情况</span><br><span class="line">        <span class="type">if</span> <span class="variable">divisor</span> <span class="operator">=</span>= INT_MIN:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span> <span class="type">if</span> <span class="variable">dividend</span> <span class="operator">=</span>= INT_MIN <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">        # 考虑被除数为 <span class="number">0</span> 的情况</span><br><span class="line">        <span class="type">if</span> <span class="variable">dividend</span> <span class="operator">=</span>= <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        is_neg = True <span class="title function_">if</span> <span class="params">((dividend &gt; <span class="number">0</span> and divisor &lt; <span class="number">0</span>)</span> or (dividend &lt; <span class="number">0</span> and divisor &gt; <span class="number">0</span>)) <span class="keyword">else</span> <span class="type">False</span></span><br><span class="line">        <span class="variable">dividend</span> <span class="operator">=</span> -dividend <span class="keyword">if</span> dividend &lt; <span class="number">0</span> <span class="keyword">else</span> <span class="type">dividend</span></span><br><span class="line">        <span class="variable">divisor</span> <span class="operator">=</span> -divisor <span class="keyword">if</span> divisor &lt; <span class="number">0</span> <span class="keyword">else</span> divisor</span><br><span class="line"></span><br><span class="line">        l, r = <span class="number">0</span>, dividend</span><br><span class="line">        <span class="keyword">while</span> l &lt; r:</span><br><span class="line">            mid = (l + r) &gt;&gt; <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> <span class="title function_">mul</span><span class="params">(mid, divisor)</span> &gt;= dividend:</span><br><span class="line">                r = mid</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                l = mid + <span class="number">1</span></span><br><span class="line">        l = (l - <span class="number">1</span>) <span class="keyword">if</span> <span class="title function_">mul</span><span class="params">(l, divisor)</span> &gt; dividend <span class="keyword">else</span> <span class="type">l</span></span><br><span class="line">        <span class="variable">ans</span> <span class="operator">=</span> -l <span class="keyword">if</span> is_neg <span class="keyword">else</span> l</span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></tbody></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> 二分查找 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
